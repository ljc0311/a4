#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½åŸºå‡†æµ‹è¯•
å¯¹æ¯”ä¼˜åŒ–å‰åçš„æ€§èƒ½å·®å¼‚
"""

import asyncio
import time
import sys
import os
import statistics
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.utils.memory_optimizer import memory_manager, image_memory_manager
from src.utils.async_task_manager import task_manager, create_task
from src.utils.logger import logger

class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.results = {}
    
    async def benchmark_memory_management(self, iterations: int = 5) -> Dict[str, Any]:
        """åŸºå‡†æµ‹è¯•å†…å­˜ç®¡ç†"""
        print(f"ğŸ§  å†…å­˜ç®¡ç†åŸºå‡†æµ‹è¯• ({iterations} æ¬¡è¿­ä»£)...")
        
        memory_usage = []
        cleanup_times = []
        
        for i in range(iterations):
            # åˆ›å»ºæµ‹è¯•å¯¹è±¡
            class TestObject:
                def __init__(self, size):
                    self.data = bytearray(size)
            
            objects = []
            start_memory = memory_manager.get_memory_stats().rss_mb
            
            # åˆ›å»ºå¤§é‡å¯¹è±¡
            for j in range(200):
                obj = TestObject(1024 * 100)  # 100KB
                objects.append(obj)
                memory_manager.register_object("benchmark", obj)
            
            peak_memory = memory_manager.get_memory_stats().rss_mb
            memory_usage.append(peak_memory - start_memory)
            
            # æµ‹è¯•æ¸…ç†æ—¶é—´
            start_time = time.time()
            memory_manager.force_cleanup()
            objects.clear()
            cleanup_time = time.time() - start_time
            cleanup_times.append(cleanup_time)
            
            await asyncio.sleep(0.1)  # çŸ­æš‚ä¼‘æ¯
        
        return {
            'avg_memory_usage_mb': statistics.mean(memory_usage),
            'max_memory_usage_mb': max(memory_usage),
            'avg_cleanup_time_s': statistics.mean(cleanup_times),
            'max_cleanup_time_s': max(cleanup_times)
        }
    
    async def benchmark_image_cache(self, iterations: int = 3) -> Dict[str, Any]:
        """åŸºå‡†æµ‹è¯•å›¾åƒç¼“å­˜"""
        print(f"ğŸ–¼ï¸ å›¾åƒç¼“å­˜åŸºå‡†æµ‹è¯• ({iterations} æ¬¡è¿­ä»£)...")
        
        cache_times = []
        retrieval_times = []
        
        for i in range(iterations):
            # æµ‹è¯•ç¼“å­˜æ€§èƒ½
            start_time = time.time()
            
            for j in range(50):
                image_data = b"test_image_data" * 1000 * (j + 1)
                key = f"benchmark_image_{i}_{j}"
                image_memory_manager.add_image_to_cache(key, image_data)
            
            cache_time = time.time() - start_time
            cache_times.append(cache_time)
            
            # æµ‹è¯•æ£€ç´¢æ€§èƒ½
            start_time = time.time()
            
            for j in range(50):
                key = f"benchmark_image_{i}_{j}"
                image_memory_manager.get_image_from_cache(key)
            
            retrieval_time = time.time() - start_time
            retrieval_times.append(retrieval_time)
            
            # æ¸…ç†ç¼“å­˜
            image_memory_manager.clear_image_cache()
        
        avg_cache_time = statistics.mean(cache_times)
        avg_retrieval_time = statistics.mean(retrieval_times)
        
        return {
            'avg_cache_time_s': avg_cache_time,
            'avg_retrieval_time_s': avg_retrieval_time,
            'cache_throughput_items_per_s': 50 / avg_cache_time if avg_cache_time > 0 else 0,
            'retrieval_throughput_items_per_s': 50 / avg_retrieval_time if avg_retrieval_time > 0 else 0
        }
    
    async def benchmark_async_tasks(self, iterations: int = 3) -> Dict[str, Any]:
        """åŸºå‡†æµ‹è¯•å¼‚æ­¥ä»»åŠ¡ç®¡ç†"""
        print(f"âš¡ å¼‚æ­¥ä»»åŠ¡ç®¡ç†åŸºå‡†æµ‹è¯• ({iterations} æ¬¡è¿­ä»£)...")
        
        async def test_task(duration: float):
            await asyncio.sleep(duration)
            return f"Task completed in {duration}s"
        
        creation_times = []
        execution_times = []
        
        for i in range(iterations):
            # æµ‹è¯•ä»»åŠ¡åˆ›å»ºæ€§èƒ½
            start_time = time.time()
            
            task_ids = []
            for j in range(20):
                task_id = create_task(
                    test_task(0.1), 
                    name=f"BenchmarkTask_{i}_{j}"
                )
                task_ids.append(task_id)
            
            creation_time = time.time() - start_time
            creation_times.append(creation_time)
            
            # æµ‹è¯•ä»»åŠ¡æ‰§è¡Œæ€§èƒ½
            start_time = time.time()
            
            for task_id in task_ids:
                await task_manager.wait_for_task(task_id)
            
            execution_time = time.time() - start_time
            execution_times.append(execution_time)
        
        avg_creation_time = statistics.mean(creation_times)
        avg_execution_time = statistics.mean(execution_times)
        
        return {
            'avg_creation_time_s': avg_creation_time,
            'avg_execution_time_s': avg_execution_time,
            'task_creation_rate_per_s': 20 / avg_creation_time if avg_creation_time > 0 else 0,
            'task_completion_rate_per_s': 20 / avg_execution_time if avg_execution_time > 0 else 0
        }
    
    async def benchmark_concurrent_processing(self) -> Dict[str, Any]:
        """åŸºå‡†æµ‹è¯•å¹¶å‘å¤„ç†"""
        print("ğŸš€ å¹¶å‘å¤„ç†åŸºå‡†æµ‹è¯•...")
        
        async def cpu_task(n: int):
            """CPUå¯†é›†å‹ä»»åŠ¡"""
            result = 0
            for i in range(n * 5000):
                result += i * i
            return result
        
        # æµ‹è¯•ä¸åŒå¹¶å‘çº§åˆ«
        concurrency_levels = [1, 2, 5, 10]
        results = {}
        
        for concurrency in concurrency_levels:
            times = []
            
            for _ in range(3):  # æ¯ä¸ªå¹¶å‘çº§åˆ«æµ‹è¯•3æ¬¡
                start_time = time.time()
                
                task_ids = []
                for i in range(concurrency):
                    task_id = create_task(
                        cpu_task(100), 
                        name=f"ConcurrentTask_{concurrency}_{i}"
                    )
                    task_ids.append(task_id)
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                for task_id in task_ids:
                    await task_manager.wait_for_task(task_id)
                
                execution_time = time.time() - start_time
                times.append(execution_time)
            
            results[f'concurrency_{concurrency}'] = {
                'avg_time_s': statistics.mean(times),
                'min_time_s': min(times),
                'max_time_s': max(times)
            }
        
        return results
    
    async def run_full_benchmark(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´åŸºå‡†æµ‹è¯•"""
        print("ğŸ¯ å¼€å§‹å®Œæ•´æ€§èƒ½åŸºå‡†æµ‹è¯•\n")
        
        # è·å–åˆå§‹ç³»ç»ŸçŠ¶æ€
        initial_stats = memory_manager.get_memory_stats()
        start_time = time.time()
        
        # è¿è¡Œå„é¡¹åŸºå‡†æµ‹è¯•
        self.results['memory_management'] = await self.benchmark_memory_management()
        self.results['image_cache'] = await self.benchmark_image_cache()
        self.results['async_tasks'] = await self.benchmark_async_tasks()
        self.results['concurrent_processing'] = await self.benchmark_concurrent_processing()
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_time = time.time() - start_time
        final_stats = memory_manager.get_memory_stats()
        
        self.results['overall'] = {
            'total_benchmark_time_s': total_time,
            'initial_memory_mb': initial_stats.rss_mb,
            'final_memory_mb': final_stats.rss_mb,
            'memory_delta_mb': final_stats.rss_mb - initial_stats.rss_mb,
            'task_stats': task_manager.get_task_stats()
        }
        
        return self.results
    
    def print_results(self):
        """æ‰“å°åŸºå‡†æµ‹è¯•ç»“æœ"""
        print("\n" + "="*60)
        print("ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ")
        print("="*60)
        
        # å†…å­˜ç®¡ç†ç»“æœ
        mem_results = self.results['memory_management']
        print(f"\nğŸ§  å†…å­˜ç®¡ç†æ€§èƒ½:")
        print(f"  å¹³å‡å†…å­˜ä½¿ç”¨: {mem_results['avg_memory_usage_mb']:.1f}MB")
        print(f"  å³°å€¼å†…å­˜ä½¿ç”¨: {mem_results['max_memory_usage_mb']:.1f}MB")
        print(f"  å¹³å‡æ¸…ç†æ—¶é—´: {mem_results['avg_cleanup_time_s']:.3f}s")
        print(f"  æœ€å¤§æ¸…ç†æ—¶é—´: {mem_results['max_cleanup_time_s']:.3f}s")
        
        # å›¾åƒç¼“å­˜ç»“æœ
        cache_results = self.results['image_cache']
        print(f"\nğŸ–¼ï¸ å›¾åƒç¼“å­˜æ€§èƒ½:")
        print(f"  å¹³å‡ç¼“å­˜æ—¶é—´: {cache_results['avg_cache_time_s']:.3f}s")
        print(f"  å¹³å‡æ£€ç´¢æ—¶é—´: {cache_results['avg_retrieval_time_s']:.3f}s")
        print(f"  ç¼“å­˜ååé‡: {cache_results['cache_throughput_items_per_s']:.1f} é¡¹/ç§’")
        print(f"  æ£€ç´¢ååé‡: {cache_results['retrieval_throughput_items_per_s']:.1f} é¡¹/ç§’")
        
        # å¼‚æ­¥ä»»åŠ¡ç»“æœ
        task_results = self.results['async_tasks']
        print(f"\nâš¡ å¼‚æ­¥ä»»åŠ¡æ€§èƒ½:")
        print(f"  å¹³å‡åˆ›å»ºæ—¶é—´: {task_results['avg_creation_time_s']:.3f}s")
        print(f"  å¹³å‡æ‰§è¡Œæ—¶é—´: {task_results['avg_execution_time_s']:.3f}s")
        print(f"  ä»»åŠ¡åˆ›å»ºé€Ÿç‡: {task_results['task_creation_rate_per_s']:.1f} ä»»åŠ¡/ç§’")
        print(f"  ä»»åŠ¡å®Œæˆé€Ÿç‡: {task_results['task_completion_rate_per_s']:.1f} ä»»åŠ¡/ç§’")
        
        # å¹¶å‘å¤„ç†ç»“æœ
        concurrent_results = self.results['concurrent_processing']
        print(f"\nğŸš€ å¹¶å‘å¤„ç†æ€§èƒ½:")
        for level, data in concurrent_results.items():
            concurrency = level.split('_')[1]
            print(f"  å¹¶å‘çº§åˆ« {concurrency}: å¹³å‡ {data['avg_time_s']:.3f}s, "
                  f"æœ€å° {data['min_time_s']:.3f}s, æœ€å¤§ {data['max_time_s']:.3f}s")
        
        # æ€»ä½“ç»“æœ
        overall = self.results['overall']
        print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"  åŸºå‡†æµ‹è¯•æ€»æ—¶é—´: {overall['total_benchmark_time_s']:.2f}s")
        print(f"  åˆå§‹å†…å­˜: {overall['initial_memory_mb']:.1f}MB")
        print(f"  æœ€ç»ˆå†…å­˜: {overall['final_memory_mb']:.1f}MB")
        print(f"  å†…å­˜å˜åŒ–: {overall['memory_delta_mb']:+.1f}MB")
        print(f"  ä»»åŠ¡æˆåŠŸç‡: {overall['task_stats']['success_rate']:.1%}")
        
        print("\n" + "="*60)

async def main():
    """ä¸»å‡½æ•°"""
    benchmark = PerformanceBenchmark()
    
    try:
        await benchmark.run_full_benchmark()
        benchmark.print_results()
        
        print("\nğŸ‰ åŸºå‡†æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # æ¸…ç†èµ„æº
        task_manager.shutdown()
        memory_manager.stop_monitoring()

if __name__ == "__main__":
    asyncio.run(main())