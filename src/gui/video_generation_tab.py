# -*- coding: utf-8 -*-
"""
è§†é¢‘ç”Ÿæˆæ ‡ç­¾é¡µ
ç”¨äºå°†é…éŸ³ã€å›¾åƒç­‰æ•°æ®ä¼ é€’åˆ°è§†é¢‘ç”Ÿæˆç•Œé¢ï¼Œè¿›è¡Œè§†é¢‘ç”Ÿæˆæ“ä½œ
"""

import os
import json
import asyncio
import time
from typing import Dict, List, Optional
from PyQt5.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton, QTableWidget,
    QTableWidgetItem, QComboBox, QFormLayout, QGroupBox, QMessageBox,
    QProgressBar, QTextEdit, QSpinBox, QDoubleSpinBox, QCheckBox, QFrame,
    QSplitter, QHeaderView, QAbstractItemView, QSlider
)
from PyQt5.QtCore import Qt, QThread, pyqtSignal, QTimer
from PyQt5.QtGui import QFont, QPixmap

from src.utils.logger import logger
from src.utils.project_manager import StoryboardProjectManager
from src.utils.shot_id_manager import ShotIDManager, ShotMapping


class VideoGenerationWorker(QThread):
    """è§†é¢‘ç”Ÿæˆå·¥ä½œçº¿ç¨‹"""
    
    progress_updated = pyqtSignal(int, str)  # è¿›åº¦, æ¶ˆæ¯
    video_generated = pyqtSignal(str, bool, str)  # è§†é¢‘è·¯å¾„, æˆåŠŸçŠ¶æ€, é”™è¯¯ä¿¡æ¯
    
    def __init__(self, scene_data, generation_config, project_manager, project_name):
        super().__init__()
        self.scene_data = scene_data
        self.generation_config = generation_config
        self.project_manager = project_manager
        self.project_name = project_name
        self.is_cancelled = False
        self._current_loop = None  # ä¿å­˜å½“å‰äº‹ä»¶å¾ªç¯å¼•ç”¨

    def cancel(self):
        """å–æ¶ˆä»»åŠ¡"""
        self.is_cancelled = True
        logger.info("è§†é¢‘ç”Ÿæˆä»»åŠ¡å·²æ ‡è®°ä¸ºå–æ¶ˆ")

        # å¦‚æœæœ‰æ­£åœ¨è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œå°è¯•å–æ¶ˆå…¶ä¸­çš„ä»»åŠ¡
        if self._current_loop and not self._current_loop.is_closed():
            try:
                # è·å–å¾ªç¯ä¸­çš„æ‰€æœ‰ä»»åŠ¡å¹¶å–æ¶ˆ
                pending_tasks = [task for task in asyncio.all_tasks(self._current_loop)
                               if not task.done()]
                for task in pending_tasks:
                    task.cancel()
                logger.info(f"å·²å–æ¶ˆ {len(pending_tasks)} ä¸ªå¼‚æ­¥ä»»åŠ¡")
            except Exception as e:
                logger.warning(f"å–æ¶ˆå¼‚æ­¥ä»»åŠ¡æ—¶å‡ºé”™: {e}")

    def run(self):
        """è¿è¡Œè§†é¢‘ç”Ÿæˆï¼ˆä¿®å¤Event loopé—®é¢˜ï¼‰"""
        loop = None
        try:
            # æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self.is_cancelled:
                logger.info("ä»»åŠ¡åœ¨å¯åŠ¨å‰å·²è¢«å–æ¶ˆ")
                self.video_generated.emit("", False, "ä»»åŠ¡å·²å–æ¶ˆ")
                return

            # ç¡®ä¿åœ¨æ–°çº¿ç¨‹ä¸­åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            try:
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰äº‹ä»¶å¾ªç¯
                existing_loop = asyncio.get_event_loop()
                if existing_loop and not existing_loop.is_closed():
                    existing_loop.close()
            except RuntimeError:
                # æ²¡æœ‰ç°æœ‰å¾ªç¯ï¼Œè¿™æ˜¯æ­£å¸¸çš„
                pass

            # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            self._current_loop = loop  # ä¿å­˜å¾ªç¯å¼•ç”¨

            # è¿è¡Œå¼‚æ­¥ç”Ÿæˆ
            result = loop.run_until_complete(self._generate_video_async())

            if result and result.success:
                self.video_generated.emit(result.video_path, True, "")
            else:
                error_msg = result.error_message if result else "æœªçŸ¥é”™è¯¯"
                self.video_generated.emit("", False, error_msg)

        except asyncio.CancelledError:
            logger.warning("è§†é¢‘ç”Ÿæˆä»»åŠ¡è¢«å–æ¶ˆ")
            self.video_generated.emit("", False, "è§†é¢‘ç”Ÿæˆä»»åŠ¡è¢«å–æ¶ˆï¼Œè¯·é‡è¯•")
        except Exception as e:
            logger.error(f"è§†é¢‘ç”Ÿæˆçº¿ç¨‹å¼‚å¸¸: {e}")
            # æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            if "CancelledError" in str(e):
                error_msg = "è§†é¢‘ç”Ÿæˆä»»åŠ¡è¢«å–æ¶ˆï¼Œè¯·é‡è¯•"
            elif "504" in str(e):
                error_msg = "æœåŠ¡å™¨å“åº”è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
            elif "timeout" in str(e).lower():
                error_msg = "ç½‘ç»œè¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•"
            elif "different loop" in str(e):
                error_msg = "äº‹ä»¶å¾ªç¯å†²çªï¼Œè¯·é‡è¯•"
            else:
                error_msg = str(e)
            self.video_generated.emit("", False, error_msg)
        finally:
            # å®‰å…¨å…³é—­äº‹ä»¶å¾ªç¯
            if 'loop' in locals() and loop and not loop.is_closed():
                try:
                    # å–æ¶ˆæ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
                    try:
                        pending = asyncio.all_tasks(loop)
                        if pending:
                            for task in pending:
                                if not task.done():
                                    task.cancel()

                            # ç­‰å¾…ä»»åŠ¡å–æ¶ˆå®Œæˆï¼Œè®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´
                            try:
                                loop.run_until_complete(
                                    asyncio.wait_for(
                                        asyncio.gather(*pending, return_exceptions=True),
                                        timeout=5.0
                                    )
                                )
                            except asyncio.TimeoutError:
                                logger.warning("ç­‰å¾…ä»»åŠ¡å–æ¶ˆè¶…æ—¶ï¼Œå¼ºåˆ¶å…³é—­")
                            except Exception as gather_error:
                                logger.warning(f"ç­‰å¾…ä»»åŠ¡å–æ¶ˆæ—¶å‡ºé”™: {gather_error}")
                    except Exception as task_error:
                        logger.warning(f"å¤„ç†æœªå®Œæˆä»»åŠ¡æ—¶å‡ºé”™: {task_error}")

                    # å…³é—­äº‹ä»¶å¾ªç¯
                    loop.close()
                except Exception as cleanup_error:
                    logger.warning(f"å…³é—­äº‹ä»¶å¾ªç¯æ—¶å‡ºé”™: {cleanup_error}")
                finally:
                    # ç¡®ä¿æ¸…ç†äº‹ä»¶å¾ªç¯å¼•ç”¨
                    try:
                        asyncio.set_event_loop(None)
                    except Exception:
                        pass
    
    async def _generate_video_async(self):
        """å¼‚æ­¥ç”Ÿæˆè§†é¢‘"""
        # å®šä¹‰ç»“æœç±»
        class Result:
            def __init__(self, success, video_path="", error_message=""):
                self.success = success
                self.video_path = video_path
                self.error_message = error_message

        try:
            # æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self.is_cancelled:
                logger.info("å¼‚æ­¥ä»»åŠ¡åœ¨å¼€å§‹å‰å·²è¢«å–æ¶ˆ")
                return Result(False, "", "ä»»åŠ¡å·²å–æ¶ˆ")

            from src.processors.video_processor import VideoProcessor
            from src.core.service_manager import ServiceManager

            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å…±äº«çš„æœåŠ¡ç®¡ç†å™¨å®ä¾‹ï¼Œé¿å…å¼•æ“çŠ¶æ€å†²çª
            service_manager = ServiceManager()  # ServiceManagerå·²ç»æ˜¯å•ä¾‹
            processor = VideoProcessor(service_manager)

            # ğŸ”§ è°ƒè¯•ï¼šæ£€æŸ¥å¼•æ“çŠ¶æ€
            scene_id = self.scene_data.get('shot_id', 'unknown')
            logger.info(f"VideoGenerationWorkerå¯åŠ¨ - åœºæ™¯ID: {scene_id}")
            logger.info(f"ServiceManagerå®ä¾‹ID: {id(service_manager)}")

            # æ›´æ–°è¿›åº¦
            self.progress_updated.emit(10, "å‡†å¤‡è§†é¢‘ç”Ÿæˆ...")

            # ä»åœºæ™¯æ•°æ®ç”Ÿæˆè§†é¢‘
            image_path = self.scene_data.get('image_path', '')

            # è·å–æç¤ºè¯ - ä¼˜å…ˆä½¿ç”¨scene_dataä¸­çš„promptå­—æ®µ
            original_prompt = self.scene_data.get('prompt', '') or self._get_prompt_from_file() or self.scene_data.get('enhanced_description', self.scene_data.get('description', ''))

            # ä¼˜åŒ–æç¤ºè¯ä»¥é€‚åˆè§†é¢‘ç”Ÿæˆ
            shot_id = self.scene_data.get('shot_id', '')
            duration = self.generation_config.get('duration', 5.0)

            # è°ƒç”¨è§†é¢‘æç¤ºè¯ä¼˜åŒ–
            try:
                from src.processors.cogvideox_prompt_optimizer import CogVideoXPromptOptimizer
                optimizer = CogVideoXPromptOptimizer()
                shot_info = {'shot_type': 'medium_shot', 'camera_angle': 'eye_level', 'movement': 'static'}
                optimized_prompt = optimizer.optimize_for_video(original_prompt, shot_info, duration)
                logger.info(f"è§†é¢‘æç¤ºè¯ä¼˜åŒ–æˆåŠŸ: {original_prompt[:50]}... -> {optimized_prompt[:50]}...")
            except Exception as e:
                logger.warning(f"è§†é¢‘æç¤ºè¯ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æç¤ºè¯: {e}")
                optimized_prompt = original_prompt

            logger.info(f"è§†é¢‘ç”Ÿæˆæç¤ºè¯: {optimized_prompt}")

            if not image_path or not os.path.exists(image_path):
                raise Exception(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")

            # å†æ¬¡æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self.is_cancelled:
                logger.info("ä»»åŠ¡åœ¨è§†é¢‘ç”Ÿæˆå‰å·²è¢«å–æ¶ˆ")
                return Result(False, "", "ä»»åŠ¡å·²å–æ¶ˆ")

            self.progress_updated.emit(30, "å¼€å§‹ç”Ÿæˆè§†é¢‘...")

            # ç”Ÿæˆè§†é¢‘ï¼ˆä½¿ç”¨æ­£ç¡®çš„åˆ†è¾¨ç‡ï¼‰
            video_path = await processor.generate_video_from_image(
                image_path=image_path,
                prompt=optimized_prompt,
                duration=self.generation_config.get('duration', 5.0),
                fps=self.generation_config.get('fps', 30),  # ä½¿ç”¨CogVideoXæ”¯æŒçš„å¸§ç‡
                width=self.generation_config.get('width', 1024),
                height=self.generation_config.get('height', 1024),
                motion_intensity=self.generation_config.get('motion_intensity', 0.5),
                preferred_engine=self.generation_config.get('engine', 'cogvideox_flash'),
                progress_callback=lambda p, msg: self.progress_updated.emit(30 + int(p * 60), msg),
                project_manager=self.project_manager,
                current_project_name=self.project_name,
                max_concurrent_tasks=self.generation_config.get('max_concurrent_tasks', 3),  # ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„å¹¶å‘æ•°
                audio_hint=self.generation_config.get('audio_hint')  # ä¼ é€’éŸ³æ•ˆæç¤º
            )

            self.progress_updated.emit(100, "è§†é¢‘ç”Ÿæˆå®Œæˆ!")
            return Result(True, video_path)

        except Exception as e:
            logger.error(f"å¼‚æ­¥è§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            return Result(False, "", str(e))

    def _get_prompt_from_file(self):
        """ä»prompt.jsonæ–‡ä»¶è·å–æç¤ºè¯"""
        try:
            if not self.project_manager or not self.project_name:
                return None

            # è·å–é¡¹ç›®ç›®å½•
            project_data = self.project_manager.get_project_data()
            if not project_data:
                return None

            project_dir = project_data.get('project_dir', '')
            if not project_dir:
                return None

            # æ„å»ºprompt.jsonæ–‡ä»¶è·¯å¾„
            prompt_file = os.path.join(project_dir, 'texts', 'prompt.json')
            if not os.path.exists(prompt_file):
                logger.debug(f"prompt.jsonæ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
                return None

            # è¯»å–prompt.jsonæ–‡ä»¶
            import json
            with open(prompt_file, 'r', encoding='utf-8') as f:
                prompt_data = json.load(f)

            # è·å–å½“å‰é•œå¤´çš„shot_id
            shot_id = self.scene_data.get('shot_id', '')
            if not shot_id:
                return None

            # æŸ¥æ‰¾å¯¹åº”çš„æç¤ºè¯
            # prompt.jsonçš„ç»“æ„æ˜¯ {"scenes": {"åœºæ™¯å": [é•œå¤´æ•°ç»„]}}
            scenes_data = prompt_data.get('scenes', {})

            # æå–shot_idä¸­çš„æ•°å­—éƒ¨åˆ†
            shot_index = None
            if shot_id.startswith('text_segment_'):
                try:
                    shot_index = int(shot_id.replace('text_segment_', ''))
                except ValueError:
                    pass

            if shot_index is None:
                logger.debug(f"æ— æ³•ä»shot_id '{shot_id}' æå–ç´¢å¼•")
                return None

            # éå†æ‰€æœ‰åœºæ™¯ï¼Œæ‰¾åˆ°å¯¹åº”ç´¢å¼•çš„é•œå¤´
            current_index = 1
            for scene_name, shots in scenes_data.items():
                if isinstance(shots, list):
                    for shot in shots:
                        if current_index == shot_index:
                            content = shot.get('content', '')
                            if content:
                                logger.debug(f"ä»prompt.jsonè·å–é•œå¤´ {shot_id} (ç´¢å¼•{shot_index}) çš„æç¤ºè¯")
                                return content
                        current_index += 1

            logger.debug(f"åœ¨prompt.jsonä¸­æœªæ‰¾åˆ°é•œå¤´ {shot_id} çš„æç¤ºè¯")
            return None

        except Exception as e:
            logger.warning(f"ä»prompt.jsonè·å–æç¤ºè¯å¤±è´¥: {e}")
            return None
    
    def cancel(self):
        """å–æ¶ˆç”Ÿæˆ"""
        self.is_cancelled = True


class VideoGenerationTab(QWidget):
    """å›¾è½¬è§†é¢‘æ ‡ç­¾é¡µ - å°†å›¾ç‰‡è½¬æ¢ä¸ºè§†é¢‘ç‰‡æ®µ"""
    
    def __init__(self, app_controller, project_manager: StoryboardProjectManager, parent=None):
        super().__init__(parent)
        self.app_controller = app_controller
        self.project_manager = project_manager
        self.parent_window = parent
        
        # å½“å‰æ•°æ®
        self.current_scenes = []
        self.current_voices = []
        self.generation_queue = []
        self.current_worker = None

        # å¹¶å‘ç”Ÿæˆç®¡ç†
        self.active_workers = {}  # {scene_id: worker}
        self.max_concurrent_videos = 3  # é»˜è®¤å¹¶å‘æ•°ï¼Œä¼šæ ¹æ®ç”¨æˆ·è®¾ç½®åŠ¨æ€è°ƒæ•´

        # ğŸ”§ æ–°å¢ï¼šç»Ÿä¸€é•œå¤´IDç®¡ç†å™¨
        self.shot_id_manager = ShotIDManager()
        
        self.init_ui()
        self.load_project_data()

    def on_concurrent_changed(self, new_value):
        """å½“ç”¨æˆ·æ”¹å˜å¹¶å‘æ•°æ—¶çš„å¤„ç†"""
        try:
            new_concurrent = int(new_value)
            old_concurrent = self.max_concurrent_videos
            self.max_concurrent_videos = new_concurrent
            logger.info(f"ç”¨æˆ·è°ƒæ•´å¹¶å‘æ•°: {old_concurrent} -> {new_concurrent}")

            # å¦‚æœå½“å‰æœ‰æ´»è·ƒä»»åŠ¡ï¼Œæ˜¾ç¤ºæç¤º
            if self.active_workers:
                active_count = len(self.active_workers)
                if new_concurrent < active_count:
                    logger.warning(f"å½“å‰æœ‰ {active_count} ä¸ªæ´»è·ƒä»»åŠ¡ï¼Œæ–°å¹¶å‘æ•° {new_concurrent} å°†åœ¨ä¸‹æ¬¡ç”Ÿæˆæ—¶ç”Ÿæ•ˆ")
                elif new_concurrent > active_count and self.generation_queue:
                    logger.info(f"å¹¶å‘æ•°å¢åŠ ï¼Œå°†å¯åŠ¨æ›´å¤šä»»åŠ¡")
                    # å¦‚æœé˜Ÿåˆ—ä¸­è¿˜æœ‰ä»»åŠ¡ä¸”å¹¶å‘æ•°å¢åŠ ï¼Œå¯åŠ¨æ›´å¤šä»»åŠ¡
                    self.start_concurrent_generation()

        except ValueError:
            logger.error(f"æ— æ•ˆçš„å¹¶å‘æ•°: {new_value}")
        except Exception as e:
            logger.error(f"å¤„ç†å¹¶å‘æ•°å˜åŒ–æ—¶å‡ºé”™: {e}")

    def _optimize_prompt_for_cogvideox(self, original_prompt: str, shot_id: str = "", duration: float = 5.0) -> str:
        """ä½¿ç”¨CogVideoXä¼˜åŒ–å™¨ä¼˜åŒ–è§†é¢‘æç¤ºè¯"""
        try:
            from src.processors.cogvideox_prompt_optimizer import CogVideoXPromptOptimizer

            # åˆ›å»ºä¼˜åŒ–å™¨å®ä¾‹
            optimizer = CogVideoXPromptOptimizer()

            # è·å–é•œå¤´ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            shot_info = self._get_shot_technical_info(shot_id)

            # ä½¿ç”¨è§†é¢‘ä¸“ç”¨ä¼˜åŒ–æ–¹æ³•
            optimized = optimizer.optimize_for_video(original_prompt, shot_info, duration)

            logger.info(f"è§†é¢‘æç¤ºè¯ä¼˜åŒ–: {original_prompt[:50]}... -> {optimized[:50]}...")
            return optimized

        except Exception as e:
            logger.warning(f"è§†é¢‘æç¤ºè¯ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æç¤ºè¯: {e}")
            return original_prompt

    def _get_shot_technical_info(self, shot_id: str) -> Dict:
        """è·å–é•œå¤´çš„æŠ€æœ¯ä¿¡æ¯"""
        try:
            if not self.project_manager or not self.project_manager.current_project:
                return {}

            project_dir = self.project_manager.current_project.get('project_dir', '')
            if not project_dir:
                return {}

            # æ„å»ºprompt.jsonæ–‡ä»¶è·¯å¾„
            prompt_file = os.path.join(project_dir, 'texts', 'prompt.json')
            if not os.path.exists(prompt_file):
                return {}

            # è¯»å–prompt.jsonæ–‡ä»¶
            import json
            with open(prompt_file, 'r', encoding='utf-8') as f:
                prompt_data = json.load(f)

            # æŸ¥æ‰¾å¯¹åº”é•œå¤´çš„æŠ€æœ¯ä¿¡æ¯
            shot_index = None
            if shot_id.startswith('text_segment_'):
                try:
                    shot_index = int(shot_id.replace('text_segment_', ''))
                except ValueError:
                    return {}

            if shot_index is None:
                return {}

            # éå†æ‰¾åˆ°å¯¹åº”é•œå¤´
            current_index = 1
            for scene_name, shots in prompt_data.get('scenes', {}).items():
                if isinstance(shots, list):
                    for shot in shots:
                        if current_index == shot_index:
                            # ä»original_descriptionæå–æŠ€æœ¯ä¿¡æ¯
                            original_desc = shot.get('original_description', '')
                            return self._parse_technical_info(original_desc)
                        current_index += 1

            return {}

        except Exception as e:
            logger.warning(f"è·å–é•œå¤´æŠ€æœ¯ä¿¡æ¯å¤±è´¥: {e}")
            return {}

    def _parse_technical_info(self, description: str) -> Dict:
        """è§£ææŠ€æœ¯ä¿¡æ¯"""
        info = {}

        # è§£æé•œå¤´ç±»å‹
        if 'å…¨æ™¯' in description:
            info['shot_type'] = 'wide shot'
        elif 'ä¸­æ™¯' in description:
            info['shot_type'] = 'medium shot'
        elif 'ç‰¹å†™' in description:
            info['shot_type'] = 'close-up shot'

        # è§£ææœºä½è§’åº¦
        if 'å¹³è§†' in description:
            info['camera_angle'] = 'eye level'
        elif 'ä¿¯è§†' in description:
            info['camera_angle'] = 'high angle'
        elif 'ä»°è§†' in description:
            info['camera_angle'] = 'low angle'
        elif 'ä¾§é¢' in description:
            info['camera_angle'] = 'side angle'

        # è§£æé•œå¤´è¿åŠ¨
        if 'é™æ­¢' in description:
            info['camera_movement'] = 'static'
        elif 'æ¨è¿›' in description:
            info['camera_movement'] = 'dolly in'
        elif 'æ‹‰è¿œ' in description:
            info['camera_movement'] = 'dolly out'

        return info
    
    def init_ui(self):
        """åˆå§‹åŒ–UIç•Œé¢"""
        main_layout = QVBoxLayout()
        
        # æ ‡é¢˜åŒºåŸŸ
        title_layout = QHBoxLayout()
        title_label = QLabel("ğŸ¬ å›¾è½¬è§†é¢‘")
        title_label.setFont(QFont("Arial", 16, QFont.Weight.Bold))
        title_layout.addWidget(title_label)
        title_layout.addStretch()
        
        # åˆ·æ–°æŒ‰é’®
        refresh_btn = QPushButton("ğŸ”„ åˆ·æ–°æ•°æ®")
        refresh_btn.clicked.connect(self.load_project_data)
        refresh_btn.setToolTip("é‡æ–°åŠ è½½é¡¹ç›®ä¸­çš„é…éŸ³å’Œå›¾åƒæ•°æ®")
        title_layout.addWidget(refresh_btn)
        
        main_layout.addLayout(title_layout)
        
        # åˆ›å»ºåˆ†å‰²å™¨
        splitter = QSplitter(Qt.Orientation.Horizontal)
        
        # å·¦ä¾§ï¼šåœºæ™¯åˆ—è¡¨
        left_panel = self.create_scene_list_panel()
        splitter.addWidget(left_panel)
        
        # å³ä¾§ï¼šç”Ÿæˆæ§åˆ¶é¢æ¿
        right_panel = self.create_generation_control_panel()
        splitter.addWidget(right_panel)
        
        # è®¾ç½®åˆ†å‰²å™¨æ¯”ä¾‹
        splitter.setSizes([600, 400])
        main_layout.addWidget(splitter)
        
        # åº•éƒ¨ï¼šè¿›åº¦æ¡å’ŒçŠ¶æ€
        self.create_progress_area(main_layout)
        
        self.setLayout(main_layout)
    
    def create_scene_list_panel(self):
        """åˆ›å»ºåœºæ™¯åˆ—è¡¨é¢æ¿"""
        panel = QFrame()
        panel.setFrameStyle(QFrame.Shape.StyledPanel)
        layout = QVBoxLayout(panel)
        
        # æ ‡é¢˜
        title_label = QLabel("ğŸ“‹ é•œå¤´åˆ—è¡¨")
        title_label.setFont(QFont("Arial", 12, QFont.Weight.Bold))
        layout.addWidget(title_label)
        
        # åœºæ™¯è¡¨æ ¼
        self.scene_table = QTableWidget()
        self.scene_table.setColumnCount(6)
        self.scene_table.setHorizontalHeaderLabels([
            "é€‰æ‹©", "é•œå¤´", "é…éŸ³", "å›¾åƒ", "è§†é¢‘", "çŠ¶æ€"
        ])
        
        # è®¾ç½®è¡¨æ ¼å±æ€§
        self.scene_table.setSelectionBehavior(QAbstractItemView.SelectionBehavior.SelectRows)
        self.scene_table.setAlternatingRowColors(True)
        
        # è®¾ç½®è¡¨æ ¼å¯è°ƒæ•´å¤§å°
        header = self.scene_table.horizontalHeader()
        header.setSectionResizeMode(QHeaderView.ResizeMode.Interactive)  # å…è®¸æ‰‹åŠ¨è°ƒæ•´åˆ—å®½
        header.setStretchLastSection(False)  # æœ€åä¸€åˆ—ä¸è‡ªåŠ¨æ‹‰ä¼¸

        # è®¾ç½®å‚ç›´è¡¨å¤´å¯è°ƒæ•´è¡Œé«˜
        v_header = self.scene_table.verticalHeader()
        v_header.setSectionResizeMode(QHeaderView.ResizeMode.Interactive)  # å…è®¸æ‰‹åŠ¨è°ƒæ•´è¡Œé«˜
        v_header.setVisible(True)  # æ˜¾ç¤ºè¡Œå·ä»¥ä¾¿è°ƒæ•´è¡Œé«˜
        v_header.setDefaultSectionSize(60)  # è®¾ç½®é»˜è®¤è¡Œé«˜ä¸º60åƒç´ ï¼Œé€‚åˆæ˜¾ç¤ºä¸¤è¡Œæ–‡æœ¬

        # è®¾ç½®åˆå§‹åˆ—å®½
        self.scene_table.setColumnWidth(0, 50)   # é€‰æ‹©
        self.scene_table.setColumnWidth(1, 180)  # é•œå¤´ï¼ˆå¢åŠ å®½åº¦ä»¥æ˜¾ç¤ºæ—ç™½é¢„è§ˆï¼‰
        self.scene_table.setColumnWidth(2, 100)  # é…éŸ³ï¼ˆå¢åŠ å®½åº¦æ˜¾ç¤ºæ—¶é•¿ï¼‰
        self.scene_table.setColumnWidth(3, 120)  # å›¾åƒ
        self.scene_table.setColumnWidth(4, 120)  # è§†é¢‘
        self.scene_table.setColumnWidth(5, 150)  # çŠ¶æ€
        
        layout.addWidget(self.scene_table)
        
        # æ‰¹é‡æ“ä½œæŒ‰é’®
        batch_layout = QHBoxLayout()
        
        self.select_all_btn = QPushButton("å…¨é€‰")
        self.select_all_btn.clicked.connect(self.select_all_scenes)
        batch_layout.addWidget(self.select_all_btn)
        
        self.select_none_btn = QPushButton("å–æ¶ˆå…¨é€‰")
        self.select_none_btn.clicked.connect(self.select_none_scenes)
        batch_layout.addWidget(self.select_none_btn)
        
        batch_layout.addStretch()
        
        self.batch_generate_btn = QPushButton("ğŸ¬ æ‰¹é‡ç”Ÿæˆ")
        self.batch_generate_btn.clicked.connect(self.start_batch_generation)
        self.batch_generate_btn.setStyleSheet("QPushButton { background-color: #4CAF50; color: white; font-weight: bold; }")
        batch_layout.addWidget(self.batch_generate_btn)
        
        layout.addLayout(batch_layout)
        
        return panel

    def create_generation_control_panel(self):
        """åˆ›å»ºç”Ÿæˆæ§åˆ¶é¢æ¿"""
        panel = QFrame()
        panel.setFrameStyle(QFrame.Shape.StyledPanel)
        layout = QVBoxLayout(panel)

        # æ ‡é¢˜
        title_label = QLabel("âš™ï¸ ç”Ÿæˆè®¾ç½®")
        title_label.setFont(QFont("Arial", 12, QFont.Weight.Bold))
        layout.addWidget(title_label)

        # CogVideoX-Flash è®¾ç½®ç»„
        cogvideox_group = QGroupBox("CogVideoX-Flash è®¾ç½®")
        cogvideox_form = QFormLayout()

        # è§†é¢‘æ—¶é•¿ - CogVideoX-Flashæ”¯æŒçš„æ—¶é•¿
        self.duration_combo = QComboBox()
        self.duration_combo.addItems(["5", "10"])  # CogVideoX-Flashåªæ”¯æŒ5ç§’å’Œ10ç§’
        self.duration_combo.setCurrentText("5")
        self.duration_combo.setToolTip("è§†é¢‘æ—¶é•¿ï¼ˆCogVideoX-Flashæ”¯æŒ5ç§’ã€10ç§’ï¼‰")
        cogvideox_form.addRow("è§†é¢‘æ—¶é•¿:", self.duration_combo)

        # åˆ†è¾¨ç‡è¯´æ˜ - è‡ªåŠ¨æ ¹æ®å›¾åƒå°ºå¯¸ç¡®å®š
        resolution_label = QLabel("åˆ†è¾¨ç‡: è‡ªåŠ¨æ ¹æ®å›¾åƒå°ºå¯¸ç¡®å®š")
        resolution_label.setStyleSheet("color: #666; font-style: italic;")
        cogvideox_form.addRow("", resolution_label)

        # å¸§ç‡ - CogVideoX-Flashåªæ”¯æŒ30å’Œ60fps
        self.fps_combo = QComboBox()
        self.fps_combo.addItems(["30", "60"])
        self.fps_combo.setCurrentText("30")
        cogvideox_form.addRow("å¸§ç‡:", self.fps_combo)

        # å¹¶å‘ä»»åŠ¡æ•° - CogVideoX-Flashæ”¯æŒå¤šä¸ªå¹¶å‘ä»»åŠ¡
        self.concurrent_tasks_combo = QComboBox()
        self.concurrent_tasks_combo.addItems(["1", "2", "3", "4", "5"])
        self.concurrent_tasks_combo.setCurrentText("3")
        self.concurrent_tasks_combo.setToolTip("åŒæ—¶è¿›è¡Œçš„è§†é¢‘ç”Ÿæˆä»»åŠ¡æ•°é‡ã€‚æ•°é‡è¶Šå¤šé€Ÿåº¦è¶Šå¿«ï¼Œä½†å¯èƒ½å¢åŠ æœåŠ¡å™¨è´Ÿè½½")
        # è¿æ¥ä¿¡å·ï¼Œå½“ç”¨æˆ·æ”¹å˜å¹¶å‘æ•°æ—¶å®æ—¶æ›´æ–°
        self.concurrent_tasks_combo.currentTextChanged.connect(self.on_concurrent_changed)
        cogvideox_form.addRow("å¹¶å‘ä»»åŠ¡æ•°:", self.concurrent_tasks_combo)

        # è¿åŠ¨å¼ºåº¦
        motion_layout = QHBoxLayout()
        self.motion_slider = QSlider(Qt.Orientation.Horizontal)
        self.motion_slider.setRange(0, 100)
        self.motion_slider.setValue(50)
        self.motion_label = QLabel("50%")
        self.motion_slider.valueChanged.connect(
            lambda v: self.motion_label.setText(f"{v}%")
        )
        motion_layout.addWidget(self.motion_slider)
        motion_layout.addWidget(self.motion_label)
        cogvideox_form.addRow("è¿åŠ¨å¼ºåº¦:", motion_layout)

        cogvideox_group.setLayout(cogvideox_form)
        layout.addWidget(cogvideox_group)

        # è¾“å‡ºè®¾ç½®ç»„
        output_group = QGroupBox("è¾“å‡ºè®¾ç½®")
        output_form = QFormLayout()

        # è¾“å‡ºç›®å½•æ˜¾ç¤º
        self.output_dir_label = QLabel("é¡¹ç›®/videos/cogvideox/")
        self.output_dir_label.setStyleSheet("color: #666; font-style: italic;")
        output_form.addRow("è¾“å‡ºç›®å½•:", self.output_dir_label)

        # è‡ªåŠ¨æ’­æ”¾
        self.auto_play_check = QCheckBox("ç”Ÿæˆå®Œæˆåè‡ªåŠ¨æ’­æ”¾")
        self.auto_play_check.setChecked(True)
        output_form.addRow(self.auto_play_check)

        output_group.setLayout(output_form)
        layout.addWidget(output_group)

        # é¢„è§ˆåŒºåŸŸ
        preview_group = QGroupBox("å½“å‰é€‰æ‹©é¢„è§ˆ")
        preview_layout = QVBoxLayout()

        # å›¾åƒé¢„è§ˆ
        self.image_preview = QLabel("é€‰æ‹©åœºæ™¯æŸ¥çœ‹å›¾åƒé¢„è§ˆ")
        self.image_preview.setMinimumHeight(150)
        self.image_preview.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_preview.setStyleSheet("border: 1px solid #ccc; background-color: #f9f9f9;")
        preview_layout.addWidget(self.image_preview)

        # æè¿°é¢„è§ˆ
        self.description_preview = QTextEdit()
        self.description_preview.setMaximumHeight(80)
        self.description_preview.setPlaceholderText("é€‰æ‹©åœºæ™¯æŸ¥çœ‹æè¿°")
        self.description_preview.setReadOnly(True)
        preview_layout.addWidget(self.description_preview)

        preview_group.setLayout(preview_layout)
        layout.addWidget(preview_group)

        # å•ä¸ªç”ŸæˆæŒ‰é’®
        self.single_generate_btn = QPushButton("ğŸ¥ ç”Ÿæˆå½“å‰é€‰æ‹©")
        self.single_generate_btn.clicked.connect(self.start_single_generation)
        self.single_generate_btn.setStyleSheet("QPushButton { background-color: #2196F3; color: white; font-weight: bold; }")
        layout.addWidget(self.single_generate_btn)

        layout.addStretch()
        return panel

    def create_progress_area(self, parent_layout):
        """åˆ›å»ºè¿›åº¦åŒºåŸŸ"""
        progress_frame = QFrame()
        progress_frame.setFrameStyle(QFrame.Shape.StyledPanel)
        progress_frame.setMaximumHeight(80)  # é™åˆ¶è¿›åº¦åŒºåŸŸé«˜åº¦
        progress_layout = QVBoxLayout(progress_frame)
        progress_layout.setContentsMargins(5, 5, 5, 5)  # å‡å°‘è¾¹è·
        progress_layout.setSpacing(3)  # å‡å°‘é—´è·

        # è¿›åº¦æ¡
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        self.progress_bar.setMaximumHeight(20)  # é™åˆ¶è¿›åº¦æ¡é«˜åº¦
        progress_layout.addWidget(self.progress_bar)

        # çŠ¶æ€æ ‡ç­¾å’Œæ§åˆ¶æŒ‰é’®åœ¨åŒä¸€è¡Œ
        status_control_layout = QHBoxLayout()

        # çŠ¶æ€æ ‡ç­¾
        self.status_label = QLabel("å°±ç»ª")
        self.status_label.setStyleSheet("color: #666; font-size: 12px;")
        status_control_layout.addWidget(self.status_label)

        status_control_layout.addStretch()

        # æ§åˆ¶æŒ‰é’®
        self.cancel_btn = QPushButton("âŒ å–æ¶ˆç”Ÿæˆ")
        self.cancel_btn.clicked.connect(self.cancel_generation)
        self.cancel_btn.setVisible(False)
        self.cancel_btn.setMaximumHeight(25)
        status_control_layout.addWidget(self.cancel_btn)

        self.open_output_btn = QPushButton("ğŸ“ æ‰“å¼€è¾“å‡ºç›®å½•")
        self.open_output_btn.clicked.connect(self.open_output_directory)
        self.open_output_btn.setMaximumHeight(25)
        status_control_layout.addWidget(self.open_output_btn)

        progress_layout.addLayout(status_control_layout)
        parent_layout.addWidget(progress_frame)

    def load_project_data(self):
        """åŠ è½½é¡¹ç›®æ•°æ®"""
        try:
            if not self.project_manager or not self.project_manager.current_project:
                self.status_label.setText("æœªåŠ è½½é¡¹ç›®")
                return

            project_data = self.project_manager.get_project_data()
            if not project_data:
                self.status_label.setText("é¡¹ç›®æ•°æ®ä¸ºç©º")
                return

            # ğŸ”§ æ–°å¢ï¼šåˆå§‹åŒ–IDç®¡ç†å™¨
            self.shot_id_manager.initialize_from_project_data(project_data)
            logger.info("è§†é¢‘ç”Ÿæˆç•Œé¢ï¼šIDç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

            # åŠ è½½åœºæ™¯æ•°æ®
            self.load_scenes_data(project_data)

            # æ›´æ–°çŠ¶æ€
            scene_count = len(self.current_scenes)
            self.status_label.setText(f"å·²åŠ è½½ {scene_count} ä¸ªé•œå¤´")

        except Exception as e:
            logger.error(f"åŠ è½½é¡¹ç›®æ•°æ®å¤±è´¥: {e}")
            self.status_label.setText(f"åŠ è½½å¤±è´¥: {e}")

    def load_scenes_data(self, project_data):
        """åŠ è½½åœºæ™¯æ•°æ®"""
        try:
            self.current_scenes = []
            logger.info(f"å¼€å§‹åŠ è½½åœºæ™¯æ•°æ®ï¼Œé¡¹ç›®æ•°æ®é”®: {list(project_data.keys())}")

            # å°è¯•å¤šç§æ•°æ®æºåŠ è½½åœºæ™¯æ•°æ®
            scenes_loaded = False

            # æ–¹æ³•1ï¼šä»æ–°çš„é¡¹ç›®æ•°æ®ç»“æ„ä¸­æå–
            if not scenes_loaded:
                scenes_loaded = self._load_from_new_structure(project_data)

            # æ–¹æ³•2ï¼šä»æ—§çš„é¡¹ç›®æ•°æ®ç»“æ„ä¸­æå–
            if not scenes_loaded:
                scenes_loaded = self._load_from_legacy_structure(project_data)

            # æ–¹æ³•3ï¼šä»åˆ†é•œå›¾åƒç”Ÿæˆæ•°æ®ä¸­æå–
            if not scenes_loaded:
                scenes_loaded = self._load_from_storyboard_data(project_data)

            if not scenes_loaded:
                logger.warning("æœªèƒ½ä»ä»»ä½•æ•°æ®æºåŠ è½½é•œå¤´æ•°æ®")
                self.status_label.setText("æœªæ‰¾åˆ°é•œå¤´æ•°æ®")
                return

            # æ›´æ–°è¡¨æ ¼æ˜¾ç¤º
            self.update_scene_table()
            logger.info(f"æˆåŠŸåŠ è½½ {len(self.current_scenes)} ä¸ªåœºæ™¯")

        except Exception as e:
            logger.error(f"åŠ è½½åœºæ™¯æ•°æ®å¤±è´¥: {e}")
            raise

    def _load_from_new_structure(self, project_data):
        """ä»æ–°çš„é¡¹ç›®æ•°æ®ç»“æ„åŠ è½½"""
        try:
            # æ–¹æ³•1ï¼šä»voice_generation.voice_segmentsåŠ è½½ï¼ˆä¼˜å…ˆï¼‰
            voice_generation = project_data.get('voice_generation', {})
            voice_segments = voice_generation.get('voice_segments', [])
            if voice_segments:
                logger.info(f"ä»voice_generation.voice_segmentsåŠ è½½ï¼Œæ‰¾åˆ° {len(voice_segments)} ä¸ªé•œå¤´")
                return self._load_from_voice_segments(voice_segments, project_data)

            # æ–¹æ³•2ï¼šä»shots_dataåŠ è½½
            shots_data = project_data.get('shots_data', [])
            if shots_data:
                logger.info(f"ä»shots_dataåŠ è½½ï¼Œæ‰¾åˆ° {len(shots_data)} ä¸ªé•œå¤´")
                return self._load_from_shots_data(shots_data, project_data)

            # æ–¹æ³•3ï¼šä»storyboard.shotsåŠ è½½
            storyboard = project_data.get('storyboard', {})
            shots = storyboard.get('shots', [])
            if shots:
                logger.info(f"ä»storyboard.shotsåŠ è½½ï¼Œæ‰¾åˆ° {len(shots)} ä¸ªé•œå¤´")
                return self._load_from_storyboard_shots(shots, project_data)

            # æ–¹æ³•4ï¼šä»äº”é˜¶æ®µæ•°æ®åŠ è½½ï¼ˆæœ€åé€‰æ‹©ï¼‰
            five_stage_data = project_data.get('five_stage_storyboard', {})
            if five_stage_data:
                logger.info("å°è¯•ä»äº”é˜¶æ®µæ•°æ®åŠ è½½")
                return self._load_from_five_stage_data(five_stage_data, project_data)

            return False

        except Exception as e:
            logger.error(f"ä»æ–°ç»“æ„åŠ è½½å¤±è´¥: {e}")
            return False

    def _load_from_voice_segments(self, voice_segments, project_data):
        """ä»voice_generation.voice_segmentsåŠ è½½"""
        try:
            self.current_scenes = []

            # è·å–enhanced_descriptionså’Œimage_generationæ•°æ®
            enhanced_descriptions = project_data.get('enhanced_descriptions', {})
            image_generation = project_data.get('image_generation', {})

            for segment in voice_segments:
                scene_data = self._create_scene_data_from_voice_segment(segment, enhanced_descriptions, image_generation, project_data)
                if scene_data:
                    self.current_scenes.append(scene_data)

            logger.info(f"ä»voice_segmentsåŠ è½½äº† {len(self.current_scenes)} ä¸ªé•œå¤´")
            return len(self.current_scenes) > 0

        except Exception as e:
            logger.error(f"ä»voice_segmentsåŠ è½½å¤±è´¥: {e}")
            return False

    def _create_scene_data_from_voice_segment(self, segment, enhanced_descriptions, image_generation, project_data):
        """ä»voice_segmentåˆ›å»ºåœºæ™¯æ•°æ®"""
        try:
            shot_id = segment.get('shot_id', '')
            scene_id = segment.get('scene_id', '')

            # è·å–åŸæ–‡å†…å®¹ - ä¼˜å…ˆä»å¤šä¸ªå­—æ®µä¸­è·å–
            original_text = (
                segment.get('original_text', '') or
                segment.get('text', '') or
                segment.get('content', '') or
                segment.get('narration', '') or
                ''
            )

            # è·å–åˆ†é•œæè¿°
            storyboard_description = (
                segment.get('storyboard_description', '') or
                segment.get('description', '') or
                segment.get('enhanced_description', '') or
                ''
            )

            # åˆ›å»ºåŸºç¡€åœºæ™¯æ•°æ®
            scene_data = {
                'shot_id': shot_id,
                'scene_id': scene_id,
                'shot_number': shot_id,
                'shot_title': shot_id,  # æ·»åŠ shot_titleå­—æ®µ
                'scene_title': scene_id,  # æ·»åŠ scene_titleå­—æ®µ
                'narration': original_text,  # ä½¿ç”¨è·å–åˆ°çš„åŸæ–‡
                'original_text': original_text,  # ä¿ç•™åŸæ–‡å­—æ®µ
                'description': storyboard_description,
                'enhanced_description': '',
                'voice_path': segment.get('audio_path', ''),
                'voice_duration': 0.0,
                'image_path': '',
                'video_path': '',
                'status': 'æœªç”Ÿæˆ'
            }

            # è·å–é…éŸ³æ—¶é•¿ - ä¼˜å…ˆä»segmentä¸­è·å–ï¼Œç„¶åä»æ–‡ä»¶è·å–
            voice_duration = segment.get('duration', 0.0) or segment.get('voice_duration', 0.0)
            if voice_duration > 0:
                scene_data['voice_duration'] = voice_duration
                logger.info(f"ä»segmentè·å–éŸ³é¢‘æ—¶é•¿: {shot_id} -> {voice_duration:.1f}s")
            elif scene_data['voice_path'] and os.path.exists(scene_data['voice_path']):
                voice_duration = self._get_audio_duration(scene_data['voice_path'])
                scene_data['voice_duration'] = voice_duration
                logger.info(f"ä»æ–‡ä»¶è·å–éŸ³é¢‘æ—¶é•¿: {scene_data['voice_path']} -> {voice_duration:.1f}s")
            else:
                logger.warning(f"æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿: {shot_id}, éŸ³é¢‘è·¯å¾„: {scene_data['voice_path']}")

            # ä»enhanced_descriptionsè·å–å›¾åƒä¿¡æ¯
            shot_key = f"### {shot_id}"
            if shot_key in enhanced_descriptions:
                enhanced_data = enhanced_descriptions[shot_key]
                scene_data['enhanced_description'] = enhanced_data.get('enhanced_prompt', '')

            # ä»å¤šä¸ªæ•°æ®æºè·å–å›¾åƒè·¯å¾„
            image_path = ''
            image_status = 'æœªç”Ÿæˆ'

            # æ–¹æ³•1ï¼šä»shot_image_mappingsè·å–ï¼ˆä¸»è¦æ•°æ®æºï¼‰
            shot_image_mappings = project_data.get('shot_image_mappings', {})
            if shot_image_mappings:
                # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€IDç®¡ç†å™¨è¿›è¡Œè½¬æ¢
                possible_keys = [shot_id]  # ç›´æ¥ä½¿ç”¨shot_id

                # ä½¿ç”¨IDç®¡ç†å™¨è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                if hasattr(self, 'shot_id_manager') and self.shot_id_manager.shot_mappings:
                    unified_key = self.shot_id_manager.convert_id(shot_id, "unified")
                    if unified_key:
                        possible_keys.append(unified_key)
                        logger.debug(f"IDç®¡ç†å™¨è½¬æ¢: {shot_id} -> {unified_key}")

                # ä¿ç•™åŸæœ‰çš„è½¬æ¢é€»è¾‘ä½œä¸ºå¤‡ç”¨
                if shot_id.startswith('text_segment_'):
                    shot_number = shot_id.split('_')[-1]
                    shot_num = str(int(shot_number))
                    possible_keys.extend([
                        f"scene_1_{shot_id}",  # scene_1_text_segment_001
                        f"scene_1_shot_{shot_num}",  # scene_1_shot_1
                        f"scene_1_shot_{shot_number}",  # scene_1_shot_001
                        f"shot_{shot_num}",  # shot_1
                        f"shot_{shot_number}",  # shot_001
                    ])

                for key in possible_keys:
                    if key in shot_image_mappings:
                        img_data = shot_image_mappings[key]
                        # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆè·å–ä¸»å›¾è·¯å¾„ï¼Œç¡®ä¿è§†é¢‘ç”Ÿæˆä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„ä¸»å›¾
                        image_path = img_data.get('main_image_path', '') or img_data.get('image_path', '')
                        image_status = img_data.get('status', 'æœªç”Ÿæˆ')
                        logger.debug(f"ä»shot_image_mappingsæ‰¾åˆ°å›¾åƒ: {key} -> {image_path} (ä¸»å›¾ä¼˜å…ˆ)")
                        break

            # æ–¹æ³•2ï¼šä»image_generationè·å–
            if not image_path:
                if shot_id in image_generation:
                    image_data = image_generation[shot_id]
                    if isinstance(image_data, dict):
                        # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆè·å–ä¸»å›¾è·¯å¾„
                        image_path = image_data.get('main_image_path', '') or image_data.get('image_path', '')
                        image_status = image_data.get('status', 'æœªç”Ÿæˆ')
                    elif isinstance(image_data, str):
                        image_path = image_data
                        image_status = 'å·²ç”Ÿæˆ' if os.path.exists(image_path) else 'æœªç”Ÿæˆ'

            # æ–¹æ³•3ï¼šä»imagesåˆ—è¡¨ä¸­æŸ¥æ‰¾
            if not image_path:
                images_list = image_generation.get('images', [])
                for img in images_list:
                    if isinstance(img, dict) and img.get('shot_id') == shot_id:
                        # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆè·å–ä¸»å›¾è·¯å¾„
                        image_path = img.get('main_image_path', '') or img.get('image_path', '')
                        image_status = img.get('status', 'æœªç”Ÿæˆ')
                        break

            # éªŒè¯å›¾åƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if image_path and os.path.exists(image_path):
                image_status = 'å·²ç”Ÿæˆ'
            elif image_path:
                logger.warning(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                image_path = ''
                image_status = 'æœªç”Ÿæˆ'

            scene_data['image_path'] = image_path

            # ğŸ”§ æ–°å¢ï¼šè·å–è§†é¢‘è·¯å¾„ä¿¡æ¯
            video_path = ''
            video_status = 'æœªç”Ÿæˆ'

            # æ–¹æ³•1ï¼šä»shot_mappingsè·å–ï¼ˆæ–°çš„ä¿å­˜æ–¹å¼ï¼‰
            shot_mappings = project_data.get('shot_mappings', {})
            if shot_id in shot_mappings:
                mapping_data = shot_mappings[shot_id]
                video_path = mapping_data.get('video_path', '')
                video_status = mapping_data.get('video_status', 'æœªç”Ÿæˆ')
                logger.debug(f"ä»shot_mappingsæ‰¾åˆ°è§†é¢‘: {shot_id} -> {video_path}")

            # æ–¹æ³•2ï¼šä»video_generation.videosè·å–
            if not video_path:
                video_generation = project_data.get('video_generation', {})
                videos = video_generation.get('videos', [])
                for video in videos:
                    if isinstance(video, dict) and video.get('shot_id') == shot_id:
                        video_path = video.get('video_path', '')
                        video_status = video.get('status', 'æœªç”Ÿæˆ')
                        logger.debug(f"ä»video_generationæ‰¾åˆ°è§†é¢‘: {shot_id} -> {video_path}")
                        break

            # éªŒè¯è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if video_path and os.path.exists(video_path):
                video_status = 'å·²ç”Ÿæˆ'
                scene_data['status'] = 'å·²ç”Ÿæˆ'  # å¦‚æœæœ‰è§†é¢‘ï¼ŒçŠ¶æ€è®¾ä¸ºå·²ç”Ÿæˆ
            elif video_path:
                logger.warning(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                video_path = ''
                video_status = 'æœªç”Ÿæˆ'

            scene_data['video_path'] = video_path

            # æ›´æ–°çŠ¶æ€ï¼šå¦‚æœæœ‰è§†é¢‘åˆ™ä¸ºå·²ç”Ÿæˆï¼Œå¦åˆ™æ ¹æ®å›¾åƒçŠ¶æ€å†³å®š
            if video_status == 'å·²ç”Ÿæˆ':
                scene_data['status'] = 'å·²ç”Ÿæˆ'
            else:
                scene_data['status'] = image_status

            logger.debug(f"é•œå¤´ {shot_id} ä¿¡æ¯: å›¾åƒ={image_path}, è§†é¢‘={video_path}, çŠ¶æ€={scene_data['status']}")

            return scene_data

        except Exception as e:
            logger.error(f"åˆ›å»ºåœºæ™¯æ•°æ®å¤±è´¥: {e}")
            return None

    def _load_from_shots_data(self, shots_data, project_data):
        """ä»shots_dataåŠ è½½"""
        try:
            # è·å–é…éŸ³æ•°æ®
            voice_generation = project_data.get('voice_generation', {})
            voice_segments = voice_generation.get('segments', [])

            # è·å–å›¾åƒæ•°æ®
            image_generation = project_data.get('image_generation', {})
            images = image_generation.get('images', [])

            # è·å–è§†é¢‘æ•°æ®
            video_generation = project_data.get('video_generation', {})
            videos = video_generation.get('videos', [])

            # å¤„ç†æ¯ä¸ªé•œå¤´
            for i, shot in enumerate(shots_data):
                shot_id = shot.get('shot_id', f'shot_{i+1}')
                scene_id = shot.get('scene_id', f'scene_{i//5+1}')  # å‡è®¾æ¯5ä¸ªé•œå¤´ä¸€ä¸ªåœºæ™¯

                scene_data = self._create_scene_data(shot_id, scene_id, shot, voice_segments, images, videos)
                self.current_scenes.append(scene_data)

            return len(self.current_scenes) > 0

        except Exception as e:
            logger.error(f"ä»shots_dataåŠ è½½å¤±è´¥: {e}")
            return False

    def _load_from_storyboard_shots(self, shots, project_data):
        """ä»storyboard.shotsåŠ è½½"""
        try:
            # è·å–é…éŸ³æ•°æ®
            voice_generation = project_data.get('voice_generation', {})
            voice_segments = voice_generation.get('segments', [])

            # è·å–å›¾åƒæ•°æ®
            image_generation = project_data.get('image_generation', {})
            images = image_generation.get('images', [])

            # è·å–è§†é¢‘æ•°æ®
            video_generation = project_data.get('video_generation', {})
            videos = video_generation.get('videos', [])

            # å¤„ç†æ¯ä¸ªé•œå¤´
            for shot in shots:
                shot_id = shot.get('shot_id', '')
                scene_id = shot.get('scene_id', '')

                scene_data = self._create_scene_data(shot_id, scene_id, shot, voice_segments, images, videos)
                self.current_scenes.append(scene_data)

            return len(self.current_scenes) > 0

        except Exception as e:
            logger.error(f"ä»storyboard.shotsåŠ è½½å¤±è´¥: {e}")
            return False

    def _load_from_five_stage_data(self, five_stage_data, project_data):
        """ä»äº”é˜¶æ®µæ•°æ®åŠ è½½"""
        try:
            stage_data = five_stage_data.get('stage_data', {})

            # ä»ç¬¬5é˜¶æ®µè·å–æœ€ç»ˆåˆ†é•œæ•°æ®
            stage_5 = stage_data.get('5', {})
            final_storyboard = stage_5.get('final_storyboard', [])

            if not final_storyboard:
                # å°è¯•ä»ç¬¬4é˜¶æ®µè·å–
                stage_4 = stage_data.get('4', {})
                storyboard_results = stage_4.get('storyboard_results', [])
                if storyboard_results:
                    # å±•å¼€æ‰€æœ‰åœºæ™¯çš„é•œå¤´
                    final_storyboard = []
                    for scene_result in storyboard_results:
                        voice_segments = scene_result.get('voice_segments', [])
                        final_storyboard.extend(voice_segments)

            if not final_storyboard:
                return False

            logger.info(f"ä»äº”é˜¶æ®µæ•°æ®åŠ è½½ï¼Œæ‰¾åˆ° {len(final_storyboard)} ä¸ªé•œå¤´")

            # è·å–é…éŸ³æ•°æ®
            voice_generation = project_data.get('voice_generation', {})
            voice_segments = voice_generation.get('segments', [])

            # è·å–å›¾åƒæ•°æ®
            image_generation = project_data.get('image_generation', {})
            images = image_generation.get('images', [])

            # è·å–è§†é¢‘æ•°æ®
            video_generation = project_data.get('video_generation', {})
            videos = video_generation.get('videos', [])

            # å¤„ç†æ¯ä¸ªé•œå¤´
            for i, shot in enumerate(final_storyboard):
                shot_id = shot.get('shot_id', f'shot_{i+1}')
                scene_id = shot.get('scene_id', f'scene_{i//5+1}')

                scene_data = self._create_scene_data(shot_id, scene_id, shot, voice_segments, images, videos)
                self.current_scenes.append(scene_data)

            return len(self.current_scenes) > 0

        except Exception as e:
            logger.error(f"ä»äº”é˜¶æ®µæ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False

    def _load_from_legacy_structure(self, project_data):
        """ä»æ—§çš„é¡¹ç›®æ•°æ®ç»“æ„åŠ è½½"""
        try:
            # æ–¹æ³•1ï¼šä»shot_image_mappingsåŠ è½½
            shot_image_mappings = project_data.get('shot_image_mappings', {})
            if shot_image_mappings:
                logger.info(f"ä»shot_image_mappingsåŠ è½½ï¼Œæ‰¾åˆ° {len(shot_image_mappings)} ä¸ªé•œå¤´æ˜ å°„")
                return self._load_from_shot_mappings(shot_image_mappings, project_data)

            # æ–¹æ³•2ï¼šä»æ—§çš„voices/images/videosç»“æ„åŠ è½½
            voices = project_data.get('voices', {})
            images = project_data.get('images', {})
            videos = project_data.get('videos', {})
            scenes = project_data.get('scenes', [])

            if not scenes and not voices and not images:
                return False

            # å¦‚æœæœ‰voices/imagesæ•°æ®ä½†æ²¡æœ‰scenesï¼Œå°è¯•ä»é”®åæ¨æ–­
            if (voices or images) and not scenes:
                return self._load_from_voice_image_keys(voices, images, videos, project_data)

            # æ ‡å‡†çš„scenesç»“æ„
            for scene_idx, scene in enumerate(scenes):
                shots = scene.get('shots', [])
                for shot_idx, shot in enumerate(shots):
                    shot_key = f"scene_{scene_idx}_shot_{shot_idx}"

                    scene_data = {
                        'scene_id': f"scene_{scene_idx}",
                        'shot_id': f"shot_{shot_idx}",
                        'scene_title': scene.get('title', f'åœºæ™¯{scene_idx + 1}'),
                        'shot_title': shot.get('title', f'é•œå¤´{shot_idx + 1}'),
                        'description': shot.get('description', ''),
                        'enhanced_description': shot.get('enhanced_description', ''),
                        'original_text': shot.get('original_text', ''),
                        'voice_path': '',
                        'voice_duration': 0.0,
                        'image_path': '',
                        'video_path': '',
                        'status': 'æœªç”Ÿæˆ'
                    }

                    # æŸ¥æ‰¾é…éŸ³æ–‡ä»¶
                    if shot_key in voices:
                        voice_info = voices[shot_key]
                        if isinstance(voice_info, dict):
                            scene_data['voice_path'] = voice_info.get('file_path', '')
                            scene_data['voice_duration'] = voice_info.get('duration', 0.0)
                        else:
                            scene_data['voice_path'] = str(voice_info)

                    # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
                    if shot_key in images:
                        image_info = images[shot_key]
                        if isinstance(image_info, dict):
                            scene_data['image_path'] = image_info.get('file_path', '')
                        else:
                            scene_data['image_path'] = str(image_info)

                    # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
                    if shot_key in videos:
                        video_info = videos[shot_key]
                        if isinstance(video_info, dict):
                            scene_data['video_path'] = video_info.get('file_path', '')
                            if scene_data['video_path'] and os.path.exists(scene_data['video_path']):
                                scene_data['status'] = 'å·²ç”Ÿæˆ'

                    self.current_scenes.append(scene_data)

            return len(self.current_scenes) > 0

        except Exception as e:
            logger.error(f"ä»æ—§ç»“æ„åŠ è½½å¤±è´¥: {e}")
            return False

    def _load_from_shot_mappings(self, shot_mappings, project_data):
        """ä»shot_image_mappingsåŠ è½½"""
        try:
            # è·å–é…éŸ³æ•°æ®
            voice_generation = project_data.get('voice_generation', {})
            voice_segments = voice_generation.get('segments', [])

            # è·å–è§†é¢‘æ•°æ®
            video_generation = project_data.get('video_generation', {})
            videos = video_generation.get('videos', [])

            for shot_key, mapping_data in shot_mappings.items():
                # è§£æshot_key (å¦‚: scene_1_shot_1)
                parts = shot_key.split('_')
                if len(parts) >= 4:
                    scene_id = f"{parts[0]}_{parts[1]}"
                    shot_id = f"{parts[2]}_{parts[3]}"
                else:
                    scene_id = f"scene_{len(self.current_scenes)//5+1}"
                    shot_id = f"shot_{len(self.current_scenes)+1}"

                scene_data = {
                    'scene_id': scene_id,
                    'shot_id': shot_id,
                    'scene_title': scene_id.replace('_', ' ').title(),
                    'shot_title': shot_id.replace('_', ' ').title(),
                    'description': mapping_data.get('enhanced_description', ''),
                    'enhanced_description': mapping_data.get('enhanced_description', ''),
                    'original_text': mapping_data.get('original_text', ''),
                    'voice_path': '',
                    'voice_duration': 0.0,
                    'image_path': mapping_data.get('main_image_path', ''),
                    'video_path': '',
                    'status': mapping_data.get('status', 'æœªç”Ÿæˆ')
                }

                # æŸ¥æ‰¾é…éŸ³æ–‡ä»¶
                for voice_segment in voice_segments:
                    if (voice_segment.get('shot_id') == shot_id or
                        voice_segment.get('shot_id') == shot_key):
                        audio_path = voice_segment.get('audio_path', '')
                        if audio_path and os.path.exists(audio_path):
                            scene_data['voice_path'] = audio_path
                            scene_data['voice_duration'] = voice_segment.get('duration', 0.0)
                        break

                # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
                for video in videos:
                    if (video.get('shot_id') == shot_id or
                        video.get('shot_id') == shot_key):
                        video_path = video.get('video_path', '')
                        if video_path and os.path.exists(video_path):
                            scene_data['video_path'] = video_path
                            scene_data['status'] = 'å·²ç”Ÿæˆ'
                        break

                self.current_scenes.append(scene_data)

            return len(self.current_scenes) > 0

        except Exception as e:
            logger.error(f"ä»shot_mappingsåŠ è½½å¤±è´¥: {e}")
            return False

    def _load_from_voice_image_keys(self, voices, images, videos, project_data):
        """ä»voice/imageé”®åæ¨æ–­é•œå¤´æ•°æ®"""
        try:
            # æ”¶é›†æ‰€æœ‰çš„é•œå¤´é”®
            all_keys = set()
            all_keys.update(voices.keys())
            all_keys.update(images.keys())
            all_keys.update(videos.keys())

            if not all_keys:
                return False

            for shot_key in sorted(all_keys):
                # è§£æshot_key
                parts = shot_key.split('_')
                if len(parts) >= 4:
                    scene_id = f"{parts[0]}_{parts[1]}"
                    shot_id = f"{parts[2]}_{parts[3]}"
                else:
                    scene_id = f"scene_{len(self.current_scenes)//5+1}"
                    shot_id = f"shot_{len(self.current_scenes)+1}"

                scene_data = {
                    'scene_id': scene_id,
                    'shot_id': shot_id,
                    'scene_title': scene_id.replace('_', ' ').title(),
                    'shot_title': shot_id.replace('_', ' ').title(),
                    'description': '',
                    'enhanced_description': '',
                    'original_text': '',
                    'voice_path': '',
                    'voice_duration': 0.0,
                    'image_path': '',
                    'video_path': '',
                    'status': 'æœªç”Ÿæˆ'
                }

                # å¤„ç†é…éŸ³æ•°æ®
                if shot_key in voices:
                    voice_info = voices[shot_key]
                    if isinstance(voice_info, dict):
                        scene_data['voice_path'] = voice_info.get('file_path', '')
                        scene_data['voice_duration'] = voice_info.get('duration', 0.0)
                    else:
                        scene_data['voice_path'] = str(voice_info)

                # å¤„ç†å›¾åƒæ•°æ®
                if shot_key in images:
                    image_info = images[shot_key]
                    if isinstance(image_info, dict):
                        scene_data['image_path'] = image_info.get('file_path', '')
                    else:
                        scene_data['image_path'] = str(image_info)

                # å¤„ç†è§†é¢‘æ•°æ®
                if shot_key in videos:
                    video_info = videos[shot_key]
                    if isinstance(video_info, dict):
                        scene_data['video_path'] = video_info.get('file_path', '')
                        if scene_data['video_path'] and os.path.exists(scene_data['video_path']):
                            scene_data['status'] = 'å·²ç”Ÿæˆ'

                self.current_scenes.append(scene_data)

            return len(self.current_scenes) > 0

        except Exception as e:
            logger.error(f"ä»voice/imageé”®åŠ è½½å¤±è´¥: {e}")
            return False

    def _load_from_storyboard_data(self, project_data):
        """ä»åˆ†é•œæ•°æ®åŠ è½½"""
        try:
            # å°è¯•ä»åˆ†é•œå›¾åƒç”Ÿæˆçš„æ•°æ®ä¸­åŠ è½½
            if hasattr(self.project_manager, 'get_storyboard_data'):
                storyboard_data = self.project_manager.get_storyboard_data()
                if storyboard_data:
                    for i, shot_data in enumerate(storyboard_data):
                        scene_data = {
                            'scene_id': f"scene_{i // 5 + 1}",  # å‡è®¾æ¯5ä¸ªé•œå¤´ä¸€ä¸ªåœºæ™¯
                            'shot_id': f"shot_{i + 1}",
                            'scene_title': f"åœºæ™¯{i // 5 + 1}",
                            'shot_title': f"é•œå¤´{i + 1}",
                            'description': shot_data.get('description', ''),
                            'enhanced_description': shot_data.get('enhanced_description', ''),
                            'original_text': shot_data.get('original_text', ''),
                            'voice_path': shot_data.get('voice_path', ''),
                            'voice_duration': shot_data.get('voice_duration', 0.0),
                            'image_path': shot_data.get('image_path', ''),
                            'video_path': '',
                            'status': 'æœªç”Ÿæˆ'
                        }
                        self.current_scenes.append(scene_data)

                    return len(self.current_scenes) > 0

            return False

        except Exception as e:
            logger.error(f"ä»åˆ†é•œæ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False

    def _create_scene_data(self, shot_id, scene_id, shot, voice_segments, images, videos):
        """åˆ›å»ºåœºæ™¯æ•°æ®"""
        # å¤„ç†ä¸åŒçš„æ•°æ®æ ¼å¼
        if isinstance(shot, dict):
            # ä»shots_dataæˆ–storyboardæ•°æ®
            description = shot.get('enhanced_description') or shot.get('scene_description') or shot.get('description', '')
            original_text = shot.get('shot_original_text') or shot.get('original_text', '')
            shot_title = shot.get('shot_type') or shot.get('sequence') or 'é•œå¤´'
        else:
            # å…¶ä»–æ ¼å¼
            description = ''
            original_text = ''
            shot_title = 'é•œå¤´'

        scene_data = {
            'scene_id': scene_id,
            'shot_id': shot_id,
            'scene_title': scene_id.replace('_', ' ').title(),
            'shot_title': shot_title,
            'description': description,
            'enhanced_description': description,
            'original_text': original_text,
            'voice_path': '',
            'voice_duration': 0.0,
            'image_path': '',
            'video_path': '',
            'status': 'æœªç”Ÿæˆ'
        }

        # æŸ¥æ‰¾å¯¹åº”çš„é…éŸ³æ–‡ä»¶
        for voice_segment in voice_segments:
            # æ”¯æŒå¤šç§åŒ¹é…æ–¹å¼
            voice_shot_id = voice_segment.get('shot_id', '')
            if (voice_shot_id == shot_id or
                voice_shot_id == f"shot_{shot_id}" or
                voice_shot_id.endswith(f"_{shot_id}")):

                audio_path = voice_segment.get('audio_path', '')
                if audio_path and os.path.exists(audio_path):
                    scene_data['voice_path'] = audio_path
                    # å°è¯•ä»æ•°æ®ä¸­è·å–æ—¶é•¿ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ£€æµ‹éŸ³é¢‘æ–‡ä»¶
                    duration = voice_segment.get('duration', 0.0)
                    if duration <= 0:
                        duration = self._get_audio_duration(audio_path)
                    scene_data['voice_duration'] = duration
                break

        # æŸ¥æ‰¾å¯¹åº”çš„å›¾åƒæ–‡ä»¶ - æ”¯æŒå¤šç§æ•°æ®æ ¼å¼
        image_found = False

        # æ–¹æ³•1ï¼šä»imagesæ•°ç»„æŸ¥æ‰¾
        for image in images:
            image_shot_id = image.get('shot_id', '')
            if (image_shot_id == shot_id or
                image_shot_id == f"shot_{shot_id}" or
                image_shot_id.endswith(f"_{shot_id}")):

                if image.get('is_main', False):
                    image_path = image.get('image_path', '')
                    if image_path and os.path.exists(image_path):
                        scene_data['image_path'] = image_path
                        image_found = True
                        break

        # æ–¹æ³•2ï¼šå¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»shotæ•°æ®æœ¬èº«è·å–
        if not image_found and isinstance(shot, dict):
            # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆè·å–ä¸»å›¾è·¯å¾„
            image_path = shot.get('main_image_path', '') or shot.get('image_path', '')
            if image_path and os.path.exists(image_path):
                scene_data['image_path'] = image_path
                image_found = True

        # æŸ¥æ‰¾å¯¹åº”çš„è§†é¢‘æ–‡ä»¶
        for video in videos:
            video_shot_id = video.get('shot_id', '')
            if (video_shot_id == shot_id or
                video_shot_id == f"shot_{shot_id}" or
                video_shot_id.endswith(f"_{shot_id}")):

                video_path = video.get('video_path', '')
                if video_path and os.path.exists(video_path):
                    scene_data['video_path'] = video_path
                    # ç¡®ä¿çŠ¶æ€æ˜¯å­—ç¬¦ä¸²ç±»å‹
                    status = video.get('status', 'å·²ç”Ÿæˆ')
                    scene_data['status'] = str(status) if status is not None else 'å·²ç”Ÿæˆ'
                break

        return scene_data

    def _get_audio_duration(self, audio_path):
        """è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not audio_path or not os.path.exists(audio_path):
                return 0.0

            # æ–¹æ³•1ï¼šä½¿ç”¨mutagenï¼ˆæœ€ç¨³å®šï¼Œä¼˜å…ˆä½¿ç”¨ï¼‰
            try:
                from mutagen._file import File
                audio_file = File(audio_path)
                if audio_file is not None and hasattr(audio_file, 'info') and audio_file.info is not None:
                    if hasattr(audio_file.info, 'length') and audio_file.info.length is not None:
                        duration = float(audio_file.info.length)
                        logger.debug(f"mutagenè·å–éŸ³é¢‘æ—¶é•¿æˆåŠŸ: {audio_path} -> {duration:.1f}s")
                        return duration
            except ImportError:
                logger.warning("mutagenåº“æœªå®‰è£…")
            except Exception as e:
                logger.warning(f"mutagenè·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")

            # æ–¹æ³•2ï¼šä½¿ç”¨pydub
            try:
                from pydub import AudioSegment
                audio = AudioSegment.from_file(audio_path)
                duration = len(audio) / 1000.0  # è½¬æ¢ä¸ºç§’
                logger.debug(f"pydubè·å–éŸ³é¢‘æ—¶é•¿æˆåŠŸ: {audio_path} -> {duration:.1f}s")
                return float(duration)
            except Exception as e:
                logger.warning(f"pydubè·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")

            # æ–¹æ³•3ï¼šä½¿ç”¨waveæ¨¡å—ï¼ˆä»…æ”¯æŒwavæ–‡ä»¶ï¼‰
            try:
                import wave
                if audio_path.lower().endswith('.wav'):
                    with wave.open(audio_path, 'r') as wav_file:
                        frames = wav_file.getnframes()
                        rate = wav_file.getframerate()
                        duration = frames / float(rate)
                        logger.debug(f"waveè·å–éŸ³é¢‘æ—¶é•¿æˆåŠŸ: {audio_path} -> {duration:.1f}s")
                        return duration
            except Exception as e:
                logger.warning(f"waveè·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")

            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
            logger.warning(f"æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿ï¼Œä½¿ç”¨é»˜è®¤å€¼5ç§’: {audio_path}")
            return 5.0  # é»˜è®¤5ç§’

        except Exception as e:
            logger.error(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
            return 5.0

    def _check_voice_duration_match(self, scene_data):
        """æ£€æŸ¥é…éŸ³æ—¶é•¿æ˜¯å¦éœ€è¦å¤šä¸ªå›¾åƒ"""
        voice_duration = scene_data.get('voice_duration', 0.0)
        if voice_duration <= 0:
            return 1, []  # æ²¡æœ‰é…éŸ³ï¼Œä½¿ç”¨1ä¸ªå›¾åƒ

        # æ¯ä¸ªè§†é¢‘ç‰‡æ®µçš„æœ€å¤§æ—¶é•¿ï¼ˆç§’ï¼‰
        max_segment_duration = 10.0  # CogVideoX-Flashæœ€å¤§æ”¯æŒ10ç§’

        # è®¡ç®—éœ€è¦çš„å›¾åƒæ•°é‡
        required_images = max(1, int(voice_duration / max_segment_duration) + (1 if voice_duration % max_segment_duration > 0 else 0))

        # è®¡ç®—æ¯ä¸ªç‰‡æ®µçš„æ—¶é•¿
        segment_durations = []
        remaining_duration = voice_duration

        for i in range(required_images):
            if remaining_duration > max_segment_duration:
                segment_durations.append(max_segment_duration)
                remaining_duration -= max_segment_duration
            else:
                segment_durations.append(remaining_duration)
                break

        return required_images, segment_durations

    def _get_scene_images(self, scene_data):
        """è·å–åœºæ™¯çš„æ‰€æœ‰å›¾åƒ"""
        shot_id = scene_data.get('shot_id', '')
        if not shot_id:
            return []

        # ä»é¡¹ç›®æ•°æ®ä¸­è·å–è¯¥é•œå¤´çš„æ‰€æœ‰å›¾åƒ
        project_data = self.project_manager.get_project_data() if self.project_manager else {}
        image_generation = project_data.get('image_generation', {})
        images = image_generation.get('images', [])

        scene_images = []
        for image in images:
            if image.get('shot_id') == shot_id:
                # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆè·å–ä¸»å›¾è·¯å¾„
                image_path = image.get('main_image_path', '') or image.get('image_path', '')
                if image_path and os.path.exists(image_path):
                    scene_images.append({
                        'path': image_path,
                        'is_main': image.get('is_main', False)
                    })

        # æŒ‰ä¸»å›¾åƒä¼˜å…ˆæ’åº
        scene_images.sort(key=lambda x: not x['is_main'])
        return scene_images

    def update_scene_table(self):
        """æ›´æ–°åœºæ™¯è¡¨æ ¼"""
        try:
            self.scene_table.setRowCount(len(self.current_scenes))

            for row, scene_data in enumerate(self.current_scenes):
                # é€‰æ‹©å¤é€‰æ¡†
                checkbox = QCheckBox()
                checkbox.stateChanged.connect(self.on_scene_selection_changed)
                self.scene_table.setCellWidget(row, 0, checkbox)

                # é•œå¤´ä¿¡æ¯ - æ˜¾ç¤ºé•œå¤´IDå’Œæ—ç™½å†…å®¹é¢„è§ˆ
                shot_id = scene_data.get('shot_id', f'é•œå¤´{row+1}')
                narration = scene_data.get('narration', scene_data.get('original_text', ''))

                # æ„å»ºæ˜¾ç¤ºæ–‡æœ¬ï¼šé•œå¤´ID + æ—ç™½é¢„è§ˆ
                if narration:
                    # æˆªå–æ—ç™½å‰30ä¸ªå­—ç¬¦ä½œä¸ºé¢„è§ˆ
                    narration_preview = narration[:30] + "..." if len(narration) > 30 else narration
                    shot_text = f"{shot_id}\n{narration_preview}"
                else:
                    shot_text = shot_id

                shot_item = QTableWidgetItem(shot_text)
                shot_item.setToolTip(f"é•œå¤´ID: {shot_id}\nå®Œæ•´æ—ç™½: {narration}")  # æ‚¬åœæ˜¾ç¤ºå®Œæ•´å†…å®¹
                self.scene_table.setItem(row, 1, shot_item)

                # é…éŸ³çŠ¶æ€å’Œæ—¶é•¿
                voice_widget = QWidget()
                voice_layout = QHBoxLayout(voice_widget)
                voice_layout.setContentsMargins(2, 2, 2, 2)

                voice_status = "âœ…" if scene_data['voice_path'] and os.path.exists(scene_data['voice_path']) else "âŒ"
                voice_status_label = QLabel(voice_status)
                voice_layout.addWidget(voice_status_label)

                # æ˜¾ç¤ºé…éŸ³æ—¶é•¿
                voice_duration = scene_data.get('voice_duration', 0.0)
                if voice_duration > 0:
                    duration_label = QLabel(f"{voice_duration:.1f}s")
                    duration_label.setStyleSheet("color: #666; font-size: 10px;")
                    voice_layout.addWidget(duration_label)

                self.scene_table.setCellWidget(row, 2, voice_widget)

                # å›¾åƒé¢„è§ˆï¼ˆå»æ‰ç»¿å‹¾ï¼Œæ”¾å¤§ç¼©ç•¥å›¾ï¼‰
                image_widget = QWidget()
                image_layout = QHBoxLayout(image_widget)
                image_layout.setContentsMargins(2, 2, 2, 2)

                # å¦‚æœæœ‰å›¾åƒï¼Œæ·»åŠ æ”¾å¤§çš„é¢„è§ˆ
                if scene_data['image_path'] and os.path.exists(scene_data['image_path']):
                    image_preview = QLabel()
                    pixmap = QPixmap(scene_data['image_path'])
                    if not pixmap.isNull():
                        # æ”¾å¤§ç¼©ç•¥å›¾å°ºå¯¸ï¼ˆä»40x30æ”¹ä¸º80x60ï¼‰
                        scaled_pixmap = pixmap.scaled(80, 60, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
                        image_preview.setPixmap(scaled_pixmap)
                        image_preview.setToolTip(f"å›¾åƒ: {os.path.basename(scene_data['image_path'])}")
                        image_layout.addWidget(image_preview)
                else:
                    # æ²¡æœ‰å›¾åƒæ—¶æ˜¾ç¤ºå ä½ç¬¦
                    no_image_label = QLabel("æš‚æ— å›¾åƒ")
                    no_image_label.setStyleSheet("color: #666; font-size: 12px;")
                    no_image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
                    image_layout.addWidget(no_image_label)

                self.scene_table.setCellWidget(row, 3, image_widget)

                # è§†é¢‘é¢„è§ˆå’Œæ’­æ”¾ï¼ˆå»æ‰çŠ¶æ€å›¾æ ‡ï¼Œæ·»åŠ ç¼©ç•¥å›¾ï¼‰
                video_widget = QWidget()
                video_layout = QHBoxLayout(video_widget)
                video_layout.setContentsMargins(2, 2, 2, 2)

                # å¦‚æœæœ‰è§†é¢‘ï¼Œæ·»åŠ ç¼©ç•¥å›¾å’Œæ’­æ”¾æŒ‰é’®
                if scene_data['video_path'] and os.path.exists(scene_data['video_path']):
                    logger.debug(f"å°è¯•ä¸ºè§†é¢‘ç”Ÿæˆç¼©ç•¥å›¾: {scene_data['video_path']}")
                    # ç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾
                    video_thumbnail = self._generate_video_thumbnail(scene_data['video_path'])
                    if video_thumbnail:
                        logger.debug(f"è§†é¢‘ç¼©ç•¥å›¾ç”ŸæˆæˆåŠŸ: {scene_data['video_path']}")
                    else:
                        logger.warning(f"è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå¤±è´¥: {scene_data['video_path']}")

                    if video_thumbnail:
                        thumbnail_label = QLabel()
                        # ä¸å›¾åƒç¼©ç•¥å›¾ä¿æŒä¸€è‡´çš„å°ºå¯¸ï¼ˆ80x60ï¼‰
                        scaled_thumbnail = video_thumbnail.scaled(80, 60, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
                        thumbnail_label.setPixmap(scaled_thumbnail)
                        thumbnail_label.setToolTip(f"è§†é¢‘: {os.path.basename(scene_data['video_path'])}")
                        video_layout.addWidget(thumbnail_label)

                    # æ’­æ”¾æŒ‰é’®
                    play_btn = QPushButton("â–¶")
                    play_btn.setMaximumSize(30, 25)
                    play_btn.setToolTip("æ’­æ”¾è§†é¢‘")
                    play_btn.clicked.connect(lambda checked=False, path=scene_data['video_path']: self.play_video(path))
                    video_layout.addWidget(play_btn)
                else:
                    # æ²¡æœ‰è§†é¢‘æ—¶æ˜¾ç¤ºå ä½ç¬¦
                    no_video_label = QLabel("æš‚æ— è§†é¢‘")
                    no_video_label.setStyleSheet("color: #666; font-size: 12px;")
                    no_video_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
                    video_layout.addWidget(no_video_label)

                self.scene_table.setCellWidget(row, 4, video_widget)

                # çŠ¶æ€æŒ‰é’®
                action_widget = QWidget()
                action_layout = QVBoxLayout(action_widget)
                action_layout.setContentsMargins(2, 2, 2, 2)
                action_layout.setSpacing(2)

                # æ£€æŸ¥é…éŸ³æ—¶é•¿å’Œæ‰€éœ€å›¾åƒæ•°é‡
                voice_duration = scene_data.get('voice_duration', 0.0)
                required_images, segment_durations = self._check_voice_duration_match(scene_data)
                scene_images = self._get_scene_images(scene_data)

                # ç”Ÿæˆè§†é¢‘æŒ‰é’®
                generate_btn = QPushButton("ğŸ¬ ç”Ÿæˆ")
                generate_btn.setMaximumSize(80, 25)

                # æ ¹æ®çŠ¶æ€è®¾ç½®æŒ‰é’®æ ·å¼å’Œæ–‡æœ¬
                status = scene_data.get('status', 'æœªç”Ÿæˆ')
                if status == 'å·²ç”Ÿæˆ':
                    generate_btn.setText("ğŸ”„ é‡æ–°ç”Ÿæˆ")
                    generate_btn.setStyleSheet("QPushButton { background-color: #FF9800; color: white; font-size: 10px; }")
                elif status == 'ç”Ÿæˆä¸­':
                    generate_btn.setText("â¸ ç”Ÿæˆä¸­...")
                    generate_btn.setEnabled(False)
                    generate_btn.setStyleSheet("QPushButton { background-color: #FFC107; color: black; font-size: 10px; }")
                else:
                    generate_btn.setStyleSheet("QPushButton { background-color: #4CAF50; color: white; font-size: 10px; }")

                # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å›¾åƒæ–‡ä»¶
                has_enough_images = len(scene_images) >= required_images

                # è®¾ç½®æŒ‰é’®çŠ¶æ€å’Œæç¤º
                if voice_duration > 10.0 and not has_enough_images:
                    generate_btn.setEnabled(False)
                    generate_btn.setToolTip(f"é…éŸ³æ—¶é•¿{voice_duration:.1f}sï¼Œéœ€è¦{required_images}ä¸ªå›¾åƒï¼Œå½“å‰åªæœ‰{len(scene_images)}ä¸ª")
                    generate_btn.setStyleSheet("QPushButton { background-color: #F44336; color: white; font-size: 10px; }")
                elif voice_duration > 10.0:
                    generate_btn.setEnabled(True)
                    generate_btn.setToolTip(f"é…éŸ³æ—¶é•¿{voice_duration:.1f}sï¼Œå°†ç”Ÿæˆ{required_images}ä¸ªè§†é¢‘ç‰‡æ®µ")
                else:
                    has_image = scene_data['image_path'] and os.path.exists(scene_data['image_path'])
                    has_voice = scene_data['voice_path'] and os.path.exists(scene_data['voice_path'])
                    is_not_generating = scene_data.get('status', 'æœªç”Ÿæˆ') != 'ç”Ÿæˆä¸­'

                    # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯å¸ƒå°”ç±»å‹
                    enable_button = bool(has_image and has_voice and is_not_generating)
                    generate_btn.setEnabled(enable_button)

                    if voice_duration > 0:
                        generate_btn.setToolTip(f"é…éŸ³æ—¶é•¿{voice_duration:.1f}sï¼Œç”Ÿæˆå•ä¸ªè§†é¢‘")
                    else:
                        generate_btn.setToolTip("ç”Ÿæˆè§†é¢‘")

                generate_btn.clicked.connect(lambda checked=False, r=row: self.generate_single_video(r))
                action_layout.addWidget(generate_btn)

                # å¦‚æœéœ€è¦å¤šä¸ªå›¾åƒï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
                if voice_duration > 10.0:
                    info_label = QLabel(f"éœ€è¦{required_images}å›¾")
                    info_label.setStyleSheet("color: #666; font-size: 9px;")
                    info_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
                    action_layout.addWidget(info_label)

                self.scene_table.setCellWidget(row, 5, action_widget)

            # è¿æ¥è¡Œé€‰æ‹©äº‹ä»¶
            self.scene_table.itemSelectionChanged.connect(self.on_scene_row_selected)

        except Exception as e:
            logger.error(f"æ›´æ–°åœºæ™¯è¡¨æ ¼å¤±è´¥: {e}")

    def play_video(self, video_path):
        """æ’­æ”¾è§†é¢‘"""
        try:
            import subprocess
            import platform

            if platform.system() == "Windows":
                subprocess.run(["start", video_path], shell=True, check=True)
            elif platform.system() == "Darwin":  # macOS
                subprocess.run(["open", video_path], check=True)
            else:  # Linux
                subprocess.run(["xdg-open", video_path], check=True)

        except Exception as e:
            logger.error(f"æ’­æ”¾è§†é¢‘å¤±è´¥: {e}")
            QMessageBox.warning(self, "è­¦å‘Š", f"æ— æ³•æ’­æ”¾è§†é¢‘: {str(e)}")

    def generate_single_video(self, row):
        """ç”Ÿæˆå•ä¸ªè§†é¢‘"""
        try:
            if row < 0 or row >= len(self.current_scenes):
                return

            scene_data = self.current_scenes[row]

            # æ£€æŸ¥å¿…è¦æ–‡ä»¶
            if not scene_data['image_path'] or not os.path.exists(scene_data['image_path']):
                QMessageBox.warning(self, "è­¦å‘Š", "è¯¥åœºæ™¯ç¼ºå°‘å›¾åƒæ–‡ä»¶")
                return

            # å¼€å§‹ç”Ÿæˆ
            self.start_generation([scene_data])

        except Exception as e:
            logger.error(f"ç”Ÿæˆå•ä¸ªè§†é¢‘å¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"ç”Ÿæˆå¤±è´¥: {str(e)}")

    def on_scene_selection_changed(self):
        """åœºæ™¯é€‰æ‹©çŠ¶æ€æ”¹å˜"""
        selected_count = self.get_selected_scene_count()
        self.batch_generate_btn.setText(f"ğŸ¬ æ‰¹é‡ç”Ÿæˆ ({selected_count})")
        self.batch_generate_btn.setEnabled(selected_count > 0)

    def on_scene_row_selected(self):
        """åœºæ™¯è¡Œè¢«é€‰ä¸­"""
        try:
            current_row = self.scene_table.currentRow()
            if 0 <= current_row < len(self.current_scenes):
                scene_data = self.current_scenes[current_row]

                # æ›´æ–°å›¾åƒé¢„è§ˆ
                self.update_image_preview(scene_data['image_path'])

                # æ›´æ–°æè¿°é¢„è§ˆ - æ˜¾ç¤º original_prompt + technical_details
                original_prompt = scene_data.get('original_prompt', '')
                technical_details = scene_data.get('technical_details', '')

                preview_text = ""
                if original_prompt:
                    preview_text += f"åŸå§‹æè¿°ï¼š\n{original_prompt}\n\n"
                if technical_details:
                    preview_text += f"æŠ€æœ¯ç»†èŠ‚ï¼š\n{technical_details}"

                if not preview_text:
                    # å¦‚æœæ²¡æœ‰è¿™ä¸¤ä¸ªå­—æ®µï¼Œä½¿ç”¨åŸæ¥çš„é€»è¾‘
                    preview_text = scene_data.get('enhanced_description') or scene_data.get('description', '')

                self.description_preview.setPlainText(preview_text)

                # å¯ç”¨å•ä¸ªç”ŸæˆæŒ‰é’®
                image_path = scene_data.get('image_path', '')
                has_image = bool(image_path and os.path.exists(image_path))
                self.single_generate_btn.setEnabled(has_image)

        except Exception as e:
            logger.error(f"å¤„ç†åœºæ™¯é€‰æ‹©å¤±è´¥: {e}")

    def update_image_preview(self, image_path):
        """æ›´æ–°å›¾åƒé¢„è§ˆ"""
        try:
            if image_path and os.path.exists(image_path):
                pixmap = QPixmap(image_path)
                if not pixmap.isNull():
                    # ç¼©æ”¾å›¾åƒä»¥é€‚åº”é¢„è§ˆåŒºåŸŸ
                    scaled_pixmap = pixmap.scaled(
                        self.image_preview.size(),
                        Qt.AspectRatioMode.KeepAspectRatio,
                        Qt.TransformationMode.SmoothTransformation
                    )
                    self.image_preview.setPixmap(scaled_pixmap)
                else:
                    self.image_preview.setText("æ— æ³•åŠ è½½å›¾åƒ")
            else:
                self.image_preview.setText("æ— å›¾åƒæ–‡ä»¶")

        except Exception as e:
            logger.error(f"æ›´æ–°å›¾åƒé¢„è§ˆå¤±è´¥: {e}")
            self.image_preview.setText("å›¾åƒåŠ è½½å¤±è´¥")

    def get_selected_scene_count(self):
        """è·å–é€‰ä¸­çš„åœºæ™¯æ•°é‡"""
        count = 0
        for row in range(self.scene_table.rowCount()):
            checkbox = self.scene_table.cellWidget(row, 0)
            if checkbox and isinstance(checkbox, QCheckBox) and checkbox.isChecked():
                count += 1
        return count

    def get_selected_scenes(self):
        """è·å–é€‰ä¸­çš„åœºæ™¯æ•°æ®"""
        selected_scenes = []
        for row in range(self.scene_table.rowCount()):
            checkbox = self.scene_table.cellWidget(row, 0)
            if checkbox and isinstance(checkbox, QCheckBox) and checkbox.isChecked() and row < len(self.current_scenes):
                selected_scenes.append(self.current_scenes[row])
        return selected_scenes

    def select_all_scenes(self):
        """å…¨é€‰åœºæ™¯"""
        for row in range(self.scene_table.rowCount()):
            checkbox = self.scene_table.cellWidget(row, 0)
            if checkbox and isinstance(checkbox, QCheckBox):
                checkbox.setChecked(True)

    def select_none_scenes(self):
        """å–æ¶ˆå…¨é€‰åœºæ™¯"""
        for row in range(self.scene_table.rowCount()):
            checkbox = self.scene_table.cellWidget(row, 0)
            if checkbox and isinstance(checkbox, QCheckBox):
                checkbox.setChecked(False)

    def start_single_generation(self):
        """å¼€å§‹å•ä¸ªè§†é¢‘ç”Ÿæˆ"""
        try:
            current_row = self.scene_table.currentRow()
            if current_row < 0 or current_row >= len(self.current_scenes):
                QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªåœºæ™¯")
                return

            scene_data = self.current_scenes[current_row]

            # æ£€æŸ¥å¿…è¦æ–‡ä»¶
            if not scene_data['image_path'] or not os.path.exists(scene_data['image_path']):
                QMessageBox.warning(self, "è­¦å‘Š", "è¯¥åœºæ™¯ç¼ºå°‘å›¾åƒæ–‡ä»¶")
                return

            # å¼€å§‹ç”Ÿæˆ
            self.start_generation([scene_data])

        except Exception as e:
            logger.error(f"å¼€å§‹å•ä¸ªç”Ÿæˆå¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"å¼€å§‹ç”Ÿæˆå¤±è´¥: {str(e)}")

    def start_batch_generation(self):
        """å¼€å§‹æ‰¹é‡è§†é¢‘ç”Ÿæˆ"""
        try:
            selected_scenes = self.get_selected_scenes()

            if not selected_scenes:
                QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©è¦ç”Ÿæˆçš„åœºæ™¯")
                return

            # æ£€æŸ¥é€‰ä¸­åœºæ™¯çš„å›¾åƒæ–‡ä»¶
            missing_images = []
            for scene in selected_scenes:
                if not scene['image_path'] or not os.path.exists(scene['image_path']):
                    missing_images.append(f"{scene['scene_title']}-{scene['shot_title']}")

            if missing_images:
                reply = QMessageBox.question(
                    self, "ç¡®è®¤",
                    f"ä»¥ä¸‹åœºæ™¯ç¼ºå°‘å›¾åƒæ–‡ä»¶ï¼Œæ˜¯å¦è·³è¿‡ï¼Ÿ\n\n{chr(10).join(missing_images)}",
                    QMessageBox.StandardButton.Yes,
                    QMessageBox.StandardButton.No
                )
                if reply == QMessageBox.StandardButton.No:
                    return

                # è¿‡æ»¤æ‰ç¼ºå°‘å›¾åƒçš„åœºæ™¯
                selected_scenes = [s for s in selected_scenes if s['image_path'] and os.path.exists(s['image_path'])]

            if not selected_scenes:
                QMessageBox.warning(self, "è­¦å‘Š", "æ²¡æœ‰å¯ç”Ÿæˆçš„åœºæ™¯")
                return

            # å¼€å§‹ç”Ÿæˆ
            self.start_generation(selected_scenes)

        except Exception as e:
            logger.error(f"å¼€å§‹æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"å¼€å§‹ç”Ÿæˆå¤±è´¥: {str(e)}")

    def start_generation(self, scenes_to_generate):
        """å¼€å§‹è§†é¢‘ç”Ÿæˆï¼ˆå¹¶å‘æ¨¡å¼ï¼‰"""
        try:
            # ğŸ”§ ä¿®å¤ï¼šåŠ¨æ€è·å–ç”¨æˆ·è®¾ç½®çš„å¹¶å‘æ•°
            user_concurrent = int(self.concurrent_tasks_combo.currentText())
            self.max_concurrent_videos = user_concurrent
            logger.info(f"ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„å¹¶å‘æ•°: {self.max_concurrent_videos}")

            # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
            if len(self.active_workers) >= self.max_concurrent_videos:
                QMessageBox.warning(self, "è­¦å‘Š", f"å·²è¾¾åˆ°æœ€å¤§å¹¶å‘æ•°({self.max_concurrent_videos})ï¼Œè¯·ç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆ")
                return

            # ğŸ”§ ä¿®å¤ï¼šè®°å½•å®é™…æäº¤çš„åœºæ™¯ï¼Œç”¨äºæ­£ç¡®ç»Ÿè®¡
            self._submitted_scenes = scenes_to_generate.copy()

            # è®¾ç½®ç”Ÿæˆé˜Ÿåˆ—
            self.generation_queue = scenes_to_generate.copy()

            logger.info(f"å¼€å§‹å¹¶å‘ç”Ÿæˆ {len(scenes_to_generate)} ä¸ªè§†é¢‘ï¼Œæœ€å¤§å¹¶å‘æ•°: {self.max_concurrent_videos}")

            # å¯åŠ¨å¹¶å‘ç”Ÿæˆ
            self.start_concurrent_generation()

        except Exception as e:
            logger.error(f"å¼€å§‹ç”Ÿæˆå¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"å¼€å§‹ç”Ÿæˆå¤±è´¥: {str(e)}")

    def start_concurrent_generation(self):
        """å¯åŠ¨å¹¶å‘ç”Ÿæˆ"""
        try:
            # å¯åŠ¨å°½å¯èƒ½å¤šçš„å¹¶å‘ä»»åŠ¡
            while (len(self.active_workers) < self.max_concurrent_videos and
                   self.generation_queue):

                # è·å–ä¸‹ä¸€ä¸ªåœºæ™¯
                current_scene = self.generation_queue.pop(0)
                scene_id = current_scene.get('shot_id', f"scene_{len(self.active_workers)}")

                # å¯åŠ¨å•ä¸ªç”Ÿæˆä»»åŠ¡
                self.start_single_video_generation(current_scene, scene_id)

            logger.info(f"å½“å‰æ´»è·ƒä»»åŠ¡æ•°: {len(self.active_workers)}/{self.max_concurrent_videos}, é˜Ÿåˆ—å‰©ä½™: {len(self.generation_queue)}")

        except Exception as e:
            logger.error(f"å¯åŠ¨å¹¶å‘ç”Ÿæˆå¤±è´¥: {e}")

    def start_single_video_generation(self, scene, scene_id):
        """å¯åŠ¨å•ä¸ªè§†é¢‘ç”Ÿæˆä»»åŠ¡"""
        try:
            # è·å–å¹¶è®¾ç½®æç¤ºè¯
            shot_id = scene.get('shot_id', '')
            prompt_from_file = self._get_prompt_for_shot(shot_id)
            if prompt_from_file:
                scene['prompt'] = prompt_from_file
                logger.info(f"ä¸ºé•œå¤´ {shot_id} è®¾ç½®æç¤ºè¯: {prompt_from_file[:50]}...")
            else:
                scene['prompt'] = scene.get('enhanced_description', scene.get('description', ''))

            # è·å–éŸ³æ•ˆæç¤º
            audio_hint = self._get_audio_hint_for_shot(shot_id)
            if audio_hint:
                scene['audio_hint'] = audio_hint

            # æ›´æ–°çŠ¶æ€
            self.update_scene_status(scene, 'ç”Ÿæˆä¸­')

            # è·å–ç”Ÿæˆé…ç½®
            image_path = scene.get('image_path', '')
            voice_duration = scene.get('voice_duration', 0.0)

            # è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥å›¾åƒè·¯å¾„
            logger.info(f"å‡†å¤‡ç”Ÿæˆè§†é¢‘ - é•œå¤´ID: {scene.get('shot_id')}, å›¾åƒè·¯å¾„: {image_path}")
            if image_path and os.path.exists(image_path):
                logger.info(f"å›¾åƒæ–‡ä»¶å­˜åœ¨ï¼Œå°†è¿›è¡Œåˆ†è¾¨ç‡è°ƒæ•´")
            else:
                logger.warning(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„ä¸ºç©ºï¼Œå°†ä½¿ç”¨é»˜è®¤åˆ†è¾¨ç‡1024x1024")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤šç‰‡æ®µç”Ÿæˆ
            required_images, segment_durations = self._check_voice_duration_match(scene)
            scene_images = self._get_scene_images(scene)

            if voice_duration > 10.0 and len(scene_images) >= required_images:
                # å¤šç‰‡æ®µç”Ÿæˆæ¨¡å¼
                self._generate_multi_segment_video(scene, scene_images, segment_durations)
                return
            else:
                # å•ç‰‡æ®µç”Ÿæˆæ¨¡å¼
                audio_hint = scene.get('audio_hint')
                generation_config = self.get_generation_config(image_path, voice_duration if voice_duration > 0 else None, audio_hint)

                # è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥ç”Ÿæˆé…ç½®
                logger.info(f"ç”Ÿæˆé…ç½® - åˆ†è¾¨ç‡: {generation_config.get('width')}x{generation_config.get('height')}, å¼•æ“: {generation_config.get('engine')}")

            # åˆ›å»ºå·¥ä½œçº¿ç¨‹
            worker = VideoGenerationWorker(
                scene,
                generation_config,
                self.project_manager,
                self.project_manager.current_project_name if self.project_manager else None
            )

            # è¿æ¥ä¿¡å·
            worker.progress_updated.connect(lambda p, msg, sid=scene_id: self.on_concurrent_progress_updated(sid, p, msg))
            worker.video_generated.connect(lambda path, success, error, sid=scene_id: self.on_concurrent_video_generated(sid, path, success, error))

            # æ·»åŠ åˆ°æ´»è·ƒä»»åŠ¡
            self.active_workers[scene_id] = {
                'worker': worker,
                'scene': scene,
                'start_time': time.time()
            }

            # æ˜¾ç¤ºè¿›åº¦ç•Œé¢ï¼ˆå¦‚æœæ˜¯ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼‰
            if len(self.active_workers) == 1:
                self.show_generation_progress()

            # å¼€å§‹ç”Ÿæˆ
            worker.start()
            logger.info(f"å¯åŠ¨è§†é¢‘ç”Ÿæˆä»»åŠ¡: {scene_id}")

        except Exception as e:
            logger.error(f"å¯åŠ¨å•ä¸ªç”Ÿæˆä»»åŠ¡å¤±è´¥: {e}")
            self.update_scene_status(scene, 'å¤±è´¥')

    def process_next_generation(self):
        """å¤„ç†ä¸‹ä¸€ä¸ªç”Ÿæˆä»»åŠ¡"""
        try:
            if not self.generation_queue:
                # æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                self.on_all_generation_complete()
                return

            # è·å–ä¸‹ä¸€ä¸ªåœºæ™¯
            current_scene = self.generation_queue.pop(0)

            # è·å–å¹¶è®¾ç½®æç¤ºè¯
            shot_id = current_scene.get('shot_id', '')
            prompt_from_file = self._get_prompt_for_shot(shot_id)
            if prompt_from_file:
                # ğŸ”§ æ–°å¢ï¼šä½¿ç”¨CogVideoXä¼˜åŒ–å™¨ä¼˜åŒ–æç¤ºè¯
                optimized_prompt = self._optimize_prompt_for_cogvideox(prompt_from_file, shot_id)
                current_scene['prompt'] = optimized_prompt
                logger.info(f"ä¸ºé•œå¤´ {shot_id} è®¾ç½®ä¼˜åŒ–æç¤ºè¯: {optimized_prompt[:80]}...")
            else:
                # ä½¿ç”¨åŸæœ‰çš„æè¿°ä½œä¸ºæç¤ºè¯ï¼Œä¹Ÿè¿›è¡Œä¼˜åŒ–
                original_desc = current_scene.get('enhanced_description', current_scene.get('description', ''))
                optimized_prompt = self._optimize_prompt_for_cogvideox(original_desc, shot_id)
                current_scene['prompt'] = optimized_prompt

            # è·å–éŸ³æ•ˆæç¤º
            audio_hint = self._get_audio_hint_for_shot(shot_id)
            if audio_hint:
                current_scene['audio_hint'] = audio_hint

            # ä¿å­˜å½“å‰ç”Ÿæˆçš„åœºæ™¯
            self._current_generating_scene = current_scene

            # æ›´æ–°çŠ¶æ€
            self.update_scene_status(current_scene, 'ç”Ÿæˆä¸­')

            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤šç‰‡æ®µç”Ÿæˆ
            voice_duration = current_scene.get('voice_duration', 0.0)
            required_images, segment_durations = self._check_voice_duration_match(current_scene)
            scene_images = self._get_scene_images(current_scene)

            # è·å–ç”Ÿæˆé…ç½®
            image_path = current_scene.get('image_path', '')

            if voice_duration > 10.0 and len(scene_images) >= required_images:
                # å¤šç‰‡æ®µç”Ÿæˆæ¨¡å¼
                self._generate_multi_segment_video(current_scene, scene_images, segment_durations)
            else:
                # å•ç‰‡æ®µç”Ÿæˆæ¨¡å¼
                audio_hint = current_scene.get('audio_hint')
                generation_config = self.get_generation_config(image_path, voice_duration if voice_duration > 0 else None, audio_hint)

            # åˆ›å»ºå·¥ä½œçº¿ç¨‹
            self.current_worker = VideoGenerationWorker(
                current_scene,
                generation_config,
                self.project_manager,
                self.project_manager.current_project_name if self.project_manager else None
            )

            # è¿æ¥ä¿¡å·
            self.current_worker.progress_updated.connect(self.on_progress_updated)
            self.current_worker.video_generated.connect(self.on_video_generated)

            # æ˜¾ç¤ºè¿›åº¦ç•Œé¢
            self.show_generation_progress()

            # å¼€å§‹ç”Ÿæˆ
            self.current_worker.start()

        except Exception as e:
            logger.error(f"å¤„ç†ä¸‹ä¸€ä¸ªç”Ÿæˆä»»åŠ¡å¤±è´¥: {e}")
            self.on_generation_error(str(e))

    def get_generation_config(self, image_path=None, target_duration=None, audio_hint=None):
        """è·å–ç”Ÿæˆé…ç½®"""
        try:
            # é»˜è®¤åˆ†è¾¨ç‡
            width, height = 1024, 1024

            # å¦‚æœæä¾›äº†å›¾åƒè·¯å¾„ï¼Œå°è¯•è·å–å›¾åƒå°ºå¯¸å¹¶è°ƒæ•´ä¸ºæ”¯æŒçš„åˆ†è¾¨ç‡
            if image_path and os.path.exists(image_path):
                try:
                    from PIL import Image
                    with Image.open(image_path) as img:
                        img_width, img_height = img.size
                        logger.info(f"ä½¿ç”¨å›¾åƒå°ºå¯¸: {img_width}x{img_height}")

                        # è°ƒæ•´ä¸ºæ”¯æŒçš„åˆ†è¾¨ç‡
                        adjusted_resolution = self._adjust_to_supported_resolution(img_width, img_height)
                        width, height = adjusted_resolution

                        if (width, height) != (img_width, img_height):
                            logger.info(f"åˆ†è¾¨ç‡è°ƒæ•´: {img_width}x{img_height} -> {width}x{height}")

                except Exception as e:
                    logger.warning(f"æ— æ³•è·å–å›¾åƒå°ºå¯¸ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            elif not image_path:
                # åªæœ‰åœ¨æ²¡æœ‰æä¾›å›¾åƒè·¯å¾„æ—¶æ‰æ˜¾ç¤ºè­¦å‘Š
                logger.debug("æ²¡æœ‰æä¾›å›¾åƒè·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤åˆ†è¾¨ç‡ 1024x1024")

            # ç¡®å®šè§†é¢‘æ—¶é•¿
            if target_duration is not None:
                # ä½¿ç”¨æŒ‡å®šçš„ç›®æ ‡æ—¶é•¿ï¼Œè‡ªåŠ¨è°ƒæ•´åˆ°æ”¯æŒçš„æ—¶é•¿
                original_duration = target_duration
                duration = self._validate_duration(target_duration)
                if duration != original_duration:
                    logger.info(f"ç›®æ ‡æ—¶é•¿å·²è‡ªåŠ¨è°ƒæ•´: {original_duration}s -> {duration}s")
            else:
                # ä½¿ç”¨UIè®¾ç½®çš„æ—¶é•¿
                duration = int(self.duration_combo.currentText())

            config = {
                'engine': 'cogvideox_flash',
                'duration': duration,
                'fps': int(self.fps_combo.currentText()),
                'width': width,
                'height': height,
                'motion_intensity': self.motion_slider.value() / 100.0,
                'max_concurrent_tasks': int(self.concurrent_tasks_combo.currentText())
            }

            # æ·»åŠ éŸ³æ•ˆæç¤º
            if audio_hint:
                config['audio_hint'] = audio_hint

            return config

        except Exception as e:
            logger.error(f"è·å–ç”Ÿæˆé…ç½®å¤±è´¥: {e}")
            return {
                'engine': 'cogvideox_flash',
                'duration': 5,
                'fps': 30,
                'width': 1024,
                'height': 1024,
                'motion_intensity': 0.5,
                'max_concurrent_tasks': 3
            }

    def _validate_duration(self, duration):
        """éªŒè¯å¹¶è°ƒæ•´è§†é¢‘æ—¶é•¿åˆ°æœ€æ¥è¿‘çš„æ”¯æŒæ—¶é•¿"""
        supported_durations = [5, 10]  # CogVideoX-Flashåªæ”¯æŒ5ç§’å’Œ10ç§’

        # ğŸ”§ ä¼˜åŒ–ï¼šæ ¹æ®é…éŸ³æ—¶é•¿æ™ºèƒ½é€‰æ‹©è§†é¢‘æ—¶é•¿
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æ˜ç¡®é€‰æ‹©äº†æ—¶é•¿
        user_selected_duration = int(self.duration_combo.currentText()) if hasattr(self, 'duration_combo') else 5

        # å¦‚æœæœ‰ç›®æ ‡æ—¶é•¿ï¼ˆé€šå¸¸æ¥è‡ªé…éŸ³æ—¶é•¿ï¼‰ï¼Œæ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„è§†é¢‘æ—¶é•¿
        if duration > 0:
            if duration <= 5:
                # é…éŸ³æ—¶é•¿5ç§’ä»¥å†…ï¼Œä½¿ç”¨5ç§’è§†é¢‘
                adjusted_duration = 5
                logger.info(f"é…éŸ³æ—¶é•¿{duration:.1f}s â‰¤ 5sï¼Œé€‰æ‹©5ç§’è§†é¢‘æ—¶é•¿")
            elif duration <= 10:
                # é…éŸ³æ—¶é•¿5-10ç§’ï¼Œä½¿ç”¨10ç§’è§†é¢‘
                adjusted_duration = 10
                logger.info(f"é…éŸ³æ—¶é•¿{duration:.1f}s â‰¤ 10sï¼Œé€‰æ‹©10ç§’è§†é¢‘æ—¶é•¿")
            else:
                # é…éŸ³æ—¶é•¿è¶…è¿‡10ç§’ï¼Œä½¿ç”¨10ç§’è§†é¢‘ï¼ˆåç»­é€šè¿‡å¾ªç¯æ’­æ”¾åŒ¹é…ï¼‰
                adjusted_duration = 10
                logger.info(f"é…éŸ³æ—¶é•¿{duration:.1f}s > 10sï¼Œé€‰æ‹©10ç§’è§†é¢‘æ—¶é•¿ï¼ˆå°†é€šè¿‡å¾ªç¯æ’­æ”¾åŒ¹é…é…éŸ³æ—¶é•¿ï¼‰")
        else:
            # æ²¡æœ‰ç›®æ ‡æ—¶é•¿ï¼Œä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ—¶é•¿
            adjusted_duration = user_selected_duration
            logger.info(f"ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ—¶é•¿: {adjusted_duration}s")

        return adjusted_duration

    def _adjust_to_supported_resolution(self, width, height):
        """è°ƒæ•´ä¸ºæ”¯æŒçš„åˆ†è¾¨ç‡ï¼Œä¼˜å…ˆä¿æŒå®½é«˜æ¯”"""
        # CogVideoX-Flashå®˜æ–¹æ”¯æŒçš„å®Œæ•´åˆ†è¾¨ç‡åˆ—è¡¨
        supported_resolutions = [
            (720, 480),     # æ ‡å‡†æ¸…æ™°åº¦
            (1024, 1024),   # æ­£æ–¹å½¢
            (1280, 960),    # 4:3 æ¨ªå±
            (960, 1280),    # 3:4 ç«–å±
            (1920, 1080),   # Full HD æ¨ªå±
            (1080, 1920),   # Full HD ç«–å±
            (2048, 1080),   # è¶…å®½å±
            (3840, 2160),   # 4K
        ]

        target_ratio = width / height

        # é¦–å…ˆæŒ‰ç…§å›¾åƒæ–¹å‘åˆ†ç±»
        if target_ratio > 1.2:
            # æ¨ªå±å›¾åƒ (å®½ > é«˜)
            candidate_resolutions = [(w, h) for w, h in supported_resolutions if w > h]
        elif target_ratio < 0.8:
            # ç«–å±å›¾åƒ (é«˜ > å®½)
            candidate_resolutions = [(w, h) for w, h in supported_resolutions if h > w]
        else:
            # æ¥è¿‘æ­£æ–¹å½¢çš„å›¾åƒ
            candidate_resolutions = [(w, h) for w, h in supported_resolutions if 0.8 <= w/h <= 1.2]

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒæ–¹å‘çš„åˆ†è¾¨ç‡ï¼Œä½¿ç”¨æ‰€æœ‰åˆ†è¾¨ç‡
        if not candidate_resolutions:
            candidate_resolutions = supported_resolutions

        # åœ¨å€™é€‰åˆ†è¾¨ç‡ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…
        best_resolution = candidate_resolutions[0]
        best_score = float('inf')

        for res_width, res_height in candidate_resolutions:
            res_ratio = res_width / res_height

            # è®¡ç®—æ¯”ä¾‹å·®å¼‚ï¼ˆæƒé‡æœ€é«˜ï¼‰
            ratio_diff = abs(target_ratio - res_ratio) / max(target_ratio, res_ratio)

            # è®¡ç®—é¢ç§¯å·®å¼‚
            target_area = width * height
            res_area = res_width * res_height
            area_diff = abs(target_area - res_area) / max(target_area, res_area)

            # ç»¼åˆè¯„åˆ†ï¼ˆæ¯”ä¾‹æƒé‡0.8ï¼Œé¢ç§¯æƒé‡0.2ï¼‰
            score = ratio_diff * 0.8 + area_diff * 0.2

            if score < best_score:
                best_score = score
                best_resolution = (res_width, res_height)

        return best_resolution

    def _generate_video_thumbnail(self, video_path):
        """ç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾"""
        try:
            # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(video_path):
                logger.warning(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                return None

            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(video_path)
            if file_size == 0:
                logger.warning(f"è§†é¢‘æ–‡ä»¶ä¸ºç©º: {video_path}")
                return None

            logger.debug(f"å°è¯•ç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾: {video_path} (å¤§å°: {file_size} å­—èŠ‚)")

            import cv2

            # æ‰“å¼€è§†é¢‘æ–‡ä»¶
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                logger.warning(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
                return None

            # è·å–è§†é¢‘ä¿¡æ¯
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = frame_count / fps if fps > 0 else 0

            logger.debug(f"è§†é¢‘ä¿¡æ¯: å¸§æ•°={frame_count}, FPS={fps:.2f}, æ—¶é•¿={duration:.2f}ç§’")

            # å°è¯•è·³åˆ°è§†é¢‘çš„1/4ä½ç½®è·å–å¸§ï¼ˆé¿å…é»‘å±ï¼‰
            if frame_count > 10:
                target_frame = min(frame_count // 4, 30)  # æœ€å¤šè·³åˆ°ç¬¬30å¸§
                cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
                logger.debug(f"è·³è½¬åˆ°ç¬¬{target_frame}å¸§")

            # è·å–è§†é¢‘å¸§
            ret, frame = cap.read()
            cap.release()

            if not ret or frame is None:
                logger.warning(f"æ— æ³•è¯»å–è§†é¢‘å¸§: {video_path}")
                return None

            # æ£€æŸ¥å¸§çš„æœ‰æ•ˆæ€§
            if frame.size == 0:
                logger.warning(f"è¯»å–åˆ°ç©ºå¸§: {video_path}")
                return None

            # å°†OpenCVçš„BGRæ ¼å¼è½¬æ¢ä¸ºRGBæ ¼å¼
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # è½¬æ¢ä¸ºQPixmap
            from PyQt5.QtGui import QImage, QPixmap
            height, width, _ = frame_rgb.shape  # å¿½ç•¥channelå˜é‡
            bytes_per_line = 3 * width
            q_image = QImage(frame_rgb.data, width, height, bytes_per_line, QImage.Format_RGB888)
            pixmap = QPixmap.fromImage(q_image)

            if pixmap.isNull():
                logger.warning(f"ç”Ÿæˆçš„QPixmapä¸ºç©º: {video_path}")
                return None

            logger.debug(f"æˆåŠŸç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾: {video_path} -> {width}x{height}")
            return pixmap

        except ImportError:
            logger.warning("OpenCVæœªå®‰è£…ï¼Œæ— æ³•ç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾")
            return None
        except Exception as e:
            logger.error(f"ç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾å¤±è´¥: {video_path} -> {e}")
            return None

    def _get_prompt_for_shot(self, shot_id):
        """è·å–æŒ‡å®šé•œå¤´çš„æç¤ºè¯"""
        try:
            if not self.project_manager:
                return None

            # è·å–é¡¹ç›®ç›®å½•
            project_data = self.project_manager.get_project_data()
            if not project_data:
                return None

            project_dir = project_data.get('project_dir', '')
            if not project_dir:
                # å°è¯•ä½¿ç”¨å½“å‰é¡¹ç›®åç§°æ„å»ºè·¯å¾„
                if hasattr(self.project_manager, 'current_project_name') and self.project_manager.current_project_name:
                    project_dir = os.path.join(self.project_manager.projects_dir, self.project_manager.current_project_name)
                elif hasattr(self.project_manager, 'projects_dir'):
                    # å°è¯•ä½¿ç”¨é»˜è®¤é¡¹ç›®
                    project_dir = os.path.join(self.project_manager.projects_dir, "æ„Ÿäººæ•…äº‹")
                else:
                    return None

            # æ„å»ºprompt.jsonæ–‡ä»¶è·¯å¾„
            prompt_file = os.path.join(project_dir, 'texts', 'prompt.json')
            if not os.path.exists(prompt_file):
                logger.debug(f"prompt.jsonæ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
                return None

            # è¯»å–prompt.jsonæ–‡ä»¶
            import json
            with open(prompt_file, 'r', encoding='utf-8') as f:
                prompt_data = json.load(f)

            # æŸ¥æ‰¾å¯¹åº”çš„æç¤ºè¯
            # prompt.jsonçš„ç»“æ„æ˜¯ {"scenes": {"åœºæ™¯å": [é•œå¤´æ•°ç»„]}}
            scenes_data = prompt_data.get('scenes', {})

            # æå–shot_idä¸­çš„æ•°å­—éƒ¨åˆ†
            shot_index = None
            if shot_id.startswith('text_segment_'):
                try:
                    shot_index = int(shot_id.replace('text_segment_', ''))
                except ValueError:
                    pass

            if shot_index is None:
                logger.debug(f"æ— æ³•ä»shot_id '{shot_id}' æå–ç´¢å¼•")
                return None

            # éå†æ‰€æœ‰åœºæ™¯ï¼Œæ‰¾åˆ°å¯¹åº”ç´¢å¼•çš„é•œå¤´
            current_index = 1
            for scene_name, shots in scenes_data.items():
                if isinstance(shots, list):
                    for shot in shots:
                        if current_index == shot_index:
                            # ğŸ”§ ä¼˜å…ˆä½¿ç”¨ä¼˜åŒ–åçš„æç¤ºè¯
                            optimized_content = shot.get('optimized_content', '')
                            if optimized_content:
                                logger.debug(f"ä»prompt.jsonè·å–é•œå¤´ {shot_id} (ç´¢å¼•{shot_index}) çš„ä¼˜åŒ–æç¤ºè¯")
                                return optimized_content

                            # å¦‚æœæ²¡æœ‰ä¼˜åŒ–æç¤ºè¯ï¼Œä½¿ç”¨åŸå§‹content
                            content = shot.get('content', '')
                            if content:
                                logger.debug(f"ä»prompt.jsonè·å–é•œå¤´ {shot_id} (ç´¢å¼•{shot_index}) çš„åŸå§‹æç¤ºè¯")
                                return content
                        current_index += 1

            logger.debug(f"åœ¨prompt.jsonä¸­æœªæ‰¾åˆ°é•œå¤´ {shot_id} çš„æç¤ºè¯")
            return None

        except Exception as e:
            logger.warning(f"ä»prompt.jsonè·å–æç¤ºè¯å¤±è´¥: {e}")
            return None

    def _get_audio_hint_for_shot(self, shot_id):
        """è·å–æŒ‡å®šé•œå¤´çš„éŸ³æ•ˆæç¤º"""
        try:
            if not self.project_manager:
                return None

            # è·å–é¡¹ç›®ç›®å½•
            project_data = self.project_manager.get_project_data()
            if not project_data:
                return None

            project_dir = project_data.get('project_dir', '')
            if not project_dir:
                # å°è¯•ä½¿ç”¨å½“å‰é¡¹ç›®åç§°æ„å»ºè·¯å¾„
                if hasattr(self.project_manager, 'current_project_name') and self.project_manager.current_project_name:
                    project_dir = os.path.join(self.project_manager.projects_dir, self.project_manager.current_project_name)
                elif hasattr(self.project_manager, 'projects_dir'):
                    # å°è¯•ä½¿ç”¨é»˜è®¤é¡¹ç›®
                    project_dir = os.path.join(self.project_manager.projects_dir, "æ„Ÿäººæ•…äº‹")
                else:
                    return None

            # æ„å»ºprompt.jsonæ–‡ä»¶è·¯å¾„
            prompt_file = os.path.join(project_dir, 'texts', 'prompt.json')
            if not os.path.exists(prompt_file):
                return None

            # è¯»å–prompt.jsonæ–‡ä»¶
            import json
            with open(prompt_file, 'r', encoding='utf-8') as f:
                prompt_data = json.load(f)

            # æŸ¥æ‰¾å¯¹åº”çš„éŸ³æ•ˆæç¤º
            scenes_data = prompt_data.get('scenes', {})

            # æå–shot_idä¸­çš„æ•°å­—éƒ¨åˆ†
            shot_index = None
            if shot_id.startswith('text_segment_'):
                try:
                    shot_index = int(shot_id.replace('text_segment_', ''))
                except ValueError:
                    pass

            if shot_index is None:
                return None

            # éå†æ‰€æœ‰åœºæ™¯ï¼Œæ‰¾åˆ°å¯¹åº”ç´¢å¼•çš„é•œå¤´
            current_index = 1
            for scene_name, shots in scenes_data.items():
                if isinstance(shots, list):
                    for shot in shots:
                        if current_index == shot_index:
                            # ä»original_descriptionä¸­æå–éŸ³æ•ˆæç¤º
                            original_desc = shot.get('original_description', '')
                            import re
                            audio_match = re.search(r'éŸ³æ•ˆæç¤º[ï¼š:]\s*([^\n]+)', original_desc)
                            if audio_match:
                                audio_hint = audio_match.group(1).strip()
                                if audio_hint and audio_hint != "æ— ":
                                    logger.info(f"æ‰¾åˆ°é•œå¤´ {shot_id} çš„éŸ³æ•ˆæç¤º: {audio_hint}")
                                    return audio_hint
                        current_index += 1

            return None

        except Exception as e:
            logger.warning(f"ä»prompt.jsonè·å–éŸ³æ•ˆæç¤ºå¤±è´¥: {e}")
            return None

    def _generate_multi_segment_video(self, scene_data, scene_images, segment_durations):
        """ç”Ÿæˆå¤šç‰‡æ®µè§†é¢‘"""
        try:
            # åˆ›å»ºå¤šç‰‡æ®µç”Ÿæˆå·¥ä½œçº¿ç¨‹
            self.current_worker = MultiSegmentVideoWorker(
                scene_data,
                scene_images,
                segment_durations,
                self.project_manager,
                self.project_manager.current_project_name if self.project_manager else None
            )

            # è¿æ¥ä¿¡å·
            self.current_worker.progress_updated.connect(self.on_progress_updated)
            self.current_worker.video_generated.connect(self.on_video_generated)

            # æ˜¾ç¤ºè¿›åº¦ç•Œé¢
            self.show_generation_progress()

            # å¼€å§‹ç”Ÿæˆ
            self.current_worker.start()

        except Exception as e:
            logger.error(f"å¤šç‰‡æ®µè§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            self.on_generation_error(str(e))

    def show_generation_progress(self):
        """æ˜¾ç¤ºç”Ÿæˆè¿›åº¦"""
        self.progress_bar.setVisible(True)
        self.progress_bar.setValue(0)
        self.cancel_btn.setVisible(True)
        self.batch_generate_btn.setEnabled(False)
        self.single_generate_btn.setEnabled(False)

    def hide_generation_progress(self):
        """éšè—ç”Ÿæˆè¿›åº¦"""
        self.progress_bar.setVisible(False)
        self.cancel_btn.setVisible(False)
        self.batch_generate_btn.setEnabled(True)
        self.single_generate_btn.setEnabled(True)

    def update_scene_status(self, scene_data, status):
        """æ›´æ–°åœºæ™¯çŠ¶æ€"""
        try:
            logger.info(f"å°è¯•æ›´æ–°åœºæ™¯çŠ¶æ€: {scene_data.get('shot_id', 'unknown')} -> {status}")

            # åœ¨åœºæ™¯åˆ—è¡¨ä¸­æ‰¾åˆ°å¯¹åº”åœºæ™¯å¹¶æ›´æ–°çŠ¶æ€
            scene_found = False
            for i, scene in enumerate(self.current_scenes):
                # ä½¿ç”¨å¤šç§æ–¹å¼åŒ¹é…åœºæ™¯
                scene_match = False

                # æ–¹å¼1ï¼šé€šè¿‡scene_idå’Œshot_idåŒ¹é…
                if (scene.get('scene_id') == scene_data.get('scene_id') and
                    scene.get('shot_id') == scene_data.get('shot_id')):
                    scene_match = True

                # æ–¹å¼2ï¼šé€šè¿‡scene_indexå’Œshot_indexåŒ¹é…ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
                elif (scene.get('scene_index') == scene_data.get('scene_index') and
                      scene.get('shot_index') == scene_data.get('shot_index')):
                    scene_match = True

                # æ–¹å¼3ï¼šé€šè¿‡ç´¢å¼•åŒ¹é…
                elif i < len(self.current_scenes) and scene == scene_data:
                    scene_match = True

                if scene_match:
                    scene['status'] = status
                    scene_found = True
                    logger.info(f"æˆåŠŸæ›´æ–°åœºæ™¯çŠ¶æ€: {scene.get('shot_id', 'unknown')} -> {status}")
                    # åˆ·æ–°è¡¨æ ¼æ˜¾ç¤º
                    self.update_scene_table()
                    break

            if not scene_found:
                logger.warning(f"æœªæ‰¾åˆ°åŒ¹é…çš„åœºæ™¯ï¼Œæ— æ³•æ›´æ–°çŠ¶æ€: {scene_data.get('shot_id', 'unknown')}")

        except Exception as e:
            logger.error(f"æ›´æ–°åœºæ™¯çŠ¶æ€å¤±è´¥: {e}")

    def on_concurrent_progress_updated(self, scene_id, progress, message):
        """å¹¶å‘è¿›åº¦æ›´æ–°"""
        # æ›´æ–°æ€»ä½“è¿›åº¦ï¼ˆæ‰€æœ‰ä»»åŠ¡çš„å¹³å‡è¿›åº¦ï¼‰
        if self.active_workers:
            total_progress = sum([50 for _ in self.active_workers])  # å‡è®¾æ¯ä¸ªä»»åŠ¡50%è¿›åº¦
            avg_progress = total_progress // len(self.active_workers)
            self.progress_bar.setValue(avg_progress)

        # æ›´æ–°çŠ¶æ€ä¿¡æ¯
        active_count = len(self.active_workers)
        queue_count = len(self.generation_queue)
        self.status_label.setText(f"å¹¶å‘ç”Ÿæˆä¸­({active_count}ä¸ªæ´»è·ƒ, {queue_count}ä¸ªç­‰å¾…): {message}")

    def on_concurrent_video_generated(self, scene_id, video_path, success, error_message):
        """å¹¶å‘è§†é¢‘ç”Ÿæˆå®Œæˆ"""
        try:
            if scene_id not in self.active_workers:
                logger.warning(f"æ”¶åˆ°æœªçŸ¥åœºæ™¯çš„ç”Ÿæˆç»“æœ: {scene_id}")
                return

            worker_info = self.active_workers[scene_id]
            scene = worker_info['scene']

            if success:
                # ä¿å­˜è§†é¢‘è·¯å¾„åˆ°é¡¹ç›®æ•°æ®
                self._current_generating_scene = scene  # ä¸´æ—¶è®¾ç½®ç”¨äºä¿å­˜
                self.save_video_to_project(video_path)

                # æ›´æ–°åœºæ™¯çŠ¶æ€
                self.update_scene_status(scene, 'å·²ç”Ÿæˆ')

                # è‡ªåŠ¨æ’­æ”¾è§†é¢‘ï¼ˆä»…ç¬¬ä¸€ä¸ªå®Œæˆçš„ï¼‰
                if self.auto_play_check.isChecked() and len([w for w in self.active_workers.values() if w.get('completed')]) == 0:
                    self.play_video(video_path)

                logger.info(f"è§†é¢‘ç”ŸæˆæˆåŠŸ: {scene_id} -> {os.path.basename(video_path)}")

                # æ ‡è®°ä¸ºå®Œæˆ
                worker_info['completed'] = True

            else:
                # æ›´æ–°å¤±è´¥çŠ¶æ€
                self.update_scene_status(scene, 'å¤±è´¥')
                logger.error(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {scene_id} -> {error_message}")

            # ä»æ´»è·ƒä»»åŠ¡ä¸­ç§»é™¤
            del self.active_workers[scene_id]

            # å¯åŠ¨ä¸‹ä¸€ä¸ªä»»åŠ¡ï¼ˆå¦‚æœé˜Ÿåˆ—ä¸­è¿˜æœ‰ï¼‰
            if self.generation_queue:
                logger.info(f"å¯åŠ¨ä¸‹ä¸€è½®ä»»åŠ¡ï¼Œé˜Ÿåˆ—å‰©ä½™: {len(self.generation_queue)}")
                # ğŸ”§ ä¿®å¤ï¼šå¢åŠ å»¶è¿Ÿä»¥é¿å…ç½‘ç»œè¿æ¥å†²çªå’Œå¼•æ“çŠ¶æ€é—®é¢˜
                QTimer.singleShot(3000, self.start_concurrent_generation)  # å¢åŠ åˆ°3ç§’å»¶è¿Ÿ

            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆ
            if not self.active_workers and not self.generation_queue:
                self.on_all_generation_complete()
            else:
                # æ›´æ–°è¿›åº¦æ˜¾ç¤º
                completed_count = len([s for s in self.current_scenes if s.get('status') == 'å·²ç”Ÿæˆ'])
                total_count = len(self.current_scenes)
                overall_progress = int((completed_count / total_count) * 100) if total_count > 0 else 0
                self.progress_bar.setValue(overall_progress)

                active_count = len(self.active_workers)
                queue_count = len(self.generation_queue)
                self.status_label.setText(f"å¹¶å‘ç”Ÿæˆä¸­({active_count}ä¸ªæ´»è·ƒ, {queue_count}ä¸ªç­‰å¾…)")

        except Exception as e:
            logger.error(f"å¤„ç†å¹¶å‘è§†é¢‘ç”Ÿæˆç»“æœå¤±è´¥: {e}")

    def on_all_generation_complete(self):
        """æ‰€æœ‰ç”Ÿæˆä»»åŠ¡å®Œæˆ"""
        try:
            # éšè—è¿›åº¦ç•Œé¢
            self.hide_generation_progress()

            # ğŸ”§ ä¿®å¤ï¼šç»Ÿè®¡åº”è¯¥åŸºäºå®é™…æäº¤çš„ä»»åŠ¡ï¼Œè€Œä¸æ˜¯æ‰€æœ‰åœºæ™¯
            # è·å–å®é™…æäº¤çš„ä»»åŠ¡IDåˆ—è¡¨
            submitted_scene_ids = set()
            if hasattr(self, '_submitted_scenes'):
                submitted_scene_ids = set(scene.get('shot_id', '') for scene in self._submitted_scenes)

            # å¦‚æœæ²¡æœ‰è®°å½•æäº¤çš„åœºæ™¯ï¼Œåˆ™ä½¿ç”¨æ‰€æœ‰åœºæ™¯ï¼ˆå‘åå…¼å®¹ï¼‰
            if not submitted_scene_ids:
                target_scenes = self.current_scenes
                logger.warning("æœªæ‰¾åˆ°æäº¤çš„åœºæ™¯è®°å½•ï¼Œä½¿ç”¨æ‰€æœ‰åœºæ™¯è¿›è¡Œç»Ÿè®¡")
            else:
                # åªç»Ÿè®¡å®é™…æäº¤çš„åœºæ™¯
                target_scenes = [s for s in self.current_scenes if s.get('shot_id', '') in submitted_scene_ids]
                logger.info(f"ç»Ÿè®¡åŸºäºå®é™…æäº¤çš„ {len(target_scenes)} ä¸ªåœºæ™¯")

            # æ›´æ–°çŠ¶æ€ç»Ÿè®¡
            completed_count = len([s for s in target_scenes if s.get('status') == 'å·²ç”Ÿæˆ'])
            failed_count = len([s for s in target_scenes if s.get('status') == 'å¤±è´¥'])
            total_count = len(target_scenes)

            self.status_label.setText(f"æ‰€æœ‰ç”Ÿæˆä»»åŠ¡å®Œæˆï¼æˆåŠŸ: {completed_count}, å¤±è´¥: {failed_count}, æ€»è®¡: {total_count}")

            # æ˜¾ç¤ºå®Œæˆé€šçŸ¥
            if failed_count == 0:
                QMessageBox.information(self, "å®Œæˆ", f"æ‰€æœ‰ {completed_count} ä¸ªè§†é¢‘ç”Ÿæˆå®Œæˆï¼")
            else:
                QMessageBox.warning(self, "å®Œæˆ", f"ç”Ÿæˆå®Œæˆï¼æˆåŠŸ: {completed_count}, å¤±è´¥: {failed_count}")

            logger.info(f"æ‰€æœ‰è§†é¢‘ç”Ÿæˆä»»åŠ¡å®Œæˆ - æˆåŠŸ: {completed_count}, å¤±è´¥: {failed_count}")

        except Exception as e:
            logger.error(f"å¤„ç†æ‰€æœ‰ç”Ÿæˆå®Œæˆäº‹ä»¶å¤±è´¥: {e}")

    def on_progress_updated(self, progress, message):
        """è¿›åº¦æ›´æ–°ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰"""
        self.progress_bar.setValue(progress)
        self.status_label.setText(message)

    def on_video_generated(self, video_path, success, error_message):
        """è§†é¢‘ç”Ÿæˆå®Œæˆ"""
        try:
            if success:
                # ä¿å­˜è§†é¢‘è·¯å¾„åˆ°é¡¹ç›®æ•°æ®
                self.save_video_to_project(video_path)

                # æ›´æ–°å½“å‰åœºæ™¯çŠ¶æ€
                if hasattr(self, '_current_generating_scene'):
                    self.update_scene_status(self._current_generating_scene, 'å·²ç”Ÿæˆ')

                # è‡ªåŠ¨æ’­æ”¾è§†é¢‘
                if self.auto_play_check.isChecked():
                    self.play_video(video_path)

                self.status_label.setText(f"è§†é¢‘ç”ŸæˆæˆåŠŸ: {os.path.basename(video_path)}")

            else:
                # æ›´æ–°å¤±è´¥çŠ¶æ€
                if hasattr(self, '_current_generating_scene'):
                    logger.info(f"æ›´æ–°åœºæ™¯çŠ¶æ€ä¸ºå¤±è´¥: {self._current_generating_scene.get('shot_id', 'unknown')}")
                    self.update_scene_status(self._current_generating_scene, 'å¤±è´¥')
                else:
                    logger.warning("æ²¡æœ‰æ‰¾åˆ°å½“å‰ç”Ÿæˆçš„åœºæ™¯ï¼Œæ— æ³•æ›´æ–°å¤±è´¥çŠ¶æ€")

                self.status_label.setText(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {error_message}")
                QMessageBox.critical(self, "ç”Ÿæˆå¤±è´¥", f"è§†é¢‘ç”Ÿæˆå¤±è´¥:\n{error_message}")

            # å¤„ç†ä¸‹ä¸€ä¸ªä»»åŠ¡
            QTimer.singleShot(1000, self.process_next_generation)

        except Exception as e:
            logger.error(f"å¤„ç†è§†é¢‘ç”Ÿæˆç»“æœå¤±è´¥: {e}")
            self.on_generation_error(str(e))



    def on_generation_error(self, error_message):
        """ç”Ÿæˆé”™è¯¯å¤„ç†"""
        self.hide_generation_progress()
        self.status_label.setText(f"ç”Ÿæˆé”™è¯¯: {error_message}")
        logger.error(f"è§†é¢‘ç”Ÿæˆé”™è¯¯: {error_message}")

    def cancel_generation(self):
        """å–æ¶ˆç”Ÿæˆï¼ˆæ”¯æŒå¹¶å‘ï¼‰"""
        try:
            # å–æ¶ˆæ‰€æœ‰æ´»è·ƒçš„å·¥ä½œçº¿ç¨‹
            for scene_id, worker_info in list(self.active_workers.items()):
                worker = worker_info['worker']
                if worker and worker.isRunning():
                    try:
                        if hasattr(worker, 'cancel'):
                            worker.cancel()
                        worker.quit()
                        worker.wait(3000)  # ç­‰å¾…3ç§’
                    except Exception as e:
                        logger.warning(f"å–æ¶ˆå·¥ä½œçº¿ç¨‹ {scene_id} æ—¶å‡ºé”™: {e}")

            # å–æ¶ˆä¼ ç»Ÿçš„å•çº¿ç¨‹å·¥ä½œ
            if self.current_worker and self.current_worker.isRunning():
                try:
                    if hasattr(self.current_worker, 'cancel'):
                        self.current_worker.cancel()
                    self.current_worker.quit()
                    self.current_worker.wait(3000)  # ç­‰å¾…3ç§’
                except Exception as e:
                    logger.warning(f"å–æ¶ˆå½“å‰å·¥ä½œçº¿ç¨‹æ—¶å‡ºé”™: {e}")

            # æ¸…ç†çŠ¶æ€
            self.active_workers.clear()
            self.generation_queue.clear()
            self.hide_generation_progress()
            self.status_label.setText("ç”Ÿæˆå·²å–æ¶ˆ")

            logger.info("æ‰€æœ‰è§†é¢‘ç”Ÿæˆä»»åŠ¡å·²å–æ¶ˆ")

        except Exception as e:
            logger.error(f"å–æ¶ˆç”Ÿæˆå¤±è´¥: {e}")

    def save_video_to_project(self, video_path):
        """ä¿å­˜è§†é¢‘è·¯å¾„åˆ°é¡¹ç›®"""
        try:
            if not self.project_manager or not hasattr(self, '_current_generating_scene'):
                return

            # è·å–å½“å‰ç”Ÿæˆçš„åœºæ™¯
            current_scene = self._current_generating_scene
            shot_id = current_scene.get('shot_id', '')

            # åœ¨current_scenesä¸­æ‰¾åˆ°å¯¹åº”åœºæ™¯å¹¶æ›´æ–°è§†é¢‘è·¯å¾„
            for scene in self.current_scenes:
                if scene.get('shot_id') == shot_id:
                    scene['video_path'] = video_path
                    logger.info(f"ä¸ºé•œå¤´ {shot_id} ä¿å­˜è§†é¢‘è·¯å¾„: {video_path}")

                    # åˆ·æ–°è¡¨æ ¼æ˜¾ç¤º
                    self.update_scene_table()
                    break

            # è®°å½•è§†é¢‘ç”Ÿæˆä¿¡æ¯åˆ°é¡¹ç›®æ•°æ®
            self.record_video_generation(video_path, current_scene)

        except Exception as e:
            logger.error(f"ä¿å­˜è§†é¢‘åˆ°é¡¹ç›®å¤±è´¥: {e}")

    def record_video_generation(self, video_path, scene_data):
        """è®°å½•è§†é¢‘ç”Ÿæˆä¿¡æ¯åˆ°é¡¹ç›®æ•°æ®"""
        try:
            if not self.project_manager:
                return

            import os
            import time
            from datetime import datetime

            # è·å–è§†é¢‘æ–‡ä»¶ä¿¡æ¯
            file_size = os.path.getsize(video_path) if os.path.exists(video_path) else 0

            # è·å–ç”Ÿæˆé…ç½®
            config = self.get_generation_config()

            # åˆ›å»ºè§†é¢‘è®°å½•
            video_record = {
                "video_id": f"video_{int(time.time())}_{scene_data.get('shot_id', '')}",
                "shot_id": scene_data.get('shot_id', ''),
                "scene_id": scene_data.get('scene_id', ''),
                "video_path": video_path,
                "source_image_path": scene_data.get('image_path', ''),
                "prompt": scene_data.get('enhanced_description', ''),
                "duration": config.get('duration', 5),
                "fps": config.get('fps', 30),
                "width": config.get('width', 1024),
                "height": config.get('height', 1024),
                "motion_intensity": config.get('motion_intensity', 0.5),
                "engine": config.get('engine', 'cogvideox_flash'),
                "generation_time": datetime.now().isoformat(),
                "status": "å·²ç”Ÿæˆ",
                "file_size": file_size,
                "created_time": datetime.now().isoformat()
            }

            # æ·»åŠ åˆ°é¡¹ç›®æ•°æ®
            self.project_manager.add_video_record(video_record)

            # ğŸ”§ æ–°å¢ï¼šåŒæ—¶ä¿å­˜åˆ°shot_mappingsä¸­ï¼Œç¡®ä¿é‡æ–°åŠ è½½æ—¶èƒ½æ‰¾åˆ°è§†é¢‘è·¯å¾„
            try:
                shot_id = scene_data.get('shot_id', '')
                if shot_id and hasattr(self.project_manager, 'current_project') and self.project_manager.current_project:
                    # ç›´æ¥æ›´æ–°é¡¹ç›®æ•°æ®ä¸­çš„shot_mappings
                    if 'shot_mappings' not in self.project_manager.current_project:
                        self.project_manager.current_project['shot_mappings'] = {}

                    if shot_id not in self.project_manager.current_project['shot_mappings']:
                        self.project_manager.current_project['shot_mappings'][shot_id] = {}

                    self.project_manager.current_project['shot_mappings'][shot_id]['video_path'] = video_path
                    self.project_manager.current_project['shot_mappings'][shot_id]['video_status'] = 'completed'

                    # ä¿å­˜é¡¹ç›®æ•°æ®
                    self.project_manager.save_project()
                    logger.debug(f"å·²ä¿å­˜è§†é¢‘è·¯å¾„åˆ°shot_mappings: {shot_id} -> {video_path}")
            except Exception as e:
                logger.warning(f"ä¿å­˜è§†é¢‘è·¯å¾„åˆ°shot_mappingså¤±è´¥: {e}")

            logger.info(f"å·²è®°å½•è§†é¢‘ç”Ÿæˆä¿¡æ¯: {video_record['video_id']}")

        except Exception as e:
            logger.error(f"è®°å½•è§†é¢‘ç”Ÿæˆä¿¡æ¯å¤±è´¥: {e}")

    def play_video(self, video_path):
        """æ’­æ”¾è§†é¢‘"""
        try:
            import subprocess
            import platform

            if platform.system() == "Windows":
                os.startfile(video_path)
            elif platform.system() == "Darwin":  # macOS
                subprocess.run(["open", video_path])
            else:  # Linux
                subprocess.run(["xdg-open", video_path])

        except Exception as e:
            logger.error(f"æ’­æ”¾è§†é¢‘å¤±è´¥: {e}")

    def open_output_directory(self):
        """æ‰“å¼€è¾“å‡ºç›®å½•"""
        try:
            output_dir = "output/videos"
            if self.project_manager and self.project_manager.current_project:
                project_data = self.project_manager.get_project_data()
                if project_data and 'project_path' in project_data:
                    output_dir = os.path.join(project_data['project_path'], 'videos')

            if not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)

            import subprocess
            import platform

            if platform.system() == "Windows":
                os.startfile(output_dir)
            elif platform.system() == "Darwin":  # macOS
                subprocess.run(["open", output_dir])
            else:  # Linux
                subprocess.run(["xdg-open", output_dir])

        except Exception as e:
            logger.error(f"æ‰“å¼€è¾“å‡ºç›®å½•å¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"æ‰“å¼€è¾“å‡ºç›®å½•å¤±è´¥: {str(e)}")


class MultiSegmentVideoWorker(QThread):
    """å¤šç‰‡æ®µè§†é¢‘ç”Ÿæˆå·¥ä½œçº¿ç¨‹"""
    progress_updated = pyqtSignal(int, str)
    video_generated = pyqtSignal(bool, str, str)

    def __init__(self, scene_data, scene_images, segment_durations, project_manager, project_name):
        super().__init__()
        self.scene_data = scene_data
        self.scene_images = scene_images
        self.segment_durations = segment_durations
        self.project_manager = project_manager
        self.project_name = project_name

    def run(self):
        """è¿è¡Œå¤šç‰‡æ®µè§†é¢‘ç”Ÿæˆï¼ˆä¿®å¤Event loopé—®é¢˜ï¼‰"""
        try:
            self.progress_updated.emit(0, "å¼€å§‹ç”Ÿæˆå¤šç‰‡æ®µè§†é¢‘...")

            # åˆ›å»ºä¸€ä¸ªäº‹ä»¶å¾ªç¯ç”¨äºæ•´ä¸ªç”Ÿæˆè¿‡ç¨‹
            import asyncio

            # ç¡®ä¿åœ¨æ–°çº¿ç¨‹ä¸­åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

            try:
                # è¿è¡Œå¼‚æ­¥ç”Ÿæˆæ–¹æ³•
                final_video_path = loop.run_until_complete(self._generate_all_videos_async())
            finally:
                # ç¡®ä¿äº‹ä»¶å¾ªç¯æ­£ç¡®å…³é—­
                try:
                    # å–æ¶ˆæ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
                    pending = asyncio.all_tasks(loop)
                    if pending:
                        for task in pending:
                            task.cancel()

                        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆæˆ–å–æ¶ˆ
                        loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))

                except Exception as cleanup_error:
                    logger.warning(f"æ¸…ç†äº‹ä»¶å¾ªç¯æ—¶å‡ºé”™: {cleanup_error}")
                finally:
                    loop.close()

            self.progress_updated.emit(100, "è§†é¢‘ç”Ÿæˆå®Œæˆ")
            self.video_generated.emit(True, "å¤šç‰‡æ®µè§†é¢‘ç”ŸæˆæˆåŠŸ", final_video_path)

        except Exception as e:
            logger.error(f"å¤šç‰‡æ®µè§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            self.video_generated.emit(False, str(e), "")

    async def _generate_all_videos_async(self):
        """å¼‚æ­¥ç”Ÿæˆæ‰€æœ‰è§†é¢‘ç‰‡æ®µ"""
        from src.models.video_engines.video_generation_service import VideoGenerationService

        # åˆ›å»ºè§†é¢‘ç”ŸæˆæœåŠ¡
        video_service = VideoGenerationService()
        generated_videos = []
        total_segments = len(self.segment_durations)

        for i, duration in enumerate(self.segment_durations):
            if i >= len(self.scene_images):
                break

            self.progress_updated.emit(
                int((i / total_segments) * 80),
                f"ç”Ÿæˆç¬¬{i+1}/{total_segments}ä¸ªç‰‡æ®µ..."
            )

            # è·å–å½“å‰ç‰‡æ®µçš„å›¾åƒ
            image_path = self.scene_images[i]['path']

            try:
                # ç”Ÿæˆè§†é¢‘
                result = await video_service.generate_video(
                    prompt=self.scene_data.get('enhanced_description', ''),
                    image_path=image_path,
                    duration=duration,
                    fps=24,
                    width=1024,
                    height=1024,
                    motion_intensity=0.5,
                    preferred_engines=["cogvideox_flash"],
                    project_manager=self.project_manager,
                    current_project_name=self.project_name
                )

                if result.success:
                    generated_videos.append(result.video_path)
                    logger.info(f"ç‰‡æ®µ{i+1}ç”ŸæˆæˆåŠŸ: {result.video_path}")
                else:
                    raise Exception(result.error_message)

            except Exception as e:
                logger.error(f"ç‰‡æ®µ{i+1}ç”Ÿæˆå¤±è´¥: {e}")
                raise Exception(f"ç‰‡æ®µ{i+1}ç”Ÿæˆå¤±è´¥: {e}")

        # åˆå¹¶è§†é¢‘ç‰‡æ®µ
        self.progress_updated.emit(85, "åˆå¹¶è§†é¢‘ç‰‡æ®µ...")
        final_video_path = self._merge_video_segments(generated_videos)

        return final_video_path

    def _merge_video_segments(self, video_paths):
        """åˆå¹¶è§†é¢‘ç‰‡æ®µ"""
        try:
            if len(video_paths) == 1:
                return video_paths[0]

            # ä½¿ç”¨ffmpegåˆå¹¶è§†é¢‘
            import subprocess
            import tempfile

            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_dir = os.path.dirname(video_paths[0])
            shot_id = self.scene_data.get('shot_id', 'unknown')
            output_path = os.path.join(output_dir, f"{shot_id}_merged.mp4")

            # åˆ›å»ºæ–‡ä»¶åˆ—è¡¨
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                for video_path in video_paths:
                    f.write(f"file '{video_path}'\n")
                list_file = f.name

            try:
                # ä½¿ç”¨ffmpegåˆå¹¶
                cmd = [
                    'ffmpeg', '-f', 'concat', '-safe', '0',
                    '-i', list_file, '-c', 'copy', output_path, '-y'
                ]
                subprocess.run(cmd, check=True, capture_output=True)

                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                os.unlink(list_file)

                # åˆ é™¤åŸå§‹ç‰‡æ®µæ–‡ä»¶
                for video_path in video_paths:
                    try:
                        os.unlink(video_path)
                    except:
                        pass

                return output_path

            except subprocess.CalledProcessError as e:
                logger.error(f"ffmpegåˆå¹¶å¤±è´¥: {e}")
                # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œè¿”å›ç¬¬ä¸€ä¸ªç‰‡æ®µ
                return video_paths[0]

        except Exception as e:
            logger.error(f"åˆå¹¶è§†é¢‘ç‰‡æ®µå¤±è´¥: {e}")
            # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œè¿”å›ç¬¬ä¸€ä¸ªç‰‡æ®µ
            return video_paths[0] if video_paths else ""
