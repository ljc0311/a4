# -*- coding: utf-8 -*-
"""
è§†é¢‘ç”Ÿæˆæ ‡ç­¾é¡µ
ç”¨äºå°†é…éŸ³ã€å›¾åƒç­‰æ•°æ®ä¼ é€’åˆ°è§†é¢‘ç”Ÿæˆç•Œé¢ï¼Œè¿›è¡Œè§†é¢‘ç”Ÿæˆæ“ä½œ
"""

import os
import json
import asyncio
import time
from datetime import datetime
from typing import Dict, List, Optional
from PyQt5.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton, QTableWidget,
    QTableWidgetItem, QComboBox, QFormLayout, QGroupBox, QMessageBox,
    QProgressBar, QTextEdit, QSpinBox, QDoubleSpinBox, QCheckBox, QFrame,
    QSplitter, QHeaderView, QAbstractItemView, QSlider
)
from PyQt5.QtCore import Qt, QThread, pyqtSignal, QTimer
from PyQt5.QtGui import QFont, QPixmap

from src.utils.logger import logger
from src.utils.project_manager import StoryboardProjectManager
from src.utils.shot_id_manager import ShotIDManager, ShotMapping


class VideoGenerationWorker(QThread):
    """è§†é¢‘ç”Ÿæˆå·¥ä½œçº¿ç¨‹"""
    
    progress_updated = pyqtSignal(int, str)  # è¿›åº¦, æ¶ˆæ¯
    video_generated = pyqtSignal(str, bool, str)  # è§†é¢‘è·¯å¾„, æˆåŠŸçŠ¶æ€, é”™è¯¯ä¿¡æ¯
    
    def __init__(self, scene_data, generation_config, project_manager, project_name):
        super().__init__()
        self.scene_data = scene_data
        self.generation_config = generation_config
        self.project_manager = project_manager
        self.project_name = project_name
        self.is_cancelled = False
        self._current_loop = None  # ä¿å­˜å½“å‰äº‹ä»¶å¾ªç¯å¼•ç”¨

    def cancel(self):
        """å–æ¶ˆä»»åŠ¡"""
        self.is_cancelled = True
        logger.info("è§†é¢‘ç”Ÿæˆä»»åŠ¡å·²æ ‡è®°ä¸ºå–æ¶ˆ")

        # å¦‚æœæœ‰æ­£åœ¨è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œå°è¯•å–æ¶ˆå…¶ä¸­çš„ä»»åŠ¡
        if self._current_loop and not self._current_loop.is_closed():
            try:
                # è·å–å¾ªç¯ä¸­çš„æ‰€æœ‰ä»»åŠ¡å¹¶å–æ¶ˆ
                pending_tasks = [task for task in asyncio.all_tasks(self._current_loop)
                               if not task.done()]
                for task in pending_tasks:
                    task.cancel()
                logger.info(f"å·²å–æ¶ˆ {len(pending_tasks)} ä¸ªå¼‚æ­¥ä»»åŠ¡")
            except Exception as e:
                logger.warning(f"å–æ¶ˆå¼‚æ­¥ä»»åŠ¡æ—¶å‡ºé”™: {e}")

    def run(self):
        """è¿è¡Œè§†é¢‘ç”Ÿæˆï¼ˆä¿®å¤Event loopé—®é¢˜ï¼‰"""
        loop = None
        try:
            # æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self.is_cancelled:
                logger.info("ä»»åŠ¡åœ¨å¯åŠ¨å‰å·²è¢«å–æ¶ˆ")
                self.video_generated.emit("", False, "ä»»åŠ¡å·²å–æ¶ˆ")
                return

            # ç¡®ä¿åœ¨æ–°çº¿ç¨‹ä¸­åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            try:
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰äº‹ä»¶å¾ªç¯
                existing_loop = asyncio.get_event_loop()
                if existing_loop and not existing_loop.is_closed():
                    existing_loop.close()
            except RuntimeError:
                # æ²¡æœ‰ç°æœ‰å¾ªç¯ï¼Œè¿™æ˜¯æ­£å¸¸çš„
                pass

            # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            self._current_loop = loop  # ä¿å­˜å¾ªç¯å¼•ç”¨

            # è¿è¡Œå¼‚æ­¥ç”Ÿæˆ
            result = loop.run_until_complete(self._generate_video_async())

            if result and result.success:
                self.video_generated.emit(result.video_path, True, "")
            else:
                error_msg = result.error_message if result else "æœªçŸ¥é”™è¯¯"
                self.video_generated.emit("", False, error_msg)

        except asyncio.CancelledError:
            logger.warning("è§†é¢‘ç”Ÿæˆä»»åŠ¡è¢«å–æ¶ˆ")
            self.video_generated.emit("", False, "è§†é¢‘ç”Ÿæˆä»»åŠ¡è¢«å–æ¶ˆï¼Œè¯·é‡è¯•")
        except Exception as e:
            logger.error(f"è§†é¢‘ç”Ÿæˆçº¿ç¨‹å¼‚å¸¸: {e}")
            # æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            if "CancelledError" in str(e):
                error_msg = "è§†é¢‘ç”Ÿæˆä»»åŠ¡è¢«å–æ¶ˆï¼Œè¯·é‡è¯•"
            elif "504" in str(e):
                error_msg = "æœåŠ¡å™¨å“åº”è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
            elif "timeout" in str(e).lower():
                error_msg = "ç½‘ç»œè¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•"
            elif "different loop" in str(e):
                error_msg = "äº‹ä»¶å¾ªç¯å†²çªï¼Œè¯·é‡è¯•"
            else:
                error_msg = str(e)
            self.video_generated.emit("", False, error_msg)
        finally:
            # å®‰å…¨å…³é—­äº‹ä»¶å¾ªç¯
            if 'loop' in locals() and loop and not loop.is_closed():
                try:
                    # å–æ¶ˆæ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
                    try:
                        pending = asyncio.all_tasks(loop)
                        if pending:
                            for task in pending:
                                if not task.done():
                                    task.cancel()

                            # ç­‰å¾…ä»»åŠ¡å–æ¶ˆå®Œæˆï¼Œè®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´
                            try:
                                loop.run_until_complete(
                                    asyncio.wait_for(
                                        asyncio.gather(*pending, return_exceptions=True),
                                        timeout=5.0
                                    )
                                )
                            except asyncio.TimeoutError:
                                logger.warning("ç­‰å¾…ä»»åŠ¡å–æ¶ˆè¶…æ—¶ï¼Œå¼ºåˆ¶å…³é—­")
                            except Exception as gather_error:
                                logger.warning(f"ç­‰å¾…ä»»åŠ¡å–æ¶ˆæ—¶å‡ºé”™: {gather_error}")
                    except Exception as task_error:
                        logger.warning(f"å¤„ç†æœªå®Œæˆä»»åŠ¡æ—¶å‡ºé”™: {task_error}")

                    # å…³é—­äº‹ä»¶å¾ªç¯
                    loop.close()
                except Exception as cleanup_error:
                    logger.warning(f"å…³é—­äº‹ä»¶å¾ªç¯æ—¶å‡ºé”™: {cleanup_error}")
                finally:
                    # ç¡®ä¿æ¸…ç†äº‹ä»¶å¾ªç¯å¼•ç”¨
                    try:
                        asyncio.set_event_loop(None)
                    except Exception:
                        pass
    
    async def _generate_video_async(self):
        """å¼‚æ­¥ç”Ÿæˆè§†é¢‘"""
        # å®šä¹‰ç»“æœç±»
        class Result:
            def __init__(self, success, video_path="", error_message=""):
                self.success = success
                self.video_path = video_path
                self.error_message = error_message

        try:
            # æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self.is_cancelled:
                logger.info("å¼‚æ­¥ä»»åŠ¡åœ¨å¼€å§‹å‰å·²è¢«å–æ¶ˆ")
                return Result(False, "", "ä»»åŠ¡å·²å–æ¶ˆ")

            from src.processors.video_processor import VideoProcessor
            from src.core.service_manager import ServiceManager

            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å…±äº«çš„æœåŠ¡ç®¡ç†å™¨å®ä¾‹ï¼Œé¿å…å¼•æ“çŠ¶æ€å†²çª
            service_manager = ServiceManager()  # ServiceManagerå·²ç»æ˜¯å•ä¾‹
            processor = VideoProcessor(service_manager)

            # ğŸ”§ è°ƒè¯•ï¼šæ£€æŸ¥å¼•æ“çŠ¶æ€
            scene_id = self.scene_data.get('shot_id', 'unknown')
            logger.info(f"VideoGenerationWorkerå¯åŠ¨ - åœºæ™¯ID: {scene_id}")
            logger.info(f"ServiceManagerå®ä¾‹ID: {id(service_manager)}")

            # æ›´æ–°è¿›åº¦
            self.progress_updated.emit(10, "å‡†å¤‡è§†é¢‘ç”Ÿæˆ...")

            # ä»åœºæ™¯æ•°æ®ç”Ÿæˆè§†é¢‘
            image_path = self.scene_data.get('image_path', '')

            # è·å–æç¤ºè¯ - ä¼˜å…ˆä½¿ç”¨scene_dataä¸­çš„promptå­—æ®µ
            original_prompt = self.scene_data.get('prompt', '') or self._get_prompt_from_file() or self.scene_data.get('enhanced_description', self.scene_data.get('description', ''))

            # ä¼˜åŒ–æç¤ºè¯ä»¥é€‚åˆè§†é¢‘ç”Ÿæˆ
            shot_id = self.scene_data.get('shot_id', '')
            duration = self.generation_config.get('duration', 5.0)

            # è°ƒç”¨è§†é¢‘æç¤ºè¯ä¼˜åŒ–
            try:
                from src.processors.cogvideox_prompt_optimizer import CogVideoXPromptOptimizer
                optimizer = CogVideoXPromptOptimizer()
                shot_info = {'shot_type': 'medium_shot', 'camera_angle': 'eye_level', 'movement': 'static'}
                optimized_prompt = optimizer.optimize_for_video(original_prompt, shot_info, duration)
                logger.info(f"è§†é¢‘æç¤ºè¯ä¼˜åŒ–æˆåŠŸ: {original_prompt[:50]}... -> {optimized_prompt[:50]}...")
            except Exception as e:
                logger.warning(f"è§†é¢‘æç¤ºè¯ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æç¤ºè¯: {e}")
                optimized_prompt = original_prompt

            logger.info(f"è§†é¢‘ç”Ÿæˆæç¤ºè¯: {optimized_prompt}")

            if not image_path or not os.path.exists(image_path):
                raise Exception(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")

            # å†æ¬¡æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self.is_cancelled:
                logger.info("ä»»åŠ¡åœ¨è§†é¢‘ç”Ÿæˆå‰å·²è¢«å–æ¶ˆ")
                return Result(False, "", "ä»»åŠ¡å·²å–æ¶ˆ")

            self.progress_updated.emit(30, "å¼€å§‹ç”Ÿæˆè§†é¢‘...")

            # ç”Ÿæˆè§†é¢‘ï¼ˆä½¿ç”¨æ­£ç¡®çš„åˆ†è¾¨ç‡ï¼‰
            video_path = await processor.generate_video_from_image(
                image_path=image_path,
                prompt=optimized_prompt,
                duration=self.generation_config.get('duration', 5.0),
                fps=self.generation_config.get('fps', 30),  # ä½¿ç”¨CogVideoXæ”¯æŒçš„å¸§ç‡
                width=self.generation_config.get('width', 1024),
                height=self.generation_config.get('height', 1024),
                motion_intensity=self.generation_config.get('motion_intensity', 0.5),
                preferred_engine=self.generation_config.get('engine', 'cogvideox_flash'),
                progress_callback=lambda p, msg: self.progress_updated.emit(30 + int(p * 60), msg),
                project_manager=self.project_manager,
                current_project_name=self.project_name,
                max_concurrent_tasks=self.generation_config.get('max_concurrent_tasks', 3),  # ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„å¹¶å‘æ•°
                audio_hint=self.generation_config.get('audio_hint')  # ä¼ é€’éŸ³æ•ˆæç¤º
            )

            self.progress_updated.emit(100, "è§†é¢‘ç”Ÿæˆå®Œæˆ!")
            return Result(True, video_path)

        except Exception as e:
            logger.error(f"å¼‚æ­¥è§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            return Result(False, "", str(e))

    def _get_prompt_from_file(self):
        """ä»prompt.jsonæ–‡ä»¶è·å–æç¤ºè¯"""
        try:
            if not self.project_manager or not self.project_name:
                return None

            # è·å–é¡¹ç›®ç›®å½•
            project_data = self.project_manager.get_project_data()
            if not project_data:
                return None

            project_dir = project_data.get('project_dir', '')
            if not project_dir:
                return None

            # æ„å»ºprompt.jsonæ–‡ä»¶è·¯å¾„
            prompt_file = os.path.join(project_dir, 'texts', 'prompt.json')
            if not os.path.exists(prompt_file):
                logger.debug(f"prompt.jsonæ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
                return None

            # è¯»å–prompt.jsonæ–‡ä»¶
            import json
            with open(prompt_file, 'r', encoding='utf-8') as f:
                prompt_data = json.load(f)

            # è·å–å½“å‰é•œå¤´çš„shot_id
            shot_id = self.scene_data.get('shot_id', '')
            if not shot_id:
                return None

            # æŸ¥æ‰¾å¯¹åº”çš„æç¤ºè¯
            # prompt.jsonçš„ç»“æ„æ˜¯ {"scenes": {"åœºæ™¯å": [é•œå¤´æ•°ç»„]}}
            scenes_data = prompt_data.get('scenes', {})

            # æå–shot_idä¸­çš„æ•°å­—éƒ¨åˆ†
            shot_index = None
            if shot_id.startswith('text_segment_'):
                try:
                    shot_index = int(shot_id.replace('text_segment_', ''))
                except ValueError:
                    pass

            if shot_index is None:
                logger.debug(f"æ— æ³•ä»shot_id '{shot_id}' æå–ç´¢å¼•")
                return None

            # éå†æ‰€æœ‰åœºæ™¯ï¼Œæ‰¾åˆ°å¯¹åº”ç´¢å¼•çš„é•œå¤´
            current_index = 1
            for scene_name, shots in scenes_data.items():
                if isinstance(shots, list):
                    for shot in shots:
                        if current_index == shot_index:
                            content = shot.get('content', '')
                            if content:
                                logger.debug(f"ä»prompt.jsonè·å–é•œå¤´ {shot_id} (ç´¢å¼•{shot_index}) çš„æç¤ºè¯")
                                return content
                        current_index += 1

            logger.debug(f"åœ¨prompt.jsonä¸­æœªæ‰¾åˆ°é•œå¤´ {shot_id} çš„æç¤ºè¯")
            return None

        except Exception as e:
            logger.warning(f"ä»prompt.jsonè·å–æç¤ºè¯å¤±è´¥: {e}")
            return None
    
    def cancel(self):
        """å–æ¶ˆç”Ÿæˆ"""
        self.is_cancelled = True


class VideoGenerationTab(QWidget):
    """å›¾è½¬è§†é¢‘æ ‡ç­¾é¡µ - å°†å›¾ç‰‡è½¬æ¢ä¸ºè§†é¢‘ç‰‡æ®µ"""
    
    def __init__(self, app_controller, project_manager: StoryboardProjectManager, parent=None):
        super().__init__(parent)
        self.app_controller = app_controller
        self.project_manager = project_manager
        self.parent_window = parent
        
        # å½“å‰æ•°æ®
        self.current_scenes = []
        self.current_voices = []
        self.generation_queue = []
        self.current_worker = None

        # å¹¶å‘ç”Ÿæˆç®¡ç†
        self.active_workers = {}  # {scene_id: worker}
        self.max_concurrent_videos = 3  # é»˜è®¤å¹¶å‘æ•°ï¼Œä¼šæ ¹æ®ç”¨æˆ·è®¾ç½®åŠ¨æ€è°ƒæ•´

        # æ‰¹é‡å›¾åƒå¤„ç†ç®¡ç†
        self.batch_processing_active = False
        self.batch_processing_queue = []
        self.batch_processing_completed = 0
        self.batch_processing_total = 0
        self.batch_processing_failed = 0

        # ğŸ”§ æ–°å¢ï¼šç»Ÿä¸€é•œå¤´IDç®¡ç†å™¨
        self.shot_id_manager = ShotIDManager()
        
        self.init_ui()
        self.load_project_data()

    def on_concurrent_changed(self, new_value):
        """å½“ç”¨æˆ·æ”¹å˜å¹¶å‘æ•°æ—¶çš„å¤„ç†"""
        try:
            new_concurrent = int(new_value)
            old_concurrent = self.max_concurrent_videos
            self.max_concurrent_videos = new_concurrent
            logger.info(f"ç”¨æˆ·è°ƒæ•´å¹¶å‘æ•°: {old_concurrent} -> {new_concurrent}")

            # å¦‚æœå½“å‰æœ‰æ´»è·ƒä»»åŠ¡ï¼Œæ˜¾ç¤ºæç¤º
            if self.active_workers:
                active_count = len(self.active_workers)
                if new_concurrent < active_count:
                    logger.warning(f"å½“å‰æœ‰ {active_count} ä¸ªæ´»è·ƒä»»åŠ¡ï¼Œæ–°å¹¶å‘æ•° {new_concurrent} å°†åœ¨ä¸‹æ¬¡ç”Ÿæˆæ—¶ç”Ÿæ•ˆ")
                elif new_concurrent > active_count and self.generation_queue:
                    logger.info(f"å¹¶å‘æ•°å¢åŠ ï¼Œå°†å¯åŠ¨æ›´å¤šä»»åŠ¡")
                    # å¦‚æœé˜Ÿåˆ—ä¸­è¿˜æœ‰ä»»åŠ¡ä¸”å¹¶å‘æ•°å¢åŠ ï¼Œå¯åŠ¨æ›´å¤šä»»åŠ¡
                    self.start_concurrent_generation()

        except ValueError:
            logger.error(f"æ— æ•ˆçš„å¹¶å‘æ•°: {new_value}")
        except Exception as e:
            logger.error(f"å¤„ç†å¹¶å‘æ•°å˜åŒ–æ—¶å‡ºé”™: {e}")

    def on_engine_changed(self):
        """å¼•æ“é€‰æ‹©æ”¹å˜æ—¶çš„å¤„ç†"""
        try:
            selected_engine = self.engine_combo.currentData()
            logger.info(f"ç”¨æˆ·é€‰æ‹©è§†é¢‘ç”Ÿæˆå¼•æ“: {selected_engine}")

            # æ ¹æ®é€‰æ‹©çš„å¼•æ“æ˜¾ç¤º/éšè—ç›¸åº”çš„è®¾ç½®ç»„
            if selected_engine == "cogvideox_flash":
                self.cogvideox_group.setVisible(True)
                self.doubao_group.setVisible(False)
                if hasattr(self, 'vheer_group'):
                    self.vheer_group.setVisible(False)
            elif selected_engine in ["doubao_seedance_pro", "doubao_seedance_lite"]:
                self.cogvideox_group.setVisible(False)
                self.doubao_group.setVisible(True)
                if hasattr(self, 'vheer_group'):
                    self.vheer_group.setVisible(False)
                # æ ¹æ®å¼•æ“ç±»å‹è°ƒæ•´å¹¶å‘æ•°é€‰é¡¹
                self._update_doubao_concurrent_options(selected_engine)
            elif selected_engine == "vheer":
                self.cogvideox_group.setVisible(False)
                self.doubao_group.setVisible(False)
                if hasattr(self, 'vheer_group'):
                    self.vheer_group.setVisible(True)
            else:
                # é»˜è®¤æ˜¾ç¤ºCogVideoXè®¾ç½®
                self.cogvideox_group.setVisible(True)
                self.doubao_group.setVisible(False)
                if hasattr(self, 'vheer_group'):
                    self.vheer_group.setVisible(False)

        except Exception as e:
            logger.error(f"å¤„ç†å¼•æ“é€‰æ‹©æ”¹å˜æ—¶å‡ºé”™: {e}")

    def _update_doubao_concurrent_options(self, selected_engine: str):
        """æ ¹æ®é€‰æ‹©çš„è±†åŒ…å¼•æ“ç±»å‹æ›´æ–°å¹¶å‘æ•°é€‰é¡¹"""
        try:
            current_value = self.doubao_concurrent_tasks_combo.currentText()
            self.doubao_concurrent_tasks_combo.clear()

            if selected_engine == "doubao_seedance_pro":
                # Proç‰ˆæ”¯æŒ1-10å¹¶å‘
                self.doubao_concurrent_tasks_combo.addItems(["1", "2", "3", "4", "5", "6", "7", "8", "9", "10"])
                # è®¾ç½®é»˜è®¤å€¼ä¸º2ï¼Œå¦‚æœä¹‹å‰çš„å€¼åœ¨èŒƒå›´å†…åˆ™ä¿æŒ
                if current_value in ["1", "2", "3", "4", "5", "6", "7", "8", "9", "10"]:
                    self.doubao_concurrent_tasks_combo.setCurrentText(current_value)
                else:
                    self.doubao_concurrent_tasks_combo.setCurrentText("2")
                self.doubao_concurrent_tasks_combo.setToolTip("åŒæ—¶è¿›è¡Œçš„è§†é¢‘ç”Ÿæˆä»»åŠ¡æ•°é‡ï¼ˆProç‰ˆæœ€å¤š10ä¸ªï¼‰")

            elif selected_engine == "doubao_seedance_lite":
                # Liteç‰ˆæ”¯æŒ1-5å¹¶å‘
                self.doubao_concurrent_tasks_combo.addItems(["1", "2", "3", "4", "5"])
                # è®¾ç½®é»˜è®¤å€¼ä¸º2ï¼Œå¦‚æœä¹‹å‰çš„å€¼åœ¨èŒƒå›´å†…åˆ™ä¿æŒ
                if current_value in ["1", "2", "3", "4", "5"]:
                    self.doubao_concurrent_tasks_combo.setCurrentText(current_value)
                else:
                    self.doubao_concurrent_tasks_combo.setCurrentText("2")
                self.doubao_concurrent_tasks_combo.setToolTip("åŒæ—¶è¿›è¡Œçš„è§†é¢‘ç”Ÿæˆä»»åŠ¡æ•°é‡ï¼ˆLiteç‰ˆæœ€å¤š5ä¸ªï¼‰")

            logger.info(f"å·²æ›´æ–°è±†åŒ…å¹¶å‘æ•°é€‰é¡¹: {selected_engine} -> {self.doubao_concurrent_tasks_combo.count()}ä¸ªé€‰é¡¹")

        except Exception as e:
            logger.error(f"æ›´æ–°è±†åŒ…å¹¶å‘æ•°é€‰é¡¹å¤±è´¥: {e}")

    def _optimize_prompt_for_cogvideox(self, original_prompt: str, shot_id: str = "", duration: float = 5.0) -> str:
        """ä½¿ç”¨CogVideoXä¼˜åŒ–å™¨ä¼˜åŒ–è§†é¢‘æç¤ºè¯"""
        try:
            from src.processors.cogvideox_prompt_optimizer import CogVideoXPromptOptimizer

            # åˆ›å»ºä¼˜åŒ–å™¨å®ä¾‹
            optimizer = CogVideoXPromptOptimizer()

            # è·å–é•œå¤´ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            shot_info = self._get_shot_technical_info(shot_id)

            # ä½¿ç”¨è§†é¢‘ä¸“ç”¨ä¼˜åŒ–æ–¹æ³•
            optimized = optimizer.optimize_for_video(original_prompt, shot_info, duration)

            logger.info(f"è§†é¢‘æç¤ºè¯ä¼˜åŒ–: {original_prompt[:50]}... -> {optimized[:50]}...")
            return optimized

        except Exception as e:
            logger.warning(f"è§†é¢‘æç¤ºè¯ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æç¤ºè¯: {e}")
            return original_prompt

    def _get_shot_technical_info(self, shot_id: str) -> Dict:
        """è·å–é•œå¤´çš„æŠ€æœ¯ä¿¡æ¯"""
        try:
            if not self.project_manager or not self.project_manager.current_project:
                return {}

            project_dir = self.project_manager.current_project.get('project_dir', '')
            if not project_dir:
                return {}

            # æ„å»ºprompt.jsonæ–‡ä»¶è·¯å¾„
            prompt_file = os.path.join(project_dir, 'texts', 'prompt.json')
            if not os.path.exists(prompt_file):
                return {}

            # è¯»å–prompt.jsonæ–‡ä»¶
            import json
            with open(prompt_file, 'r', encoding='utf-8') as f:
                prompt_data = json.load(f)

            # æŸ¥æ‰¾å¯¹åº”é•œå¤´çš„æŠ€æœ¯ä¿¡æ¯
            shot_index = None
            if shot_id.startswith('text_segment_'):
                try:
                    shot_index = int(shot_id.replace('text_segment_', ''))
                except ValueError:
                    return {}

            if shot_index is None:
                return {}

            # éå†æ‰¾åˆ°å¯¹åº”é•œå¤´
            current_index = 1
            for scene_name, shots in prompt_data.get('scenes', {}).items():
                if isinstance(shots, list):
                    for shot in shots:
                        if current_index == shot_index:
                            # ä»original_descriptionæå–æŠ€æœ¯ä¿¡æ¯
                            original_desc = shot.get('original_description', '')
                            return self._parse_technical_info(original_desc)
                        current_index += 1

            return {}

        except Exception as e:
            logger.warning(f"è·å–é•œå¤´æŠ€æœ¯ä¿¡æ¯å¤±è´¥: {e}")
            return {}

    def _parse_technical_info(self, description: str) -> Dict:
        """è§£ææŠ€æœ¯ä¿¡æ¯"""
        info = {}

        # è§£æé•œå¤´ç±»å‹
        if 'å…¨æ™¯' in description:
            info['shot_type'] = 'wide shot'
        elif 'ä¸­æ™¯' in description:
            info['shot_type'] = 'medium shot'
        elif 'ç‰¹å†™' in description:
            info['shot_type'] = 'close-up shot'

        # è§£ææœºä½è§’åº¦
        if 'å¹³è§†' in description:
            info['camera_angle'] = 'eye level'
        elif 'ä¿¯è§†' in description:
            info['camera_angle'] = 'high angle'
        elif 'ä»°è§†' in description:
            info['camera_angle'] = 'low angle'
        elif 'ä¾§é¢' in description:
            info['camera_angle'] = 'side angle'

        # è§£æé•œå¤´è¿åŠ¨
        if 'é™æ­¢' in description:
            info['camera_movement'] = 'static'
        elif 'æ¨è¿›' in description:
            info['camera_movement'] = 'dolly in'
        elif 'æ‹‰è¿œ' in description:
            info['camera_movement'] = 'dolly out'

        return info
    
    def init_ui(self):
        """åˆå§‹åŒ–UIç•Œé¢"""
        main_layout = QVBoxLayout()
        
        # æ ‡é¢˜åŒºåŸŸ
        title_layout = QHBoxLayout()
        title_label = QLabel("ğŸ¬ å›¾è½¬è§†é¢‘")
        title_label.setFont(QFont("Arial", 16, QFont.Weight.Bold))
        title_layout.addWidget(title_label)
        title_layout.addStretch()
        
        # åˆ·æ–°æŒ‰é’®
        refresh_btn = QPushButton("ğŸ”„ åˆ·æ–°æ•°æ®")
        refresh_btn.clicked.connect(self.load_project_data)
        refresh_btn.setToolTip("é‡æ–°åŠ è½½é¡¹ç›®ä¸­çš„é…éŸ³å’Œå›¾åƒæ•°æ®")
        title_layout.addWidget(refresh_btn)
        
        main_layout.addLayout(title_layout)
        
        # åˆ›å»ºåˆ†å‰²å™¨
        splitter = QSplitter(Qt.Orientation.Horizontal)
        
        # å·¦ä¾§ï¼šåœºæ™¯åˆ—è¡¨
        left_panel = self.create_scene_list_panel()
        splitter.addWidget(left_panel)
        
        # å³ä¾§ï¼šç”Ÿæˆæ§åˆ¶é¢æ¿
        right_panel = self.create_generation_control_panel()
        splitter.addWidget(right_panel)
        
        # è®¾ç½®åˆ†å‰²å™¨æ¯”ä¾‹
        splitter.setSizes([600, 400])
        main_layout.addWidget(splitter)
        
        # åº•éƒ¨ï¼šè¿›åº¦æ¡å’ŒçŠ¶æ€
        self.create_progress_area(main_layout)
        
        self.setLayout(main_layout)
    
    def create_scene_list_panel(self):
        """åˆ›å»ºåœºæ™¯åˆ—è¡¨é¢æ¿"""
        panel = QFrame()
        panel.setFrameStyle(QFrame.Shape.StyledPanel)
        layout = QVBoxLayout(panel)
        
        # æ ‡é¢˜
        title_label = QLabel("ğŸ“‹ é•œå¤´åˆ—è¡¨")
        title_label.setFont(QFont("Arial", 12, QFont.Weight.Bold))
        layout.addWidget(title_label)
        
        # åœºæ™¯è¡¨æ ¼
        self.scene_table = QTableWidget()
        self.scene_table.setColumnCount(7)
        self.scene_table.setHorizontalHeaderLabels([
            "é€‰æ‹©", "é•œå¤´", "é…éŸ³", "å›¾åƒ", "è§†é¢‘", "çŠ¶æ€", "æ“ä½œ"
        ])
        
        # è®¾ç½®è¡¨æ ¼å±æ€§
        self.scene_table.setSelectionBehavior(QAbstractItemView.SelectionBehavior.SelectRows)
        self.scene_table.setAlternatingRowColors(True)
        
        # è®¾ç½®è¡¨æ ¼å¯è°ƒæ•´å¤§å°
        header = self.scene_table.horizontalHeader()
        header.setSectionResizeMode(QHeaderView.ResizeMode.Interactive)  # å…è®¸æ‰‹åŠ¨è°ƒæ•´åˆ—å®½
        header.setStretchLastSection(False)  # æœ€åä¸€åˆ—ä¸è‡ªåŠ¨æ‹‰ä¼¸

        # è®¾ç½®å‚ç›´è¡¨å¤´å¯è°ƒæ•´è¡Œé«˜
        v_header = self.scene_table.verticalHeader()
        v_header.setSectionResizeMode(QHeaderView.ResizeMode.Interactive)  # å…è®¸æ‰‹åŠ¨è°ƒæ•´è¡Œé«˜
        v_header.setVisible(True)  # æ˜¾ç¤ºè¡Œå·ä»¥ä¾¿è°ƒæ•´è¡Œé«˜
        v_header.setDefaultSectionSize(60)  # è®¾ç½®é»˜è®¤è¡Œé«˜ä¸º60åƒç´ ï¼Œé€‚åˆæ˜¾ç¤ºä¸¤è¡Œæ–‡æœ¬

        # è®¾ç½®åˆå§‹åˆ—å®½
        self.scene_table.setColumnWidth(0, 50)   # é€‰æ‹©
        self.scene_table.setColumnWidth(1, 180)  # é•œå¤´ï¼ˆå¢åŠ å®½åº¦ä»¥æ˜¾ç¤ºæ—ç™½é¢„è§ˆï¼‰
        self.scene_table.setColumnWidth(2, 100)  # é…éŸ³ï¼ˆå¢åŠ å®½åº¦æ˜¾ç¤ºæ—¶é•¿ï¼‰
        self.scene_table.setColumnWidth(3, 120)  # å›¾åƒ
        self.scene_table.setColumnWidth(4, 120)  # è§†é¢‘
        self.scene_table.setColumnWidth(5, 150)  # çŠ¶æ€
        
        layout.addWidget(self.scene_table)
        
        # æ‰¹é‡æ“ä½œæŒ‰é’®
        batch_layout = QHBoxLayout()
        
        self.select_all_btn = QPushButton("å…¨é€‰")
        self.select_all_btn.clicked.connect(self.select_all_scenes)
        batch_layout.addWidget(self.select_all_btn)
        
        self.select_none_btn = QPushButton("å–æ¶ˆå…¨é€‰")
        self.select_none_btn.clicked.connect(self.select_none_scenes)
        batch_layout.addWidget(self.select_none_btn)
        
        batch_layout.addStretch()

        self.batch_generate_btn = QPushButton("ğŸ¬ æ‰¹é‡ç”Ÿæˆ")
        self.batch_generate_btn.clicked.connect(self.start_batch_generation)
        self.batch_generate_btn.setStyleSheet("QPushButton { background-color: #4CAF50; color: white; font-weight: bold; }")
        batch_layout.addWidget(self.batch_generate_btn)

        # æ‰¹é‡ä½¿ç”¨å›¾åƒæŒ‰é’®
        self.batch_use_image_btn = QPushButton("ğŸ–¼ï¸ æ‰¹é‡ä½¿ç”¨å›¾åƒ")
        self.batch_use_image_btn.clicked.connect(self.start_batch_use_image)
        self.batch_use_image_btn.setStyleSheet("QPushButton { background-color: #2196F3; color: white; font-weight: bold; }")
        self.batch_use_image_btn.setToolTip("æ‰¹é‡ä½¿ç”¨å›¾åƒåˆ›å»ºé™æ€è§†é¢‘ï¼ˆé€‚ç”¨äºè§†é¢‘ç”Ÿæˆå¤±è´¥çš„æƒ…å†µï¼‰")
        batch_layout.addWidget(self.batch_use_image_btn)
        
        layout.addLayout(batch_layout)
        
        return panel

    def create_generation_control_panel(self):
        """åˆ›å»ºç”Ÿæˆæ§åˆ¶é¢æ¿"""
        panel = QFrame()
        panel.setFrameStyle(QFrame.Shape.StyledPanel)
        layout = QVBoxLayout(panel)

        # æ ‡é¢˜
        title_label = QLabel("âš™ï¸ ç”Ÿæˆè®¾ç½®")
        title_label.setFont(QFont("Arial", 12, QFont.Weight.Bold))
        layout.addWidget(title_label)

        # å¼•æ“é€‰æ‹©ç»„
        engine_group = QGroupBox("è§†é¢‘ç”Ÿæˆå¼•æ“")
        engine_form = QFormLayout()

        # å¼•æ“é€‰æ‹©ä¸‹æ‹‰æ¡†
        self.engine_combo = QComboBox()
        self.engine_combo.addItem("ğŸŒŸ CogVideoX-Flash (å…è´¹)", "cogvideox_flash")
        self.engine_combo.addItem("ğŸ­ è±†åŒ…è§†é¢‘ç”Ÿæˆ Proç‰ˆ", "doubao_seedance_pro")
        self.engine_combo.addItem("ğŸ’° è±†åŒ…è§†é¢‘ç”Ÿæˆ Liteç‰ˆ (ä¾¿å®œ33%)", "doubao_seedance_lite")
        self.engine_combo.addItem("ğŸ†“ Vheer.com (å…è´¹å›¾ç”Ÿè§†é¢‘)", "vheer")
        self.engine_combo.setCurrentIndex(0)  # é»˜è®¤é€‰æ‹©CogVideoX-Flash
        self.engine_combo.currentTextChanged.connect(self.on_engine_changed)
        engine_form.addRow("é€‰æ‹©å¼•æ“:", self.engine_combo)

        engine_group.setLayout(engine_form)
        layout.addWidget(engine_group)

        # CogVideoX-Flash è®¾ç½®ç»„
        self.cogvideox_group = QGroupBox("CogVideoX-Flash è®¾ç½®")
        cogvideox_form = QFormLayout()

        # è§†é¢‘æ—¶é•¿ - CogVideoX-Flashæ”¯æŒçš„æ—¶é•¿
        self.duration_combo = QComboBox()
        self.duration_combo.addItems(["5", "10"])  # CogVideoX-Flashåªæ”¯æŒ5ç§’å’Œ10ç§’
        self.duration_combo.setCurrentText("5")
        self.duration_combo.setToolTip("è§†é¢‘æ—¶é•¿ï¼ˆCogVideoX-Flashæ”¯æŒ5ç§’ã€10ç§’ï¼‰")
        cogvideox_form.addRow("è§†é¢‘æ—¶é•¿:", self.duration_combo)

        # åˆ†è¾¨ç‡è¯´æ˜ - è‡ªåŠ¨æ ¹æ®å›¾åƒå°ºå¯¸ç¡®å®š
        resolution_label = QLabel("åˆ†è¾¨ç‡: è‡ªåŠ¨æ ¹æ®å›¾åƒå°ºå¯¸ç¡®å®š")
        resolution_label.setStyleSheet("color: #666; font-style: italic;")
        cogvideox_form.addRow("", resolution_label)

        # å¸§ç‡ - CogVideoX-Flashåªæ”¯æŒ30å’Œ60fps
        self.fps_combo = QComboBox()
        self.fps_combo.addItems(["30", "60"])
        self.fps_combo.setCurrentText("30")
        cogvideox_form.addRow("å¸§ç‡:", self.fps_combo)

        # å¹¶å‘ä»»åŠ¡æ•° - CogVideoX-Flashæ”¯æŒå¤šä¸ªå¹¶å‘ä»»åŠ¡
        self.concurrent_tasks_combo = QComboBox()
        self.concurrent_tasks_combo.addItems(["1", "2", "3", "4", "5"])
        self.concurrent_tasks_combo.setCurrentText("3")
        self.concurrent_tasks_combo.setToolTip("åŒæ—¶è¿›è¡Œçš„è§†é¢‘ç”Ÿæˆä»»åŠ¡æ•°é‡ã€‚æ•°é‡è¶Šå¤šé€Ÿåº¦è¶Šå¿«ï¼Œä½†å¯èƒ½å¢åŠ æœåŠ¡å™¨è´Ÿè½½")
        # è¿æ¥ä¿¡å·ï¼Œå½“ç”¨æˆ·æ”¹å˜å¹¶å‘æ•°æ—¶å®æ—¶æ›´æ–°
        self.concurrent_tasks_combo.currentTextChanged.connect(self.on_concurrent_changed)
        cogvideox_form.addRow("å¹¶å‘ä»»åŠ¡æ•°:", self.concurrent_tasks_combo)

        # è¿åŠ¨å¼ºåº¦
        motion_layout = QHBoxLayout()
        self.motion_slider = QSlider(Qt.Orientation.Horizontal)
        self.motion_slider.setRange(0, 100)
        self.motion_slider.setValue(50)
        self.motion_label = QLabel("50%")
        self.motion_slider.valueChanged.connect(
            lambda v: self.motion_label.setText(f"{v}%")
        )
        motion_layout.addWidget(self.motion_slider)
        motion_layout.addWidget(self.motion_label)
        cogvideox_form.addRow("è¿åŠ¨å¼ºåº¦:", motion_layout)

        self.cogvideox_group.setLayout(cogvideox_form)
        layout.addWidget(self.cogvideox_group)

        # è±†åŒ…è§†é¢‘ç”Ÿæˆè®¾ç½®ç»„
        self.doubao_group = QGroupBox("è±†åŒ…è§†é¢‘ç”Ÿæˆè®¾ç½®")
        doubao_form = QFormLayout()

        # è§†é¢‘æ—¶é•¿ - è±†åŒ…æ”¯æŒçš„æ—¶é•¿
        self.doubao_duration_combo = QComboBox()
        self.doubao_duration_combo.addItems(["5", "10"])  # è±†åŒ…æ”¯æŒ5ç§’å’Œ10ç§’
        self.doubao_duration_combo.setCurrentText("5")
        self.doubao_duration_combo.setToolTip("è§†é¢‘æ—¶é•¿ï¼ˆè±†åŒ…æ”¯æŒ5ç§’å’Œ10ç§’ï¼‰")
        doubao_form.addRow("è§†é¢‘æ—¶é•¿:", self.doubao_duration_combo)

        # åˆ†è¾¨ç‡é€‰æ‹© - è±†åŒ…æ”¯æŒçš„åˆ†è¾¨ç‡
        self.doubao_resolution_combo = QComboBox()
        self.doubao_resolution_combo.addItems([
            "480p", "720p", "1080p"
        ])
        self.doubao_resolution_combo.setCurrentText("720p")
        doubao_form.addRow("åˆ†è¾¨ç‡:", self.doubao_resolution_combo)

        # å®½é«˜æ¯”é€‰æ‹©
        self.doubao_ratio_combo = QComboBox()
        self.doubao_ratio_combo.addItems([
            "16:9 (æ¨ªå±)", "9:16 (ç«–å±)", "1:1 (æ­£æ–¹å½¢)",
            "4:3", "3:4", "21:9", "9:21", "keep_ratio (ä¿æŒåŸæ¯”ä¾‹)", "adaptive (è‡ªé€‚åº”)"
        ])
        self.doubao_ratio_combo.setCurrentText("16:9 (æ¨ªå±)")
        doubao_form.addRow("å®½é«˜æ¯”:", self.doubao_ratio_combo)

        # å¸§ç‡ - è±†åŒ…è‡ªåŠ¨ç¡®å®š
        doubao_fps_label = QLabel("30 fps (è‡ªåŠ¨)")
        doubao_fps_label.setStyleSheet("color: #666; font-style: italic;")
        doubao_form.addRow("å¸§ç‡:", doubao_fps_label)

        # å¹¶å‘ä»»åŠ¡æ•° - è±†åŒ…Proæ”¯æŒ10å¹¶å‘ï¼ŒLiteæ”¯æŒ5å¹¶å‘
        self.doubao_concurrent_tasks_combo = QComboBox()
        self.doubao_concurrent_tasks_combo.addItems(["1", "2", "3", "4", "5", "6", "7", "8", "9", "10"])
        self.doubao_concurrent_tasks_combo.setCurrentText("2")
        self.doubao_concurrent_tasks_combo.setToolTip("åŒæ—¶è¿›è¡Œçš„è§†é¢‘ç”Ÿæˆä»»åŠ¡æ•°é‡ï¼ˆProç‰ˆæœ€å¤š10ä¸ªï¼ŒLiteç‰ˆæœ€å¤š5ä¸ªï¼‰")
        doubao_form.addRow("å¹¶å‘ä»»åŠ¡æ•°:", self.doubao_concurrent_tasks_combo)

        self.doubao_group.setLayout(doubao_form)
        layout.addWidget(self.doubao_group)

        # é»˜è®¤éšè—è±†åŒ…è®¾ç½®ç»„
        self.doubao_group.setVisible(False)

        # åˆå§‹åŒ–è±†åŒ…å¹¶å‘æ•°é€‰é¡¹ï¼ˆä¸ºäº†ç¡®ä¿é€‰é¡¹æ­£ç¡®ï¼‰
        self._update_doubao_concurrent_options("doubao_seedance_pro")

        # Vheer.com å…è´¹å›¾ç”Ÿè§†é¢‘è®¾ç½®ç»„
        self.vheer_group = QGroupBox("Vheer.com å…è´¹å›¾ç”Ÿè§†é¢‘è®¾ç½®")
        vheer_form = QFormLayout()

        # è§†é¢‘æ ¼å¼ - æ ¹æ®æˆªå›¾æ·»åŠ 
        self.vheer_format_combo = QComboBox()
        self.vheer_format_combo.addItem("MP4", "mp4")
        self.vheer_format_combo.addItem("WebM", "webm")
        self.vheer_format_combo.setCurrentIndex(0)  # é»˜è®¤MP4
        vheer_form.addRow("è§†é¢‘æ ¼å¼:", self.vheer_format_combo)

        # è§†é¢‘æ—¶é•¿ - æ ¹æ®æˆªå›¾æ›´æ–°
        self.vheer_duration_combo = QComboBox()
        self.vheer_duration_combo.addItem("5ç§’", 5)
        self.vheer_duration_combo.setCurrentIndex(0)  # é»˜è®¤5ç§’
        vheer_form.addRow("è§†é¢‘æ—¶é•¿:", self.vheer_duration_combo)

        # è§†é¢‘å¸§ç‡ - æ ¹æ®æˆªå›¾æ·»åŠ 
        self.vheer_fps_combo = QComboBox()
        self.vheer_fps_combo.addItem("24å¸§/ç§’", 24)
        self.vheer_fps_combo.addItem("25å¸§/ç§’", 25)
        self.vheer_fps_combo.addItem("30å¸§/ç§’", 30)
        self.vheer_fps_combo.setCurrentIndex(0)  # é»˜è®¤24å¸§/ç§’
        vheer_form.addRow("è§†é¢‘å¸§ç‡:", self.vheer_fps_combo)

        # ç­‰å¾…è¶…æ—¶æ—¶é—´
        self.vheer_timeout_spin = QSpinBox()
        self.vheer_timeout_spin.setRange(60, 600)
        self.vheer_timeout_spin.setValue(300)
        self.vheer_timeout_spin.setSuffix(" ç§’")
        self.vheer_timeout_spin.setToolTip("ç­‰å¾…è§†é¢‘ç”Ÿæˆå®Œæˆçš„æœ€å¤§æ—¶é—´")
        vheer_form.addRow("è¶…æ—¶æ—¶é—´:", self.vheer_timeout_spin)

        # æ— å¤´æ¨¡å¼ - ä¿®å¤é€‰é¡¹æ— æ•ˆé—®é¢˜
        self.vheer_headless_check = QCheckBox("æ— å¤´æ¨¡å¼ï¼ˆåå°è¿è¡Œï¼‰")
        self.vheer_headless_check.setChecked(False)  # é»˜è®¤å…³é—­ï¼Œé¿å…è°ƒè¯•é—®é¢˜
        self.vheer_headless_check.setToolTip("å¯ç”¨åæµè§ˆå™¨å°†åœ¨åå°è¿è¡Œï¼Œä¸æ˜¾ç¤ºç•Œé¢ã€‚è°ƒè¯•æ—¶å»ºè®®å…³é—­ã€‚")
        vheer_form.addRow(self.vheer_headless_check)

        # è¯´æ˜æ–‡å­—
        vheer_info = QLabel("ğŸ†“ Vheer.comæ˜¯å…è´¹çš„å›¾ç”Ÿè§†é¢‘æœåŠ¡ï¼Œæ— éœ€APIå¯†é’¥\n"
                           "âš ï¸ ç”±äºæ˜¯ç½‘é¡µè‡ªåŠ¨åŒ–ï¼Œç”Ÿæˆé€Ÿåº¦è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…")
        vheer_info.setStyleSheet("color: #666; font-size: 10px; padding: 5px;")
        vheer_info.setWordWrap(True)
        vheer_form.addRow(vheer_info)

        self.vheer_group.setLayout(vheer_form)
        layout.addWidget(self.vheer_group)

        # é»˜è®¤éšè—Vheerè®¾ç½®ç»„
        self.vheer_group.setVisible(False)

        # è¾“å‡ºè®¾ç½®ç»„
        output_group = QGroupBox("è¾“å‡ºè®¾ç½®")
        output_form = QFormLayout()

        # è¾“å‡ºç›®å½•æ˜¾ç¤º
        self.output_dir_label = QLabel("é¡¹ç›®/videos/cogvideox/")
        self.output_dir_label.setStyleSheet("color: #666; font-style: italic;")
        output_form.addRow("è¾“å‡ºç›®å½•:", self.output_dir_label)

        # è‡ªåŠ¨æ’­æ”¾
        self.auto_play_check = QCheckBox("ç”Ÿæˆå®Œæˆåè‡ªåŠ¨æ’­æ”¾")
        self.auto_play_check.setChecked(True)
        output_form.addRow(self.auto_play_check)

        output_group.setLayout(output_form)
        layout.addWidget(output_group)

        # é¢„è§ˆåŒºåŸŸ
        preview_group = QGroupBox("å½“å‰é€‰æ‹©é¢„è§ˆ")
        preview_layout = QVBoxLayout()

        # å›¾åƒé¢„è§ˆ
        self.image_preview = QLabel("é€‰æ‹©åœºæ™¯æŸ¥çœ‹å›¾åƒé¢„è§ˆ")
        self.image_preview.setMinimumHeight(150)
        self.image_preview.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_preview.setStyleSheet("border: 1px solid #ccc; background-color: #f9f9f9;")
        preview_layout.addWidget(self.image_preview)

        # æè¿°é¢„è§ˆ
        self.description_preview = QTextEdit()
        self.description_preview.setMaximumHeight(80)
        self.description_preview.setPlaceholderText("é€‰æ‹©åœºæ™¯æŸ¥çœ‹æè¿°")
        self.description_preview.setReadOnly(True)
        preview_layout.addWidget(self.description_preview)

        preview_group.setLayout(preview_layout)
        layout.addWidget(preview_group)

        # å•ä¸ªç”ŸæˆæŒ‰é’®
        self.single_generate_btn = QPushButton("ğŸ¥ ç”Ÿæˆå½“å‰é€‰æ‹©")
        self.single_generate_btn.clicked.connect(self.start_single_generation)
        self.single_generate_btn.setStyleSheet("QPushButton { background-color: #2196F3; color: white; font-weight: bold; }")
        layout.addWidget(self.single_generate_btn)

        layout.addStretch()
        return panel

    def create_progress_area(self, parent_layout):
        """åˆ›å»ºè¿›åº¦åŒºåŸŸ"""
        progress_frame = QFrame()
        progress_frame.setFrameStyle(QFrame.Shape.StyledPanel)
        progress_frame.setMaximumHeight(80)  # é™åˆ¶è¿›åº¦åŒºåŸŸé«˜åº¦
        progress_layout = QVBoxLayout(progress_frame)
        progress_layout.setContentsMargins(5, 5, 5, 5)  # å‡å°‘è¾¹è·
        progress_layout.setSpacing(3)  # å‡å°‘é—´è·

        # è¿›åº¦æ¡
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        self.progress_bar.setMaximumHeight(20)  # é™åˆ¶è¿›åº¦æ¡é«˜åº¦
        progress_layout.addWidget(self.progress_bar)

        # çŠ¶æ€æ ‡ç­¾å’Œæ§åˆ¶æŒ‰é’®åœ¨åŒä¸€è¡Œ
        status_control_layout = QHBoxLayout()

        # çŠ¶æ€æ ‡ç­¾
        self.status_label = QLabel("å°±ç»ª")
        self.status_label.setStyleSheet("color: #666; font-size: 12px;")
        status_control_layout.addWidget(self.status_label)

        status_control_layout.addStretch()

        # æ§åˆ¶æŒ‰é’®
        self.cancel_btn = QPushButton("âŒ å–æ¶ˆç”Ÿæˆ")
        self.cancel_btn.clicked.connect(self.cancel_generation)
        self.cancel_btn.setVisible(False)
        self.cancel_btn.setMaximumHeight(25)
        status_control_layout.addWidget(self.cancel_btn)

        self.open_output_btn = QPushButton("ğŸ“ æ‰“å¼€è¾“å‡ºç›®å½•")
        self.open_output_btn.clicked.connect(self.open_output_directory)
        self.open_output_btn.setMaximumHeight(25)
        status_control_layout.addWidget(self.open_output_btn)

        # æ¸…ç†ç¼ºå¤±è§†é¢‘æ•°æ®æŒ‰é’®
        self.clean_missing_btn = QPushButton("ğŸ§¹ æ¸…ç†ç¼ºå¤±æ•°æ®")
        self.clean_missing_btn.clicked.connect(self.clean_all_missing_video_data)
        self.clean_missing_btn.setMaximumHeight(25)
        self.clean_missing_btn.setToolTip("æ¸…ç†é¡¹ç›®ä¸­å·²åˆ é™¤è§†é¢‘æ–‡ä»¶çš„æ•°æ®è®°å½•")
        status_control_layout.addWidget(self.clean_missing_btn)

        progress_layout.addLayout(status_control_layout)
        parent_layout.addWidget(progress_frame)

    def load_project_data(self):
        """åŠ è½½é¡¹ç›®æ•°æ®"""
        try:
            if not self.project_manager or not self.project_manager.current_project:
                self.status_label.setText("æœªåŠ è½½é¡¹ç›®")
                self.update_output_dir_label()
                return

            project_data = self.project_manager.get_project_data()
            if not project_data:
                self.status_label.setText("é¡¹ç›®æ•°æ®ä¸ºç©º")
                self.update_output_dir_label()
                return

            # ğŸ”§ æ–°å¢ï¼šåˆå§‹åŒ–IDç®¡ç†å™¨
            self.shot_id_manager.initialize_from_project_data(project_data)
            logger.info("è§†é¢‘ç”Ÿæˆç•Œé¢ï¼šIDç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

            # åŠ è½½åœºæ™¯æ•°æ®
            self.load_scenes_data(project_data)

            # æ›´æ–°è¾“å‡ºç›®å½•æ ‡ç­¾
            self.update_output_dir_label()

            # æ›´æ–°çŠ¶æ€
            scene_count = len(self.current_scenes)
            self.status_label.setText(f"å·²åŠ è½½ {scene_count} ä¸ªé•œå¤´")

        except Exception as e:
            logger.error(f"åŠ è½½é¡¹ç›®æ•°æ®å¤±è´¥: {e}")
            self.status_label.setText(f"åŠ è½½å¤±è´¥: {e}")
            self.update_output_dir_label()

    def load_scenes_data(self, project_data):
        """åŠ è½½åœºæ™¯æ•°æ®"""
        try:
            self.current_scenes = []
            logger.info(f"å¼€å§‹åŠ è½½åœºæ™¯æ•°æ®ï¼Œé¡¹ç›®æ•°æ®é”®: {list(project_data.keys())}")

            # å°è¯•å¤šç§æ•°æ®æºåŠ è½½åœºæ™¯æ•°æ®
            scenes_loaded = False

            # æ–¹æ³•1ï¼šä»æ–°çš„é¡¹ç›®æ•°æ®ç»“æ„ä¸­æå–
            if not scenes_loaded:
                scenes_loaded = self._load_from_new_structure(project_data)

            # æ–¹æ³•2ï¼šä»æ—§çš„é¡¹ç›®æ•°æ®ç»“æ„ä¸­æå–
            if not scenes_loaded:
                scenes_loaded = self._load_from_legacy_structure(project_data)

            # æ–¹æ³•3ï¼šä»åˆ†é•œå›¾åƒç”Ÿæˆæ•°æ®ä¸­æå–
            if not scenes_loaded:
                scenes_loaded = self._load_from_storyboard_data(project_data)

            if not scenes_loaded:
                logger.warning("æœªèƒ½ä»ä»»ä½•æ•°æ®æºåŠ è½½é•œå¤´æ•°æ®")
                self.status_label.setText("æœªæ‰¾åˆ°é•œå¤´æ•°æ®")
                return

            # æ›´æ–°è¡¨æ ¼æ˜¾ç¤º
            self.update_scene_table()

            # ğŸ”§ æ–°å¢ï¼šå¼ºåˆ¶åˆ·æ–°è¡¨æ ¼æ˜¾ç¤º
            self.scene_table.viewport().update()
            self.scene_table.repaint()

            # ğŸ”§ è°ƒè¯•ï¼šç»Ÿè®¡è§†é¢‘æ•°æ®
            video_count = sum(1 for scene in self.current_scenes if scene.get('video_path') and os.path.exists(scene.get('video_path', '')))
            logger.info(f"æˆåŠŸåŠ è½½ {len(self.current_scenes)} ä¸ªåœºæ™¯ï¼Œå…¶ä¸­ {video_count} ä¸ªæœ‰è§†é¢‘æ–‡ä»¶")

        except Exception as e:
            logger.error(f"åŠ è½½åœºæ™¯æ•°æ®å¤±è´¥: {e}")
            raise

    def _load_from_new_structure(self, project_data):
        """ä»æ–°çš„é¡¹ç›®æ•°æ®ç»“æ„åŠ è½½"""
        try:
            # æ–¹æ³•1ï¼šä»voice_generation.voice_segmentsåŠ è½½ï¼ˆä¼˜å…ˆï¼‰
            voice_generation = project_data.get('voice_generation', {})
            voice_segments = voice_generation.get('voice_segments', [])
            if voice_segments:
                logger.info(f"ä»voice_generation.voice_segmentsåŠ è½½ï¼Œæ‰¾åˆ° {len(voice_segments)} ä¸ªé•œå¤´")
                return self._load_from_voice_segments(voice_segments, project_data)

            # æ–¹æ³•2ï¼šä»shots_dataåŠ è½½
            shots_data = project_data.get('shots_data', [])
            if shots_data:
                logger.info(f"ä»shots_dataåŠ è½½ï¼Œæ‰¾åˆ° {len(shots_data)} ä¸ªé•œå¤´")
                return self._load_from_shots_data(shots_data, project_data)

            # æ–¹æ³•3ï¼šä»storyboard.shotsåŠ è½½
            storyboard = project_data.get('storyboard', {})
            shots = storyboard.get('shots', [])
            if shots:
                logger.info(f"ä»storyboard.shotsåŠ è½½ï¼Œæ‰¾åˆ° {len(shots)} ä¸ªé•œå¤´")
                return self._load_from_storyboard_shots(shots, project_data)

            # æ–¹æ³•4ï¼šä»äº”é˜¶æ®µæ•°æ®åŠ è½½ï¼ˆæœ€åé€‰æ‹©ï¼‰
            five_stage_data = project_data.get('five_stage_storyboard', {})
            if five_stage_data:
                logger.info("å°è¯•ä»äº”é˜¶æ®µæ•°æ®åŠ è½½")
                return self._load_from_five_stage_data(five_stage_data, project_data)

            return False

        except Exception as e:
            logger.error(f"ä»æ–°ç»“æ„åŠ è½½å¤±è´¥: {e}")
            return False

    def _load_from_voice_segments(self, voice_segments, project_data):
        """ä»voice_generation.voice_segmentsåŠ è½½"""
        try:
            self.current_scenes = []

            # è·å–enhanced_descriptionså’Œimage_generationæ•°æ®
            enhanced_descriptions = project_data.get('enhanced_descriptions', {})
            image_generation = project_data.get('image_generation', {})

            for segment in voice_segments:
                scene_data = self._create_scene_data_from_voice_segment(segment, enhanced_descriptions, image_generation, project_data)
                if scene_data:
                    self.current_scenes.append(scene_data)

            logger.info(f"ä»voice_segmentsåŠ è½½äº† {len(self.current_scenes)} ä¸ªé•œå¤´")
            return len(self.current_scenes) > 0

        except Exception as e:
            logger.error(f"ä»voice_segmentsåŠ è½½å¤±è´¥: {e}")
            return False

    def _create_scene_data_from_voice_segment(self, segment, enhanced_descriptions, image_generation, project_data):
        """ä»voice_segmentåˆ›å»ºåœºæ™¯æ•°æ®"""
        try:
            shot_id = segment.get('shot_id', '')
            scene_id = segment.get('scene_id', '')

            # è·å–åŸæ–‡å†…å®¹ - ä¼˜å…ˆä»å¤šä¸ªå­—æ®µä¸­è·å–
            original_text = (
                segment.get('original_text', '') or
                segment.get('text', '') or
                segment.get('content', '') or
                segment.get('narration', '') or
                ''
            )

            # è·å–åˆ†é•œæè¿°
            storyboard_description = (
                segment.get('storyboard_description', '') or
                segment.get('description', '') or
                segment.get('enhanced_description', '') or
                ''
            )

            # åˆ›å»ºåŸºç¡€åœºæ™¯æ•°æ®
            scene_data = {
                'shot_id': shot_id,
                'scene_id': scene_id,
                'shot_number': shot_id,
                'shot_title': shot_id,  # æ·»åŠ shot_titleå­—æ®µ
                'scene_title': scene_id,  # æ·»åŠ scene_titleå­—æ®µ
                'narration': original_text,  # ä½¿ç”¨è·å–åˆ°çš„åŸæ–‡
                'original_text': original_text,  # ä¿ç•™åŸæ–‡å­—æ®µ
                'description': storyboard_description,
                'enhanced_description': '',
                'voice_path': segment.get('audio_path', ''),
                'voice_duration': 0.0,
                'image_path': '',
                'video_path': '',
                'status': 'æœªç”Ÿæˆ'
            }

            # è·å–é…éŸ³æ—¶é•¿ - ä¼˜å…ˆä»segmentä¸­è·å–ï¼Œç„¶åä»æ–‡ä»¶è·å–
            voice_duration = segment.get('duration', 0.0) or segment.get('voice_duration', 0.0)
            if voice_duration > 0:
                scene_data['voice_duration'] = voice_duration
                logger.info(f"ä»segmentè·å–éŸ³é¢‘æ—¶é•¿: {shot_id} -> {voice_duration:.1f}s")
            elif scene_data['voice_path'] and os.path.exists(scene_data['voice_path']):
                voice_duration = self._get_audio_duration(scene_data['voice_path'])
                scene_data['voice_duration'] = voice_duration
                logger.info(f"ä»æ–‡ä»¶è·å–éŸ³é¢‘æ—¶é•¿: {scene_data['voice_path']} -> {voice_duration:.1f}s")
            else:
                logger.warning(f"æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿: {shot_id}, éŸ³é¢‘è·¯å¾„: {scene_data['voice_path']}")

            # ä»enhanced_descriptionsè·å–å›¾åƒä¿¡æ¯
            shot_key = f"### {shot_id}"
            if shot_key in enhanced_descriptions:
                enhanced_data = enhanced_descriptions[shot_key]
                scene_data['enhanced_description'] = enhanced_data.get('enhanced_prompt', '')

            # ä»å¤šä¸ªæ•°æ®æºè·å–å›¾åƒè·¯å¾„
            image_path = ''
            image_status = 'æœªç”Ÿæˆ'

            # æ–¹æ³•1ï¼šä»shot_image_mappingsè·å–ï¼ˆä¸»è¦æ•°æ®æºï¼‰
            shot_image_mappings = project_data.get('shot_image_mappings', {})
            if shot_image_mappings:
                # ğŸ”§ ä¿®å¤ï¼šæ„å»ºæ›´å…¨é¢çš„å¯èƒ½é”®ååˆ—è¡¨
                possible_keys = []

                # ç›´æ¥ä½¿ç”¨shot_id
                possible_keys.append(shot_id)

                # å¦‚æœshot_idæ˜¯text_segment_xxxæ ¼å¼ï¼Œç”Ÿæˆå¯¹åº”çš„scene_shotæ ¼å¼
                if shot_id.startswith('text_segment_'):
                    shot_number = shot_id.split('_')[-1]
                    try:
                        shot_num = str(int(shot_number))  # å»æ‰å‰å¯¼é›¶
                        possible_keys.extend([
                            f"scene_1_{shot_id}",  # scene_1_text_segment_001
                            f"scene_1_shot_{shot_num}",  # scene_1_shot_1
                            f"scene_1_shot_{shot_number}",  # scene_1_shot_001
                            f"shot_{shot_num}",  # shot_1
                            f"shot_{shot_number}",  # shot_001
                        ])
                    except ValueError:
                        pass

                # å¦‚æœshot_idæ˜¯shot_xxxæ ¼å¼ï¼Œç”Ÿæˆå¯¹åº”çš„scene_shotæ ¼å¼
                elif shot_id.startswith('shot_'):
                    shot_number = shot_id.split('_')[-1]
                    possible_keys.extend([
                        f"scene_1_{shot_id}",  # scene_1_shot_1
                        f"text_segment_{shot_number.zfill(3)}",  # text_segment_001
                    ])

                # ä½¿ç”¨IDç®¡ç†å™¨è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if hasattr(self, 'shot_id_manager') and self.shot_id_manager and hasattr(self.shot_id_manager, 'shot_mappings'):
                    try:
                        unified_key = self.shot_id_manager.convert_id(shot_id, "unified")
                        if unified_key and unified_key not in possible_keys:
                            possible_keys.append(unified_key)
                            logger.debug(f"IDç®¡ç†å™¨è½¬æ¢: {shot_id} -> {unified_key}")
                    except Exception as e:
                        logger.debug(f"IDç®¡ç†å™¨è½¬æ¢å¤±è´¥: {e}")

                # å°è¯•æ‰€æœ‰å¯èƒ½çš„é”®å
                for key in possible_keys:
                    if key in shot_image_mappings:
                        img_data = shot_image_mappings[key]
                        # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆè·å–ä¸»å›¾è·¯å¾„ï¼Œç¡®ä¿è§†é¢‘ç”Ÿæˆä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„ä¸»å›¾
                        image_path = img_data.get('main_image_path', '') or img_data.get('image_path', '')
                        image_status = img_data.get('status', 'æœªç”Ÿæˆ')
                        logger.debug(f"ä»shot_image_mappingsæ‰¾åˆ°å›¾åƒ: {key} -> {image_path} (ä¸»å›¾ä¼˜å…ˆ)")
                        break

                # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
                if not image_path:
                    for mapping_key, img_data in shot_image_mappings.items():
                        # æ£€æŸ¥é”®åæ˜¯å¦åŒ…å«shot_idçš„æ•°å­—éƒ¨åˆ†
                        if shot_id.startswith('text_segment_'):
                            shot_number = shot_id.split('_')[-1]
                            if shot_number in mapping_key:
                                image_path = img_data.get('main_image_path', '') or img_data.get('image_path', '')
                                image_status = img_data.get('status', 'æœªç”Ÿæˆ')
                                logger.debug(f"æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°å›¾åƒ: {mapping_key} -> {image_path}")
                                break

            # æ–¹æ³•2ï¼šä»image_generationè·å–
            if not image_path:
                if shot_id in image_generation:
                    image_data = image_generation[shot_id]
                    if isinstance(image_data, dict):
                        # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆè·å–ä¸»å›¾è·¯å¾„
                        image_path = image_data.get('main_image_path', '') or image_data.get('image_path', '')
                        image_status = image_data.get('status', 'æœªç”Ÿæˆ')
                    elif isinstance(image_data, str):
                        image_path = image_data
                        image_status = 'å·²ç”Ÿæˆ' if os.path.exists(image_path) else 'æœªç”Ÿæˆ'

            # æ–¹æ³•3ï¼šä»imagesåˆ—è¡¨ä¸­æŸ¥æ‰¾
            if not image_path:
                images_list = image_generation.get('images', [])
                for img in images_list:
                    if isinstance(img, dict) and img.get('shot_id') == shot_id:
                        # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆè·å–ä¸»å›¾è·¯å¾„
                        image_path = img.get('main_image_path', '') or img.get('image_path', '')
                        image_status = img.get('status', 'æœªç”Ÿæˆ')
                        break

            # éªŒè¯å›¾åƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if image_path and os.path.exists(image_path):
                image_status = 'å·²ç”Ÿæˆ'
            elif image_path:
                logger.warning(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                image_path = ''
                image_status = 'æœªç”Ÿæˆ'

            scene_data['image_path'] = image_path

            # ğŸ”§ æ–°å¢ï¼šè·å–è§†é¢‘è·¯å¾„ä¿¡æ¯
            video_path = ''
            video_status = 'æœªç”Ÿæˆ'

            # æ–¹æ³•1ï¼šä»shot_mappingsè·å–ï¼ˆæ–°çš„ä¿å­˜æ–¹å¼ï¼‰
            shot_mappings = project_data.get('shot_mappings', {})
            if shot_id in shot_mappings:
                mapping_data = shot_mappings[shot_id]
                video_path = mapping_data.get('video_path', '')
                video_status = mapping_data.get('video_status', 'æœªç”Ÿæˆ')
                logger.debug(f"ä»shot_mappingsæ‰¾åˆ°è§†é¢‘: {shot_id} -> {video_path}")

            # æ–¹æ³•2ï¼šä»video_generation.videosè·å–
            if not video_path:
                video_generation = project_data.get('video_generation', {})
                videos = video_generation.get('videos', [])
                for video in videos:
                    if isinstance(video, dict) and video.get('shot_id') == shot_id:
                        video_path = video.get('video_path', '')
                        video_status = video.get('status', 'æœªç”Ÿæˆ')
                        logger.debug(f"ä»video_generationæ‰¾åˆ°è§†é¢‘: {shot_id} -> {video_path}")
                        break

            # éªŒè¯è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if video_path and os.path.exists(video_path):
                video_status = 'å·²ç”Ÿæˆ'
                scene_data['status'] = 'å·²ç”Ÿæˆ'  # å¦‚æœæœ‰è§†é¢‘ï¼ŒçŠ¶æ€è®¾ä¸ºå·²ç”Ÿæˆ
            elif video_path:
                logger.warning(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                video_path = ''
                video_status = 'æœªç”Ÿæˆ'

            scene_data['video_path'] = video_path

            # æ›´æ–°çŠ¶æ€ï¼šå¦‚æœæœ‰è§†é¢‘åˆ™ä¸ºå·²ç”Ÿæˆï¼Œå¦åˆ™æ ¹æ®å›¾åƒçŠ¶æ€å†³å®š
            if video_status == 'å·²ç”Ÿæˆ':
                scene_data['status'] = 'å·²ç”Ÿæˆ'
            else:
                scene_data['status'] = image_status

            logger.debug(f"é•œå¤´ {shot_id} ä¿¡æ¯: å›¾åƒ={image_path}, è§†é¢‘={video_path}, çŠ¶æ€={scene_data['status']}")

            return scene_data

        except Exception as e:
            logger.error(f"åˆ›å»ºåœºæ™¯æ•°æ®å¤±è´¥: {e}")
            return None

    def _load_from_shots_data(self, shots_data, project_data):
        """ä»shots_dataåŠ è½½"""
        try:
            # è·å–é…éŸ³æ•°æ®
            voice_generation = project_data.get('voice_generation', {})
            voice_segments = voice_generation.get('segments', [])

            # è·å–å›¾åƒæ•°æ®
            image_generation = project_data.get('image_generation', {})
            images = image_generation.get('images', [])

            # è·å–è§†é¢‘æ•°æ®
            video_generation = project_data.get('video_generation', {})
            videos = video_generation.get('videos', [])

            # å¤„ç†æ¯ä¸ªé•œå¤´
            for i, shot in enumerate(shots_data):
                shot_id = shot.get('shot_id', f'shot_{i+1}')
                scene_id = shot.get('scene_id', f'scene_{i//5+1}')  # å‡è®¾æ¯5ä¸ªé•œå¤´ä¸€ä¸ªåœºæ™¯

                scene_data = self._create_scene_data(shot_id, scene_id, shot, voice_segments, images, videos)
                self.current_scenes.append(scene_data)

            return len(self.current_scenes) > 0

        except Exception as e:
            logger.error(f"ä»shots_dataåŠ è½½å¤±è´¥: {e}")
            return False

    def _load_from_storyboard_shots(self, shots, project_data):
        """ä»storyboard.shotsåŠ è½½"""
        try:
            # è·å–é…éŸ³æ•°æ®
            voice_generation = project_data.get('voice_generation', {})
            voice_segments = voice_generation.get('segments', [])

            # è·å–å›¾åƒæ•°æ®
            image_generation = project_data.get('image_generation', {})
            images = image_generation.get('images', [])

            # è·å–è§†é¢‘æ•°æ®
            video_generation = project_data.get('video_generation', {})
            videos = video_generation.get('videos', [])

            # å¤„ç†æ¯ä¸ªé•œå¤´
            for shot in shots:
                shot_id = shot.get('shot_id', '')
                scene_id = shot.get('scene_id', '')

                scene_data = self._create_scene_data(shot_id, scene_id, shot, voice_segments, images, videos)
                self.current_scenes.append(scene_data)

            return len(self.current_scenes) > 0

        except Exception as e:
            logger.error(f"ä»storyboard.shotsåŠ è½½å¤±è´¥: {e}")
            return False

    def _load_from_five_stage_data(self, five_stage_data, project_data):
        """ä»äº”é˜¶æ®µæ•°æ®åŠ è½½"""
        try:
            stage_data = five_stage_data.get('stage_data', {})

            # ä»ç¬¬5é˜¶æ®µè·å–æœ€ç»ˆåˆ†é•œæ•°æ®
            stage_5 = stage_data.get('5', {})
            final_storyboard = stage_5.get('final_storyboard', [])

            if not final_storyboard:
                # å°è¯•ä»ç¬¬4é˜¶æ®µè·å–
                stage_4 = stage_data.get('4', {})
                storyboard_results = stage_4.get('storyboard_results', [])
                if storyboard_results:
                    # å±•å¼€æ‰€æœ‰åœºæ™¯çš„é•œå¤´
                    final_storyboard = []
                    for scene_result in storyboard_results:
                        voice_segments = scene_result.get('voice_segments', [])
                        final_storyboard.extend(voice_segments)

            if not final_storyboard:
                return False

            logger.info(f"ä»äº”é˜¶æ®µæ•°æ®åŠ è½½ï¼Œæ‰¾åˆ° {len(final_storyboard)} ä¸ªé•œå¤´")

            # è·å–é…éŸ³æ•°æ®
            voice_generation = project_data.get('voice_generation', {})
            voice_segments = voice_generation.get('segments', [])

            # è·å–å›¾åƒæ•°æ®
            image_generation = project_data.get('image_generation', {})
            images = image_generation.get('images', [])

            # è·å–è§†é¢‘æ•°æ®
            video_generation = project_data.get('video_generation', {})
            videos = video_generation.get('videos', [])

            # å¤„ç†æ¯ä¸ªé•œå¤´
            for i, shot in enumerate(final_storyboard):
                shot_id = shot.get('shot_id', f'shot_{i+1}')
                scene_id = shot.get('scene_id', f'scene_{i//5+1}')

                scene_data = self._create_scene_data(shot_id, scene_id, shot, voice_segments, images, videos)
                self.current_scenes.append(scene_data)

            return len(self.current_scenes) > 0

        except Exception as e:
            logger.error(f"ä»äº”é˜¶æ®µæ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False

    def _load_from_legacy_structure(self, project_data):
        """ä»æ—§çš„é¡¹ç›®æ•°æ®ç»“æ„åŠ è½½"""
        try:
            # æ–¹æ³•1ï¼šä»shot_image_mappingsåŠ è½½
            shot_image_mappings = project_data.get('shot_image_mappings', {})
            if shot_image_mappings:
                logger.info(f"ä»shot_image_mappingsåŠ è½½ï¼Œæ‰¾åˆ° {len(shot_image_mappings)} ä¸ªé•œå¤´æ˜ å°„")
                return self._load_from_shot_mappings(shot_image_mappings, project_data)

            # æ–¹æ³•2ï¼šä»æ—§çš„voices/images/videosç»“æ„åŠ è½½
            voices = project_data.get('voices', {})
            images = project_data.get('images', {})
            videos = project_data.get('videos', {})
            scenes = project_data.get('scenes', [])

            if not scenes and not voices and not images:
                return False

            # å¦‚æœæœ‰voices/imagesæ•°æ®ä½†æ²¡æœ‰scenesï¼Œå°è¯•ä»é”®åæ¨æ–­
            if (voices or images) and not scenes:
                return self._load_from_voice_image_keys(voices, images, videos, project_data)

            # æ ‡å‡†çš„scenesç»“æ„
            for scene_idx, scene in enumerate(scenes):
                shots = scene.get('shots', [])
                for shot_idx, shot in enumerate(shots):
                    shot_key = f"scene_{scene_idx}_shot_{shot_idx}"

                    scene_data = {
                        'scene_id': f"scene_{scene_idx}",
                        'shot_id': f"shot_{shot_idx}",
                        'scene_title': scene.get('title', f'åœºæ™¯{scene_idx + 1}'),
                        'shot_title': shot.get('title', f'é•œå¤´{shot_idx + 1}'),
                        'description': shot.get('description', ''),
                        'enhanced_description': shot.get('enhanced_description', ''),
                        'original_text': shot.get('original_text', ''),
                        'voice_path': '',
                        'voice_duration': 0.0,
                        'image_path': '',
                        'video_path': '',
                        'status': 'æœªç”Ÿæˆ'
                    }

                    # æŸ¥æ‰¾é…éŸ³æ–‡ä»¶
                    if shot_key in voices:
                        voice_info = voices[shot_key]
                        if isinstance(voice_info, dict):
                            scene_data['voice_path'] = voice_info.get('file_path', '')
                            scene_data['voice_duration'] = voice_info.get('duration', 0.0)
                        else:
                            scene_data['voice_path'] = str(voice_info)

                    # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
                    if shot_key in images:
                        image_info = images[shot_key]
                        if isinstance(image_info, dict):
                            scene_data['image_path'] = image_info.get('file_path', '')
                        else:
                            scene_data['image_path'] = str(image_info)

                    # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
                    if shot_key in videos:
                        video_info = videos[shot_key]
                        if isinstance(video_info, dict):
                            scene_data['video_path'] = video_info.get('file_path', '')
                            if scene_data['video_path'] and os.path.exists(scene_data['video_path']):
                                scene_data['status'] = 'å·²ç”Ÿæˆ'

                    self.current_scenes.append(scene_data)

            return len(self.current_scenes) > 0

        except Exception as e:
            logger.error(f"ä»æ—§ç»“æ„åŠ è½½å¤±è´¥: {e}")
            return False

    def _load_from_shot_mappings(self, shot_mappings, project_data):
        """ä»shot_image_mappingsåŠ è½½"""
        try:
            # è·å–é…éŸ³æ•°æ®
            voice_generation = project_data.get('voice_generation', {})
            voice_segments = voice_generation.get('segments', [])

            # è·å–è§†é¢‘æ•°æ®
            video_generation = project_data.get('video_generation', {})
            videos = video_generation.get('videos', [])

            for shot_key, mapping_data in shot_mappings.items():
                # è§£æshot_key (å¦‚: scene_1_shot_1)
                parts = shot_key.split('_')
                if len(parts) >= 4:
                    scene_id = f"{parts[0]}_{parts[1]}"
                    shot_id = f"{parts[2]}_{parts[3]}"
                else:
                    scene_id = f"scene_{len(self.current_scenes)//5+1}"
                    shot_id = f"shot_{len(self.current_scenes)+1}"

                scene_data = {
                    'scene_id': scene_id,
                    'shot_id': shot_id,
                    'scene_title': scene_id.replace('_', ' ').title(),
                    'shot_title': shot_id.replace('_', ' ').title(),
                    'description': mapping_data.get('enhanced_description', ''),
                    'enhanced_description': mapping_data.get('enhanced_description', ''),
                    'original_text': mapping_data.get('original_text', ''),
                    'voice_path': '',
                    'voice_duration': 0.0,
                    'image_path': mapping_data.get('main_image_path', ''),
                    'video_path': '',
                    'status': mapping_data.get('status', 'æœªç”Ÿæˆ')
                }

                # æŸ¥æ‰¾é…éŸ³æ–‡ä»¶
                for voice_segment in voice_segments:
                    if (voice_segment.get('shot_id') == shot_id or
                        voice_segment.get('shot_id') == shot_key):
                        audio_path = voice_segment.get('audio_path', '')
                        if audio_path and os.path.exists(audio_path):
                            scene_data['voice_path'] = audio_path
                            scene_data['voice_duration'] = voice_segment.get('duration', 0.0)
                        break

                # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
                for video in videos:
                    if (video.get('shot_id') == shot_id or
                        video.get('shot_id') == shot_key):
                        video_path = video.get('video_path', '')
                        if video_path and os.path.exists(video_path):
                            scene_data['video_path'] = video_path
                            scene_data['status'] = 'å·²ç”Ÿæˆ'
                        break

                self.current_scenes.append(scene_data)

            return len(self.current_scenes) > 0

        except Exception as e:
            logger.error(f"ä»shot_mappingsåŠ è½½å¤±è´¥: {e}")
            return False

    def _load_from_voice_image_keys(self, voices, images, videos, project_data):
        """ä»voice/imageé”®åæ¨æ–­é•œå¤´æ•°æ®"""
        try:
            # æ”¶é›†æ‰€æœ‰çš„é•œå¤´é”®
            all_keys = set()
            all_keys.update(voices.keys())
            all_keys.update(images.keys())
            all_keys.update(videos.keys())

            if not all_keys:
                return False

            for shot_key in sorted(all_keys):
                # è§£æshot_key
                parts = shot_key.split('_')
                if len(parts) >= 4:
                    scene_id = f"{parts[0]}_{parts[1]}"
                    shot_id = f"{parts[2]}_{parts[3]}"
                else:
                    scene_id = f"scene_{len(self.current_scenes)//5+1}"
                    shot_id = f"shot_{len(self.current_scenes)+1}"

                scene_data = {
                    'scene_id': scene_id,
                    'shot_id': shot_id,
                    'scene_title': scene_id.replace('_', ' ').title(),
                    'shot_title': shot_id.replace('_', ' ').title(),
                    'description': '',
                    'enhanced_description': '',
                    'original_text': '',
                    'voice_path': '',
                    'voice_duration': 0.0,
                    'image_path': '',
                    'video_path': '',
                    'status': 'æœªç”Ÿæˆ'
                }

                # å¤„ç†é…éŸ³æ•°æ®
                if shot_key in voices:
                    voice_info = voices[shot_key]
                    if isinstance(voice_info, dict):
                        scene_data['voice_path'] = voice_info.get('file_path', '')
                        scene_data['voice_duration'] = voice_info.get('duration', 0.0)
                    else:
                        scene_data['voice_path'] = str(voice_info)

                # å¤„ç†å›¾åƒæ•°æ®
                if shot_key in images:
                    image_info = images[shot_key]
                    if isinstance(image_info, dict):
                        scene_data['image_path'] = image_info.get('file_path', '')
                    else:
                        scene_data['image_path'] = str(image_info)

                # å¤„ç†è§†é¢‘æ•°æ®
                if shot_key in videos:
                    video_info = videos[shot_key]
                    if isinstance(video_info, dict):
                        scene_data['video_path'] = video_info.get('file_path', '')
                        if scene_data['video_path'] and os.path.exists(scene_data['video_path']):
                            scene_data['status'] = 'å·²ç”Ÿæˆ'

                self.current_scenes.append(scene_data)

            return len(self.current_scenes) > 0

        except Exception as e:
            logger.error(f"ä»voice/imageé”®åŠ è½½å¤±è´¥: {e}")
            return False

    def _load_from_storyboard_data(self, project_data):
        """ä»åˆ†é•œæ•°æ®åŠ è½½"""
        try:
            # å°è¯•ä»åˆ†é•œå›¾åƒç”Ÿæˆçš„æ•°æ®ä¸­åŠ è½½
            if hasattr(self.project_manager, 'get_storyboard_data'):
                storyboard_data = self.project_manager.get_storyboard_data()
                if storyboard_data:
                    for i, shot_data in enumerate(storyboard_data):
                        scene_data = {
                            'scene_id': f"scene_{i // 5 + 1}",  # å‡è®¾æ¯5ä¸ªé•œå¤´ä¸€ä¸ªåœºæ™¯
                            'shot_id': f"shot_{i + 1}",
                            'scene_title': f"åœºæ™¯{i // 5 + 1}",
                            'shot_title': f"é•œå¤´{i + 1}",
                            'description': shot_data.get('description', ''),
                            'enhanced_description': shot_data.get('enhanced_description', ''),
                            'original_text': shot_data.get('original_text', ''),
                            'voice_path': shot_data.get('voice_path', ''),
                            'voice_duration': shot_data.get('voice_duration', 0.0),
                            'image_path': shot_data.get('image_path', ''),
                            'video_path': '',
                            'status': 'æœªç”Ÿæˆ'
                        }
                        self.current_scenes.append(scene_data)

                    return len(self.current_scenes) > 0

            return False

        except Exception as e:
            logger.error(f"ä»åˆ†é•œæ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False

    def _create_scene_data(self, shot_id, scene_id, shot, voice_segments, images, videos):
        """åˆ›å»ºåœºæ™¯æ•°æ®"""
        # å¤„ç†ä¸åŒçš„æ•°æ®æ ¼å¼
        if isinstance(shot, dict):
            # ä»shots_dataæˆ–storyboardæ•°æ®
            description = shot.get('enhanced_description') or shot.get('scene_description') or shot.get('description', '')
            original_text = shot.get('shot_original_text') or shot.get('original_text', '')
            shot_title = shot.get('shot_type') or shot.get('sequence') or 'é•œå¤´'
        else:
            # å…¶ä»–æ ¼å¼
            description = ''
            original_text = ''
            shot_title = 'é•œå¤´'

        scene_data = {
            'scene_id': scene_id,
            'shot_id': shot_id,
            'scene_title': scene_id.replace('_', ' ').title(),
            'shot_title': shot_title,
            'description': description,
            'enhanced_description': description,
            'original_text': original_text,
            'voice_path': '',
            'voice_duration': 0.0,
            'image_path': '',
            'video_path': '',
            'status': 'æœªç”Ÿæˆ'
        }

        # æŸ¥æ‰¾å¯¹åº”çš„é…éŸ³æ–‡ä»¶
        for voice_segment in voice_segments:
            # æ”¯æŒå¤šç§åŒ¹é…æ–¹å¼
            voice_shot_id = voice_segment.get('shot_id', '')
            if (voice_shot_id == shot_id or
                voice_shot_id == f"shot_{shot_id}" or
                voice_shot_id.endswith(f"_{shot_id}")):

                audio_path = voice_segment.get('audio_path', '')
                if audio_path and os.path.exists(audio_path):
                    scene_data['voice_path'] = audio_path
                    # å°è¯•ä»æ•°æ®ä¸­è·å–æ—¶é•¿ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ£€æµ‹éŸ³é¢‘æ–‡ä»¶
                    duration = voice_segment.get('duration', 0.0)
                    if duration <= 0:
                        duration = self._get_audio_duration(audio_path)
                    scene_data['voice_duration'] = duration
                break

        # æŸ¥æ‰¾å¯¹åº”çš„å›¾åƒæ–‡ä»¶ - æ”¯æŒå¤šç§æ•°æ®æ ¼å¼
        image_found = False

        # æ–¹æ³•1ï¼šä»imagesæ•°ç»„æŸ¥æ‰¾
        for image in images:
            image_shot_id = image.get('shot_id', '')
            if (image_shot_id == shot_id or
                image_shot_id == f"shot_{shot_id}" or
                image_shot_id.endswith(f"_{shot_id}")):

                if image.get('is_main', False):
                    image_path = image.get('image_path', '')
                    if image_path and os.path.exists(image_path):
                        scene_data['image_path'] = image_path
                        image_found = True
                        break

        # æ–¹æ³•2ï¼šå¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»shotæ•°æ®æœ¬èº«è·å–
        if not image_found and isinstance(shot, dict):
            # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆè·å–ä¸»å›¾è·¯å¾„
            image_path = shot.get('main_image_path', '') or shot.get('image_path', '')
            if image_path and os.path.exists(image_path):
                scene_data['image_path'] = image_path
                image_found = True

        # æŸ¥æ‰¾å¯¹åº”çš„è§†é¢‘æ–‡ä»¶
        for video in videos:
            video_shot_id = video.get('shot_id', '')
            if (video_shot_id == shot_id or
                video_shot_id == f"shot_{shot_id}" or
                video_shot_id.endswith(f"_{shot_id}")):

                video_path = video.get('video_path', '')
                if video_path and os.path.exists(video_path):
                    scene_data['video_path'] = video_path
                    # ç¡®ä¿çŠ¶æ€æ˜¯å­—ç¬¦ä¸²ç±»å‹
                    status = video.get('status', 'å·²ç”Ÿæˆ')
                    scene_data['status'] = str(status) if status is not None else 'å·²ç”Ÿæˆ'
                break

        return scene_data

    def _get_audio_duration(self, audio_path):
        """è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not audio_path or not os.path.exists(audio_path):
                return 0.0

            # æ–¹æ³•1ï¼šä½¿ç”¨mutagenï¼ˆæœ€ç¨³å®šï¼Œä¼˜å…ˆä½¿ç”¨ï¼‰
            try:
                from mutagen._file import File
                audio_file = File(audio_path)
                if audio_file is not None and hasattr(audio_file, 'info') and audio_file.info is not None:
                    if hasattr(audio_file.info, 'length') and audio_file.info.length is not None:
                        duration = float(audio_file.info.length)
                        logger.debug(f"mutagenè·å–éŸ³é¢‘æ—¶é•¿æˆåŠŸ: {audio_path} -> {duration:.1f}s")
                        return duration
            except ImportError:
                logger.warning("mutagenåº“æœªå®‰è£…")
            except Exception as e:
                logger.warning(f"mutagenè·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")

            # æ–¹æ³•2ï¼šä½¿ç”¨pydub
            try:
                from pydub import AudioSegment
                audio = AudioSegment.from_file(audio_path)
                duration = len(audio) / 1000.0  # è½¬æ¢ä¸ºç§’
                logger.debug(f"pydubè·å–éŸ³é¢‘æ—¶é•¿æˆåŠŸ: {audio_path} -> {duration:.1f}s")
                return float(duration)
            except Exception as e:
                logger.warning(f"pydubè·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")

            # æ–¹æ³•3ï¼šä½¿ç”¨waveæ¨¡å—ï¼ˆä»…æ”¯æŒwavæ–‡ä»¶ï¼‰
            try:
                import wave
                if audio_path.lower().endswith('.wav'):
                    with wave.open(audio_path, 'r') as wav_file:
                        frames = wav_file.getnframes()
                        rate = wav_file.getframerate()
                        duration = frames / float(rate)
                        logger.debug(f"waveè·å–éŸ³é¢‘æ—¶é•¿æˆåŠŸ: {audio_path} -> {duration:.1f}s")
                        return duration
            except Exception as e:
                logger.warning(f"waveè·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")

            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
            logger.warning(f"æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿ï¼Œä½¿ç”¨é»˜è®¤å€¼5ç§’: {audio_path}")
            return 5.0  # é»˜è®¤5ç§’

        except Exception as e:
            logger.error(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
            return 5.0

    def _check_voice_duration_match(self, scene_data):
        """æ£€æŸ¥é…éŸ³æ—¶é•¿æ˜¯å¦éœ€è¦å¤šä¸ªå›¾åƒ"""
        voice_duration = scene_data.get('voice_duration', 0.0)
        if voice_duration <= 0:
            return 1, []  # æ²¡æœ‰é…éŸ³ï¼Œä½¿ç”¨1ä¸ªå›¾åƒ

        # æ¯ä¸ªè§†é¢‘ç‰‡æ®µçš„æœ€å¤§æ—¶é•¿ï¼ˆç§’ï¼‰
        max_segment_duration = 10.0  # CogVideoX-Flashæœ€å¤§æ”¯æŒ10ç§’

        # è®¡ç®—éœ€è¦çš„å›¾åƒæ•°é‡
        required_images = max(1, int(voice_duration / max_segment_duration) + (1 if voice_duration % max_segment_duration > 0 else 0))

        # è®¡ç®—æ¯ä¸ªç‰‡æ®µçš„æ—¶é•¿
        segment_durations = []
        remaining_duration = voice_duration

        for i in range(required_images):
            if remaining_duration > max_segment_duration:
                segment_durations.append(max_segment_duration)
                remaining_duration -= max_segment_duration
            else:
                segment_durations.append(remaining_duration)
                break

        return required_images, segment_durations

    def _get_scene_images(self, scene_data):
        """è·å–åœºæ™¯çš„æ‰€æœ‰å›¾åƒ"""
        shot_id = scene_data.get('shot_id', '')
        if not shot_id:
            return []

        # ä»é¡¹ç›®æ•°æ®ä¸­è·å–è¯¥é•œå¤´çš„æ‰€æœ‰å›¾åƒ
        project_data = self.project_manager.get_project_data() if self.project_manager else {}
        image_generation = project_data.get('image_generation', {})
        images = image_generation.get('images', [])

        scene_images = []
        for image in images:
            if image.get('shot_id') == shot_id:
                # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆè·å–ä¸»å›¾è·¯å¾„
                image_path = image.get('main_image_path', '') or image.get('image_path', '')
                if image_path and os.path.exists(image_path):
                    scene_images.append({
                        'path': image_path,
                        'is_main': image.get('is_main', False)
                    })

        # æŒ‰ä¸»å›¾åƒä¼˜å…ˆæ’åº
        scene_images.sort(key=lambda x: not x['is_main'])
        return scene_images

    def update_scene_table(self):
        """æ›´æ–°åœºæ™¯è¡¨æ ¼"""
        try:
            self.scene_table.setRowCount(len(self.current_scenes))

            for row, scene_data in enumerate(self.current_scenes):
                # é€‰æ‹©å¤é€‰æ¡†
                checkbox = QCheckBox()
                checkbox.stateChanged.connect(self.on_scene_selection_changed)
                self.scene_table.setCellWidget(row, 0, checkbox)

                # é•œå¤´ä¿¡æ¯ - æ˜¾ç¤ºé•œå¤´IDå’Œæ—ç™½å†…å®¹é¢„è§ˆ
                shot_id = scene_data.get('shot_id', f'é•œå¤´{row+1}')
                narration = scene_data.get('narration', scene_data.get('original_text', ''))

                # æ„å»ºæ˜¾ç¤ºæ–‡æœ¬ï¼šé•œå¤´ID + æ—ç™½é¢„è§ˆ
                if narration:
                    # æˆªå–æ—ç™½å‰30ä¸ªå­—ç¬¦ä½œä¸ºé¢„è§ˆ
                    narration_preview = narration[:30] + "..." if len(narration) > 30 else narration
                    shot_text = f"{shot_id}\n{narration_preview}"
                else:
                    shot_text = shot_id

                shot_item = QTableWidgetItem(shot_text)
                shot_item.setToolTip(f"é•œå¤´ID: {shot_id}\nå®Œæ•´æ—ç™½: {narration}")  # æ‚¬åœæ˜¾ç¤ºå®Œæ•´å†…å®¹
                self.scene_table.setItem(row, 1, shot_item)

                # é…éŸ³çŠ¶æ€å’Œæ—¶é•¿
                voice_widget = QWidget()
                voice_layout = QHBoxLayout(voice_widget)
                voice_layout.setContentsMargins(2, 2, 2, 2)

                voice_status = "âœ…" if scene_data['voice_path'] and os.path.exists(scene_data['voice_path']) else "âŒ"
                voice_status_label = QLabel(voice_status)
                voice_layout.addWidget(voice_status_label)

                # æ˜¾ç¤ºé…éŸ³æ—¶é•¿
                voice_duration = scene_data.get('voice_duration', 0.0)
                if voice_duration > 0:
                    duration_label = QLabel(f"{voice_duration:.1f}s")
                    duration_label.setStyleSheet("color: #666; font-size: 10px;")
                    voice_layout.addWidget(duration_label)

                self.scene_table.setCellWidget(row, 2, voice_widget)

                # å›¾åƒé¢„è§ˆï¼ˆå»æ‰ç»¿å‹¾ï¼Œæ”¾å¤§ç¼©ç•¥å›¾ï¼‰
                image_widget = QWidget()
                image_layout = QHBoxLayout(image_widget)
                image_layout.setContentsMargins(2, 2, 2, 2)

                # å¦‚æœæœ‰å›¾åƒï¼Œæ·»åŠ æ”¾å¤§çš„é¢„è§ˆ
                if scene_data['image_path'] and os.path.exists(scene_data['image_path']):
                    image_preview = QLabel()
                    pixmap = QPixmap(scene_data['image_path'])
                    if not pixmap.isNull():
                        # æ”¾å¤§ç¼©ç•¥å›¾å°ºå¯¸ï¼ˆä»40x30æ”¹ä¸º80x60ï¼‰
                        scaled_pixmap = pixmap.scaled(80, 60, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
                        image_preview.setPixmap(scaled_pixmap)
                        image_preview.setToolTip(f"å›¾åƒ: {os.path.basename(scene_data['image_path'])}")
                        image_layout.addWidget(image_preview)
                else:
                    # æ²¡æœ‰å›¾åƒæ—¶æ˜¾ç¤ºå ä½ç¬¦
                    no_image_label = QLabel("æš‚æ— å›¾åƒ")
                    no_image_label.setStyleSheet("color: #666; font-size: 12px;")
                    no_image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
                    image_layout.addWidget(no_image_label)

                self.scene_table.setCellWidget(row, 3, image_widget)

                # è§†é¢‘é¢„è§ˆå’Œæ’­æ”¾ï¼ˆå»æ‰çŠ¶æ€å›¾æ ‡ï¼Œæ·»åŠ ç¼©ç•¥å›¾ï¼‰
                video_widget = QWidget()
                video_layout = QHBoxLayout(video_widget)
                video_layout.setContentsMargins(2, 2, 2, 2)

                # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æ¸…ç†æ•°æ®
                video_exists = scene_data['video_path'] and os.path.exists(scene_data['video_path'])
                if scene_data['video_path'] and not video_exists:
                    # è§†é¢‘æ–‡ä»¶å·²è¢«åˆ é™¤ï¼Œæ¸…ç†é¡¹ç›®æ•°æ®
                    self._clean_missing_video_data(scene_data)
                    scene_data['video_path'] = ''  # æ¸…ç©ºå½“å‰æ•°æ®ä¸­çš„è·¯å¾„

                # å¦‚æœæœ‰è§†é¢‘ï¼Œæ·»åŠ ç¼©ç•¥å›¾å’Œæ’­æ”¾æŒ‰é’®
                if video_exists:
                    logger.debug(f"å°è¯•ä¸ºè§†é¢‘ç”Ÿæˆç¼©ç•¥å›¾: {scene_data['video_path']}")
                    # ç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾
                    video_thumbnail = self._generate_video_thumbnail(scene_data['video_path'])
                    if video_thumbnail:
                        logger.debug(f"è§†é¢‘ç¼©ç•¥å›¾ç”ŸæˆæˆåŠŸ: {scene_data['video_path']}")
                    else:
                        logger.warning(f"è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå¤±è´¥: {scene_data['video_path']}")

                    if video_thumbnail:
                        thumbnail_label = QLabel()
                        # ä¸å›¾åƒç¼©ç•¥å›¾ä¿æŒä¸€è‡´çš„å°ºå¯¸ï¼ˆ80x60ï¼‰
                        scaled_thumbnail = video_thumbnail.scaled(80, 60, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
                        thumbnail_label.setPixmap(scaled_thumbnail)
                        thumbnail_label.setToolTip(f"è§†é¢‘: {os.path.basename(scene_data['video_path'])}")
                        video_layout.addWidget(thumbnail_label)

                    # æ’­æ”¾æŒ‰é’®
                    play_btn = QPushButton("â–¶")
                    play_btn.setMaximumSize(30, 25)
                    play_btn.setToolTip("æ’­æ”¾è§†é¢‘")
                    play_btn.clicked.connect(lambda checked=False, path=scene_data['video_path']: self.play_video(path))
                    video_layout.addWidget(play_btn)
                else:
                    # æ²¡æœ‰è§†é¢‘æ—¶æ˜¾ç¤ºå ä½ç¬¦
                    no_video_label = QLabel("æš‚æ— è§†é¢‘")
                    no_video_label.setStyleSheet("color: #666; font-size: 12px;")
                    no_video_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
                    video_layout.addWidget(no_video_label)

                self.scene_table.setCellWidget(row, 4, video_widget)

                # çŠ¶æ€æŒ‰é’®
                action_widget = QWidget()
                action_layout = QVBoxLayout(action_widget)
                action_layout.setContentsMargins(2, 2, 2, 2)
                action_layout.setSpacing(2)

                # æ£€æŸ¥é…éŸ³æ—¶é•¿å’Œæ‰€éœ€å›¾åƒæ•°é‡
                voice_duration = scene_data.get('voice_duration', 0.0)
                required_images, segment_durations = self._check_voice_duration_match(scene_data)
                scene_images = self._get_scene_images(scene_data)

                # ç”Ÿæˆè§†é¢‘æŒ‰é’®
                generate_btn = QPushButton("ğŸ¬ ç”Ÿæˆ")
                generate_btn.setMaximumSize(80, 25)

                # æ ¹æ®çŠ¶æ€å’Œè§†é¢‘æ–‡ä»¶å­˜åœ¨æƒ…å†µè®¾ç½®æŒ‰é’®æ ·å¼å’Œæ–‡æœ¬
                status = scene_data.get('status', 'æœªç”Ÿæˆ')
                has_video = scene_data.get('video_path') and os.path.exists(scene_data.get('video_path', ''))

                if status == 'å·²ç”Ÿæˆ' or has_video:
                    generate_btn.setText("ğŸ”„ é‡æ–°ç”Ÿæˆ")
                    generate_btn.setStyleSheet("QPushButton { background-color: #FF9800; color: white; font-size: 10px; }")
                elif status == 'ç”Ÿæˆä¸­':
                    generate_btn.setText("â¸ ç”Ÿæˆä¸­...")
                    generate_btn.setEnabled(False)
                    generate_btn.setStyleSheet("QPushButton { background-color: #FFC107; color: black; font-size: 10px; }")
                else:
                    generate_btn.setStyleSheet("QPushButton { background-color: #4CAF50; color: white; font-size: 10px; }")

                # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å›¾åƒæ–‡ä»¶
                has_enough_images = len(scene_images) >= required_images

                # è®¾ç½®æŒ‰é’®çŠ¶æ€å’Œæç¤º
                if voice_duration > 10.0 and not has_enough_images:
                    generate_btn.setEnabled(False)
                    generate_btn.setToolTip(f"é…éŸ³æ—¶é•¿{voice_duration:.1f}sï¼Œéœ€è¦{required_images}ä¸ªå›¾åƒï¼Œå½“å‰åªæœ‰{len(scene_images)}ä¸ª")
                    generate_btn.setStyleSheet("QPushButton { background-color: #F44336; color: white; font-size: 10px; }")
                elif voice_duration > 10.0:
                    generate_btn.setEnabled(True)
                    generate_btn.setToolTip(f"é…éŸ³æ—¶é•¿{voice_duration:.1f}sï¼Œå°†ç”Ÿæˆ{required_images}ä¸ªè§†é¢‘ç‰‡æ®µ")
                else:
                    has_image = scene_data['image_path'] and os.path.exists(scene_data['image_path'])
                    has_voice = scene_data['voice_path'] and os.path.exists(scene_data['voice_path'])
                    is_not_generating = scene_data.get('status', 'æœªç”Ÿæˆ') != 'ç”Ÿæˆä¸­'

                    # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯å¸ƒå°”ç±»å‹
                    enable_button = bool(has_image and has_voice and is_not_generating)
                    # ç¡®ä¿ä¼ é€’ç»™setEnabledçš„æ˜¯å¸ƒå°”å€¼
                    try:
                        generate_btn.setEnabled(bool(enable_button))
                    except Exception as e:
                        logger.error(f"è®¾ç½®æŒ‰é’®çŠ¶æ€å¤±è´¥: {e}, enable_buttonç±»å‹: {type(enable_button)}, å€¼: {enable_button}")
                        generate_btn.setEnabled(False)

                    if voice_duration > 0:
                        generate_btn.setToolTip(f"é…éŸ³æ—¶é•¿{voice_duration:.1f}sï¼Œç”Ÿæˆå•ä¸ªè§†é¢‘")
                    else:
                        generate_btn.setToolTip("ç”Ÿæˆè§†é¢‘")

                generate_btn.clicked.connect(lambda checked=False, r=row: self.generate_single_video(r))
                action_layout.addWidget(generate_btn)

                # å¦‚æœéœ€è¦å¤šä¸ªå›¾åƒï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
                if voice_duration > 10.0:
                    info_label = QLabel(f"éœ€è¦{required_images}å›¾")
                    info_label.setStyleSheet("color: #666; font-size: 9px;")
                    info_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
                    action_layout.addWidget(info_label)

                self.scene_table.setCellWidget(row, 5, action_widget)

                # æ“ä½œåˆ— - æ·»åŠ "ä½¿ç”¨å›¾åƒ"æŒ‰é’®
                operation_widget = QWidget()
                operation_layout = QVBoxLayout(operation_widget)
                operation_layout.setContentsMargins(2, 2, 2, 2)
                operation_layout.setSpacing(2)

                # ä½¿ç”¨å›¾åƒæŒ‰é’®
                use_image_btn = QPushButton("ğŸ–¼ï¸ ä½¿ç”¨å›¾åƒ")
                use_image_btn.setMaximumSize(80, 25)
                use_image_btn.setStyleSheet("QPushButton { background-color: #2196F3; color: white; font-size: 9px; }")
                use_image_btn.setToolTip("ä½¿ç”¨å›¾åƒåˆ›å»ºé™æ€è§†é¢‘ï¼ˆé€‚ç”¨äºå†…å®¹å®‰å…¨æ£€æµ‹å¤±è´¥çš„æƒ…å†µï¼‰")

                # æ£€æŸ¥æ˜¯å¦æœ‰å›¾åƒæ–‡ä»¶
                has_image = scene_data['image_path'] and os.path.exists(scene_data['image_path'])
                use_image_btn.setEnabled(has_image)

                if not has_image:
                    use_image_btn.setToolTip("éœ€è¦å…ˆæœ‰å›¾åƒæ–‡ä»¶æ‰èƒ½ä½¿ç”¨æ­¤åŠŸèƒ½")
                    use_image_btn.setStyleSheet("QPushButton { background-color: #CCCCCC; color: #666666; font-size: 9px; }")

                use_image_btn.clicked.connect(lambda checked=False, r=row: self.use_image_for_video(r))
                operation_layout.addWidget(use_image_btn)

                self.scene_table.setCellWidget(row, 6, operation_widget)

            # è¿æ¥è¡Œé€‰æ‹©äº‹ä»¶
            self.scene_table.itemSelectionChanged.connect(self.on_scene_row_selected)

        except Exception as e:
            logger.error(f"æ›´æ–°åœºæ™¯è¡¨æ ¼å¤±è´¥: {e}")

    def play_video(self, video_path):
        """æ’­æ”¾è§†é¢‘"""
        try:
            import subprocess
            import platform

            if platform.system() == "Windows":
                subprocess.run(["start", video_path], shell=True, check=True)
            elif platform.system() == "Darwin":  # macOS
                subprocess.run(["open", video_path], check=True)
            else:  # Linux
                subprocess.run(["xdg-open", video_path], check=True)

        except Exception as e:
            logger.error(f"æ’­æ”¾è§†é¢‘å¤±è´¥: {e}")
            QMessageBox.warning(self, "è­¦å‘Š", f"æ— æ³•æ’­æ”¾è§†é¢‘: {str(e)}")

    def generate_single_video(self, row):
        """ç”Ÿæˆå•ä¸ªè§†é¢‘"""
        try:
            if row < 0 or row >= len(self.current_scenes):
                return

            scene_data = self.current_scenes[row]

            # æ£€æŸ¥å¿…è¦æ–‡ä»¶
            if not scene_data['image_path'] or not os.path.exists(scene_data['image_path']):
                QMessageBox.warning(self, "è­¦å‘Š", "è¯¥åœºæ™¯ç¼ºå°‘å›¾åƒæ–‡ä»¶")
                return

            # å¼€å§‹ç”Ÿæˆ
            self.start_generation([scene_data])

        except Exception as e:
            logger.error(f"ç”Ÿæˆå•ä¸ªè§†é¢‘å¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"ç”Ÿæˆå¤±è´¥: {str(e)}")

    def use_image_for_video(self, row):
        """ä½¿ç”¨å›¾åƒåˆ›å»ºé™æ€è§†é¢‘"""
        try:
            if row < 0 or row >= len(self.current_scenes):
                return

            scene_data = self.current_scenes[row]
            shot_id = scene_data.get('shot_id', f'shot_{row+1}')

            logger.info(f"ç”¨æˆ·æ‰‹åŠ¨è§¦å‘å›¾åƒé™çº§: {shot_id}")

            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾åƒæ–‡ä»¶
            if not scene_data['image_path'] or not os.path.exists(scene_data['image_path']):
                QMessageBox.warning(self, "è­¦å‘Š", "æ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„å›¾åƒæ–‡ä»¶ï¼Œæ— æ³•åˆ›å»ºé™æ€è§†é¢‘")
                return

            # ç¡®è®¤å¯¹è¯æ¡†
            reply = QMessageBox.question(
                self,
                "ç¡®è®¤æ“ä½œ",
                f"ç¡®å®šè¦ä½¿ç”¨å›¾åƒä¸ºé•œå¤´ {shot_id} åˆ›å»ºé™æ€è§†é¢‘å—ï¼Ÿ\n\n"
                f"è¿™å°†åˆ›å»ºä¸€ä¸ªåŸºäºå›¾åƒçš„é™æ€è§†é¢‘ï¼Œæ—¶é•¿ä¸é…éŸ³ä¿æŒä¸€è‡´ã€‚\n"
                f"é€‚ç”¨äºè§†é¢‘ç”Ÿæˆé‡åˆ°å†…å®¹å®‰å…¨æ£€æµ‹é—®é¢˜çš„æƒ…å†µã€‚",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                QMessageBox.StandardButton.No
            )

            if reply != QMessageBox.StandardButton.Yes:
                return

            # æ›´æ–°çŠ¶æ€ä¸ºç”Ÿæˆä¸­
            self.update_scene_status(scene_data, 'ç”Ÿæˆä¸­')

            # æ˜¾ç¤ºè¿›åº¦
            self.status_label.setText(f"æ­£åœ¨ä½¿ç”¨å›¾åƒåˆ›å»ºé™æ€è§†é¢‘: {shot_id}")

            # æ¨¡æ‹Ÿå†…å®¹å®‰å…¨é”™è¯¯ï¼Œè§¦å‘é™çº§æœºåˆ¶
            error_message = "ç”¨æˆ·æ‰‹åŠ¨è§¦å‘å›¾åƒé™çº§åŠŸèƒ½"
            self._current_generating_scene = scene_data

            # ç›´æ¥è°ƒç”¨é™çº§å¤„ç†
            self._fallback_to_image_video(scene_data, error_message)

        except Exception as e:
            logger.error(f"ä½¿ç”¨å›¾åƒåˆ›å»ºè§†é¢‘å¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"ä½¿ç”¨å›¾åƒåˆ›å»ºè§†é¢‘å¤±è´¥: {str(e)}")

            # æ¢å¤çŠ¶æ€
            if 'scene_data' in locals():
                self.update_scene_status(scene_data, 'å¤±è´¥')

    def on_scene_selection_changed(self):
        """åœºæ™¯é€‰æ‹©çŠ¶æ€æ”¹å˜"""
        selected_count = self.get_selected_scene_count()
        self.batch_generate_btn.setText(f"ğŸ¬ æ‰¹é‡ç”Ÿæˆ ({selected_count})")
        self.batch_generate_btn.setEnabled(selected_count > 0)

        # æ›´æ–°æ‰¹é‡ä½¿ç”¨å›¾åƒæŒ‰é’®
        self.batch_use_image_btn.setText(f"ğŸ–¼ï¸ æ‰¹é‡ä½¿ç”¨å›¾åƒ ({selected_count})")
        # æ£€æŸ¥é€‰ä¸­çš„åœºæ™¯æ˜¯å¦éƒ½æœ‰å›¾åƒ
        has_images = self._check_selected_scenes_have_images()
        self.batch_use_image_btn.setEnabled(selected_count > 0 and has_images)

    def on_scene_row_selected(self):
        """åœºæ™¯è¡Œè¢«é€‰ä¸­"""
        try:
            current_row = self.scene_table.currentRow()
            if 0 <= current_row < len(self.current_scenes):
                scene_data = self.current_scenes[current_row]

                # æ›´æ–°å›¾åƒé¢„è§ˆ
                self.update_image_preview(scene_data['image_path'])

                # æ›´æ–°æè¿°é¢„è§ˆ - æ˜¾ç¤º original_prompt + technical_details
                original_prompt = scene_data.get('original_prompt', '')
                technical_details = scene_data.get('technical_details', '')

                preview_text = ""
                if original_prompt:
                    preview_text += f"åŸå§‹æè¿°ï¼š\n{original_prompt}\n\n"
                if technical_details:
                    preview_text += f"æŠ€æœ¯ç»†èŠ‚ï¼š\n{technical_details}"

                if not preview_text:
                    # å¦‚æœæ²¡æœ‰è¿™ä¸¤ä¸ªå­—æ®µï¼Œä½¿ç”¨åŸæ¥çš„é€»è¾‘
                    preview_text = scene_data.get('enhanced_description') or scene_data.get('description', '')

                self.description_preview.setPlainText(preview_text)

                # å¯ç”¨å•ä¸ªç”ŸæˆæŒ‰é’®
                image_path = scene_data.get('image_path', '')
                has_image = bool(image_path and os.path.exists(image_path))
                self.single_generate_btn.setEnabled(has_image)

        except Exception as e:
            logger.error(f"å¤„ç†åœºæ™¯é€‰æ‹©å¤±è´¥: {e}")

    def update_image_preview(self, image_path):
        """æ›´æ–°å›¾åƒé¢„è§ˆ"""
        try:
            if image_path and os.path.exists(image_path):
                pixmap = QPixmap(image_path)
                if not pixmap.isNull():
                    # ç¼©æ”¾å›¾åƒä»¥é€‚åº”é¢„è§ˆåŒºåŸŸ
                    scaled_pixmap = pixmap.scaled(
                        self.image_preview.size(),
                        Qt.AspectRatioMode.KeepAspectRatio,
                        Qt.TransformationMode.SmoothTransformation
                    )
                    self.image_preview.setPixmap(scaled_pixmap)
                else:
                    self.image_preview.setText("æ— æ³•åŠ è½½å›¾åƒ")
            else:
                self.image_preview.setText("æ— å›¾åƒæ–‡ä»¶")

        except Exception as e:
            logger.error(f"æ›´æ–°å›¾åƒé¢„è§ˆå¤±è´¥: {e}")
            self.image_preview.setText("å›¾åƒåŠ è½½å¤±è´¥")

    def get_selected_scene_count(self):
        """è·å–é€‰ä¸­çš„åœºæ™¯æ•°é‡"""
        count = 0
        for row in range(self.scene_table.rowCount()):
            checkbox = self.scene_table.cellWidget(row, 0)
            if checkbox and isinstance(checkbox, QCheckBox) and checkbox.isChecked():
                count += 1
        return count

    def get_selected_scenes(self):
        """è·å–é€‰ä¸­çš„åœºæ™¯æ•°æ®"""
        selected_scenes = []
        for row in range(self.scene_table.rowCount()):
            checkbox = self.scene_table.cellWidget(row, 0)
            if checkbox and isinstance(checkbox, QCheckBox) and checkbox.isChecked() and row < len(self.current_scenes):
                selected_scenes.append(self.current_scenes[row])
        return selected_scenes

    def select_all_scenes(self):
        """å…¨é€‰åœºæ™¯"""
        for row in range(self.scene_table.rowCount()):
            checkbox = self.scene_table.cellWidget(row, 0)
            if checkbox and isinstance(checkbox, QCheckBox):
                checkbox.setChecked(True)

    def select_none_scenes(self):
        """å–æ¶ˆå…¨é€‰åœºæ™¯"""
        for row in range(self.scene_table.rowCount()):
            checkbox = self.scene_table.cellWidget(row, 0)
            if checkbox and isinstance(checkbox, QCheckBox):
                checkbox.setChecked(False)

    def start_single_generation(self):
        """å¼€å§‹å•ä¸ªè§†é¢‘ç”Ÿæˆ"""
        try:
            current_row = self.scene_table.currentRow()
            if current_row < 0 or current_row >= len(self.current_scenes):
                QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªåœºæ™¯")
                return

            scene_data = self.current_scenes[current_row]

            # æ£€æŸ¥å¿…è¦æ–‡ä»¶
            if not scene_data['image_path'] or not os.path.exists(scene_data['image_path']):
                QMessageBox.warning(self, "è­¦å‘Š", "è¯¥åœºæ™¯ç¼ºå°‘å›¾åƒæ–‡ä»¶")
                return

            # å¼€å§‹ç”Ÿæˆ
            self.start_generation([scene_data])

        except Exception as e:
            logger.error(f"å¼€å§‹å•ä¸ªç”Ÿæˆå¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"å¼€å§‹ç”Ÿæˆå¤±è´¥: {str(e)}")

    def start_batch_generation(self):
        """å¼€å§‹æ‰¹é‡è§†é¢‘ç”Ÿæˆ"""
        try:
            selected_scenes = self.get_selected_scenes()

            if not selected_scenes:
                QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©è¦ç”Ÿæˆçš„åœºæ™¯")
                return

            # æ£€æŸ¥é€‰ä¸­åœºæ™¯çš„å›¾åƒæ–‡ä»¶
            missing_images = []
            for scene in selected_scenes:
                if not scene['image_path'] or not os.path.exists(scene['image_path']):
                    missing_images.append(f"{scene['scene_title']}-{scene['shot_title']}")

            if missing_images:
                reply = QMessageBox.question(
                    self, "ç¡®è®¤",
                    f"ä»¥ä¸‹åœºæ™¯ç¼ºå°‘å›¾åƒæ–‡ä»¶ï¼Œæ˜¯å¦è·³è¿‡ï¼Ÿ\n\n{chr(10).join(missing_images)}",
                    QMessageBox.StandardButton.Yes,
                    QMessageBox.StandardButton.No
                )
                if reply == QMessageBox.StandardButton.No:
                    return

                # è¿‡æ»¤æ‰ç¼ºå°‘å›¾åƒçš„åœºæ™¯
                selected_scenes = [s for s in selected_scenes if s['image_path'] and os.path.exists(s['image_path'])]

            if not selected_scenes:
                QMessageBox.warning(self, "è­¦å‘Š", "æ²¡æœ‰å¯ç”Ÿæˆçš„åœºæ™¯")
                return

            # å¼€å§‹ç”Ÿæˆ
            self.start_generation(selected_scenes)

        except Exception as e:
            logger.error(f"å¼€å§‹æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"å¼€å§‹ç”Ÿæˆå¤±è´¥: {str(e)}")

    def _check_selected_scenes_have_images(self):
        """æ£€æŸ¥é€‰ä¸­çš„åœºæ™¯æ˜¯å¦éƒ½æœ‰å›¾åƒ"""
        try:
            for row in range(self.scene_table.rowCount()):
                checkbox = self.scene_table.cellWidget(row, 0)
                if checkbox and checkbox.isChecked():
                    if row < len(self.current_scenes):
                        scene_data = self.current_scenes[row]
                        image_path = scene_data.get('image_path')
                        if not image_path or not os.path.exists(image_path):
                            return False
            return True
        except Exception as e:
            logger.error(f"æ£€æŸ¥åœºæ™¯å›¾åƒå¤±è´¥: {e}")
            return False

    def start_batch_use_image(self):
        """å¼€å§‹æ‰¹é‡ä½¿ç”¨å›¾åƒç”Ÿæˆè§†é¢‘"""
        try:
            # è·å–é€‰ä¸­çš„åœºæ™¯
            selected_scenes = []
            for row in range(self.scene_table.rowCount()):
                checkbox = self.scene_table.cellWidget(row, 0)
                if checkbox and checkbox.isChecked():
                    if row < len(self.current_scenes):
                        scene_data = self.current_scenes[row]
                        # æ£€æŸ¥æ˜¯å¦æœ‰å›¾åƒ
                        image_path = scene_data.get('image_path')
                        if image_path and os.path.exists(image_path):
                            selected_scenes.append(scene_data)

            if not selected_scenes:
                QMessageBox.warning(self, "è­¦å‘Š", "æ²¡æœ‰é€‰ä¸­æœ‰æ•ˆçš„åœºæ™¯æˆ–åœºæ™¯ç¼ºå°‘å›¾åƒæ–‡ä»¶")
                return

            # ç¡®è®¤å¯¹è¯æ¡†
            reply = QMessageBox.question(
                self,
                "ç¡®è®¤æ‰¹é‡æ“ä½œ",
                f"ç¡®å®šè¦ä¸º {len(selected_scenes)} ä¸ªé•œå¤´æ‰¹é‡ä½¿ç”¨å›¾åƒåˆ›å»ºé™æ€è§†é¢‘å—ï¼Ÿ\n\n"
                f"è¿™å°†ä¸ºæ¯ä¸ªé•œå¤´åˆ›å»ºåŸºäºå›¾åƒçš„é™æ€è§†é¢‘ï¼Œæ—¶é•¿ä¸é…éŸ³ä¿æŒä¸€è‡´ã€‚\n"
                f"è§†é¢‘åˆ†è¾¨ç‡å°†ä¸åŸå›¾åƒåˆ†è¾¨ç‡ä¿æŒä¸€è‡´ã€‚\n"
                f"é€‚ç”¨äºè§†é¢‘ç”Ÿæˆé‡åˆ°é—®é¢˜çš„æƒ…å†µã€‚",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                QMessageBox.StandardButton.No
            )

            if reply != QMessageBox.StandardButton.Yes:
                return

            # å¼€å§‹æ‰¹é‡å¤„ç†
            self.start_batch_image_processing(selected_scenes)

        except Exception as e:
            logger.error(f"å¼€å§‹æ‰¹é‡ä½¿ç”¨å›¾åƒå¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"å¼€å§‹æ‰¹é‡ä½¿ç”¨å›¾åƒå¤±è´¥: {str(e)}")

    def start_batch_image_processing(self, scenes_to_process):
        """å¼€å§‹æ‰¹é‡å›¾åƒå¤„ç†ï¼ˆå¹¶å‘æ¨¡å¼ï¼‰"""
        try:
            if not scenes_to_process:
                return

            logger.info(f"å¼€å§‹æ‰¹é‡å›¾åƒå¤„ç†ï¼Œå…± {len(scenes_to_process)} ä¸ªåœºæ™¯")

            # åˆå§‹åŒ–æ‰¹é‡å¤„ç†çŠ¶æ€
            self.batch_processing_active = True
            self.batch_processing_queue = scenes_to_process.copy()
            self.batch_processing_completed = 0
            self.batch_processing_total = len(scenes_to_process)
            self.batch_processing_failed = 0

            # æ›´æ–°æ‰€æœ‰åœºæ™¯çŠ¶æ€ä¸ºç­‰å¾…ä¸­
            for scene_data in scenes_to_process:
                self.update_scene_status(scene_data, 'ç­‰å¾…ä¸­')

            # ç¦ç”¨ç›¸å…³æŒ‰é’®
            self.batch_generate_btn.setEnabled(False)
            self.batch_use_image_btn.setEnabled(False)

            # æ›´æ–°çŠ¶æ€
            self.status_label.setText(f"æ‰¹é‡å›¾åƒå¤„ç†ä¸­: 0/{self.batch_processing_total}")

            # å¼€å§‹å¤„ç†ç¬¬ä¸€æ‰¹ä»»åŠ¡
            self.process_next_batch_image_tasks()

        except Exception as e:
            logger.error(f"å¼€å§‹æ‰¹é‡å›¾åƒå¤„ç†å¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"å¼€å§‹æ‰¹é‡å›¾åƒå¤„ç†å¤±è´¥: {str(e)}")

    def process_next_batch_image_tasks(self):
        """å¤„ç†ä¸‹ä¸€æ‰¹å›¾åƒä»»åŠ¡"""
        try:
            if not self.batch_processing_active or not self.batch_processing_queue:
                self.finish_batch_image_processing()
                return

            # è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡
            scene_data = self.batch_processing_queue.pop(0)

            # æ›´æ–°çŠ¶æ€ä¸ºç”Ÿæˆä¸­
            self.update_scene_status(scene_data, 'ç”Ÿæˆä¸­')

            # æ›´æ–°è¿›åº¦
            completed = self.batch_processing_total - len(self.batch_processing_queue)
            self.status_label.setText(f"æ‰¹é‡å›¾åƒå¤„ç†ä¸­: {completed}/{self.batch_processing_total}")

            # å¼€å§‹å¤„ç†è¿™ä¸ªåœºæ™¯
            self.process_single_image_to_video(scene_data)

        except Exception as e:
            logger.error(f"å¤„ç†ä¸‹ä¸€æ‰¹å›¾åƒä»»åŠ¡å¤±è´¥: {e}")
            self.finish_batch_image_processing()

    def process_single_image_to_video(self, scene_data):
        """å¤„ç†å•ä¸ªå›¾åƒè½¬è§†é¢‘ä»»åŠ¡"""
        try:
            shot_id = scene_data.get('shot_id', 'unknown')
            logger.info(f"å¼€å§‹å¤„ç†é•œå¤´ {shot_id} çš„å›¾åƒè½¬è§†é¢‘")

            # è·å–å›¾åƒè·¯å¾„
            image_path = scene_data.get('image_path')
            if not image_path or not os.path.exists(image_path):
                logger.error(f"é•œå¤´ {shot_id} ç¼ºå°‘å›¾åƒæ–‡ä»¶: {image_path}")
                self.handle_batch_image_task_failure(scene_data, "ç¼ºå°‘å›¾åƒæ–‡ä»¶")
                return

            # è·å–éŸ³é¢‘æ—¶é•¿ - ä¼˜å…ˆä½¿ç”¨voice_duration
            audio_duration = scene_data.get('voice_duration', 0.0)
            if audio_duration <= 0:
                # å¦‚æœæ²¡æœ‰voice_durationï¼Œå°è¯•ä»éŸ³é¢‘æ–‡ä»¶è·å–
                if scene_data.get('voice_path') and os.path.exists(scene_data.get('voice_path')):
                    audio_duration = self._get_audio_duration(scene_data.get('voice_path'))
                    logger.info(f"é•œå¤´ {scene_data.get('shot_id', 'unknown')} ä»éŸ³é¢‘æ–‡ä»¶è·å–æ—¶é•¿: {audio_duration}ç§’")
                else:
                    # å¦‚æœæ²¡æœ‰éŸ³é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤æ—¶é•¿
                    audio_duration = 5.0
                    logger.warning(f"é•œå¤´ {scene_data.get('shot_id', 'unknown')} æ²¡æœ‰é…éŸ³æ—¶é•¿ï¼Œä½¿ç”¨é»˜è®¤æ—¶é•¿: {audio_duration}ç§’")
            else:
                logger.info(f"é•œå¤´ {scene_data.get('shot_id', 'unknown')} ä½¿ç”¨é…éŸ³æ—¶é•¿: {audio_duration}ç§’")

            # åˆ›å»ºé™æ€è§†é¢‘ï¼ˆä¿æŒåŸå›¾åƒåˆ†è¾¨ç‡ï¼‰
            self.create_static_video_with_original_resolution(scene_data, image_path, audio_duration)

        except Exception as e:
            logger.error(f"å¤„ç†å•ä¸ªå›¾åƒè½¬è§†é¢‘å¤±è´¥: {e}")
            self.handle_batch_image_task_failure(scene_data, f"å¤„ç†å¼‚å¸¸: {e}")

    def create_static_video_with_original_resolution(self, scene_data, image_path, duration):
        """åˆ›å»ºä¿æŒåŸå›¾åƒåˆ†è¾¨ç‡çš„é™æ€è§†é¢‘ï¼ˆä½¿ç”¨åå°çº¿ç¨‹é¿å…UIå¡æ­»ï¼‰"""
        try:
            shot_id = scene_data.get('shot_id', 'unknown')
            logger.info(f"ä¸ºé•œå¤´ {shot_id} åˆ›å»ºå¸¦åŠ¨ç”»æ•ˆæœçš„é™æ€è§†é¢‘ï¼Œæ—¶é•¿: {duration}ç§’")

            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨åå°çº¿ç¨‹æ‰§è¡ŒFFmpegï¼Œé¿å…UIå¡æ­»
            from PyQt5.QtCore import QThread, QObject, pyqtSignal

            class AnimatedVideoCreationWorker(QObject):
                """å¸¦åŠ¨ç”»æ•ˆæœçš„è§†é¢‘åˆ›å»ºå·¥ä½œçº¿ç¨‹"""
                finished = pyqtSignal(bool, str, str, object)  # success, output_path, error_msg, scene_data

                def __init__(self, scene_data, image_path, duration, parent_tab):
                    super().__init__()
                    self.scene_data = scene_data
                    self.image_path = image_path
                    self.duration = duration
                    self.parent_tab = parent_tab

                def create_video(self):
                    """åœ¨åå°çº¿ç¨‹ä¸­åˆ›å»ºå¸¦åŠ¨ç”»æ•ˆæœçš„è§†é¢‘"""
                    try:
                        import subprocess
                        from PIL import Image
                        import hashlib

                        shot_id = self.scene_data.get('shot_id', 'unknown')

                        # è·å–åŸå›¾åƒåˆ†è¾¨ç‡
                        with Image.open(self.image_path) as img:
                            img_width, img_height = img.size
                            logger.info(f"åŸå›¾åƒå°ºå¯¸: {img_width}x{img_height}")

                        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                        timestamp = int(time.time() * 1000)
                        output_filename = f"animated_video_{shot_id}_{timestamp}.mp4"

                        # ç¡®å®šè¾“å‡ºç›®å½•
                        if self.parent_tab.project_manager and self.parent_tab.project_manager.current_project:
                            project_path = self.parent_tab.project_manager.get_current_project_path()
                            output_dir = os.path.join(project_path, 'videos', 'image_videos')
                        else:
                            output_dir = os.path.join('output', 'videos', 'image_videos')

                        os.makedirs(output_dir, exist_ok=True)
                        output_path = os.path.join(output_dir, output_filename)

                        # ğŸ¬ ä¼˜åŒ–ï¼šé€‚ä¸­å¹…åº¦çš„åŠ¨ç”»æ•ˆæœï¼ˆå‡å°‘ä¸‰åˆ†ä¹‹ä¸€å¹…åº¦ï¼‰
                        animation_effects = [
                            # ç¼©æ”¾+å·¦å³æ‘‡æ‘†ï¼ˆé€‚ä¸­ç‰ˆï¼‰
                            "scale=1.15*iw:1.15*ih,crop=iw/1.15:ih/1.15:(iw-iw/1.15)/2+sin(t*3)*40:(ih-ih/1.15)/2",
                            # ç¼©æ”¾+é€‚ä¸­å·¦ç§»ï¼ˆé€‚ä¸­ç‰ˆï¼‰
                            "scale=1.12*iw:1.12*ih,crop=iw/1.12:ih/1.12:(iw-iw/1.12)/2+t*17:(ih-ih/1.12)/2",
                            # ç¼©æ”¾+é€‚ä¸­å³ç§»ï¼ˆé€‚ä¸­ç‰ˆï¼‰
                            "scale=1.12*iw:1.12*ih,crop=iw/1.12:ih/1.12:(iw-iw/1.12)/2-t*17:(ih-ih/1.12)/2",
                            # ç¼©æ”¾+é€‚ä¸­ä¸Šç§»ï¼ˆé€‚ä¸­ç‰ˆï¼‰
                            "scale=1.14*iw:1.14*ih,crop=iw/1.14:ih/1.14:(iw-iw/1.14)/2:(ih-ih/1.14)/2+t*20",
                            # ç¼©æ”¾+é€‚ä¸­ä¸‹ç§»ï¼ˆé€‚ä¸­ç‰ˆï¼‰
                            "scale=1.14*iw:1.14*ih,crop=iw/1.14:ih/1.14:(iw-iw/1.14)/2:(ih-ih/1.14)/2-t*20",
                            # ç¼©æ”¾+é€‚ä¸­åœ†å½¢è¿åŠ¨ï¼ˆé€‚ä¸­ç‰ˆï¼‰
                            "scale=1.18*iw:1.18*ih,crop=iw/1.18:ih/1.18:(iw-iw/1.18)/2+sin(t*1.5)*53:(ih-ih/1.18)/2+cos(t*1.5)*33",
                            # ç¼©æ”¾+é€‚ä¸­å¯¹è§’çº¿ç§»åŠ¨ï¼ˆé€‚ä¸­ç‰ˆï¼‰
                            "scale=1.15*iw:1.15*ih,crop=iw/1.15:ih/1.15:(iw-iw/1.15)/2+t*13:(ih-ih/1.15)/2+t*10",
                            # ç¼©æ”¾+é€‚ä¸­æ³¢æµªè¿åŠ¨ï¼ˆé€‚ä¸­ç‰ˆï¼‰
                            "scale=1.16*iw:1.16*ih,crop=iw/1.16:ih/1.16:(iw-iw/1.16)/2+sin(t*4)*30:(ih-ih/1.16)/2+sin(t*2.5)*20",
                            # ç¼©æ”¾+é€‚ä¸­èºæ—‹è¿åŠ¨ï¼ˆé€‚ä¸­ç‰ˆï¼‰
                            "scale=1.2*iw:1.2*ih,crop=iw/1.2:ih/1.2:(iw-iw/1.2)/2+sin(t*2)*t*5:(ih-ih/1.2)/2+cos(t*2)*t*5",
                            # ç¼©æ”¾+é€‚ä¸­Zå­—å½¢è¿åŠ¨ï¼ˆé€‚ä¸­ç‰ˆï¼‰
                            "scale=1.18*iw:1.18*ih,crop=iw/1.18:ih/1.18:(iw-iw/1.18)/2+sin(t*6)*47:(ih-ih/1.18)/2+t*13"
                        ]

                        # æ ¹æ®é•œå¤´IDé€‰æ‹©åŠ¨ç”»æ•ˆæœï¼ˆç¡®ä¿åŒä¸€é•œå¤´æ€»æ˜¯ä½¿ç”¨ç›¸åŒæ•ˆæœï¼‰
                        shot_hash = int(hashlib.md5(shot_id.encode()).hexdigest()[:8], 16)
                        animation_effect = animation_effects[shot_hash % len(animation_effects)]

                        # åŠ¨ç”»æ•ˆæœåç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
                        effect_names = [
                            "ç¼©æ”¾+å·¦å³æ‘‡æ‘†ï¼ˆé€‚ä¸­ç‰ˆï¼‰", "ç¼©æ”¾+é€‚ä¸­å·¦ç§»ï¼ˆé€‚ä¸­ç‰ˆï¼‰", "ç¼©æ”¾+é€‚ä¸­å³ç§»ï¼ˆé€‚ä¸­ç‰ˆï¼‰", "ç¼©æ”¾+é€‚ä¸­ä¸Šç§»ï¼ˆé€‚ä¸­ç‰ˆï¼‰",
                            "ç¼©æ”¾+é€‚ä¸­ä¸‹ç§»ï¼ˆé€‚ä¸­ç‰ˆï¼‰", "ç¼©æ”¾+é€‚ä¸­åœ†å½¢è¿åŠ¨ï¼ˆé€‚ä¸­ç‰ˆï¼‰", "ç¼©æ”¾+é€‚ä¸­å¯¹è§’çº¿ç§»åŠ¨ï¼ˆé€‚ä¸­ç‰ˆï¼‰", "ç¼©æ”¾+é€‚ä¸­æ³¢æµªè¿åŠ¨ï¼ˆé€‚ä¸­ç‰ˆï¼‰",
                            "ç¼©æ”¾+é€‚ä¸­èºæ—‹è¿åŠ¨ï¼ˆé€‚ä¸­ç‰ˆï¼‰", "ç¼©æ”¾+é€‚ä¸­Zå­—å½¢è¿åŠ¨ï¼ˆé€‚ä¸­ç‰ˆï¼‰"
                        ]
                        effect_name = effect_names[shot_hash % len(effect_names)]

                        # ä½¿ç”¨FFmpegåˆ›å»ºå¸¦åŠ¨ç”»æ•ˆæœçš„è§†é¢‘
                        cmd = [
                            'ffmpeg/bin/ffmpeg.exe',
                            '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                            '-loop', '1',  # å¾ªç¯è¾“å…¥å›¾åƒ
                            '-i', self.image_path,  # è¾“å…¥å›¾åƒ
                            '-t', str(self.duration),  # è§†é¢‘æ—¶é•¿
                            '-r', '30',  # å¸§ç‡
                            '-vf', animation_effect,  # è§†é¢‘æ»¤é•œï¼ˆåŠ¨ç”»æ•ˆæœï¼‰
                            '-c:v', 'libx264',  # è§†é¢‘ç¼–ç å™¨
                            '-pix_fmt', 'yuv420p',  # åƒç´ æ ¼å¼
                            '-preset', 'medium',  # ç¼–ç é¢„è®¾
                            output_path
                        ]

                        logger.info(f"ä¸ºé•œå¤´ {shot_id} åˆ›å»ºå¸¦åŠ¨ç”»æ•ˆæœçš„è§†é¢‘")
                        logger.info(f"ä½¿ç”¨åŠ¨ç”»æ•ˆæœ: {effect_name}")
                        logger.info(f"æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd)}")

                        # æ‰§è¡ŒFFmpegå‘½ä»¤ï¼ˆå¢åŠ è¶…æ—¶æ—¶é—´ï¼‰
                        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)

                        if result.returncode == 0 and os.path.exists(output_path):
                            logger.info(f"å¸¦åŠ¨ç”»æ•ˆæœçš„è§†é¢‘åˆ›å»ºæˆåŠŸ: {output_path}")
                            self.finished.emit(True, output_path, "", self.scene_data)
                        else:
                            error_msg = result.stderr if result.stderr else "FFmpegæ‰§è¡Œå¤±è´¥"
                            logger.error(f"FFmpegæ‰§è¡Œå¤±è´¥: {error_msg}")
                            self.finished.emit(False, "", f"è§†é¢‘åˆ›å»ºå¤±è´¥: {error_msg}", self.scene_data)

                    except Exception as e:
                        logger.error(f"åˆ›å»ºå¸¦åŠ¨ç”»æ•ˆæœçš„è§†é¢‘å¤±è´¥: {e}")
                        self.finished.emit(False, "", f"åˆ›å»ºè§†é¢‘å¼‚å¸¸: {e}", self.scene_data)

            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨QTimerå»¶è¿Ÿæ‰§è¡Œï¼Œé¿å…çº¿ç¨‹ç®¡ç†é—®é¢˜
            def delayed_video_creation():
                try:
                    # ç›´æ¥åœ¨ä¸»çº¿ç¨‹ä¸­åˆ›å»ºworkerå¹¶æ‰§è¡Œ
                    worker = AnimatedVideoCreationWorker(scene_data, image_path, duration, self)
                    worker.finished.connect(self._on_animated_video_creation_finished)
                    worker.create_video()
                except Exception as e:
                    logger.error(f"å»¶è¿Ÿè§†é¢‘åˆ›å»ºå¤±è´¥: {e}")
                    self.handle_batch_image_task_failure(scene_data, f"è§†é¢‘åˆ›å»ºå¼‚å¸¸: {e}")

            # å»¶è¿Ÿ100msæ‰§è¡Œï¼Œç¡®ä¿UIçŠ¶æ€æ›´æ–°å®Œæˆ
            QTimer.singleShot(100, delayed_video_creation)
            logger.info(f"å·²å¯åŠ¨é•œå¤´ {shot_id} çš„åå°è§†é¢‘åˆ›å»ºä»»åŠ¡")

        except Exception as e:
            logger.error(f"å¯åŠ¨å¸¦åŠ¨ç”»æ•ˆæœçš„è§†é¢‘åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}")
            self.handle_batch_image_task_failure(scene_data, f"å¯åŠ¨ä»»åŠ¡å¼‚å¸¸: {e}")

    def _on_animated_video_creation_finished(self, success, output_path, error_msg, scene_data):
        """å¸¦åŠ¨ç”»æ•ˆæœçš„è§†é¢‘åˆ›å»ºå®Œæˆå›è°ƒ"""
        try:
            if success:
                self.handle_batch_image_task_success(scene_data, output_path)
            else:
                self.handle_batch_image_task_failure(scene_data, error_msg)

        except Exception as e:
            logger.error(f"è§†é¢‘åˆ›å»ºå®Œæˆå›è°ƒå¤±è´¥: {e}")

    def handle_batch_image_task_success(self, scene_data, output_path):
        """å¤„ç†æ‰¹é‡å›¾åƒä»»åŠ¡æˆåŠŸ"""
        try:
            shot_id = scene_data.get('shot_id', 'unknown')
            logger.info(f"å¤„ç†é•œå¤´ {shot_id} æ‰¹é‡å›¾åƒä»»åŠ¡æˆåŠŸ: {output_path}")

            # æ›´æ–°åœºæ™¯çŠ¶æ€ä¸ºå·²ç”Ÿæˆï¼Œè¿™æ ·ç•Œé¢ä¼šæ­£ç¡®æ˜¾ç¤º
            self.update_scene_status(scene_data, 'å·²ç”Ÿæˆ')

            # ä¿å­˜è§†é¢‘åˆ°é¡¹ç›® - ä¼ é€’åœºæ™¯æ•°æ®
            try:
                self.save_video_to_project(output_path, scene_data)
                logger.debug(f"é•œå¤´ {shot_id} è§†é¢‘è·¯å¾„å·²ä¿å­˜åˆ°é¡¹ç›®")
            except Exception as save_error:
                logger.error(f"ä¿å­˜é•œå¤´ {shot_id} è§†é¢‘åˆ°é¡¹ç›®å¤±è´¥: {save_error}")
                # å³ä½¿ä¿å­˜å¤±è´¥ï¼Œä¹Ÿç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªä»»åŠ¡
                pass

            # æ›´æ–°å®Œæˆè®¡æ•°
            self.batch_processing_completed += 1
            logger.debug(f"æ‰¹é‡å¤„ç†è¿›åº¦: {self.batch_processing_completed}/{self.batch_processing_total}")

            # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªä»»åŠ¡
            self.process_next_batch_image_tasks()

        except Exception as e:
            logger.error(f"å¤„ç†æ‰¹é‡å›¾åƒä»»åŠ¡æˆåŠŸå›è°ƒå¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            self.handle_batch_image_task_failure(scene_data, f"æˆåŠŸå›è°ƒå¼‚å¸¸: {e}")

    def handle_batch_image_task_failure(self, scene_data, error_message):
        """å¤„ç†æ‰¹é‡å›¾åƒä»»åŠ¡å¤±è´¥"""
        try:
            # æ›´æ–°åœºæ™¯çŠ¶æ€
            self.update_scene_status(scene_data, 'å¤±è´¥')

            # æ›´æ–°å¤±è´¥è®¡æ•°
            self.batch_processing_failed += 1

            logger.error(f"é•œå¤´ {scene_data.get('shot_id', 'unknown')} å›¾åƒå¤„ç†å¤±è´¥: {error_message}")

            # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªä»»åŠ¡
            self.process_next_batch_image_tasks()

        except Exception as e:
            logger.error(f"å¤„ç†æ‰¹é‡å›¾åƒä»»åŠ¡å¤±è´¥å›è°ƒå¤±è´¥: {e}")
            self.finish_batch_image_processing()

    def finish_batch_image_processing(self):
        """å®Œæˆæ‰¹é‡å›¾åƒå¤„ç†"""
        try:
            self.batch_processing_active = False

            # é‡æ–°å¯ç”¨æŒ‰é’®
            self.batch_generate_btn.setEnabled(True)
            self.batch_use_image_btn.setEnabled(True)

            # æ›´æ–°çŠ¶æ€
            success_count = self.batch_processing_completed
            failed_count = self.batch_processing_failed
            total_count = self.batch_processing_total

            status_msg = f"æ‰¹é‡å›¾åƒå¤„ç†å®Œæˆ: æˆåŠŸ {success_count}/{total_count}"
            if failed_count > 0:
                status_msg += f", å¤±è´¥ {failed_count}"

            self.status_label.setText(status_msg)

            # ä½¿ç”¨QTimerå»¶è¿Ÿæ˜¾ç¤ºå®Œæˆæ¶ˆæ¯ï¼Œé¿å…é˜»å¡UI
            def show_completion_message():
                try:
                    if failed_count == 0:
                        QMessageBox.information(self, "å®Œæˆ", f"æ‰¹é‡å›¾åƒå¤„ç†å®Œæˆï¼\næˆåŠŸå¤„ç† {success_count} ä¸ªé•œå¤´ã€‚")
                    else:
                        QMessageBox.warning(self, "éƒ¨åˆ†å®Œæˆ",
                            f"æ‰¹é‡å›¾åƒå¤„ç†å®Œæˆï¼\næˆåŠŸ: {success_count}\nå¤±è´¥: {failed_count}\næ€»è®¡: {total_count}")
                except Exception as msg_error:
                    logger.error(f"æ˜¾ç¤ºå®Œæˆæ¶ˆæ¯å¤±è´¥: {msg_error}")

            # å»¶è¿Ÿ500msæ˜¾ç¤ºæ¶ˆæ¯ï¼Œç¡®ä¿UIçŠ¶æ€æ›´æ–°å®Œæˆ
            QTimer.singleShot(500, show_completion_message)

            # ğŸ”§ ä¿®å¤ï¼šå»¶è¿Ÿé€šçŸ¥è§†é¢‘åˆæˆç•Œé¢åˆ·æ–°æ•°æ®ï¼Œé¿å…åœ¨æ‰¹é‡å¤„ç†å®Œæˆæ—¶ç«‹å³è§¦å‘ç•Œé¢é‡æ–°åˆå§‹åŒ–
            def delayed_notify_refresh():
                try:
                    logger.info("æ‰¹é‡å¤„ç†å®Œæˆï¼Œå»¶è¿Ÿé€šçŸ¥è§†é¢‘åˆæˆç•Œé¢åˆ·æ–°")
                    self.notify_video_synthesis_refresh()
                except Exception as notify_error:
                    logger.error(f"å»¶è¿Ÿé€šçŸ¥è§†é¢‘åˆæˆç•Œé¢åˆ·æ–°å¤±è´¥: {notify_error}")

            # å»¶è¿Ÿ2ç§’é€šçŸ¥ï¼Œç¡®ä¿æ‰¹é‡å¤„ç†çŠ¶æ€å®Œå…¨æ¸…ç†å®Œæˆ
            QTimer.singleShot(2000, delayed_notify_refresh)

            logger.info(f"æ‰¹é‡å›¾åƒå¤„ç†å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}, æ€»è®¡ {total_count}")

        except Exception as e:
            logger.error(f"å®Œæˆæ‰¹é‡å›¾åƒå¤„ç†å¤±è´¥: {e}")
            self.status_label.setText("æ‰¹é‡å›¾åƒå¤„ç†å¼‚å¸¸ç»“æŸ")

    def start_generation(self, scenes_to_generate):
        """å¼€å§‹è§†é¢‘ç”Ÿæˆï¼ˆå¹¶å‘æ¨¡å¼ï¼‰"""
        try:
            # ğŸ”§ ä¿®å¤ï¼šåŠ¨æ€è·å–ç”¨æˆ·è®¾ç½®çš„å¹¶å‘æ•°ï¼ˆæ ¹æ®é€‰æ‹©çš„å¼•æ“ï¼‰
            selected_engine = self.engine_combo.currentData() if hasattr(self, 'engine_combo') else 'cogvideox_flash'

            if selected_engine in ['doubao_seedance_pro', 'doubao_seedance_lite']:
                # è±†åŒ…å¼•æ“ä½¿ç”¨è±†åŒ…çš„å¹¶å‘æ•°è®¾ç½®
                user_concurrent = int(self.doubao_concurrent_tasks_combo.currentText())
            else:
                # CogVideoXå¼•æ“ä½¿ç”¨CogVideoXçš„å¹¶å‘æ•°è®¾ç½®
                user_concurrent = int(self.concurrent_tasks_combo.currentText())

            self.max_concurrent_videos = user_concurrent
            logger.info(f"ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„å¹¶å‘æ•°: {self.max_concurrent_videos}")

            # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
            if len(self.active_workers) >= self.max_concurrent_videos:
                QMessageBox.warning(self, "è­¦å‘Š", f"å·²è¾¾åˆ°æœ€å¤§å¹¶å‘æ•°({self.max_concurrent_videos})ï¼Œè¯·ç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆ")
                return

            # ğŸ”§ ä¿®å¤ï¼šè®°å½•å®é™…æäº¤çš„åœºæ™¯ï¼Œç”¨äºæ­£ç¡®ç»Ÿè®¡
            self._submitted_scenes = scenes_to_generate.copy()

            # è®¾ç½®ç”Ÿæˆé˜Ÿåˆ—
            self.generation_queue = scenes_to_generate.copy()

            logger.info(f"å¼€å§‹å¹¶å‘ç”Ÿæˆ {len(scenes_to_generate)} ä¸ªè§†é¢‘ï¼Œæœ€å¤§å¹¶å‘æ•°: {self.max_concurrent_videos}")

            # å¯åŠ¨å¹¶å‘ç”Ÿæˆ
            self.start_concurrent_generation()

        except Exception as e:
            logger.error(f"å¼€å§‹ç”Ÿæˆå¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"å¼€å§‹ç”Ÿæˆå¤±è´¥: {str(e)}")

    def start_concurrent_generation(self):
        """å¯åŠ¨å¹¶å‘ç”Ÿæˆ"""
        try:
            # å¯åŠ¨å°½å¯èƒ½å¤šçš„å¹¶å‘ä»»åŠ¡
            while (len(self.active_workers) < self.max_concurrent_videos and
                   self.generation_queue):

                # è·å–ä¸‹ä¸€ä¸ªåœºæ™¯
                current_scene = self.generation_queue.pop(0)
                scene_id = current_scene.get('shot_id', f"scene_{len(self.active_workers)}")

                # å¯åŠ¨å•ä¸ªç”Ÿæˆä»»åŠ¡
                self.start_single_video_generation(current_scene, scene_id)

            logger.info(f"å½“å‰æ´»è·ƒä»»åŠ¡æ•°: {len(self.active_workers)}/{self.max_concurrent_videos}, é˜Ÿåˆ—å‰©ä½™: {len(self.generation_queue)}")

        except Exception as e:
            logger.error(f"å¯åŠ¨å¹¶å‘ç”Ÿæˆå¤±è´¥: {e}")

    def start_single_video_generation(self, scene, scene_id):
        """å¯åŠ¨å•ä¸ªè§†é¢‘ç”Ÿæˆä»»åŠ¡"""
        try:
            # è·å–å¹¶è®¾ç½®æç¤ºè¯
            shot_id = scene.get('shot_id', '')
            prompt_from_file = self._get_prompt_for_shot(shot_id)
            if prompt_from_file:
                scene['prompt'] = prompt_from_file
                logger.info(f"ä¸ºé•œå¤´ {shot_id} è®¾ç½®æç¤ºè¯: {prompt_from_file[:50]}...")
            else:
                scene['prompt'] = scene.get('enhanced_description', scene.get('description', ''))

            # è·å–éŸ³æ•ˆæç¤º
            audio_hint = self._get_audio_hint_for_shot(shot_id)
            if audio_hint:
                scene['audio_hint'] = audio_hint

            # æ›´æ–°çŠ¶æ€
            self.update_scene_status(scene, 'ç”Ÿæˆä¸­')

            # è·å–ç”Ÿæˆé…ç½®
            image_path = scene.get('image_path', '')
            voice_duration = scene.get('voice_duration', 0.0)

            # è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥å›¾åƒè·¯å¾„
            logger.info(f"å‡†å¤‡ç”Ÿæˆè§†é¢‘ - é•œå¤´ID: {scene.get('shot_id')}, å›¾åƒè·¯å¾„: {image_path}")
            if image_path and os.path.exists(image_path):
                logger.info(f"å›¾åƒæ–‡ä»¶å­˜åœ¨ï¼Œå°†è¿›è¡Œåˆ†è¾¨ç‡è°ƒæ•´")
            else:
                logger.warning(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„ä¸ºç©ºï¼Œå°†ä½¿ç”¨é»˜è®¤åˆ†è¾¨ç‡1024x1024")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤šç‰‡æ®µç”Ÿæˆ
            required_images, segment_durations = self._check_voice_duration_match(scene)
            scene_images = self._get_scene_images(scene)

            if voice_duration > 10.0 and len(scene_images) >= required_images:
                # å¤šç‰‡æ®µç”Ÿæˆæ¨¡å¼
                self._generate_multi_segment_video(scene, scene_images, segment_durations)
                return
            else:
                # å•ç‰‡æ®µç”Ÿæˆæ¨¡å¼
                audio_hint = scene.get('audio_hint')
                # ä¸ä¼ é€’voice_durationï¼Œè®©ç”¨æˆ·ç•Œé¢è®¾ç½®ä¼˜å…ˆ
                generation_config = self.get_generation_config(image_path, None, audio_hint)

                # è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥ç”Ÿæˆé…ç½®
                logger.info(f"ç”Ÿæˆé…ç½® - åˆ†è¾¨ç‡: {generation_config.get('width')}x{generation_config.get('height')}, å¼•æ“: {generation_config.get('engine')}")

            # åˆ›å»ºå·¥ä½œçº¿ç¨‹
            worker = VideoGenerationWorker(
                scene,
                generation_config,
                self.project_manager,
                self.project_manager.current_project_name if self.project_manager else None
            )

            # è¿æ¥ä¿¡å·
            worker.progress_updated.connect(lambda p, msg, sid=scene_id: self.on_concurrent_progress_updated(sid, p, msg))
            worker.video_generated.connect(lambda path, success, error, sid=scene_id: self.on_concurrent_video_generated(sid, path, success, error))

            # æ·»åŠ åˆ°æ´»è·ƒä»»åŠ¡
            self.active_workers[scene_id] = {
                'worker': worker,
                'scene': scene,
                'start_time': time.time()
            }

            # æ˜¾ç¤ºè¿›åº¦ç•Œé¢ï¼ˆå¦‚æœæ˜¯ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼‰
            if len(self.active_workers) == 1:
                self.show_generation_progress()

            # å¼€å§‹ç”Ÿæˆ
            worker.start()
            logger.info(f"å¯åŠ¨è§†é¢‘ç”Ÿæˆä»»åŠ¡: {scene_id}")

        except Exception as e:
            logger.error(f"å¯åŠ¨å•ä¸ªç”Ÿæˆä»»åŠ¡å¤±è´¥: {e}")
            self.update_scene_status(scene, 'å¤±è´¥')

    def process_next_generation(self):
        """å¤„ç†ä¸‹ä¸€ä¸ªç”Ÿæˆä»»åŠ¡"""
        try:
            if not self.generation_queue:
                # æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                self.on_all_generation_complete()
                return

            # è·å–ä¸‹ä¸€ä¸ªåœºæ™¯
            current_scene = self.generation_queue.pop(0)

            # è·å–å¹¶è®¾ç½®æç¤ºè¯
            shot_id = current_scene.get('shot_id', '')
            prompt_from_file = self._get_prompt_for_shot(shot_id)
            if prompt_from_file:
                # ğŸ”§ æ–°å¢ï¼šä½¿ç”¨CogVideoXä¼˜åŒ–å™¨ä¼˜åŒ–æç¤ºè¯
                optimized_prompt = self._optimize_prompt_for_cogvideox(prompt_from_file, shot_id)
                current_scene['prompt'] = optimized_prompt
                logger.info(f"ä¸ºé•œå¤´ {shot_id} è®¾ç½®ä¼˜åŒ–æç¤ºè¯: {optimized_prompt[:80]}...")
            else:
                # ä½¿ç”¨åŸæœ‰çš„æè¿°ä½œä¸ºæç¤ºè¯ï¼Œä¹Ÿè¿›è¡Œä¼˜åŒ–
                original_desc = current_scene.get('enhanced_description', current_scene.get('description', ''))
                optimized_prompt = self._optimize_prompt_for_cogvideox(original_desc, shot_id)
                current_scene['prompt'] = optimized_prompt

            # è·å–éŸ³æ•ˆæç¤º
            audio_hint = self._get_audio_hint_for_shot(shot_id)
            if audio_hint:
                current_scene['audio_hint'] = audio_hint

            # ä¿å­˜å½“å‰ç”Ÿæˆçš„åœºæ™¯
            self._current_generating_scene = current_scene

            # æ›´æ–°çŠ¶æ€
            self.update_scene_status(current_scene, 'ç”Ÿæˆä¸­')

            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤šç‰‡æ®µç”Ÿæˆ
            voice_duration = current_scene.get('voice_duration', 0.0)
            required_images, segment_durations = self._check_voice_duration_match(current_scene)
            scene_images = self._get_scene_images(current_scene)

            # è·å–ç”Ÿæˆé…ç½®
            image_path = current_scene.get('image_path', '')

            if voice_duration > 10.0 and len(scene_images) >= required_images:
                # å¤šç‰‡æ®µç”Ÿæˆæ¨¡å¼
                self._generate_multi_segment_video(current_scene, scene_images, segment_durations)
            else:
                # å•ç‰‡æ®µç”Ÿæˆæ¨¡å¼
                audio_hint = current_scene.get('audio_hint')
                generation_config = self.get_generation_config(image_path, voice_duration if voice_duration > 0 else None, audio_hint)

            # åˆ›å»ºå·¥ä½œçº¿ç¨‹
            self.current_worker = VideoGenerationWorker(
                current_scene,
                generation_config,
                self.project_manager,
                self.project_manager.current_project_name if self.project_manager else None
            )

            # è¿æ¥ä¿¡å·
            self.current_worker.progress_updated.connect(self.on_progress_updated)
            self.current_worker.video_generated.connect(self.on_video_generated)

            # æ˜¾ç¤ºè¿›åº¦ç•Œé¢
            self.show_generation_progress()

            # å¼€å§‹ç”Ÿæˆ
            self.current_worker.start()

        except Exception as e:
            logger.error(f"å¤„ç†ä¸‹ä¸€ä¸ªç”Ÿæˆä»»åŠ¡å¤±è´¥: {e}")
            self.on_generation_error(str(e))

    def get_generation_config(self, image_path=None, target_duration=None, audio_hint=None):
        """è·å–ç”Ÿæˆé…ç½®"""
        try:
            # é»˜è®¤åˆ†è¾¨ç‡
            width, height = 1024, 1024

            # å¦‚æœæä¾›äº†å›¾åƒè·¯å¾„ï¼Œå°è¯•è·å–å›¾åƒå°ºå¯¸å¹¶è°ƒæ•´ä¸ºæ”¯æŒçš„åˆ†è¾¨ç‡
            if image_path and os.path.exists(image_path):
                try:
                    from PIL import Image
                    with Image.open(image_path) as img:
                        img_width, img_height = img.size
                        logger.info(f"ä½¿ç”¨å›¾åƒå°ºå¯¸: {img_width}x{img_height}")

                        # è°ƒæ•´ä¸ºæ”¯æŒçš„åˆ†è¾¨ç‡
                        adjusted_resolution = self._adjust_to_supported_resolution(img_width, img_height)
                        width, height = adjusted_resolution

                        if (width, height) != (img_width, img_height):
                            logger.info(f"åˆ†è¾¨ç‡è°ƒæ•´: {img_width}x{img_height} -> {width}x{height}")

                except Exception as e:
                    logger.warning(f"æ— æ³•è·å–å›¾åƒå°ºå¯¸ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            elif not image_path:
                # åªæœ‰åœ¨æ²¡æœ‰æä¾›å›¾åƒè·¯å¾„æ—¶æ‰æ˜¾ç¤ºè­¦å‘Š
                logger.debug("æ²¡æœ‰æä¾›å›¾åƒè·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤åˆ†è¾¨ç‡ 1024x1024")

            # è·å–é€‰æ‹©çš„å¼•æ“
            selected_engine = self.engine_combo.currentData() if hasattr(self, 'engine_combo') else 'cogvideox_flash'

            # æ ¹æ®å¼•æ“ç±»å‹ç¡®å®šå‚æ•°
            if selected_engine in ['doubao_seedance_pro', 'doubao_seedance_lite']:
                # è±†åŒ…å¼•æ“é…ç½®ï¼ˆProç‰ˆå’ŒLiteç‰ˆï¼‰
                if target_duration is not None:
                    # è±†åŒ…æ”¯æŒ5ç§’å’Œ10ç§’ï¼Œé€‰æ‹©æœ€æ¥è¿‘çš„
                    duration = 5 if target_duration <= 7.5 else 10
                    if duration != target_duration:
                        logger.info(f"è±†åŒ…å¼•æ“æ—¶é•¿å·²è°ƒæ•´: {target_duration}s -> {duration}s")
                else:
                    # ä½¿ç”¨è±†åŒ…UIè®¾ç½®çš„æ—¶é•¿
                    duration = int(self.doubao_duration_combo.currentText())

                # è§£æè±†åŒ…åˆ†è¾¨ç‡å’Œå®½é«˜æ¯”
                resolution_text = self.doubao_resolution_combo.currentText()
                ratio_text = self.doubao_ratio_combo.currentText()

                # æ ¹æ®åˆ†è¾¨ç‡å’Œå®½é«˜æ¯”ç¡®å®šå®é™…åƒç´ å°ºå¯¸
                width, height = self._calculate_doubao_dimensions(resolution_text, ratio_text)

                config = {
                    'engine': selected_engine,  # ä½¿ç”¨å®é™…é€‰æ‹©çš„å¼•æ“
                    'duration': duration,
                    'fps': 30,  # è±†åŒ…æ ¹æ®åˆ†è¾¨ç‡è‡ªåŠ¨ç¡®å®šå¸§ç‡
                    'width': width,
                    'height': height,
                    'motion_intensity': 0.5,  # è±†åŒ…æ²¡æœ‰è¿åŠ¨å¼ºåº¦è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    'max_concurrent_tasks': int(self.doubao_concurrent_tasks_combo.currentText()),
                    'resolution': resolution_text,  # ä¼ é€’ç»™å¼•æ“çš„åˆ†è¾¨ç‡å‚æ•°
                    'ratio': ratio_text  # ä¼ é€’ç»™å¼•æ“çš„å®½é«˜æ¯”å‚æ•°
                }
            elif selected_engine == 'vheer':
                # Vheer.com å…è´¹å›¾ç”Ÿè§†é¢‘é…ç½®
                if target_duration is not None:
                    # Vheerç›®å‰åªæ”¯æŒ5ç§’
                    duration = 5
                    if duration != target_duration:
                        logger.info(f"Vheerå¼•æ“æ—¶é•¿å·²è°ƒæ•´: {target_duration}s -> {duration}s")
                else:
                    # ä½¿ç”¨Vheer UIè®¾ç½®çš„æ—¶é•¿
                    duration = self.vheer_duration_combo.currentData()

                config = {
                    'engine': 'vheer',
                    'duration': duration,
                    'fps': self.vheer_fps_combo.currentData(),  # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„å¸§ç‡
                    'width': 1024,  # ç½‘ç«™è‡ªé€‚åº”ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    'height': 1024,  # ç½‘ç«™è‡ªé€‚åº”ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    'format': self.vheer_format_combo.currentData(),  # è§†é¢‘æ ¼å¼
                    'max_concurrent_tasks': 1,  # Vheeråªæ”¯æŒå•ä»»åŠ¡
                    'timeout': self.vheer_timeout_spin.value(),
                    'headless': self.vheer_headless_check.isChecked()
                }
            else:
                # CogVideoX-Flash å¼•æ“é…ç½®ï¼ˆé»˜è®¤ï¼‰
                if target_duration is not None:
                    # ä½¿ç”¨æŒ‡å®šçš„ç›®æ ‡æ—¶é•¿ï¼Œè‡ªåŠ¨è°ƒæ•´åˆ°æ”¯æŒçš„æ—¶é•¿
                    original_duration = target_duration
                    duration = self._validate_duration(target_duration)
                    if duration != original_duration:
                        logger.info(f"ç›®æ ‡æ—¶é•¿å·²è‡ªåŠ¨è°ƒæ•´: {original_duration}s -> {duration}s")
                else:
                    # ä½¿ç”¨UIè®¾ç½®çš„æ—¶é•¿
                    duration = int(self.duration_combo.currentText())

                config = {
                    'engine': 'cogvideox_flash',
                    'duration': duration,
                    'fps': int(self.fps_combo.currentText()),
                    'width': width,
                    'height': height,
                    'motion_intensity': self.motion_slider.value() / 100.0,
                    'max_concurrent_tasks': int(self.concurrent_tasks_combo.currentText())
                }

            # æ·»åŠ éŸ³æ•ˆæç¤º
            if audio_hint:
                config['audio_hint'] = audio_hint

            return config

        except Exception as e:
            logger.error(f"è·å–ç”Ÿæˆé…ç½®å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤é…ç½®ï¼Œä¼˜å…ˆä½¿ç”¨CogVideoX-Flash
            selected_engine = 'cogvideox_flash'
            try:
                if hasattr(self, 'engine_combo'):
                    selected_engine = self.engine_combo.currentData() or 'cogvideox_flash'
            except:
                pass

            if selected_engine in ['doubao_seedance_pro', 'doubao_seedance_lite']:
                return {
                    'engine': selected_engine,
                    'duration': 5,  # è±†åŒ…é»˜è®¤5ç§’
                    'fps': 30,
                    'width': 768,
                    'height': 768,
                    'motion_intensity': 0.5,
                    'max_concurrent_tasks': 2
                }
            elif selected_engine == 'vheer':
                return {
                    'engine': 'vheer',
                    'duration': 5,  # Vheeré»˜è®¤5ç§’
                    'fps': 24,
                    'width': 768,
                    'height': 768,
                    'motion_intensity': 0.5,
                    'max_concurrent_tasks': 1,
                    'timeout': 300,
                    'headless': True
                }
            else:
                return {
                    'engine': 'cogvideox_flash',
                    'duration': 5,
                    'fps': 30,
                    'width': 1024,
                    'height': 1024,
                    'motion_intensity': 0.5,
                    'max_concurrent_tasks': 3
                }

    def _calculate_doubao_dimensions(self, resolution_text: str, ratio_text: str) -> tuple:
        """æ ¹æ®è±†åŒ…çš„åˆ†è¾¨ç‡å’Œå®½é«˜æ¯”å‚æ•°è®¡ç®—å®é™…åƒç´ å°ºå¯¸"""
        try:
            # åŸºç¡€åˆ†è¾¨ç‡æ˜ å°„
            base_sizes = {
                '480p': 480,
                '720p': 720,
                '1080p': 1080
            }

            # è·å–åŸºç¡€å°ºå¯¸
            base_size = base_sizes.get(resolution_text, 720)

            # æ ¹æ®å®½é«˜æ¯”è®¡ç®—å®é™…å°ºå¯¸
            if '16:9' in ratio_text:
                if base_size == 480:
                    return (854, 480)
                elif base_size == 720:
                    return (1280, 720)
                else:  # 1080p
                    return (1920, 1080)
            elif '9:16' in ratio_text:
                if base_size == 480:
                    return (480, 854)
                elif base_size == 720:
                    return (720, 1280)
                else:  # 1080p
                    return (1080, 1920)
            elif '1:1' in ratio_text:
                return (base_size, base_size)
            elif '4:3' in ratio_text:
                if base_size == 480:
                    return (640, 480)
                elif base_size == 720:
                    return (960, 720)
                else:  # 1080p
                    return (1440, 1080)
            elif '3:4' in ratio_text:
                if base_size == 480:
                    return (480, 640)
                elif base_size == 720:
                    return (720, 960)
                else:  # 1080p
                    return (1080, 1440)
            elif '21:9' in ratio_text:
                if base_size == 480:
                    return (1120, 480)
                elif base_size == 720:
                    return (1680, 720)
                else:  # 1080p
                    return (2520, 1080)
            elif '9:21' in ratio_text:
                if base_size == 480:
                    return (480, 1120)
                elif base_size == 720:
                    return (720, 1680)
                else:  # 1080p
                    return (1080, 2520)
            else:
                # é»˜è®¤16:9æˆ–è‡ªé€‚åº”
                if base_size == 720:
                    return (1280, 720)
                else:
                    return (1920, 1080)

        except Exception as e:
            logger.warning(f"è®¡ç®—è±†åŒ…å°ºå¯¸å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            return (1280, 720)  # é»˜è®¤720p 16:9

    def _validate_duration(self, duration):
        """éªŒè¯å¹¶è°ƒæ•´è§†é¢‘æ—¶é•¿åˆ°æœ€æ¥è¿‘çš„æ”¯æŒæ—¶é•¿"""
        supported_durations = [5, 10]  # CogVideoX-Flashåªæ”¯æŒ5ç§’å’Œ10ç§’

        # ğŸ”§ ä¼˜åŒ–ï¼šæ ¹æ®é…éŸ³æ—¶é•¿æ™ºèƒ½é€‰æ‹©è§†é¢‘æ—¶é•¿
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æ˜ç¡®é€‰æ‹©äº†æ—¶é•¿
        user_selected_duration = int(self.duration_combo.currentText()) if hasattr(self, 'duration_combo') else 5

        # å¦‚æœæœ‰ç›®æ ‡æ—¶é•¿ï¼ˆé€šå¸¸æ¥è‡ªé…éŸ³æ—¶é•¿ï¼‰ï¼Œæ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„è§†é¢‘æ—¶é•¿
        if duration > 0:
            if duration <= 5:
                # é…éŸ³æ—¶é•¿5ç§’ä»¥å†…ï¼Œä½¿ç”¨5ç§’è§†é¢‘
                adjusted_duration = 5
                logger.info(f"é…éŸ³æ—¶é•¿{duration:.1f}s â‰¤ 5sï¼Œé€‰æ‹©5ç§’è§†é¢‘æ—¶é•¿")
            elif duration <= 10:
                # é…éŸ³æ—¶é•¿5-10ç§’ï¼Œä½¿ç”¨10ç§’è§†é¢‘
                adjusted_duration = 10
                logger.info(f"é…éŸ³æ—¶é•¿{duration:.1f}s â‰¤ 10sï¼Œé€‰æ‹©10ç§’è§†é¢‘æ—¶é•¿")
            else:
                # é…éŸ³æ—¶é•¿è¶…è¿‡10ç§’ï¼Œä½¿ç”¨10ç§’è§†é¢‘ï¼ˆåç»­é€šè¿‡å¾ªç¯æ’­æ”¾åŒ¹é…ï¼‰
                adjusted_duration = 10
                logger.info(f"é…éŸ³æ—¶é•¿{duration:.1f}s > 10sï¼Œé€‰æ‹©10ç§’è§†é¢‘æ—¶é•¿ï¼ˆå°†é€šè¿‡å¾ªç¯æ’­æ”¾åŒ¹é…é…éŸ³æ—¶é•¿ï¼‰")
        else:
            # æ²¡æœ‰ç›®æ ‡æ—¶é•¿ï¼Œä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ—¶é•¿
            adjusted_duration = user_selected_duration
            logger.info(f"ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ—¶é•¿: {adjusted_duration}s")

        return adjusted_duration

    def _adjust_to_supported_resolution(self, width, height):
        """è°ƒæ•´ä¸ºæ”¯æŒçš„åˆ†è¾¨ç‡ï¼Œä¼˜å…ˆä¿æŒå®½é«˜æ¯”"""
        # CogVideoX-Flashå®˜æ–¹æ”¯æŒçš„å®Œæ•´åˆ†è¾¨ç‡åˆ—è¡¨
        supported_resolutions = [
            (720, 480),     # æ ‡å‡†æ¸…æ™°åº¦
            (1024, 1024),   # æ­£æ–¹å½¢
            (1280, 960),    # 4:3 æ¨ªå±
            (960, 1280),    # 3:4 ç«–å±
            (1920, 1080),   # Full HD æ¨ªå±
            (1080, 1920),   # Full HD ç«–å±
            (2048, 1080),   # è¶…å®½å±
            (3840, 2160),   # 4K
        ]

        target_ratio = width / height

        # é¦–å…ˆæŒ‰ç…§å›¾åƒæ–¹å‘åˆ†ç±»
        if target_ratio > 1.2:
            # æ¨ªå±å›¾åƒ (å®½ > é«˜)
            candidate_resolutions = [(w, h) for w, h in supported_resolutions if w > h]
        elif target_ratio < 0.8:
            # ç«–å±å›¾åƒ (é«˜ > å®½)
            candidate_resolutions = [(w, h) for w, h in supported_resolutions if h > w]
        else:
            # æ¥è¿‘æ­£æ–¹å½¢çš„å›¾åƒ
            candidate_resolutions = [(w, h) for w, h in supported_resolutions if 0.8 <= w/h <= 1.2]

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒæ–¹å‘çš„åˆ†è¾¨ç‡ï¼Œä½¿ç”¨æ‰€æœ‰åˆ†è¾¨ç‡
        if not candidate_resolutions:
            candidate_resolutions = supported_resolutions

        # åœ¨å€™é€‰åˆ†è¾¨ç‡ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…
        best_resolution = candidate_resolutions[0]
        best_score = float('inf')

        for res_width, res_height in candidate_resolutions:
            res_ratio = res_width / res_height

            # è®¡ç®—æ¯”ä¾‹å·®å¼‚ï¼ˆæƒé‡æœ€é«˜ï¼‰
            ratio_diff = abs(target_ratio - res_ratio) / max(target_ratio, res_ratio)

            # è®¡ç®—é¢ç§¯å·®å¼‚
            target_area = width * height
            res_area = res_width * res_height
            area_diff = abs(target_area - res_area) / max(target_area, res_area)

            # ç»¼åˆè¯„åˆ†ï¼ˆæ¯”ä¾‹æƒé‡0.8ï¼Œé¢ç§¯æƒé‡0.2ï¼‰
            score = ratio_diff * 0.8 + area_diff * 0.2

            if score < best_score:
                best_score = score
                best_resolution = (res_width, res_height)

        return best_resolution

    def _generate_video_thumbnail(self, video_path):
        """ç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾"""
        try:
            # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(video_path):
                logger.warning(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                return None

            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(video_path)
            if file_size == 0:
                logger.warning(f"è§†é¢‘æ–‡ä»¶ä¸ºç©º: {video_path}")
                return None

            logger.debug(f"å°è¯•ç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾: {video_path} (å¤§å°: {file_size} å­—èŠ‚)")

            import cv2

            # æ‰“å¼€è§†é¢‘æ–‡ä»¶
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                logger.warning(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
                return None

            # è·å–è§†é¢‘ä¿¡æ¯
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = frame_count / fps if fps > 0 else 0

            logger.debug(f"è§†é¢‘ä¿¡æ¯: å¸§æ•°={frame_count}, FPS={fps:.2f}, æ—¶é•¿={duration:.2f}ç§’")

            # å°è¯•è·³åˆ°è§†é¢‘çš„1/4ä½ç½®è·å–å¸§ï¼ˆé¿å…é»‘å±ï¼‰
            if frame_count > 10:
                target_frame = min(frame_count // 4, 30)  # æœ€å¤šè·³åˆ°ç¬¬30å¸§
                cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
                logger.debug(f"è·³è½¬åˆ°ç¬¬{target_frame}å¸§")

            # è·å–è§†é¢‘å¸§
            ret, frame = cap.read()
            cap.release()

            if not ret or frame is None:
                logger.warning(f"æ— æ³•è¯»å–è§†é¢‘å¸§: {video_path}")
                return None

            # æ£€æŸ¥å¸§çš„æœ‰æ•ˆæ€§
            if frame.size == 0:
                logger.warning(f"è¯»å–åˆ°ç©ºå¸§: {video_path}")
                return None

            # å°†OpenCVçš„BGRæ ¼å¼è½¬æ¢ä¸ºRGBæ ¼å¼
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # è½¬æ¢ä¸ºQPixmap
            from PyQt5.QtGui import QImage, QPixmap
            height, width, _ = frame_rgb.shape  # å¿½ç•¥channelå˜é‡
            bytes_per_line = 3 * width
            q_image = QImage(frame_rgb.data, width, height, bytes_per_line, QImage.Format_RGB888)
            pixmap = QPixmap.fromImage(q_image)

            if pixmap.isNull():
                logger.warning(f"ç”Ÿæˆçš„QPixmapä¸ºç©º: {video_path}")
                return None

            logger.debug(f"æˆåŠŸç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾: {video_path} -> {width}x{height}")
            return pixmap

        except ImportError:
            logger.warning("OpenCVæœªå®‰è£…ï¼Œæ— æ³•ç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾")
            return None
        except Exception as e:
            logger.error(f"ç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾å¤±è´¥: {video_path} -> {e}")
            return None

    def _get_prompt_for_shot(self, shot_id):
        """è·å–æŒ‡å®šé•œå¤´çš„æç¤ºè¯"""
        try:
            if not self.project_manager:
                return None

            # è·å–é¡¹ç›®ç›®å½•
            project_data = self.project_manager.get_project_data()
            if not project_data:
                return None

            project_dir = project_data.get('project_dir', '')
            if not project_dir:
                # å°è¯•ä½¿ç”¨å½“å‰é¡¹ç›®åç§°æ„å»ºè·¯å¾„
                if hasattr(self.project_manager, 'current_project_name') and self.project_manager.current_project_name:
                    project_dir = os.path.join(self.project_manager.projects_dir, self.project_manager.current_project_name)
                elif hasattr(self.project_manager, 'projects_dir'):
                    # å°è¯•ä½¿ç”¨é»˜è®¤é¡¹ç›®
                    project_dir = os.path.join(self.project_manager.projects_dir, "æ„Ÿäººæ•…äº‹")
                else:
                    return None

            # æ„å»ºprompt.jsonæ–‡ä»¶è·¯å¾„
            prompt_file = os.path.join(project_dir, 'texts', 'prompt.json')
            if not os.path.exists(prompt_file):
                logger.debug(f"prompt.jsonæ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
                return None

            # è¯»å–prompt.jsonæ–‡ä»¶
            import json
            with open(prompt_file, 'r', encoding='utf-8') as f:
                prompt_data = json.load(f)

            # æŸ¥æ‰¾å¯¹åº”çš„æç¤ºè¯
            # prompt.jsonçš„ç»“æ„æ˜¯ {"scenes": {"åœºæ™¯å": [é•œå¤´æ•°ç»„]}}
            scenes_data = prompt_data.get('scenes', {})

            # æå–shot_idä¸­çš„æ•°å­—éƒ¨åˆ†
            shot_index = None
            if shot_id.startswith('text_segment_'):
                try:
                    shot_index = int(shot_id.replace('text_segment_', ''))
                except ValueError:
                    pass

            if shot_index is None:
                logger.debug(f"æ— æ³•ä»shot_id '{shot_id}' æå–ç´¢å¼•")
                return None

            # éå†æ‰€æœ‰åœºæ™¯ï¼Œæ‰¾åˆ°å¯¹åº”ç´¢å¼•çš„é•œå¤´
            current_index = 1
            for scene_name, shots in scenes_data.items():
                if isinstance(shots, list):
                    for shot in shots:
                        if current_index == shot_index:
                            # ğŸ”§ ä¼˜å…ˆä½¿ç”¨ä¼˜åŒ–åçš„æç¤ºè¯
                            optimized_content = shot.get('optimized_content', '')
                            if optimized_content:
                                logger.debug(f"ä»prompt.jsonè·å–é•œå¤´ {shot_id} (ç´¢å¼•{shot_index}) çš„ä¼˜åŒ–æç¤ºè¯")
                                return optimized_content

                            # å¦‚æœæ²¡æœ‰ä¼˜åŒ–æç¤ºè¯ï¼Œä½¿ç”¨åŸå§‹content
                            content = shot.get('content', '')
                            if content:
                                logger.debug(f"ä»prompt.jsonè·å–é•œå¤´ {shot_id} (ç´¢å¼•{shot_index}) çš„åŸå§‹æç¤ºè¯")
                                return content
                        current_index += 1

            logger.debug(f"åœ¨prompt.jsonä¸­æœªæ‰¾åˆ°é•œå¤´ {shot_id} çš„æç¤ºè¯")
            return None

        except Exception as e:
            logger.warning(f"ä»prompt.jsonè·å–æç¤ºè¯å¤±è´¥: {e}")
            return None

    def _get_audio_hint_for_shot(self, shot_id):
        """è·å–æŒ‡å®šé•œå¤´çš„éŸ³æ•ˆæç¤º"""
        try:
            if not self.project_manager:
                return None

            # è·å–é¡¹ç›®ç›®å½•
            project_data = self.project_manager.get_project_data()
            if not project_data:
                return None

            project_dir = project_data.get('project_dir', '')
            if not project_dir:
                # å°è¯•ä½¿ç”¨å½“å‰é¡¹ç›®åç§°æ„å»ºè·¯å¾„
                if hasattr(self.project_manager, 'current_project_name') and self.project_manager.current_project_name:
                    project_dir = os.path.join(self.project_manager.projects_dir, self.project_manager.current_project_name)
                elif hasattr(self.project_manager, 'projects_dir'):
                    # å°è¯•ä½¿ç”¨é»˜è®¤é¡¹ç›®
                    project_dir = os.path.join(self.project_manager.projects_dir, "æ„Ÿäººæ•…äº‹")
                else:
                    return None

            # æ„å»ºprompt.jsonæ–‡ä»¶è·¯å¾„
            prompt_file = os.path.join(project_dir, 'texts', 'prompt.json')
            if not os.path.exists(prompt_file):
                return None

            # è¯»å–prompt.jsonæ–‡ä»¶
            import json
            with open(prompt_file, 'r', encoding='utf-8') as f:
                prompt_data = json.load(f)

            # æŸ¥æ‰¾å¯¹åº”çš„éŸ³æ•ˆæç¤º
            scenes_data = prompt_data.get('scenes', {})

            # æå–shot_idä¸­çš„æ•°å­—éƒ¨åˆ†
            shot_index = None
            if shot_id.startswith('text_segment_'):
                try:
                    shot_index = int(shot_id.replace('text_segment_', ''))
                except ValueError:
                    pass

            if shot_index is None:
                return None

            # éå†æ‰€æœ‰åœºæ™¯ï¼Œæ‰¾åˆ°å¯¹åº”ç´¢å¼•çš„é•œå¤´
            current_index = 1
            for scene_name, shots in scenes_data.items():
                if isinstance(shots, list):
                    for shot in shots:
                        if current_index == shot_index:
                            # ä»original_descriptionä¸­æå–éŸ³æ•ˆæç¤º
                            original_desc = shot.get('original_description', '')
                            import re
                            audio_match = re.search(r'éŸ³æ•ˆæç¤º[ï¼š:]\s*([^\n]+)', original_desc)
                            if audio_match:
                                audio_hint = audio_match.group(1).strip()
                                if audio_hint and audio_hint != "æ— ":
                                    logger.info(f"æ‰¾åˆ°é•œå¤´ {shot_id} çš„éŸ³æ•ˆæç¤º: {audio_hint}")
                                    return audio_hint
                        current_index += 1

            return None

        except Exception as e:
            logger.warning(f"ä»prompt.jsonè·å–éŸ³æ•ˆæç¤ºå¤±è´¥: {e}")
            return None

    def _generate_multi_segment_video(self, scene_data, scene_images, segment_durations):
        """ç”Ÿæˆå¤šç‰‡æ®µè§†é¢‘"""
        try:
            # åˆ›å»ºå¤šç‰‡æ®µç”Ÿæˆå·¥ä½œçº¿ç¨‹
            self.current_worker = MultiSegmentVideoWorker(
                scene_data,
                scene_images,
                segment_durations,
                self.project_manager,
                self.project_manager.current_project_name if self.project_manager else None
            )

            # è¿æ¥ä¿¡å·
            self.current_worker.progress_updated.connect(self.on_progress_updated)
            self.current_worker.video_generated.connect(self.on_video_generated)

            # æ˜¾ç¤ºè¿›åº¦ç•Œé¢
            self.show_generation_progress()

            # å¼€å§‹ç”Ÿæˆ
            self.current_worker.start()

        except Exception as e:
            logger.error(f"å¤šç‰‡æ®µè§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            self.on_generation_error(str(e))

    def show_generation_progress(self):
        """æ˜¾ç¤ºç”Ÿæˆè¿›åº¦"""
        self.progress_bar.setVisible(True)
        self.progress_bar.setValue(0)
        self.cancel_btn.setVisible(True)
        self.batch_generate_btn.setEnabled(False)
        self.single_generate_btn.setEnabled(False)

    def hide_generation_progress(self):
        """éšè—ç”Ÿæˆè¿›åº¦"""
        self.progress_bar.setVisible(False)
        self.cancel_btn.setVisible(False)
        self.batch_generate_btn.setEnabled(True)
        self.single_generate_btn.setEnabled(True)

    def update_scene_status(self, scene_data, status):
        """æ›´æ–°åœºæ™¯çŠ¶æ€"""
        try:
            target_shot_id = scene_data.get('shot_id', '')
            logger.info(f"å°è¯•æ›´æ–°åœºæ™¯çŠ¶æ€: {target_shot_id} -> {status}")

            # åœ¨åœºæ™¯åˆ—è¡¨ä¸­æ‰¾åˆ°å¯¹åº”åœºæ™¯å¹¶æ›´æ–°çŠ¶æ€
            scene_found = False

            for i, scene in enumerate(self.current_scenes):
                # ä½¿ç”¨å¤šç§æ–¹å¼åŒ¹é…åœºæ™¯ï¼Œä¼˜å…ˆä½¿ç”¨shot_idç²¾ç¡®åŒ¹é…
                current_shot_id = scene.get('shot_id', '')

                # æ–¹å¼1ï¼šé€šè¿‡shot_idç²¾ç¡®åŒ¹é…ï¼ˆæœ€ä¼˜å…ˆï¼‰
                if target_shot_id and current_shot_id and target_shot_id == current_shot_id:
                    scene['status'] = status
                    scene_found = True
                    logger.info(f"æˆåŠŸæ›´æ–°åœºæ™¯çŠ¶æ€: {target_shot_id} -> {status} (ç²¾ç¡®åŒ¹é…: {current_shot_id})")
                    # åˆ·æ–°è¡¨æ ¼æ˜¾ç¤º
                    self.update_scene_table()
                    break

                # æ–¹å¼2ï¼šé€šè¿‡scene_idå’Œshot_idåŒ¹é…
                elif (scene.get('scene_id') == scene_data.get('scene_id') and
                      scene.get('shot_id') == scene_data.get('shot_id')):
                    scene['status'] = status
                    scene_found = True
                    logger.info(f"æˆåŠŸæ›´æ–°åœºæ™¯çŠ¶æ€: {target_shot_id} -> {status} (scene_id+shot_idåŒ¹é…: {current_shot_id})")
                    # åˆ·æ–°è¡¨æ ¼æ˜¾ç¤º
                    self.update_scene_table()
                    break

                # æ–¹å¼3ï¼šé€šè¿‡scene_indexå’Œshot_indexåŒ¹é…ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
                elif (scene_data.get('scene_index') is not None and scene.get('scene_index') is not None and
                      scene_data.get('shot_index') is not None and scene.get('shot_index') is not None and
                      scene.get('scene_index') == scene_data.get('scene_index') and
                      scene.get('shot_index') == scene_data.get('shot_index')):
                    scene['status'] = status
                    scene_found = True
                    logger.info(f"æˆåŠŸæ›´æ–°åœºæ™¯çŠ¶æ€: {target_shot_id} -> {status} (ç´¢å¼•åŒ¹é…: {current_shot_id})")
                    # åˆ·æ–°è¡¨æ ¼æ˜¾ç¤º
                    self.update_scene_table()
                    break

            # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ•°å­—ç´¢å¼•åŒ¹é…ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰
            if not scene_found and target_shot_id:
                import re
                target_match = re.search(r'(\d+)', target_shot_id)
                if target_match:
                    target_num = int(target_match.group(1))

                    for i, scene in enumerate(self.current_scenes):
                        current_shot_id = scene.get('shot_id', '')
                        current_match = re.search(r'(\d+)', current_shot_id) if current_shot_id else None

                        # é€šè¿‡æ•°å­—ç´¢å¼•åŒ¹é…
                        if current_match:
                            current_num = int(current_match.group(1))
                            if target_num == current_num:
                                scene['status'] = status
                                scene_found = True
                                logger.info(f"æˆåŠŸæ›´æ–°åœºæ™¯çŠ¶æ€: {target_shot_id} -> {status} (æ•°å­—åŒ¹é…: {current_shot_id})")
                                self.update_scene_table()
                                break
                        # é€šè¿‡ä½ç½®ç´¢å¼•åŒ¹é…
                        elif i + 1 == target_num:  # ç´¢å¼•ä»0å¼€å§‹ï¼Œä½†ç¼–å·ä»1å¼€å§‹
                            scene['status'] = status
                            scene_found = True
                            logger.info(f"æˆåŠŸæ›´æ–°åœºæ™¯çŠ¶æ€: {target_shot_id} -> {status} (ä½ç½®åŒ¹é…: ä½ç½®{i+1})")
                            self.update_scene_table()
                            break

            if not scene_found:
                logger.warning(f"æœªæ‰¾åˆ°åŒ¹é…çš„åœºæ™¯ï¼Œæ— æ³•æ›´æ–°çŠ¶æ€: {target_shot_id}")
                logger.debug(f"å¯ç”¨åœºæ™¯åˆ—è¡¨: {[s.get('shot_id', f'index_{i}') for i, s in enumerate(self.current_scenes)]}")

        except Exception as e:
            logger.error(f"æ›´æ–°åœºæ™¯çŠ¶æ€å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def on_concurrent_progress_updated(self, scene_id, progress, message):
        """å¹¶å‘è¿›åº¦æ›´æ–°"""
        # æ›´æ–°æ€»ä½“è¿›åº¦ï¼ˆæ‰€æœ‰ä»»åŠ¡çš„å¹³å‡è¿›åº¦ï¼‰
        if self.active_workers:
            total_progress = sum([50 for _ in self.active_workers])  # å‡è®¾æ¯ä¸ªä»»åŠ¡50%è¿›åº¦
            avg_progress = total_progress // len(self.active_workers)
            self.progress_bar.setValue(avg_progress)

        # æ›´æ–°çŠ¶æ€ä¿¡æ¯
        active_count = len(self.active_workers)
        queue_count = len(self.generation_queue)
        self.status_label.setText(f"å¹¶å‘ç”Ÿæˆä¸­({active_count}ä¸ªæ´»è·ƒ, {queue_count}ä¸ªç­‰å¾…): {message}")

    def on_concurrent_video_generated(self, scene_id, video_path, success, error_message):
        """å¹¶å‘è§†é¢‘ç”Ÿæˆå®Œæˆ"""
        try:
            if scene_id not in self.active_workers:
                logger.warning(f"æ”¶åˆ°æœªçŸ¥åœºæ™¯çš„ç”Ÿæˆç»“æœ: {scene_id}")
                return

            worker_info = self.active_workers[scene_id]
            scene = worker_info['scene']

            if success:
                # ä¿å­˜è§†é¢‘è·¯å¾„åˆ°é¡¹ç›®æ•°æ®
                self._current_generating_scene = scene  # ä¸´æ—¶è®¾ç½®ç”¨äºä¿å­˜
                self.save_video_to_project(video_path)

                # æ›´æ–°åœºæ™¯çŠ¶æ€
                self.update_scene_status(scene, 'å·²ç”Ÿæˆ')

                # è‡ªåŠ¨æ’­æ”¾è§†é¢‘ï¼ˆä»…ç¬¬ä¸€ä¸ªå®Œæˆçš„ï¼‰
                if self.auto_play_check.isChecked() and len([w for w in self.active_workers.values() if w.get('completed')]) == 0:
                    self.play_video(video_path)

                logger.info(f"è§†é¢‘ç”ŸæˆæˆåŠŸ: {scene_id} -> {os.path.basename(video_path)}")

                # æ ‡è®°ä¸ºå®Œæˆ
                worker_info['completed'] = True

            else:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦é™çº§å¤„ç†
                if self._should_fallback_to_image(error_message):
                    logger.info(f"å¹¶å‘è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œå°è¯•é™çº§ä¸ºå›¾åƒè§†é¢‘: {scene_id} -> {error_message}")

                    # è®¾ç½®å½“å‰ç”Ÿæˆåœºæ™¯ç”¨äºé™çº§å¤„ç†
                    self._current_generating_scene = scene

                    # ä»æ´»è·ƒä»»åŠ¡ä¸­ç§»é™¤ï¼ˆé™çº§å¤„ç†ä¼šé‡æ–°ç®¡ç†çŠ¶æ€ï¼‰
                    del self.active_workers[scene_id]

                    # è°ƒç”¨é™çº§å¤„ç†
                    self._fallback_to_image_video(scene, error_message)

                    # å¯åŠ¨ä¸‹ä¸€ä¸ªä»»åŠ¡ï¼ˆå¦‚æœé˜Ÿåˆ—ä¸­è¿˜æœ‰ï¼‰
                    if self.generation_queue:
                        logger.info(f"é™çº§å¤„ç†åå¯åŠ¨ä¸‹ä¸€è½®ä»»åŠ¡ï¼Œé˜Ÿåˆ—å‰©ä½™: {len(self.generation_queue)}")
                        QTimer.singleShot(3000, self.start_concurrent_generation)

                    return  # ä¸ç»§ç»­å¤„ç†ï¼Œç­‰å¾…é™çº§å®Œæˆ

                # æ›´æ–°å¤±è´¥çŠ¶æ€
                self.update_scene_status(scene, 'å¤±è´¥')
                logger.error(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {scene_id} -> {error_message}")

                # ä»æ´»è·ƒä»»åŠ¡ä¸­ç§»é™¤
                del self.active_workers[scene_id]

            # å¯åŠ¨ä¸‹ä¸€ä¸ªä»»åŠ¡ï¼ˆå¦‚æœé˜Ÿåˆ—ä¸­è¿˜æœ‰ï¼‰
            if self.generation_queue:
                logger.info(f"å¯åŠ¨ä¸‹ä¸€è½®ä»»åŠ¡ï¼Œé˜Ÿåˆ—å‰©ä½™: {len(self.generation_queue)}")
                # ğŸ”§ ä¿®å¤ï¼šå¢åŠ å»¶è¿Ÿä»¥é¿å…ç½‘ç»œè¿æ¥å†²çªå’Œå¼•æ“çŠ¶æ€é—®é¢˜
                QTimer.singleShot(3000, self.start_concurrent_generation)  # å¢åŠ åˆ°3ç§’å»¶è¿Ÿ

            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆ
            if not self.active_workers and not self.generation_queue:
                self.on_all_generation_complete()
            else:
                # æ›´æ–°è¿›åº¦æ˜¾ç¤º
                completed_count = len([s for s in self.current_scenes if s.get('status') == 'å·²ç”Ÿæˆ'])
                total_count = len(self.current_scenes)
                overall_progress = int((completed_count / total_count) * 100) if total_count > 0 else 0
                self.progress_bar.setValue(overall_progress)

                active_count = len(self.active_workers)
                queue_count = len(self.generation_queue)
                self.status_label.setText(f"å¹¶å‘ç”Ÿæˆä¸­({active_count}ä¸ªæ´»è·ƒ, {queue_count}ä¸ªç­‰å¾…)")

        except Exception as e:
            logger.error(f"å¤„ç†å¹¶å‘è§†é¢‘ç”Ÿæˆç»“æœå¤±è´¥: {e}")

    def on_all_generation_complete(self):
        """æ‰€æœ‰ç”Ÿæˆä»»åŠ¡å®Œæˆ"""
        try:
            # éšè—è¿›åº¦ç•Œé¢
            self.hide_generation_progress()

            # ğŸ”§ ä¿®å¤ï¼šç»Ÿè®¡åº”è¯¥åŸºäºå®é™…æäº¤çš„ä»»åŠ¡ï¼Œè€Œä¸æ˜¯æ‰€æœ‰åœºæ™¯
            # è·å–å®é™…æäº¤çš„ä»»åŠ¡IDåˆ—è¡¨
            submitted_scene_ids = set()
            if hasattr(self, '_submitted_scenes'):
                submitted_scene_ids = set(scene.get('shot_id', '') for scene in self._submitted_scenes)

            # å¦‚æœæ²¡æœ‰è®°å½•æäº¤çš„åœºæ™¯ï¼Œåˆ™ä½¿ç”¨æ‰€æœ‰åœºæ™¯ï¼ˆå‘åå…¼å®¹ï¼‰
            if not submitted_scene_ids:
                target_scenes = self.current_scenes
                logger.warning("æœªæ‰¾åˆ°æäº¤çš„åœºæ™¯è®°å½•ï¼Œä½¿ç”¨æ‰€æœ‰åœºæ™¯è¿›è¡Œç»Ÿè®¡")
            else:
                # åªç»Ÿè®¡å®é™…æäº¤çš„åœºæ™¯
                target_scenes = [s for s in self.current_scenes if s.get('shot_id', '') in submitted_scene_ids]
                logger.info(f"ç»Ÿè®¡åŸºäºå®é™…æäº¤çš„ {len(target_scenes)} ä¸ªåœºæ™¯")

            # æ›´æ–°çŠ¶æ€ç»Ÿè®¡
            completed_count = len([s for s in target_scenes if s.get('status') == 'å·²ç”Ÿæˆ'])
            failed_count = len([s for s in target_scenes if s.get('status') == 'å¤±è´¥'])
            total_count = len(target_scenes)

            # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ¯ä¸ªåœºæ™¯çš„çŠ¶æ€
            logger.info(f"åœºæ™¯çŠ¶æ€ç»Ÿè®¡:")
            for scene in target_scenes:
                shot_id = scene.get('shot_id', 'unknown')
                status = scene.get('status', 'unknown')
                logger.info(f"  - {shot_id}: {status}")
            logger.info(f"ç»Ÿè®¡ç»“æœ: æˆåŠŸ={completed_count}, å¤±è´¥={failed_count}, æ€»è®¡={total_count}")

            self.status_label.setText(f"æ‰€æœ‰ç”Ÿæˆä»»åŠ¡å®Œæˆï¼æˆåŠŸ: {completed_count}, å¤±è´¥: {failed_count}, æ€»è®¡: {total_count}")

            # ä½¿ç”¨QTimerå»¶è¿Ÿæ˜¾ç¤ºå®Œæˆé€šçŸ¥ï¼Œé¿å…é˜»å¡UI
            def show_completion_notification():
                try:
                    if failed_count == 0:
                        QMessageBox.information(self, "å®Œæˆ", f"æ‰€æœ‰ {completed_count} ä¸ªè§†é¢‘ç”Ÿæˆå®Œæˆï¼")
                    else:
                        QMessageBox.warning(self, "å®Œæˆ", f"ç”Ÿæˆå®Œæˆï¼æˆåŠŸ: {completed_count}, å¤±è´¥: {failed_count}")
                except Exception as msg_error:
                    logger.error(f"æ˜¾ç¤ºå®Œæˆé€šçŸ¥å¤±è´¥: {msg_error}")

            # å»¶è¿Ÿ500msæ˜¾ç¤ºé€šçŸ¥ï¼Œç¡®ä¿UIçŠ¶æ€æ›´æ–°å®Œæˆ
            QTimer.singleShot(500, show_completion_notification)

            logger.info(f"æ‰€æœ‰è§†é¢‘ç”Ÿæˆä»»åŠ¡å®Œæˆ - æˆåŠŸ: {completed_count}, å¤±è´¥: {failed_count}")

        except Exception as e:
            logger.error(f"å¤„ç†æ‰€æœ‰ç”Ÿæˆå®Œæˆäº‹ä»¶å¤±è´¥: {e}")

    def on_progress_updated(self, progress, message):
        """è¿›åº¦æ›´æ–°ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰"""
        self.progress_bar.setValue(progress)
        self.status_label.setText(message)

    def on_video_generated(self, video_path, success, error_message):
        """è§†é¢‘ç”Ÿæˆå®Œæˆ"""
        try:
            if success:
                # ä¿å­˜è§†é¢‘è·¯å¾„åˆ°é¡¹ç›®æ•°æ®
                self.save_video_to_project(video_path)

                # æ›´æ–°å½“å‰åœºæ™¯çŠ¶æ€
                if hasattr(self, '_current_generating_scene'):
                    self.update_scene_status(self._current_generating_scene, 'å·²ç”Ÿæˆ')

                # è‡ªåŠ¨æ’­æ”¾è§†é¢‘
                if self.auto_play_check.isChecked():
                    self.play_video(video_path)

                self.status_label.setText(f"è§†é¢‘ç”ŸæˆæˆåŠŸ: {os.path.basename(video_path)}")

            else:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦é™çº§å¤„ç†
                if hasattr(self, '_current_generating_scene') and self._should_fallback_to_image(error_message):
                    logger.info(f"è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œå°è¯•é™çº§ä¸ºå›¾åƒè§†é¢‘: {error_message}")
                    self._fallback_to_image_video(self._current_generating_scene, error_message)
                    return  # ä¸ç»§ç»­å¤„ç†ï¼Œç­‰å¾…é™çº§å®Œæˆ

                # æ›´æ–°å¤±è´¥çŠ¶æ€
                if hasattr(self, '_current_generating_scene'):
                    logger.info(f"æ›´æ–°åœºæ™¯çŠ¶æ€ä¸ºå¤±è´¥: {self._current_generating_scene.get('shot_id', 'unknown')}")
                    self.update_scene_status(self._current_generating_scene, 'å¤±è´¥')
                else:
                    logger.warning("æ²¡æœ‰æ‰¾åˆ°å½“å‰ç”Ÿæˆçš„åœºæ™¯ï¼Œæ— æ³•æ›´æ–°å¤±è´¥çŠ¶æ€")

                self.status_label.setText(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {error_message}")
                QMessageBox.critical(self, "ç”Ÿæˆå¤±è´¥", f"è§†é¢‘ç”Ÿæˆå¤±è´¥:\n{error_message}")

            # å¤„ç†ä¸‹ä¸€ä¸ªä»»åŠ¡
            QTimer.singleShot(1000, self.process_next_generation)

        except Exception as e:
            logger.error(f"å¤„ç†è§†é¢‘ç”Ÿæˆç»“æœå¤±è´¥: {e}")
            self.on_generation_error(str(e))



    def on_generation_error(self, error_message):
        """ç”Ÿæˆé”™è¯¯å¤„ç†"""
        self.hide_generation_progress()
        self.status_label.setText(f"ç”Ÿæˆé”™è¯¯: {error_message}")
        logger.error(f"è§†é¢‘ç”Ÿæˆé”™è¯¯: {error_message}")

    def cancel_generation(self):
        """å–æ¶ˆç”Ÿæˆï¼ˆæ”¯æŒå¹¶å‘ï¼‰"""
        try:
            # å–æ¶ˆæ‰€æœ‰æ´»è·ƒçš„å·¥ä½œçº¿ç¨‹
            for scene_id, worker_info in list(self.active_workers.items()):
                worker = worker_info['worker']
                if worker and worker.isRunning():
                    try:
                        if hasattr(worker, 'cancel'):
                            worker.cancel()
                        worker.quit()
                        worker.wait(3000)  # ç­‰å¾…3ç§’
                    except Exception as e:
                        logger.warning(f"å–æ¶ˆå·¥ä½œçº¿ç¨‹ {scene_id} æ—¶å‡ºé”™: {e}")

            # å–æ¶ˆä¼ ç»Ÿçš„å•çº¿ç¨‹å·¥ä½œ
            if self.current_worker and self.current_worker.isRunning():
                try:
                    if hasattr(self.current_worker, 'cancel'):
                        self.current_worker.cancel()
                    self.current_worker.quit()
                    self.current_worker.wait(3000)  # ç­‰å¾…3ç§’
                except Exception as e:
                    logger.warning(f"å–æ¶ˆå½“å‰å·¥ä½œçº¿ç¨‹æ—¶å‡ºé”™: {e}")

            # æ¸…ç†çŠ¶æ€
            self.active_workers.clear()
            self.generation_queue.clear()
            self.hide_generation_progress()
            self.status_label.setText("ç”Ÿæˆå·²å–æ¶ˆ")

            logger.info("æ‰€æœ‰è§†é¢‘ç”Ÿæˆä»»åŠ¡å·²å–æ¶ˆ")

        except Exception as e:
            logger.error(f"å–æ¶ˆç”Ÿæˆå¤±è´¥: {e}")

    def save_video_to_project(self, video_path, scene_data=None):
        """ä¿å­˜è§†é¢‘è·¯å¾„åˆ°é¡¹ç›®"""
        try:
            if not self.project_manager:
                logger.warning("é¡¹ç›®ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä¿å­˜è§†é¢‘")
                return

            # è·å–åœºæ™¯æ•°æ® - ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„scene_dataï¼Œå¦åˆ™ä½¿ç”¨_current_generating_scene
            current_scene = scene_data
            if not current_scene and hasattr(self, '_current_generating_scene'):
                current_scene = self._current_generating_scene

            if not current_scene:
                logger.warning("æ²¡æœ‰åœºæ™¯æ•°æ®ï¼Œæ— æ³•ä¿å­˜è§†é¢‘")
                return

            shot_id = current_scene.get('shot_id', '')
            logger.info(f"æ­£åœ¨ä¸ºé•œå¤´ {shot_id} ä¿å­˜è§†é¢‘è·¯å¾„: {video_path}")

            # åœ¨current_scenesä¸­æ‰¾åˆ°å¯¹åº”åœºæ™¯å¹¶æ›´æ–°è§†é¢‘è·¯å¾„
            scene_found = False
            for scene in self.current_scenes:
                if scene.get('shot_id') == shot_id:
                    scene['video_path'] = video_path
                    logger.info(f"ä¸ºé•œå¤´ {shot_id} ä¿å­˜è§†é¢‘è·¯å¾„: {video_path}")
                    scene_found = True
                    break

            if not scene_found:
                logger.warning(f"æœªæ‰¾åˆ°é•œå¤´ {shot_id} å¯¹åº”çš„åœºæ™¯æ•°æ®")

            # åˆ·æ–°è¡¨æ ¼æ˜¾ç¤º
            self.update_scene_table()

            # è®°å½•è§†é¢‘ç”Ÿæˆä¿¡æ¯åˆ°é¡¹ç›®æ•°æ®
            try:
                self.record_video_generation(video_path, current_scene)
                logger.debug(f"é•œå¤´ {shot_id} è§†é¢‘ç”Ÿæˆä¿¡æ¯å·²è®°å½•")
            except Exception as record_error:
                logger.error(f"è®°å½•é•œå¤´ {shot_id} è§†é¢‘ç”Ÿæˆä¿¡æ¯å¤±è´¥: {record_error}")
                # è®°å½•å¤±è´¥ä¸å½±å“ä¸»æµç¨‹

            # é€šçŸ¥ä¸»çª—å£åˆ·æ–°è§†é¢‘åˆæˆç•Œé¢
            try:
                self.notify_video_synthesis_refresh()
                logger.debug(f"å·²é€šçŸ¥è§†é¢‘åˆæˆç•Œé¢åˆ·æ–°")
            except Exception as notify_error:
                logger.warning(f"é€šçŸ¥è§†é¢‘åˆæˆç•Œé¢åˆ·æ–°å¤±è´¥: {notify_error}")
                # é€šçŸ¥å¤±è´¥ä¸å½±å“ä¸»æµç¨‹

        except Exception as e:
            logger.error(f"ä¿å­˜è§†é¢‘åˆ°é¡¹ç›®å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")

    def notify_video_synthesis_refresh(self):
        """é€šçŸ¥è§†é¢‘åˆæˆç•Œé¢åˆ·æ–°æ•°æ®"""
        try:
            # ğŸ”§ ä¿®å¤ï¼šåœ¨æ‰¹é‡å¤„ç†è¿‡ç¨‹ä¸­è·³è¿‡é€šçŸ¥ï¼Œé¿å…è§¦å‘ç•Œé¢é‡æ–°åŠ è½½
            if self.batch_processing_active:
                logger.debug("æ‰¹é‡å¤„ç†è¿›è¡Œä¸­ï¼Œè·³è¿‡è§†é¢‘åˆæˆç•Œé¢åˆ·æ–°é€šçŸ¥")
                return

            # é€šè¿‡ä¸»çª—å£åˆ·æ–°è§†é¢‘åˆæˆç•Œé¢
            main_window = self.parent()
            while main_window and not hasattr(main_window, 'pages'):
                main_window = main_window.parent()

            if main_window and hasattr(main_window, 'pages') and 'video' in main_window.pages:
                video_composition_tab = main_window.pages['video']
                if hasattr(video_composition_tab, 'load_project_data'):
                    video_composition_tab.load_project_data()
                    logger.info("å·²é€šçŸ¥è§†é¢‘åˆæˆç•Œé¢åˆ·æ–°æ•°æ®")
                elif hasattr(video_composition_tab, 'refresh_data'):
                    video_composition_tab.refresh_data()
                    logger.info("å·²é€šçŸ¥è§†é¢‘åˆæˆç•Œé¢åˆ·æ–°æ•°æ®")
        except Exception as e:
            logger.warning(f"é€šçŸ¥è§†é¢‘åˆæˆç•Œé¢åˆ·æ–°å¤±è´¥: {e}")

    def record_video_generation(self, video_path, scene_data):
        """è®°å½•è§†é¢‘ç”Ÿæˆä¿¡æ¯åˆ°é¡¹ç›®æ•°æ®"""
        try:
            if not self.project_manager:
                return

            import os
            import time
            from datetime import datetime

            # è·å–è§†é¢‘æ–‡ä»¶ä¿¡æ¯
            file_size = os.path.getsize(video_path) if os.path.exists(video_path) else 0

            # è·å–ç”Ÿæˆé…ç½®
            config = self.get_generation_config()

            # åˆ›å»ºè§†é¢‘è®°å½•
            video_record = {
                "video_id": f"video_{int(time.time())}_{scene_data.get('shot_id', '')}",
                "shot_id": scene_data.get('shot_id', ''),
                "scene_id": scene_data.get('scene_id', ''),
                "video_path": video_path,
                "source_image_path": scene_data.get('image_path', ''),
                "prompt": scene_data.get('enhanced_description', ''),
                "duration": config.get('duration', 5),
                "fps": config.get('fps', 30),
                "width": config.get('width', 1024),
                "height": config.get('height', 1024),
                "motion_intensity": config.get('motion_intensity', 0.5),
                "engine": config.get('engine', 'cogvideox_flash'),
                "generation_time": datetime.now().isoformat(),
                "status": "å·²ç”Ÿæˆ",
                "file_size": file_size,
                "created_time": datetime.now().isoformat()
            }

            # ğŸ”§ æ–°å¢ï¼šåŒæ—¶ä¿å­˜åˆ°shot_mappingsä¸­ï¼Œç¡®ä¿é‡æ–°åŠ è½½æ—¶èƒ½æ‰¾åˆ°è§†é¢‘è·¯å¾„
            try:
                shot_id = scene_data.get('shot_id', '')
                if shot_id and hasattr(self.project_manager, 'current_project') and self.project_manager.current_project:
                    # ç›´æ¥æ›´æ–°é¡¹ç›®æ•°æ®ä¸­çš„shot_mappings
                    if 'shot_mappings' not in self.project_manager.current_project:
                        self.project_manager.current_project['shot_mappings'] = {}

                    if shot_id not in self.project_manager.current_project['shot_mappings']:
                        self.project_manager.current_project['shot_mappings'][shot_id] = {}

                    self.project_manager.current_project['shot_mappings'][shot_id]['video_path'] = video_path
                    self.project_manager.current_project['shot_mappings'][shot_id]['video_status'] = 'completed'

                    # åŒæ—¶æ›´æ–°voice_segmentsä¸­çš„è§†é¢‘æ•°æ®
                    if 'voice_generation' in self.project_manager.current_project and 'voice_segments' in self.project_manager.current_project['voice_generation']:
                        for segment in self.project_manager.current_project['voice_generation']['voice_segments']:
                            if segment.get('shot_id') == shot_id:
                                segment['video_path'] = video_path
                                segment['video_status'] = 'å·²ç”Ÿæˆ'
                                break

                    logger.debug(f"å·²æ›´æ–°è§†é¢‘è·¯å¾„åˆ°shot_mappingså’Œvoice_segments: {shot_id} -> {video_path}")
            except Exception as e:
                logger.warning(f"æ›´æ–°è§†é¢‘è·¯å¾„å¤±è´¥: {e}")

            # æ·»åŠ åˆ°é¡¹ç›®æ•°æ®ï¼ˆè¿™ä¼šè‡ªåŠ¨ä¿å­˜é¡¹ç›®ï¼‰
            self.project_manager.add_video_record(video_record)

            logger.info(f"å·²è®°å½•è§†é¢‘ç”Ÿæˆä¿¡æ¯: {video_record['video_id']}")

        except Exception as e:
            logger.error(f"è®°å½•è§†é¢‘ç”Ÿæˆä¿¡æ¯å¤±è´¥: {e}")

    def _clean_missing_video_data(self, scene_data):
        """æ¸…ç†å·²åˆ é™¤è§†é¢‘çš„é¡¹ç›®æ•°æ®"""
        try:
            if not self.project_manager or not self.project_manager.current_project:
                return

            shot_id = scene_data.get('shot_id', '')
            if not shot_id:
                return

            project_data = self.project_manager.current_project
            data_cleaned = False

            # æ¸…ç†shot_mappingsä¸­çš„è§†é¢‘è·¯å¾„
            if 'shot_mappings' in project_data and shot_id in project_data['shot_mappings']:
                if 'video_path' in project_data['shot_mappings'][shot_id]:
                    del project_data['shot_mappings'][shot_id]['video_path']
                    data_cleaned = True
                if 'video_status' in project_data['shot_mappings'][shot_id]:
                    project_data['shot_mappings'][shot_id]['video_status'] = 'missing'
                    data_cleaned = True

            # æ¸…ç†video_generationè®°å½•ä¸­çš„ç›¸å…³è§†é¢‘
            if 'video_generation' in project_data and 'videos' in project_data['video_generation']:
                videos_to_remove = []
                for i, video_record in enumerate(project_data['video_generation']['videos']):
                    if (video_record.get('shot_id') == shot_id and
                        video_record.get('video_path') and
                        not os.path.exists(video_record['video_path'])):
                        videos_to_remove.append(i)

                # ä»åå¾€å‰åˆ é™¤ï¼Œé¿å…ç´¢å¼•å˜åŒ–
                for i in reversed(videos_to_remove):
                    del project_data['video_generation']['videos'][i]
                    data_cleaned = True

            # å¦‚æœæ¸…ç†äº†æ•°æ®ï¼Œä¿å­˜é¡¹ç›®
            if data_cleaned:
                self.project_manager.save_project()
                logger.info(f"å·²æ¸…ç†é•œå¤´ {shot_id} çš„ç¼ºå¤±è§†é¢‘æ•°æ®")

        except Exception as e:
            logger.error(f"æ¸…ç†ç¼ºå¤±è§†é¢‘æ•°æ®å¤±è´¥: {e}")

    def clean_all_missing_video_data(self):
        """æ¸…ç†æ‰€æœ‰ç¼ºå¤±çš„è§†é¢‘æ•°æ®"""
        try:
            if not self.project_manager or not self.project_manager.current_project:
                QMessageBox.warning(self, "è­¦å‘Š", "æ²¡æœ‰å½“å‰é¡¹ç›®")
                return

            # ç¡®è®¤å¯¹è¯æ¡†
            reply = QMessageBox.question(
                self, "ç¡®è®¤æ¸…ç†",
                "ç¡®å®šè¦æ¸…ç†æ‰€æœ‰å·²åˆ é™¤è§†é¢‘æ–‡ä»¶çš„æ•°æ®è®°å½•å—ï¼Ÿ\n"
                "è¿™å°†åˆ é™¤é¡¹ç›®ä¸­æŒ‡å‘ä¸å­˜åœ¨æ–‡ä»¶çš„è§†é¢‘è·¯å¾„è®°å½•ã€‚",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                QMessageBox.StandardButton.No
            )

            if reply != QMessageBox.StandardButton.Yes:
                return

            project_data = self.project_manager.current_project
            cleaned_count = 0

            # æ¸…ç†shot_mappingsä¸­çš„ç¼ºå¤±è§†é¢‘
            if 'shot_mappings' in project_data:
                for shot_id, mapping_data in project_data['shot_mappings'].items():
                    if ('video_path' in mapping_data and
                        mapping_data['video_path'] and
                        not os.path.exists(mapping_data['video_path'])):
                        del mapping_data['video_path']
                        mapping_data['video_status'] = 'missing'
                        cleaned_count += 1
                        logger.info(f"æ¸…ç†shot_mappingsä¸­çš„ç¼ºå¤±è§†é¢‘: {shot_id}")

            # æ¸…ç†video_generationè®°å½•ä¸­çš„ç¼ºå¤±è§†é¢‘
            if 'video_generation' in project_data and 'videos' in project_data['video_generation']:
                videos_to_remove = []
                for i, video_record in enumerate(project_data['video_generation']['videos']):
                    if (video_record.get('video_path') and
                        not os.path.exists(video_record['video_path'])):
                        videos_to_remove.append(i)

                # ä»åå¾€å‰åˆ é™¤ï¼Œé¿å…ç´¢å¼•å˜åŒ–
                for i in reversed(videos_to_remove):
                    del project_data['video_generation']['videos'][i]
                    cleaned_count += 1

            # æ¸…ç†current_scenesä¸­çš„ç¼ºå¤±è§†é¢‘è·¯å¾„
            for scene_data in self.current_scenes:
                if (scene_data.get('video_path') and
                    not os.path.exists(scene_data['video_path'])):
                    scene_data['video_path'] = ''
                    cleaned_count += 1

            # ä¿å­˜é¡¹ç›®æ•°æ®
            if cleaned_count > 0:
                self.project_manager.save_project()
                # åˆ·æ–°ç•Œé¢
                self.update_scene_table()
                QMessageBox.information(
                    self, "æ¸…ç†å®Œæˆ",
                    f"å·²æ¸…ç† {cleaned_count} ä¸ªç¼ºå¤±è§†é¢‘çš„æ•°æ®è®°å½•"
                )
                logger.info(f"æ¸…ç†å®Œæˆï¼Œå…±æ¸…ç† {cleaned_count} ä¸ªç¼ºå¤±è§†é¢‘æ•°æ®")
            else:
                QMessageBox.information(self, "æ¸…ç†å®Œæˆ", "æ²¡æœ‰å‘ç°éœ€è¦æ¸…ç†çš„ç¼ºå¤±è§†é¢‘æ•°æ®")

        except Exception as e:
            logger.error(f"æ¸…ç†æ‰€æœ‰ç¼ºå¤±è§†é¢‘æ•°æ®å¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"æ¸…ç†å¤±è´¥: {e}")

    def play_video(self, video_path):
        """æ’­æ”¾è§†é¢‘"""
        try:
            import subprocess
            import platform

            if platform.system() == "Windows":
                os.startfile(video_path)
            elif platform.system() == "Darwin":  # macOS
                subprocess.run(["open", video_path])
            else:  # Linux
                subprocess.run(["xdg-open", video_path])

        except Exception as e:
            logger.error(f"æ’­æ”¾è§†é¢‘å¤±è´¥: {e}")

    def open_output_directory(self):
        """æ‰“å¼€è¾“å‡ºç›®å½•"""
        try:
            output_dir = "output/videos"
            if self.project_manager and self.project_manager.current_project:
                # ä½¿ç”¨é¡¹ç›®ç®¡ç†å™¨çš„æ–¹æ³•è·å–å½“å‰é¡¹ç›®è·¯å¾„
                project_path = self.project_manager.get_current_project_path()
                if project_path:
                    output_dir = os.path.join(project_path, 'videos')

            if not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)

            import subprocess
            import platform

            if platform.system() == "Windows":
                os.startfile(output_dir)
            elif platform.system() == "Darwin":  # macOS
                subprocess.run(["open", output_dir])
            else:  # Linux
                subprocess.run(["xdg-open", output_dir])

        except Exception as e:
            logger.error(f"æ‰“å¼€è¾“å‡ºç›®å½•å¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"æ‰“å¼€è¾“å‡ºç›®å½•å¤±è´¥: {str(e)}")

    def update_output_dir_label(self):
        """æ›´æ–°è¾“å‡ºç›®å½•æ ‡ç­¾æ˜¾ç¤º"""
        try:
            if self.project_manager and self.project_manager.current_project:
                # ä½¿ç”¨é¡¹ç›®ç®¡ç†å™¨çš„æ–¹æ³•è·å–å½“å‰é¡¹ç›®è·¯å¾„
                project_path = self.project_manager.get_current_project_path()
                if project_path:
                    output_dir = os.path.join(project_path, 'videos')
                    # æ˜¾ç¤ºç›¸å¯¹è·¯å¾„ï¼Œæ›´ç®€æ´
                    project_name = os.path.basename(project_path)
                    self.output_dir_label.setText(f"{project_name}/videos/")
                    self.output_dir_label.setToolTip(f"å®Œæ•´è·¯å¾„: {output_dir}")
                    return

            # é»˜è®¤æ˜¾ç¤º
            self.output_dir_label.setText("output/videos/")
            self.output_dir_label.setToolTip("é»˜è®¤è¾“å‡ºç›®å½•")

        except Exception as e:
            logger.error(f"æ›´æ–°è¾“å‡ºç›®å½•æ ‡ç­¾å¤±è´¥: {e}")
            self.output_dir_label.setText("è¾“å‡ºç›®å½•è·å–å¤±è´¥")
            self.output_dir_label.setToolTip(f"é”™è¯¯: {e}")

    def _should_fallback_to_image(self, error_message):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é™çº§ä¸ºå›¾åƒè§†é¢‘"""
        if not error_message:
            return False

        # æ£€æŸ¥å†…å®¹å®‰å…¨ç›¸å…³çš„é”™è¯¯æ¨¡å¼
        safety_patterns = [
            'å†…å®¹å®‰å…¨', 'æ•æ„Ÿå†…å®¹', 'ä¸å®‰å…¨å†…å®¹', 'unsafe content', 'sensitive content',
            'è¿è§„å†…å®¹', 'å®¡æ ¸å¤±è´¥', 'content violation', 'content policy',
            'è¡€è…¥', 'æš´åŠ›', 'è¡€è¿¹', 'blood', 'violence', 'violent',
            'ä¸å½“å†…å®¹', 'inappropriate content', 'å†…å®¹å®¡æ ¸',
            'å®‰å…¨æ£€æµ‹', 'safety check', 'content filter',
            'è¢«æ‹’ç»', 'rejected', 'blocked', 'å±è”½'
        ]

        error_lower = error_message.lower()
        for pattern in safety_patterns:
            if pattern.lower() in error_lower:
                logger.info(f"æ£€æµ‹åˆ°å†…å®¹å®‰å…¨ç›¸å…³é”™è¯¯ï¼Œè§¦å‘é™çº§æœºåˆ¶: {pattern}")
                return True

        return False

    def _fallback_to_image_video(self, scene_data, original_error):
        """é™çº§ä¸ºå›¾åƒè§†é¢‘"""
        try:
            logger.info(f"å¼€å§‹é™çº§å¤„ç†é•œå¤´: {scene_data.get('shot_id', 'unknown')}")
            self.status_label.setText("æ£€æµ‹åˆ°å†…å®¹é™åˆ¶ï¼Œæ­£åœ¨ä½¿ç”¨å›¾åƒç”Ÿæˆé™æ€è§†é¢‘...")

            # è·å–é•œå¤´å¯¹åº”çš„å›¾åƒè·¯å¾„
            image_path = self._get_scene_image_path(scene_data)
            if not image_path or not os.path.exists(image_path):
                logger.error(f"æ— æ³•æ‰¾åˆ°é•œå¤´å›¾åƒï¼Œé™çº§å¤±è´¥: {image_path}")
                self._handle_fallback_failure(scene_data, "æ— æ³•æ‰¾åˆ°å¯¹åº”çš„å›¾åƒæ–‡ä»¶")
                return

            # è·å–éŸ³é¢‘æ—¶é•¿æ¥ç¡®å®šè§†é¢‘æ—¶é•¿ - ä¼˜å…ˆä½¿ç”¨voice_duration
            audio_duration = scene_data.get('voice_duration', 0.0)
            if audio_duration <= 0:
                # å¦‚æœæ²¡æœ‰voice_durationï¼Œå°è¯•ä»éŸ³é¢‘æ–‡ä»¶è·å–
                if scene_data.get('voice_path') and os.path.exists(scene_data.get('voice_path')):
                    audio_duration = self._get_audio_duration(scene_data.get('voice_path'))
                    logger.info(f"é™çº§å¤„ç† - é•œå¤´ {scene_data.get('shot_id', 'unknown')} ä»éŸ³é¢‘æ–‡ä»¶è·å–æ—¶é•¿: {audio_duration}ç§’")
                else:
                    # å¦‚æœæ²¡æœ‰éŸ³é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤æ—¶é•¿
                    audio_duration = 5.0
                    logger.warning(f"é™çº§å¤„ç† - é•œå¤´ {scene_data.get('shot_id', 'unknown')} æ²¡æœ‰é…éŸ³æ—¶é•¿ï¼Œä½¿ç”¨é»˜è®¤æ—¶é•¿: {audio_duration}ç§’")
            else:
                logger.info(f"é™çº§å¤„ç† - é•œå¤´ {scene_data.get('shot_id', 'unknown')} ä½¿ç”¨é…éŸ³æ—¶é•¿: {audio_duration}ç§’")

            # åˆ›å»ºé™æ€è§†é¢‘ï¼ˆä»å›¾åƒï¼‰
            self._create_static_video_from_image(scene_data, image_path, audio_duration, original_error)

        except Exception as e:
            logger.error(f"é™çº§å¤„ç†å¤±è´¥: {e}")
            self._handle_fallback_failure(scene_data, f"é™çº§å¤„ç†å¼‚å¸¸: {e}")

    def _create_static_video_from_image(self, scene_data, image_path, duration, original_error):
        """ä»å›¾åƒåˆ›å»ºé™æ€è§†é¢‘"""
        try:
            import subprocess
            import tempfile

            shot_id = scene_data.get('shot_id', 'unknown')
            logger.info(f"ä¸ºé•œå¤´ {shot_id} åˆ›å»ºé™æ€è§†é¢‘ï¼Œæ—¶é•¿: {duration}ç§’")

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            timestamp = int(time.time() * 1000)
            output_filename = f"fallback_{shot_id}_{timestamp}.mp4"

            # ç¡®å®šè¾“å‡ºç›®å½•
            if self.project_manager and self.project_manager.current_project:
                project_path = self.project_manager.get_current_project_path()
                output_dir = os.path.join(project_path, 'videos', 'fallback')
            else:
                output_dir = os.path.join('output', 'videos', 'fallback')

            os.makedirs(output_dir, exist_ok=True)
            output_path = os.path.join(output_dir, output_filename)

            # è·å–åŸå›¾åƒåˆ†è¾¨ç‡
            try:
                from PIL import Image
                with Image.open(image_path) as img:
                    img_width, img_height = img.size
                    logger.info(f"é™çº§å¤„ç† - åŸå›¾åƒå°ºå¯¸: {img_width}x{img_height}")
            except Exception as e:
                logger.warning(f"æ— æ³•è·å–å›¾åƒå°ºå¯¸ï¼Œä½¿ç”¨é»˜è®¤åˆ†è¾¨ç‡: {e}")
                img_width, img_height = 1024, 1024

            # ä½¿ç”¨FFmpegåˆ›å»ºé™æ€è§†é¢‘ï¼Œä¿æŒåŸå›¾åƒåˆ†è¾¨ç‡
            cmd = [
                'ffmpeg/bin/ffmpeg.exe',
                '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                '-loop', '1',  # å¾ªç¯è¾“å…¥å›¾åƒ
                '-i', image_path,  # è¾“å…¥å›¾åƒ
                '-t', str(duration),  # è§†é¢‘æ—¶é•¿
                '-r', '30',  # å¸§ç‡
                '-c:v', 'libx264',  # è§†é¢‘ç¼–ç å™¨
                '-pix_fmt', 'yuv420p',  # åƒç´ æ ¼å¼
                '-preset', 'medium',  # ç¼–ç é¢„è®¾
                output_path
            ]

            logger.info(f"æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd)}")

            # æ‰§è¡ŒFFmpegå‘½ä»¤
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)

            if result.returncode == 0 and os.path.exists(output_path):
                logger.info(f"é™æ€è§†é¢‘åˆ›å»ºæˆåŠŸ: {output_path}")

                # è®°å½•é™çº§ä¿¡æ¯åˆ°é¡¹ç›®æ•°æ®
                self._record_fallback_video(scene_data, output_path, original_error)

                # æ›´æ–°åœºæ™¯çŠ¶æ€ä¸ºå·²ç”Ÿæˆï¼ˆé™çº§ï¼‰
                self.update_scene_status(scene_data, 'å·²ç”Ÿæˆ(å›¾åƒ)')

                # ä¿å­˜è§†é¢‘åˆ°é¡¹ç›®
                self.save_video_to_project(output_path)

                self.status_label.setText(f"å·²ä½¿ç”¨å›¾åƒç”Ÿæˆé™æ€è§†é¢‘: {os.path.basename(output_path)}")

                # è‡ªåŠ¨æ’­æ”¾è§†é¢‘
                if self.auto_play_check.isChecked():
                    self.play_video(output_path)

                # å¤„ç†ä¸‹ä¸€ä¸ªä»»åŠ¡ - æ£€æŸ¥æ˜¯å¦åœ¨å¹¶å‘æ¨¡å¼
                if hasattr(self, 'generation_queue') and (self.generation_queue or self.active_workers):
                    # å¹¶å‘æ¨¡å¼ï¼šæ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆ
                    if not self.active_workers and not self.generation_queue:
                        QTimer.singleShot(1000, self.on_all_generation_complete)
                    else:
                        # æ›´æ–°è¿›åº¦æ˜¾ç¤º
                        completed_count = len([s for s in self.current_scenes if s.get('status') in ['å·²ç”Ÿæˆ', 'å·²ç”Ÿæˆ(å›¾åƒ)']])
                        total_count = len(self.current_scenes)
                        overall_progress = int((completed_count / total_count) * 100) if total_count > 0 else 0
                        self.progress_bar.setValue(overall_progress)

                        active_count = len(self.active_workers)
                        queue_count = len(self.generation_queue)
                        self.status_label.setText(f"å¹¶å‘ç”Ÿæˆä¸­({active_count}ä¸ªæ´»è·ƒ, {queue_count}ä¸ªç­‰å¾…) - å·²é™çº§å¤„ç†")
                else:
                    # å•ä¸ªç”Ÿæˆæ¨¡å¼
                    QTimer.singleShot(1000, self.process_next_generation)

            else:
                error_msg = result.stderr if result.stderr else "FFmpegæ‰§è¡Œå¤±è´¥"
                logger.error(f"é™æ€è§†é¢‘åˆ›å»ºå¤±è´¥: {error_msg}")
                self._handle_fallback_failure(scene_data, f"FFmpegé”™è¯¯: {error_msg}")

        except subprocess.TimeoutExpired:
            logger.error("é™æ€è§†é¢‘åˆ›å»ºè¶…æ—¶")
            self._handle_fallback_failure(scene_data, "è§†é¢‘åˆ›å»ºè¶…æ—¶")
        except Exception as e:
            logger.error(f"åˆ›å»ºé™æ€è§†é¢‘å¼‚å¸¸: {e}")
            self._handle_fallback_failure(scene_data, f"åˆ›å»ºå¼‚å¸¸: {e}")

    def _record_fallback_video(self, scene_data, video_path, original_error):
        """è®°å½•é™çº§è§†é¢‘ä¿¡æ¯"""
        try:
            if not self.project_manager or not self.project_manager.current_project:
                return

            shot_id = scene_data.get('shot_id', 'unknown')

            # åˆ›å»ºè§†é¢‘è®°å½•
            video_record = {
                "video_id": f"fallback_{int(time.time())}_{shot_id}",
                "shot_id": shot_id,
                "scene_id": scene_data.get('scene_id', 'scene_1'),
                "video_path": video_path,
                "source_image_path": self._get_scene_image_path(scene_data),
                "prompt": scene_data.get('enhanced_description', ''),
                "duration": scene_data.get('duration', 5.0),
                "fps": 30,
                "width": 1024,
                "height": 1024,
                "motion_intensity": 0.0,  # é™æ€è§†é¢‘
                "engine": "fallback_static",
                "generation_time": datetime.now().isoformat(),
                "status": "å·²ç”Ÿæˆ(é™çº§)",
                "file_size": os.path.getsize(video_path) if os.path.exists(video_path) else 0,
                "created_time": datetime.now().isoformat(),
                "fallback_info": {
                    "original_error": original_error,
                    "fallback_reason": "å†…å®¹å®‰å…¨æ£€æµ‹",
                    "fallback_type": "static_image"
                }
            }

            # ä¿å­˜åˆ°é¡¹ç›®æ•°æ®
            project_data = self.project_manager.get_project_data()
            if 'video_generation' not in project_data:
                project_data['video_generation'] = {'videos': []}
            if 'videos' not in project_data['video_generation']:
                project_data['video_generation']['videos'] = []

            project_data['video_generation']['videos'].append(video_record)
            self.project_manager.save_project_data(project_data)

            logger.info(f"é™çº§è§†é¢‘è®°å½•å·²ä¿å­˜: {shot_id}")

        except Exception as e:
            logger.error(f"è®°å½•é™çº§è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")

    def _handle_fallback_failure(self, scene_data, error_message):
        """å¤„ç†é™çº§å¤±è´¥"""
        logger.error(f"é™çº§å¤±è´¥: {error_message}")

        # æ›´æ–°åœºæ™¯çŠ¶æ€ä¸ºå¤±è´¥
        self.update_scene_status(scene_data, 'å¤±è´¥')

        self.status_label.setText(f"é™çº§å¤±è´¥: {error_message}")
        QMessageBox.critical(self, "é™çº§å¤±è´¥", f"å›¾åƒé™çº§å¤„ç†å¤±è´¥:\n{error_message}")

        # å¤„ç†ä¸‹ä¸€ä¸ªä»»åŠ¡ - æ£€æŸ¥æ˜¯å¦åœ¨å¹¶å‘æ¨¡å¼
        if hasattr(self, 'generation_queue') and (self.generation_queue or self.active_workers):
            # å¹¶å‘æ¨¡å¼ï¼šæ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆ
            if not self.active_workers and not self.generation_queue:
                QTimer.singleShot(1000, self.on_all_generation_complete)
            else:
                # å¯åŠ¨ä¸‹ä¸€ä¸ªä»»åŠ¡
                if self.generation_queue:
                    QTimer.singleShot(3000, self.start_concurrent_generation)
        else:
            # å•ä¸ªç”Ÿæˆæ¨¡å¼
            QTimer.singleShot(1000, self.process_next_generation)

    def _get_scene_image_path(self, scene_data):
        """è·å–åœºæ™¯å¯¹åº”çš„å›¾åƒè·¯å¾„"""
        try:
            if not self.project_manager or not self.project_manager.current_project:
                return None

            project_data = self.project_manager.get_project_data()
            shot_image_mappings = project_data.get('shot_image_mappings', {})

            shot_id = scene_data.get('shot_id', '')
            if not shot_id:
                return None

            # å°è¯•å¤šç§å¯èƒ½çš„é”®å
            possible_keys = [
                f'scene_1_{shot_id}',
                shot_id,
                f'scene_1_shot_{shot_id.split("_")[-1]}' if 'text_segment_' in shot_id else shot_id
            ]

            # å¦‚æœæ˜¯text_segment_XXXæ ¼å¼ï¼Œä¹Ÿå°è¯•scene_1_shot_XXæ ¼å¼
            if shot_id.startswith('text_segment_'):
                shot_number = shot_id.split('_')[-1]
                possible_keys.append(f'scene_1_shot_{shot_number}')
                possible_keys.append(f'scene_1_shot_{int(shot_number)}')  # å»æ‰å‰å¯¼é›¶

            for key in possible_keys:
                if key in shot_image_mappings:
                    img_data = shot_image_mappings[key]
                    if isinstance(img_data, dict):
                        # ä¼˜å…ˆè·å–ä¸»å›¾è·¯å¾„
                        image_path = img_data.get('main_image_path', '') or img_data.get('image_path', '')
                        if image_path and os.path.exists(image_path):
                            logger.debug(f"æ‰¾åˆ°é•œå¤´å›¾åƒ: {key} -> {image_path}")
                            return image_path
                    elif isinstance(img_data, str) and os.path.exists(img_data):
                        logger.debug(f"æ‰¾åˆ°é•œå¤´å›¾åƒ: {key} -> {img_data}")
                        return img_data

            # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
            if shot_id.startswith('text_segment_'):
                shot_number = shot_id.split('_')[-1]
                for mapping_key, img_data in shot_image_mappings.items():
                    if shot_number in mapping_key:
                        if isinstance(img_data, dict):
                            image_path = img_data.get('main_image_path', '') or img_data.get('image_path', '')
                            if image_path and os.path.exists(image_path):
                                logger.debug(f"æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°é•œå¤´å›¾åƒ: {mapping_key} -> {image_path}")
                                return image_path
                        elif isinstance(img_data, str) and os.path.exists(img_data):
                            logger.debug(f"æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°é•œå¤´å›¾åƒ: {mapping_key} -> {img_data}")
                            return img_data

            logger.warning(f"æœªæ‰¾åˆ°é•œå¤´ {shot_id} å¯¹åº”çš„å›¾åƒ")
            return None

        except Exception as e:
            logger.error(f"è·å–åœºæ™¯å›¾åƒè·¯å¾„å¤±è´¥: {e}")
            return None

    def showEvent(self, event):
        """é¡µé¢æ˜¾ç¤ºæ—¶çš„äº‹ä»¶å¤„ç†"""
        super().showEvent(event)
        try:
            # ğŸ”§ ä¿®å¤ï¼šåªåœ¨æ‰¹é‡å¤„ç†ä¸æ´»è·ƒæ—¶æ‰é‡æ–°åŠ è½½é¡¹ç›®æ•°æ®
            if not self.batch_processing_active:
                self.load_project_data()
                logger.info("å›¾é“ƒè§†é¢‘é¡µé¢æ˜¾ç¤ºï¼Œå·²é‡æ–°åŠ è½½é¡¹ç›®æ•°æ®")
            else:
                logger.debug("æ‰¹é‡å¤„ç†è¿›è¡Œä¸­ï¼Œè·³è¿‡é¡¹ç›®æ•°æ®é‡æ–°åŠ è½½")
                # åªæ›´æ–°è¾“å‡ºç›®å½•æ ‡ç­¾ï¼Œä¸é‡æ–°åŠ è½½æ•°æ®
                self.update_output_dir_label()
        except Exception as e:
            logger.error(f"é¡µé¢æ˜¾ç¤ºæ—¶åŠ è½½æ•°æ®å¤±è´¥: {e}")


class MultiSegmentVideoWorker(QThread):
    """å¤šç‰‡æ®µè§†é¢‘ç”Ÿæˆå·¥ä½œçº¿ç¨‹"""
    progress_updated = pyqtSignal(int, str)
    video_generated = pyqtSignal(bool, str, str)

    def __init__(self, scene_data, scene_images, segment_durations, project_manager, project_name):
        super().__init__()
        self.scene_data = scene_data
        self.scene_images = scene_images
        self.segment_durations = segment_durations
        self.project_manager = project_manager
        self.project_name = project_name

    def run(self):
        """è¿è¡Œå¤šç‰‡æ®µè§†é¢‘ç”Ÿæˆï¼ˆä¿®å¤Event loopé—®é¢˜ï¼‰"""
        try:
            self.progress_updated.emit(0, "å¼€å§‹ç”Ÿæˆå¤šç‰‡æ®µè§†é¢‘...")

            # åˆ›å»ºä¸€ä¸ªäº‹ä»¶å¾ªç¯ç”¨äºæ•´ä¸ªç”Ÿæˆè¿‡ç¨‹
            import asyncio

            # ç¡®ä¿åœ¨æ–°çº¿ç¨‹ä¸­åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

            try:
                # è¿è¡Œå¼‚æ­¥ç”Ÿæˆæ–¹æ³•
                final_video_path = loop.run_until_complete(self._generate_all_videos_async())
            finally:
                # ç¡®ä¿äº‹ä»¶å¾ªç¯æ­£ç¡®å…³é—­
                try:
                    # å–æ¶ˆæ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
                    pending = asyncio.all_tasks(loop)
                    if pending:
                        for task in pending:
                            task.cancel()

                        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆæˆ–å–æ¶ˆ
                        loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))

                except Exception as cleanup_error:
                    logger.warning(f"æ¸…ç†äº‹ä»¶å¾ªç¯æ—¶å‡ºé”™: {cleanup_error}")
                finally:
                    loop.close()

            self.progress_updated.emit(100, "è§†é¢‘ç”Ÿæˆå®Œæˆ")
            self.video_generated.emit(True, "å¤šç‰‡æ®µè§†é¢‘ç”ŸæˆæˆåŠŸ", final_video_path)

        except Exception as e:
            logger.error(f"å¤šç‰‡æ®µè§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            self.video_generated.emit(False, str(e), "")

    async def _generate_all_videos_async(self):
        """å¼‚æ­¥ç”Ÿæˆæ‰€æœ‰è§†é¢‘ç‰‡æ®µ"""
        from src.models.video_engines.video_generation_service import VideoGenerationService

        # åˆ›å»ºè§†é¢‘ç”ŸæˆæœåŠ¡
        video_service = VideoGenerationService()
        generated_videos = []
        total_segments = len(self.segment_durations)

        for i, duration in enumerate(self.segment_durations):
            if i >= len(self.scene_images):
                break

            self.progress_updated.emit(
                int((i / total_segments) * 80),
                f"ç”Ÿæˆç¬¬{i+1}/{total_segments}ä¸ªç‰‡æ®µ..."
            )

            # è·å–å½“å‰ç‰‡æ®µçš„å›¾åƒ
            image_path = self.scene_images[i]['path']

            try:
                # ç”Ÿæˆè§†é¢‘
                result = await video_service.generate_video(
                    prompt=self.scene_data.get('enhanced_description', ''),
                    image_path=image_path,
                    duration=duration,
                    fps=24,
                    width=1024,
                    height=1024,
                    motion_intensity=0.5,
                    preferred_engines=["cogvideox_flash"],
                    project_manager=self.project_manager,
                    current_project_name=self.project_name
                )

                if result.success:
                    generated_videos.append(result.video_path)
                    logger.info(f"ç‰‡æ®µ{i+1}ç”ŸæˆæˆåŠŸ: {result.video_path}")
                else:
                    raise Exception(result.error_message)

            except Exception as e:
                logger.error(f"ç‰‡æ®µ{i+1}ç”Ÿæˆå¤±è´¥: {e}")
                raise Exception(f"ç‰‡æ®µ{i+1}ç”Ÿæˆå¤±è´¥: {e}")

        # åˆå¹¶è§†é¢‘ç‰‡æ®µ
        self.progress_updated.emit(85, "åˆå¹¶è§†é¢‘ç‰‡æ®µ...")
        final_video_path = self._merge_video_segments(generated_videos)

        return final_video_path

    def _merge_video_segments(self, video_paths):
        """åˆå¹¶è§†é¢‘ç‰‡æ®µ"""
        try:
            if len(video_paths) == 1:
                return video_paths[0]

            # ä½¿ç”¨ffmpegåˆå¹¶è§†é¢‘
            import subprocess
            import tempfile

            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_dir = os.path.dirname(video_paths[0])
            shot_id = self.scene_data.get('shot_id', 'unknown')
            output_path = os.path.join(output_dir, f"{shot_id}_merged.mp4")

            # åˆ›å»ºæ–‡ä»¶åˆ—è¡¨
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                for video_path in video_paths:
                    f.write(f"file '{video_path}'\n")
                list_file = f.name

            try:
                # ä½¿ç”¨ffmpegåˆå¹¶
                cmd = [
                    'ffmpeg', '-f', 'concat', '-safe', '0',
                    '-i', list_file, '-c', 'copy', output_path, '-y'
                ]
                subprocess.run(cmd, check=True, capture_output=True)

                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                os.unlink(list_file)

                # åˆ é™¤åŸå§‹ç‰‡æ®µæ–‡ä»¶
                for video_path in video_paths:
                    try:
                        os.unlink(video_path)
                    except:
                        pass

                return output_path

            except subprocess.CalledProcessError as e:
                logger.error(f"ffmpegåˆå¹¶å¤±è´¥: {e}")
                # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œè¿”å›ç¬¬ä¸€ä¸ªç‰‡æ®µ
                return video_paths[0]

        except Exception as e:
            logger.error(f"åˆå¹¶è§†é¢‘ç‰‡æ®µå¤±è´¥: {e}")
            # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œè¿”å›ç¬¬ä¸€ä¸ªç‰‡æ®µ
            return video_paths[0] if video_paths else ""
