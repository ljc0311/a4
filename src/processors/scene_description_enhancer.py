# -*- coding: utf-8 -*-
"""
åœºæ™¯æè¿°æ™ºèƒ½å¢å¼ºå™¨

å®ç°å¯¹äº”é˜¶æ®µåˆ†é•œè„šæœ¬ä¸­ç”»é¢æè¿°çš„æ™ºèƒ½å¢å¼ºï¼ŒåŒ…æ‹¬ï¼š
1. æŠ€æœ¯ç»†èŠ‚åˆ†æå’Œè¡¥å……
2. è§’è‰²åœºæ™¯ä¸€è‡´æ€§æè¿°æ³¨å…¥
3. å†…å®¹èåˆå’Œä¼˜åŒ–
"""

import re
import json
import os
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from src.utils.logger import logger
from src.utils.character_scene_manager import CharacterSceneManager
from src.utils.color_optimizer import ColorOptimizer
from src.utils.character_detection_config import CharacterDetectionConfig
from src.utils.style_consistency_manager import StyleConsistencyManager


@dataclass
class TechnicalDetails:
    """æŠ€æœ¯ç»†èŠ‚æ•°æ®ç»“æ„"""
    shot_type: str = ""  # é•œå¤´ç±»å‹
    camera_angle: str = ""  # æœºä½è§’åº¦
    camera_movement: str = ""  # é•œå¤´è¿åŠ¨
    depth_of_field: str = ""  # æ™¯æ·±
    lighting: str = ""  # å…‰çº¿
    composition: str = ""  # æ„å›¾
    color_tone: str = ""  # è‰²è°ƒ
    
    def to_description(self) -> str:
        """è½¬æ¢ä¸ºæè¿°æ–‡æœ¬"""
        parts = []
        if self.shot_type:
            parts.append(f"é•œå¤´ç±»å‹ï¼š{self.shot_type}")
        if self.camera_angle:
            parts.append(f"æœºä½è§’åº¦ï¼š{self.camera_angle}")
        if self.camera_movement:
            parts.append(f"é•œå¤´è¿åŠ¨ï¼š{self.camera_movement}")
        if self.depth_of_field:
            parts.append(f"æ™¯æ·±ï¼š{self.depth_of_field}")
        if self.lighting:
            parts.append(f"å…‰çº¿ï¼š{self.lighting}")
        if self.composition:
            parts.append(f"æ„å›¾ï¼š{self.composition}")
        if self.color_tone:
            parts.append(f"è‰²è°ƒï¼š{self.color_tone}")
        return "ï¼Œ".join(parts)


@dataclass
class ConsistencyInfo:
    """ä¸€è‡´æ€§ä¿¡æ¯æ•°æ®ç»“æ„"""
    characters: List[str] = field(default_factory=list)  # è§’è‰²ä¸€è‡´æ€§æè¿°
    scenes: List[str] = field(default_factory=list)  # åœºæ™¯ä¸€è‡´æ€§æè¿°
    detected_characters: List[str] = field(default_factory=list)  # æ£€æµ‹åˆ°çš„è§’è‰²åç§°
    detected_scenes: List[str] = field(default_factory=list)  # æ£€æµ‹åˆ°çš„åœºæ™¯åç§°
    
    def to_description(self) -> str:
        """è½¬æ¢ä¸ºæè¿°æ–‡æœ¬"""
        parts = []
        if self.characters:
            parts.extend([f"è§’è‰²ä¸€è‡´æ€§ï¼š{char}" for char in self.characters])
        if self.scenes:
            parts.extend([f"åœºæ™¯ä¸€è‡´æ€§ï¼š{scene}" for scene in self.scenes])
        return "ï¼›".join(parts)


class TechnicalDetailsAnalyzer:
    """æŠ€æœ¯ç»†èŠ‚åˆ†æå™¨"""
    
    def __init__(self):
        # æŠ€æœ¯ç»†èŠ‚æ¨ç†è§„åˆ™
        self.shot_type_rules = {
            r'(ç‰¹å†™|close.?up|ç‰¹å†™é•œå¤´)': 'ç‰¹å†™',
            r'(è¿‘æ™¯|medium.?shot|ä¸­æ™¯)': 'è¿‘æ™¯',
            r'(ä¸­æ™¯|medium.?shot)': 'ä¸­æ™¯',
            r'(è¿œæ™¯|long.?shot|å…¨æ™¯)': 'è¿œæ™¯',
            r'(å…¨æ™¯|wide.?shot|å¤§å…¨æ™¯)': 'å…¨æ™¯',
            r'(å¤§å…¨æ™¯|extreme.?wide)': 'å¤§å…¨æ™¯'
        }
        
        self.camera_angle_rules = {
            r'(ä¿¯è§†|ä¿¯æ‹|bird.?eye|ä»ä¸Šå¾€ä¸‹)': 'ä¿¯è§†è§’åº¦',
            r'(ä»°è§†|ä»°æ‹|worm.?eye|ä»ä¸‹å¾€ä¸Š)': 'ä»°è§†è§’åº¦',
            r'(å¹³è§†|æ°´å¹³|eye.?level)': 'å¹³è§†è§’åº¦',
            r'(ä¾§é¢|ä¾§è§†|profile)': 'ä¾§é¢è§’åº¦'
        }
        
        self.camera_movement_rules = {
            r'(æ¨è¿›|æ¨é•œ|dolly.?in|zoom.?in)': 'æ¨é•œ',
            r'(æ‹‰è¿œ|æ‹‰é•œ|dolly.?out|zoom.?out)': 'æ‹‰é•œ',
            r'(æ‘‡é•œ|æ‘‡æ‘†|pan)': 'æ‘‡é•œ',
            r'(è·Ÿæ‹|è·Ÿéš|follow)': 'è·Ÿæ‹',
            r'(ç¯ç»•|å›´ç»•|orbit)': 'ç¯ç»•æ‹æ‘„',
            r'(æ‰‹æŒ|æ™ƒåŠ¨|handheld)': 'æ‰‹æŒæ‹æ‘„'
        }
        
        self.lighting_rules = {
            r'(è‡ªç„¶å…‰|é˜³å…‰|æ—¥å…‰|daylight)': 'è‡ªç„¶å…‰',
            r'(å®¤å†…å…‰|ç¯å…‰|artificial)': 'äººå·¥å…‰æº',
            r'(æŸ”å…‰|soft.?light)': 'æŸ”å…‰',
            r'(ç¡¬å…‰|hard.?light)': 'ç¡¬å…‰',
            r'(é€†å…‰|backlight)': 'é€†å…‰',
            r'(ä¾§å…‰|side.?light)': 'ä¾§å…‰',
            r'(é¡¶å…‰|top.?light)': 'é¡¶å…‰',
            r'(æš–å…‰|warm.?light)': 'æš–è‰²è°ƒå…‰çº¿',
            r'(å†·å…‰|cool.?light)': 'å†·è‰²è°ƒå…‰çº¿'
        }
        
        self.composition_rules = {
            r'(ä¸‰åˆ†æ³•|rule.?of.?thirds)': 'ä¸‰åˆ†æ³•æ„å›¾',
            r'(å¯¹ç§°|symmetr)': 'å¯¹ç§°æ„å›¾',
            r'(å¯¹è§’çº¿|diagonal)': 'å¯¹è§’çº¿æ„å›¾',
            r'(ä¸­å¿ƒ|center)': 'ä¸­å¿ƒæ„å›¾',
            r'(æ¡†æ¶|frame)': 'æ¡†æ¶æ„å›¾',
            r'(å¼•å¯¼çº¿|leading.?line)': 'å¼•å¯¼çº¿æ„å›¾'
        }
        
        self.depth_rules = {
            r'(æµ…æ™¯æ·±|shallow.?depth)': 'æµ…æ™¯æ·±',
            r'(æ·±æ™¯æ·±|deep.?depth)': 'æ·±æ™¯æ·±',
            r'(èƒŒæ™¯è™šåŒ–|blur|bokeh)': 'èƒŒæ™¯è™šåŒ–',
            r'(å‰æ™¯|foreground)': 'å‰æ™¯çªå‡º',
            r'(èƒŒæ™¯|background)': 'èƒŒæ™¯æ¸…æ™°'
        }
        
        self.color_tone_rules = {
            r'(æš–è‰²è°ƒ|warm.?tone)': 'æš–è‰²è°ƒ',
            r'(å†·è‰²è°ƒ|cool.?tone)': 'å†·è‰²è°ƒ',
            r'(é«˜å¯¹æ¯”|high.?contrast)': 'é«˜å¯¹æ¯”åº¦',
            r'(ä½å¯¹æ¯”|low.?contrast)': 'ä½å¯¹æ¯”åº¦',
            r'(é¥±å’Œ|saturated)': 'é«˜é¥±å’Œåº¦',
            r'(æ·¡é›…|desaturated)': 'ä½é¥±å’Œåº¦',
            r'(é»‘ç™½|monochrome)': 'é»‘ç™½è‰²è°ƒ'
        }
    
    def analyze_description(self, description: str) -> TechnicalDetails:
        """åˆ†æç”»é¢æè¿°ï¼Œæ¨ç†æŠ€æœ¯ç»†èŠ‚
        
        Args:
            description: åŸå§‹ç”»é¢æè¿°
            
        Returns:
            TechnicalDetails: æ¨ç†å‡ºçš„æŠ€æœ¯ç»†èŠ‚
        """
        details = TechnicalDetails()
        
        try:
            # åˆ†æé•œå¤´ç±»å‹
            details.shot_type = self._analyze_with_rules(description, self.shot_type_rules)
            
            # åˆ†ææœºä½è§’åº¦
            details.camera_angle = self._analyze_with_rules(description, self.camera_angle_rules)
            
            # åˆ†æé•œå¤´è¿åŠ¨
            details.camera_movement = self._analyze_with_rules(description, self.camera_movement_rules)
            
            # åˆ†æå…‰çº¿
            details.lighting = self._analyze_with_rules(description, self.lighting_rules)
            
            # åˆ†ææ„å›¾
            details.composition = self._analyze_with_rules(description, self.composition_rules)
            
            # åˆ†ææ™¯æ·±
            details.depth_of_field = self._analyze_with_rules(description, self.depth_rules)
            
            # åˆ†æè‰²è°ƒ
            details.color_tone = self._analyze_with_rules(description, self.color_tone_rules)
            
            # æ™ºèƒ½æ¨ç†è¡¥å……
            self._intelligent_inference(description, details)
            
        except Exception as e:
            logger.error(f"æŠ€æœ¯ç»†èŠ‚åˆ†æå¤±è´¥: {e}")
        
        return details
    
    def _analyze_with_rules(self, text: str, rules: Dict[str, str]) -> str:
        """ä½¿ç”¨è§„åˆ™åˆ†ææ–‡æœ¬"""
        for pattern, result in rules.items():
            if re.search(pattern, text, re.IGNORECASE):
                return result
        return ""
    

    
    def _intelligent_inference(self, description: str, details: TechnicalDetails):
        """æ™ºèƒ½æ¨ç†è¡¥å……æŠ€æœ¯ç»†èŠ‚"""
        # åŸºäºå†…å®¹æ¨ç†é•œå¤´ç±»å‹
        if not details.shot_type:
            if any(word in description for word in ['è„¸éƒ¨', 'è¡¨æƒ…', 'çœ¼ç¥', 'é¢éƒ¨']):
                details.shot_type = 'ç‰¹å†™'
            elif any(word in description for word in ['å…¨èº«', 'æ•´ä¸ªäºº', 'ç«™ç«‹', 'èµ°è·¯']):
                details.shot_type = 'å…¨æ™¯'
            elif any(word in description for word in ['ä¸ŠåŠèº«', 'èƒ¸éƒ¨ä»¥ä¸Š', 'è‚©è†€']):
                details.shot_type = 'ä¸­æ™¯'
        
        # åŸºäºåœºæ™¯æ¨ç†å…‰çº¿
        if not details.lighting:
            if any(word in description for word in ['å®¤å¤–', 'é˜³å…‰', 'ç™½å¤©', 'æˆ·å¤–']):
                details.lighting = 'è‡ªç„¶å…‰'
            elif any(word in description for word in ['å®¤å†…', 'ç¯å…‰', 'å¤œæ™š']):
                details.lighting = 'äººå·¥å…‰æº'
        
        # åŸºäºåŠ¨ä½œæ¨ç†é•œå¤´è¿åŠ¨
        if not details.camera_movement:
            if any(word in description for word in ['èµ°å‘', 'é è¿‘', 'æ¥è¿‘']):
                details.camera_movement = 'æ¨é•œ'
            elif any(word in description for word in ['è¿œç¦»', 'åé€€', 'ç¦»å¼€']):
                details.camera_movement = 'æ‹‰é•œ'
            elif any(word in description for word in ['è½¬èº«', 'ç¯é¡¾', 'å››å‘¨']):
                details.camera_movement = 'æ‘‡é•œ'


class ConsistencyInjector:
    """ä¸€è‡´æ€§æè¿°æ³¨å…¥å™¨ - ä½¿ç”¨é€šç”¨NLPæŠ€æœ¯åŠ¨æ€è¯†åˆ«è§’è‰²å’Œåœºæ™¯"""

    def __init__(self, character_scene_manager: CharacterSceneManager, service_manager=None):
        self.character_scene_manager = character_scene_manager
        self.service_manager = service_manager  # æ·»åŠ service_managerå±æ€§

        # ç¼“å­˜å·²åŠ è½½çš„è§’è‰²å’Œåœºæ™¯æ•°æ®
        self._characters_cache = None
        self._scenes_cache = None
        self._last_cache_update = 0

        # é€šç”¨åœºæ™¯ç±»å‹å…³é”®è¯ï¼ˆä¸ä¾èµ–ç‰¹å®šå°è¯´ï¼‰
        self.generic_scene_patterns = {
            'å®¤å†…': ['å®¤å†…', 'æˆ¿é—´', 'å±‹å†…', 'å†…éƒ¨', 'é‡Œé¢'],
            'å®¤å¤–': ['å®¤å¤–', 'æˆ·å¤–', 'å¤–é¢', 'é‡å¤–', 'è¡—é“'],
            'åŠå…¬åœºæ‰€': ['åŠå…¬å®¤', 'ä¼šè®®å®¤', 'å·¥ä½œå®¤', 'ä¹¦æˆ¿'],
            'å±…ä½åœºæ‰€': ['å®¶', 'å®¢å…', 'å§å®¤', 'å¨æˆ¿', 'æµ´å®¤'],
            'æ•™è‚²åœºæ‰€': ['å­¦æ ¡', 'æ•™å®¤', 'å®éªŒå®¤', 'å›¾ä¹¦é¦†', 'æ ¡å›­'],
            'è‡ªç„¶ç¯å¢ƒ': ['å±±', 'æµ·', 'æ£®æ—', 'è‰åŸ', 'æ²™æ¼ ', 'æ²³æµ'],
            'åŸå¸‚ç¯å¢ƒ': ['åŸå¸‚', 'è¡—é“', 'å¹¿åœº', 'å…¬å›­', 'å•†åœº']
        }
    
    def extract_consistency_info(self, description: str, characters: Optional[List[str]] = None) -> ConsistencyInfo:
        """ä»æè¿°ä¸­æå–ä¸€è‡´æ€§ä¿¡æ¯
        
        Args:
            description: ç”»é¢æè¿°
            characters: å·²çŸ¥è§’è‰²åˆ—è¡¨
            
        Returns:
            ConsistencyInfo: ä¸€è‡´æ€§ä¿¡æ¯
        """
        consistency_info = ConsistencyInfo()
        
        try:
            # è¯†åˆ«è§’è‰²
            detected_characters = self._detect_characters(description, characters)
            consistency_info.detected_characters = detected_characters
            
            # è®°å½•è§’è‰²æ£€æµ‹è¯¦æƒ…
            logger.debug(f"è§’è‰²æ£€æµ‹ç»“æœ: {detected_characters}")
            
            # è·å–è§’è‰²ä¸€è‡´æ€§æè¿°
            for char_name in detected_characters:
                char_consistency = self._get_character_consistency(char_name)
                if char_consistency:
                    consistency_info.characters.append(char_consistency)
                    logger.debug(f"è§’è‰² '{char_name}' ä¸€è‡´æ€§æè¿°: {char_consistency[:50]}...")
                else:
                    logger.debug(f"è§’è‰² '{char_name}' æœªæ‰¾åˆ°ä¸€è‡´æ€§æè¿°")
            
            # è¯†åˆ«åœºæ™¯
            detected_scenes = self._detect_scenes(description)
            consistency_info.detected_scenes = detected_scenes
            
            # è®°å½•åœºæ™¯æ£€æµ‹è¯¦æƒ…
            logger.debug(f"åœºæ™¯æ£€æµ‹ç»“æœ: {detected_scenes}")
            
            # è·å–åœºæ™¯ä¸€è‡´æ€§æè¿°
            for scene_name in detected_scenes:
                scene_consistency = self._get_scene_consistency(scene_name)
                if scene_consistency:
                    consistency_info.scenes.append(scene_consistency)
                    logger.debug(f"åœºæ™¯ '{scene_name}' ä¸€è‡´æ€§æè¿°: {scene_consistency[:50]}...")
                else:
                    logger.debug(f"åœºæ™¯ '{scene_name}' æœªæ‰¾åˆ°ä¸€è‡´æ€§æè¿°")
                    
        except Exception as e:
            logger.error(f"ä¸€è‡´æ€§ä¿¡æ¯æå–å¤±è´¥: {e}")
        
        return consistency_info
    
    def _detect_characters(self, description: str, known_characters: Optional[List[str]] = None) -> List[str]:
        """åŠ¨æ€æ£€æµ‹æè¿°ä¸­çš„è§’è‰² - æ”¹è¿›ç‰ˆ"""
        detected = []
        
        # è·å–é¡¹ç›®ä¸­çš„æ‰€æœ‰è§’è‰²æ•°æ®ï¼ˆåŒ…å«åˆ«åå’Œå…³é”®è¯ï¼‰
        project_characters_data = self._get_all_project_characters_with_data()
        
        # ä¼˜å…ˆæ£€æµ‹å·²çŸ¥è§’è‰²ï¼ˆä»å‚æ•°ä¼ å…¥ï¼‰
        if known_characters:
            for char in known_characters:
                if self._is_character_mentioned(char, description, project_characters_data):
                    if char not in detected:
                        detected.append(char)
        
        # æ£€æµ‹é¡¹ç›®ä¸­çš„æ‰€æœ‰è§’è‰²
        for char_name, char_data in project_characters_data.items():
            if self._is_character_mentioned(char_name, description, {char_name: char_data}):
                if char_name not in detected:
                    detected.append(char_name)
        
        return detected
    
    def _nlp_character_matching(self, char_name: str, description: str, char_data: dict) -> bool:
        """NLPè§’è‰²åŒ¹é…ï¼šä½¿ç”¨è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯å¤„ç†å„ç§å¤æ‚çš„è§’è‰²ç§°è°“ï¼ˆä¸åŒ…å«LLMï¼‰"""
        try:
            # 1. åŸºç¡€åŒä¹‰è¯åŒ¹é…ï¼ˆå¯æ‰©å±•çš„æ˜ å°„è¡¨ï¼‰
            if self._check_character_synonyms(char_name, description):
                return True
            
            # 2. è§’è‰²ç±»å‹å’Œç‰¹å¾åŒ¹é…
            if self._check_character_type_matching(char_name, description, char_data):
                return True
            
            return False
            
        except Exception as e:
            logger.debug(f"NLPè§’è‰²åŒ¹é…å¤±è´¥: {e}")
            return False
    
    def _intelligent_character_matching(self, char_name: str, description: str, char_data: dict) -> bool:
        """æ™ºèƒ½è§’è‰²åŒ¹é…ï¼šä¼˜å…ˆä½¿ç”¨LLMï¼Œç„¶åä½¿ç”¨NLPæŠ€æœ¯"""
        try:
            # 1. ä¼˜å…ˆä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½åŒ¹é…
            if self._use_llm_for_character_matching(char_name, description, char_data):
                return True
            
            # 2. å¦‚æœLLMåŒ¹é…å¤±è´¥ï¼Œåˆ™ä½¿ç”¨NLPæŠ€æœ¯è¿›è¡ŒåŒ¹é…
            if self._nlp_character_matching(char_name, description, char_data):
                return True
            
            return False
            
        except Exception as e:
            logger.debug(f"æ™ºèƒ½è§’è‰²åŒ¹é…å¤±è´¥: {e}")
            return False
    
    def _check_character_synonyms(self, char_name: str, description: str) -> bool:
        """æ£€æŸ¥è§’è‰²åŒä¹‰è¯åŒ¹é…"""
        from src.utils.character_detection_config import CharacterDetectionConfig
        
        # è·å–æ‰€æœ‰åŒä¹‰è¯æ˜ å°„
        all_synonyms = CharacterDetectionConfig.get_all_synonyms()
        
        # æ£€æŸ¥åŒä¹‰è¯åŒ¹é…
        synonyms = all_synonyms.get(char_name, [])
        for synonym in synonyms:
            if synonym in description:
                return True
        
        # åå‘æ£€æŸ¥ï¼šå¦‚æœæè¿°ä¸­çš„è¯æ˜¯è§’è‰²åçš„åŒä¹‰è¯
        for base_name, synonym_list in all_synonyms.items():
            if char_name in synonym_list:
                if base_name in description:
                    return True
        
        return False
    
    def _check_character_type_matching(self, char_name: str, description: str, char_data: dict) -> bool:
        """æ£€æŸ¥è§’è‰²ç±»å‹å’Œç‰¹å¾åŒ¹é…"""
        # è·å–è§’è‰²ç±»å‹
        char_type = char_data.get('type', '').lower()
        
        # åŠ¨ç‰©è§’è‰²ç‰¹æ®Šå¤„ç†
        if char_type == 'animal' or self._is_animal_character(char_name):
            return self._match_animal_character(char_name, description, char_data)
        
        # äººç±»è§’è‰²å¤„ç†
        if char_type == 'human' or char_type == '':
            return self._match_human_character(char_name, description, char_data)
        
        # å…¶ä»–ç±»å‹è§’è‰²ï¼ˆæœºå™¨äººã€ç¥è¯ç”Ÿç‰©ç­‰ï¼‰
        return self._match_other_character(char_name, description, char_data)
    
    def _is_animal_character(self, char_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºåŠ¨ç‰©è§’è‰²"""
        from src.utils.character_detection_config import CharacterDetectionConfig
        
        animal_info = CharacterDetectionConfig.get_animal_info()
        animal_keywords = animal_info['keywords']
        return any(animal in char_name for animal in animal_keywords)
    
    def _match_animal_character(self, char_name: str, description: str, char_data: dict) -> bool:  # noqa: ARG002
        """åŒ¹é…åŠ¨ç‰©è§’è‰²"""
        from src.utils.character_detection_config import CharacterDetectionConfig
        
        # æå–åŠ¨ç‰©ç±»å‹
        animal_type = self._extract_animal_type(char_name)
        if animal_type and animal_type in description:
            return True
        
        # æ£€æŸ¥åŠ¨ç‰©ç›¸å…³çš„æè¿°è¯
        animal_info = CharacterDetectionConfig.get_animal_info()
        animal_descriptors = animal_info['descriptors']
        
        for animal, descriptors in animal_descriptors.items():
            if animal in char_name:
                if any(desc in description for desc in descriptors):
                    return True
        
        return False
    
    def _extract_animal_type(self, char_name: str) -> str:
        """ä»è§’è‰²åä¸­æå–åŠ¨ç‰©ç±»å‹"""
        from src.utils.character_detection_config import CharacterDetectionConfig
        
        animal_info = CharacterDetectionConfig.get_animal_info()
        animal_map = animal_info['type_map']
        
        for key, value in animal_map.items():
            if key in char_name:
                return value
        return ''
    
    def _match_human_character(self, char_name: str, description: str, char_data: dict) -> bool:  # noqa: ARG002
        """åŒ¹é…äººç±»è§’è‰²"""
        from src.utils.character_detection_config import CharacterDetectionConfig
        
        # æ£€æŸ¥å¹´é¾„ç›¸å…³æè¿°
        age_keywords = CharacterDetectionConfig.AGE_KEYWORDS
        
        for age_indicator, keywords in age_keywords.items():
            if age_indicator in char_name:
                if any(keyword in description for keyword in keywords):
                    return True
        
        return False
    
    def _match_other_character(self, char_name: str, description: str, char_data: dict) -> bool:  # noqa: ARG002
        """åŒ¹é…å…¶ä»–ç±»å‹è§’è‰²"""
        from src.utils.character_detection_config import CharacterDetectionConfig
        
        # æœºå™¨äººã€å¤–æ˜Ÿäººã€ç¥è¯ç”Ÿç‰©ç­‰çš„åŒ¹é…é€»è¾‘
        special_info = CharacterDetectionConfig.get_special_type_info()
        special_descriptors = special_info['descriptors']
        
        for char_type, keywords in special_descriptors.items():
            if char_type in char_name:
                if any(keyword in description for keyword in keywords):
                    return True
        
        return False
    

    
    def _use_llm_for_character_matching(self, char_name: str, description: str, char_data: dict) -> bool:
        """ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½è§’è‰²åŒ¹é…ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        try:
            # æ„å»ºæ›´å…¨é¢çš„è§’è‰²ç‰¹å¾æè¿°
            char_features = []
            
            # åŸºæœ¬ä¿¡æ¯
            char_type = char_data.get('type', 'human')
            char_features.append(f"ç±»å‹ï¼š{char_type}")
            
            # å¤–è²Œç‰¹å¾ - å®‰å…¨å¤„ç†å¯èƒ½æ˜¯å­—ç¬¦ä¸²çš„æƒ…å†µ
            appearance = char_data.get('appearance', {})
            if isinstance(appearance, dict):
                if appearance.get('gender'):
                    char_features.append(f"æ€§åˆ«ï¼š{appearance['gender']}")
                if appearance.get('age_range'):
                    char_features.append(f"å¹´é¾„ï¼š{appearance['age_range']}")
                if appearance.get('hair'):
                    char_features.append(f"å¤´å‘ï¼š{appearance['hair']}")
                if appearance.get('build'):
                    char_features.append(f"ä½“å‹ï¼š{appearance['build']}")
                if appearance.get('species'):
                    char_features.append(f"ç§æ—/ç‰©ç§ï¼š{appearance['species']}")
            elif isinstance(appearance, str) and appearance:
                char_features.append(f"å¤–è²Œï¼š{appearance}")
            
            # ğŸ”§ ä¿®å¤ï¼šæœè£…ç‰¹å¾ - å®‰å…¨å¤„ç†å¯èƒ½æ˜¯å­—ç¬¦ä¸²çš„æƒ…å†µ
            clothing = char_data.get('clothing', {})
            if isinstance(clothing, dict):
                if clothing.get('style'):
                    char_features.append(f"æœè£…ï¼š{clothing['style']}")
            elif isinstance(clothing, str) and clothing:
                char_features.append(f"æœè£…ï¼š{clothing}")

            # ğŸ”§ ä¿®å¤ï¼šæ€§æ ¼ç‰¹å¾ - å®‰å…¨å¤„ç†å¯èƒ½æ˜¯å­—ç¬¦ä¸²çš„æƒ…å†µ
            personality = char_data.get('personality', {})
            if isinstance(personality, dict):
                if personality.get('traits'):
                    char_features.append(f"æ€§æ ¼ï¼š{personality['traits']}")
            elif isinstance(personality, str) and personality:
                char_features.append(f"æ€§æ ¼ï¼š{personality}")
            
            # åˆ«å
            aliases = char_data.get('aliases', [])
            if aliases:
                char_features.append(f"åˆ«åï¼š{', '.join(aliases)}")
            
            # å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„ç‰¹å¾ä¿¡æ¯ï¼Œä¸ä½¿ç”¨LLM
            if len(char_features) < 2:
                return False
            
            # æ„å»ºå¢å¼ºçš„LLMæç¤º
            prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬æè¿°ä¸­æ˜¯å¦æåˆ°äº†æŒ‡å®šè§’è‰²ã€‚

è§’è‰²ä¿¡æ¯ï¼š
- åç§°ï¼š{char_name}
- ç‰¹å¾ï¼š{'; '.join(char_features)}

æ–‡æœ¬æè¿°ï¼š
{description}

åˆ†æè¦æ±‚ï¼š
1. å³ä½¿åç§°ä¸å®Œå…¨åŒ¹é…ï¼Œä½†å¦‚æœç‰¹å¾é«˜åº¦å»åˆï¼Œä¹Ÿåº”è®¤ä¸ºæ˜¯åŒä¸€è§’è‰²
2. å¯¹äºåŠ¨ç‰©è§’è‰²ï¼Œé‡ç‚¹å…³æ³¨ç‰©ç§ã€è¡Œä¸ºç‰¹å¾
3. å¯¹äºäººç±»è§’è‰²ï¼Œé‡ç‚¹å…³æ³¨å¤–è²Œã€å¹´é¾„ã€æ€§åˆ«ç‰¹å¾
4. è€ƒè™‘åŒä¹‰è¯ã€æ˜µç§°ã€ç§°è°“å˜åŒ–

è¯·ä»…å›ç­”"æ˜¯"æˆ–"å¦"ã€‚"""
            
            # è°ƒç”¨LLMæœåŠ¡
            if hasattr(self, 'service_manager') and self.service_manager:
                from src.core.service_manager import ServiceType
                llm_service = self.service_manager.get_service(ServiceType.LLM)
                if llm_service:
                    try:
                        # ä½¿ç”¨å¼‚æ­¥è°ƒç”¨å¹¶æ­£ç¡®å¤„ç†è¿”å›å€¼
                        import asyncio
                        import concurrent.futures

                        def run_llm_call():
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                            try:
                                result = loop.run_until_complete(
                                    llm_service.execute(prompt=prompt, max_tokens=20, temperature=0.3)
                                )
                                return result
                            finally:
                                loop.close()

                        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡
                        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                            future = executor.submit(run_llm_call)
                            try:
                                result = future.result(timeout=30)  # 30ç§’è¶…æ—¶
                                if result and result.success and result.data:
                                    response_text = result.data.get('content', '')
                                    if isinstance(response_text, str):
                                        return 'æ˜¯' in response_text or 'yes' in response_text.lower()
                            except concurrent.futures.TimeoutError:
                                logger.debug("LLMè§’è‰²åŒ¹é…è°ƒç”¨è¶…æ—¶")
                            except Exception as e:
                                logger.debug(f"LLMè§’è‰²åŒ¹é…è°ƒç”¨å¤±è´¥: {e}")
                    except Exception as e:
                        logger.debug(f"LLMè§’è‰²åŒ¹é…æœåŠ¡è°ƒç”¨å¼‚å¸¸: {e}")

            return False
            
        except Exception as e:
            logger.debug(f"LLMè§’è‰²åŒ¹é…å¤±è´¥: {e}")
            return False
    
    def _is_character_mentioned(self, char_name: str, description: str, characters_data: dict) -> bool:
        """æ£€æŸ¥è§’è‰²æ˜¯å¦åœ¨æè¿°ä¸­è¢«æåŠ - æ”¹è¿›ç‰ˆï¼Œä¼˜å…ˆä½¿ç”¨LLMæ™ºèƒ½åŒ¹é…"""
        # ç›´æ¥åç§°åŒ¹é…
        if char_name in description:
            return True

        # æ£€æŸ¥è§’è‰²æ•°æ®ä¸­çš„åˆ«åå’Œå…³é”®è¯
        char_data = characters_data.get(char_name, {})

        # æ£€æŸ¥åˆ«åï¼ˆä½¿ç”¨æ™ºèƒ½åŒ¹é…é¿å…è¯¯åŒ¹é…ï¼‰
        aliases = char_data.get('aliases', [])
        if isinstance(aliases, list):
            for alias in aliases:
                if alias and self._smart_alias_matching(alias, description):
                    return True

        # æ™ºèƒ½åç§°åŒ¹é…ï¼šæ£€æŸ¥æ˜¯å¦æ˜¯è§’è‰²åçš„ä¸€éƒ¨åˆ†ï¼ˆå¦‚"æé’å±±"å’Œ"é’å±±"ï¼‰
        if self._smart_name_matching(char_name, description):
            return True

        # 1. ä¼˜å…ˆä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½åŒ¹é…
        if self._use_llm_for_character_matching(char_name, description, char_data):
            return True

        # 2. å¦‚æœLLMåŒ¹é…å¤±è´¥ï¼Œåˆ™ä½¿ç”¨NLPæŠ€æœ¯è¿›è¡ŒåŒ¹é…
        # æ™ºèƒ½åŒ¹é…ï¼šä½¿ç”¨æ›´çµæ´»çš„è§’è‰²æ£€æµ‹ç­–ç•¥ï¼ˆä¸åŒ…å«LLMï¼‰
        if self._nlp_character_matching(char_name, description, char_data):
            return True
        
        # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥å¤–è²Œç‰¹å¾å…³é”®è¯ - å®‰å…¨å¤„ç†å¯èƒ½æ˜¯å­—ç¬¦ä¸²çš„æƒ…å†µ
        appearance = char_data.get('appearance', {})
        if appearance:
            if isinstance(appearance, dict):
                # æ£€æŸ¥å¤´å‘ç‰¹å¾
                hair = appearance.get('hair', '')
                if isinstance(hair, str) and hair:
                    if any(keyword in description for keyword in hair.split() if len(keyword) > 1):
                        return True

                # æ£€æŸ¥æ€§åˆ«å’Œå¹´é¾„
                gender = appearance.get('gender', '')
                age_range = appearance.get('age_range', '')
                if gender and gender in description:
                    return True
                if 'å¤§å”' in description and '40-50å²' in age_range:
                    return True
                if 'å…‰å¤´' in description and 'å…‰å¤´' in hair:
                    return True
            elif isinstance(appearance, str):
                # å¦‚æœappearanceæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥åœ¨æè¿°ä¸­æŸ¥æ‰¾å…³é”®è¯
                if any(keyword in description for keyword in appearance.split() if len(keyword) > 1):
                    return True

        # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥æœè£…ç‰¹å¾ - å®‰å…¨å¤„ç†å¯èƒ½æ˜¯å­—ç¬¦ä¸²çš„æƒ…å†µ
        clothing = char_data.get('clothing', {})
        if clothing:
            if isinstance(clothing, dict):
                style = clothing.get('style', '')
                if isinstance(style, str) and style:
                    if any(keyword in description for keyword in style.split() if len(keyword) > 1):
                        return True
            elif isinstance(clothing, str):
                # å¦‚æœclothingæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥åœ¨æè¿°ä¸­æŸ¥æ‰¾å…³é”®è¯
                if any(keyword in description for keyword in clothing.split() if len(keyword) > 1):
                    return True
        
        return False

    def _smart_name_matching(self, char_name: str, description: str) -> bool:
        """æ™ºèƒ½åç§°åŒ¹é…ï¼šæ£€æŸ¥æè¿°ä¸­æ˜¯å¦åŒ…å«è§’è‰²åçš„ä¸€éƒ¨åˆ†æˆ–å˜ä½“

        Args:
            char_name: å®Œæ•´è§’è‰²åï¼ˆå¦‚"æé’å±±"ï¼‰
            description: æè¿°æ–‡æœ¬ï¼ˆå¯èƒ½åŒ…å«"é’å±±"ï¼‰

        Returns:
            bool: æ˜¯å¦åŒ¹é…
        """
        if not char_name or not description:
            return False

        # 1. æ£€æŸ¥æ˜¯å¦æ˜¯è§’è‰²åçš„åç¼€ï¼ˆå¦‚"æé’å±±" -> "é’å±±"ï¼‰
        if len(char_name) >= 3:  # è‡³å°‘3ä¸ªå­—ç¬¦æ‰è€ƒè™‘åç¼€åŒ¹é…
            # å–åä¸¤ä¸ªå­—ç¬¦ä½œä¸ºå¯èƒ½çš„æ˜µç§°
            suffix_2 = char_name[-2:]
            if suffix_2 in description and len(suffix_2) >= 2:
                # ç¡®ä¿ä¸æ˜¯å…¶ä»–è¯çš„ä¸€éƒ¨åˆ†ï¼Œæ£€æŸ¥å‰åå­—ç¬¦
                pattern = rf'(?<![a-zA-Z\u4e00-\u9fa5]){re.escape(suffix_2)}(?![a-zA-Z\u4e00-\u9fa5])'
                if re.search(pattern, description):
                    logger.debug(f"æ™ºèƒ½åŒ¹é…æˆåŠŸ: {char_name} -> {suffix_2}")
                    return True

            # å–åä¸‰ä¸ªå­—ç¬¦ä½œä¸ºå¯èƒ½çš„æ˜µç§°ï¼ˆå¦‚æœè§’è‰²åå¤Ÿé•¿ï¼‰
            if len(char_name) >= 4:
                suffix_3 = char_name[-3:]
                if suffix_3 in description and len(suffix_3) >= 3:
                    pattern = rf'(?<![a-zA-Z\u4e00-\u9fa5]){re.escape(suffix_3)}(?![a-zA-Z\u4e00-\u9fa5])'
                    if re.search(pattern, description):
                        logger.debug(f"æ™ºèƒ½åŒ¹é…æˆåŠŸ: {char_name} -> {suffix_3}")
                        return True

        # 2. æ£€æŸ¥æ˜¯å¦æ˜¯è§’è‰²åçš„å‰ç¼€ï¼ˆå¦‚"æé’å±±" -> "æé’"ï¼‰
        if len(char_name) >= 3:
            prefix_2 = char_name[:2]
            if prefix_2 in description and len(prefix_2) >= 2:
                pattern = rf'(?<![a-zA-Z\u4e00-\u9fa5]){re.escape(prefix_2)}(?![a-zA-Z\u4e00-\u9fa5])'
                if re.search(pattern, description):
                    logger.debug(f"æ™ºèƒ½åŒ¹é…æˆåŠŸ: {char_name} -> {prefix_2}")
                    return True

        # 3. æ£€æŸ¥æ˜¯å¦æ˜¯è§’è‰²åçš„ä¸­é—´éƒ¨åˆ†ï¼ˆå¦‚"æé’å±±" -> "é’"ï¼Œä½†è¿™ç§æƒ…å†µè¦æ›´è°¨æ…ï¼‰
        if len(char_name) >= 4:
            for i in range(1, len(char_name) - 1):
                for j in range(i + 2, len(char_name) + 1):  # è‡³å°‘2ä¸ªå­—ç¬¦
                    middle_part = char_name[i:j]
                    if len(middle_part) >= 2 and middle_part in description:
                        pattern = rf'(?<![a-zA-Z\u4e00-\u9fa5]){re.escape(middle_part)}(?![a-zA-Z\u4e00-\u9fa5])'
                        if re.search(pattern, description):
                            logger.debug(f"æ™ºèƒ½åŒ¹é…æˆåŠŸ: {char_name} -> {middle_part}")
                            return True

        return False

    def _smart_alias_matching(self, alias: str, description: str) -> bool:
        """æ™ºèƒ½åˆ«ååŒ¹é…ï¼šé¿å…åœ¨åœ°ç†åè¯ç­‰ä¸Šä¸‹æ–‡ä¸­è¯¯åŒ¹é…

        Args:
            alias: è§’è‰²åˆ«åï¼ˆå¦‚"é’å±±"ï¼‰
            description: æè¿°æ–‡æœ¬

        Returns:
            bool: æ˜¯å¦åŒ¹é…
        """
        if not alias or not description or alias not in description:
            return False

        # åœ°ç†åè¯é»‘åå•æ£€æŸ¥ï¼ˆæ£€æŸ¥æ•´ä¸ªæè¿°ï¼‰
        geographic_patterns = [
            'é’å±±ç»¿æ°´', 'å±±æ¸…æ°´ç§€', 'é’å±±å¦‚é»›', 'é’å±±ä¾æ—§',
            'å°å±±æ‘', 'å°å±±å¡', 'å°å±±ä¸˜', 'é’å±±ç»¿æ°´çš„ç¾æ™¯'
        ]

        # å¦‚æœåŒ¹é…åˆ°åœ°ç†åè¯æ¨¡å¼ï¼Œä¸åŒ¹é…
        for geo_pattern in geographic_patterns:
            if geo_pattern in description:
                return False

        # æ£€æŸ¥æ˜¯å¦æœ‰äººç‰©åŠ¨ä½œæˆ–å¯¹è¯çš„ä¸Šä¸‹æ–‡
        person_indicators = ['è¯´', 'é“', 'ç¬‘', 'å“­', 'èµ°', 'è·‘', 'ç«™', 'å', 'çœ‹', 'å¬', 'æƒ³', 'æ„Ÿåˆ°', 'è§‰å¾—', 'æ‹”å‡º', 'å‡†å¤‡', 'å¾®ç¬‘', 'ç‚¹å¤´', 'çœºæœ›']
        has_person_context = any(indicator in description for indicator in person_indicators)

        if has_person_context:
            return True

        # æ£€æŸ¥æ˜¯å¦åœ¨å¥å­å¼€å¤´ï¼ˆç®€åŒ–ç‰ˆï¼‰
        if description.startswith(alias):
            return True

        return False

    def _detect_scenes(self, description: str) -> List[str]:
        """åŠ¨æ€æ£€æµ‹æè¿°ä¸­çš„åœºæ™¯"""
        detected = []
        
        # åŠ¨æ€åŠ è½½é¡¹ç›®ä¸­çš„æ‰€æœ‰åœºæ™¯å¹¶è¿›è¡ŒåŒ¹é…
        project_scenes = self._get_all_project_scenes()
        for scene_name, scene_keywords in project_scenes.items():
            # æ£€æŸ¥åœºæ™¯åç§°ç›´æ¥åŒ¹é…
            if scene_name in description:
                detected.append(scene_name)
                continue
            
            # æ£€æŸ¥åœºæ™¯å…³é”®è¯åŒ¹é…
            if scene_keywords and any(keyword in description for keyword in scene_keywords):
                detected.append(scene_name)
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å…·ä½“åœºæ™¯ï¼Œå°è¯•åŒ¹é…é€šç”¨åœºæ™¯ç±»å‹
        if not detected:
            for scene_type, keywords in self.generic_scene_patterns.items():
                if any(keyword in description for keyword in keywords):
                    detected.append(f"é€šç”¨{scene_type}")
                    break
        
        return detected
    
    def _get_character_consistency(self, character_name: str) -> str:
        """è·å–è§’è‰²ä¸€è‡´æ€§æè¿°"""
        try:
            if not self.character_scene_manager:
                logger.warning("è§’è‰²åœºæ™¯ç®¡ç†å™¨æœªåˆå§‹åŒ–")
                return ""

            characters_data = self.character_scene_manager._load_json(
                self.character_scene_manager.characters_file
            )

            # æŸ¥æ‰¾è§’è‰²æ•°æ®
            for _char_id, char_data in characters_data.get('characters', {}).items():
                if char_data.get('name') == character_name or char_data.get('id') == character_name:
                    consistency_prompt = char_data.get('consistency_prompt', '')
                    if consistency_prompt:
                        logger.info(f"è·å–åˆ°è§’è‰²'{character_name}'çš„ä¸€è‡´æ€§æè¿°: {consistency_prompt}")
                        return consistency_prompt
                    else:
                        logger.warning(f"è§’è‰²'{character_name}'æ²¡æœ‰ä¸€è‡´æ€§æè¿°")
                        return ""

            logger.warning(f"æœªæ‰¾åˆ°è§’è‰²'{character_name}'çš„æ•°æ®")
            return ""

        except Exception as e:
            logger.error(f"è·å–è§’è‰²ä¸€è‡´æ€§æè¿°å¤±è´¥ {character_name}: {e}")
            return ""
    
    def _get_scene_consistency(self, scene_name: str) -> str:
        """è·å–åœºæ™¯ä¸€è‡´æ€§æè¿°"""
        try:
            scenes_data = self.character_scene_manager._load_json(
                self.character_scene_manager.scenes_file
            )
            
            # æŸ¥æ‰¾åœºæ™¯æ•°æ®
            for _scene_id, scene_data in scenes_data.get('scenes', {}).items():
                if scene_data.get('name') == scene_name or scene_data.get('id') == scene_name:
                    return scene_data.get('consistency_prompt', '')
            
        except Exception as e:
            logger.error(f"è·å–åœºæ™¯ä¸€è‡´æ€§æè¿°å¤±è´¥ {scene_name}: {e}")
        
        return ""
    
    def _get_all_project_characters(self) -> List[str]:
        """è·å–é¡¹ç›®ä¸­çš„æ‰€æœ‰è§’è‰²åç§°"""
        try:
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦éœ€è¦æ›´æ–°
            import time
            current_time = time.time()
            if (self._characters_cache is None or 
                current_time - self._last_cache_update > 60):  # ç¼“å­˜60ç§’
                
                characters_data = self.character_scene_manager._load_json(
                    self.character_scene_manager.characters_file
                )
                
                character_names = []
                for char_data in characters_data.get('characters', {}).values():
                    char_name = char_data.get('name', '')
                    if char_name:
                        character_names.append(char_name)
                        
                        # ä¹Ÿæ·»åŠ è§’è‰²çš„åˆ«åæˆ–æ˜µç§°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                        aliases = char_data.get('aliases', [])
                        if isinstance(aliases, list):
                            character_names.extend(aliases)
                
                self._characters_cache = character_names
                self._last_cache_update = current_time
            
            return self._characters_cache or []
            
        except Exception as e:
            logger.error(f"è·å–é¡¹ç›®è§’è‰²åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def _get_all_project_characters_with_data(self) -> Dict[str, dict]:
        """è·å–é¡¹ç›®ä¸­çš„æ‰€æœ‰è§’è‰²åŠå…¶å®Œæ•´æ•°æ®"""
        try:
            characters_data = self.character_scene_manager._load_json(
                self.character_scene_manager.characters_file
            )
            
            character_dict = {}
            for char_data in characters_data.get('characters', {}).values():
                char_name = char_data.get('name', '')
                if char_name:
                    character_dict[char_name] = char_data
            
            return character_dict
            
        except Exception as e:
            logger.error(f"è·å–é¡¹ç›®è§’è‰²æ•°æ®å¤±è´¥: {e}")
            return {}
    
    def _get_all_project_scenes(self) -> Dict[str, List[str]]:
        """è·å–é¡¹ç›®ä¸­çš„æ‰€æœ‰åœºæ™¯åŠå…¶å…³é”®è¯"""
        try:
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦éœ€è¦æ›´æ–°
            import time
            current_time = time.time()
            if (self._scenes_cache is None or 
                current_time - self._last_cache_update > 60):  # ç¼“å­˜60ç§’
                
                scenes_data = self.character_scene_manager._load_json(
                    self.character_scene_manager.scenes_file
                )
                
                scene_info = {}
                for scene_data in scenes_data.get('scenes', {}).values():
                    scene_name = scene_data.get('name', '')
                    if scene_name:
                        # è·å–åœºæ™¯å…³é”®è¯
                        keywords = scene_data.get('keywords', [])
                        if not isinstance(keywords, list):
                            keywords = []
                        
                        # æ·»åŠ åœºæ™¯æè¿°ä¸­çš„å…³é”®è¯ï¼ˆç®€å•æå–ï¼‰
                        description = scene_data.get('description', '')
                        if description:
                            # ç®€å•çš„å…³é”®è¯æå–ï¼šåˆ†å‰²å¹¶è¿‡æ»¤å¸¸è§è¯æ±‡
                            desc_words = [word.strip('ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š') for word in description.split() 
                                        if len(word.strip('ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š')) > 1]
                            keywords.extend(desc_words[:5])  # åªå–å‰5ä¸ªè¯é¿å…è¿‡å¤š
                        
                        scene_info[scene_name] = keywords
                
                self._scenes_cache = scene_info
                self._last_cache_update = current_time
            
            return self._scenes_cache or {}
            
        except Exception as e:
            logger.error(f"è·å–é¡¹ç›®åœºæ™¯åˆ—è¡¨å¤±è´¥: {e}")
            return {}


@dataclass
class FusionResult:
    """å†…å®¹èåˆç»“æœæ•°æ®ç»“æ„"""
    enhanced_description: str = ""
    technical_additions: List[str] = field(default_factory=list)
    consistency_additions: List[str] = field(default_factory=list)
    fusion_quality_score: float = 0.0


class ContentFuser:
    """æ™ºèƒ½å†…å®¹èåˆå™¨ - ç¬¬äºŒé˜¶æ®µæ ¸å¿ƒç»„ä»¶"""
    
    def __init__(self, project_root=None, llm_api=None, character_scene_manager=None):
        # åˆå§‹åŒ–LLM API
        self.llm_api = llm_api
        self.project_root = project_root
        self.character_scene_manager = character_scene_manager
        self.style_manager = StyleConsistencyManager(project_root) if project_root else None
        # åˆå§‹åŒ–è§’è‰²åœºæ™¯ç®¡ç†å™¨
        if character_scene_manager is None and project_root:
            from src.utils.character_scene_manager import CharacterSceneManager
            self.character_scene_manager = CharacterSceneManager(project_root)
        else:
            self.character_scene_manager = character_scene_manager
        
        # èåˆç­–ç•¥é…ç½®
        self.fusion_strategies = {
            'natural': self._natural_fusion,
            'structured': self._structured_fusion,
            'minimal': self._minimal_fusion,
            'intelligent': self._natural_fusion  # æ–°å¢æ™ºèƒ½èåˆç­–ç•¥
        }
        
        # å†…å®¹ä¼˜å…ˆçº§æƒé‡
        self.priority_weights = {
            'original_description': 1.0,
            'character_consistency': 0.8,
            'scene_consistency': 0.7,
            'technical_details': 0.6
        }

        # èåˆè´¨é‡è¯„ä¼°è§„åˆ™
        self.quality_rules = {
            'length_balance': 0.3,  # é•¿åº¦å¹³è¡¡
            'content_coherence': 0.4,  # å†…å®¹è¿è´¯æ€§
            'information_density': 0.3  # ä¿¡æ¯å¯†åº¦
        }

    def _is_already_enhanced(self, description: str) -> bool:
        """æ£€æŸ¥æè¿°æ˜¯å¦å·²ç»å¢å¼ºè¿‡"""
        try:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«è§’è‰²ä¸€è‡´æ€§æè¿°çš„ç‰¹å¾
            if "ï¼ˆä¸­å›½äººï¼Œ" in description and "å²" in description and ("æˆ˜è¢" in description or "å†›è£…" in description):
                return True

            # æ£€æŸ¥æ˜¯å¦åŒ…å«é£æ ¼æç¤ºè¯
            if "æ°´å½©ç”»é£ï¼ŒæŸ”å’Œç¬”è§¦ï¼Œç²‰å½©è‰²ï¼Œæ’ç”»ï¼Œæ¸©æŸ”" in description:
                return True

            return False

        except Exception as e:
            logger.debug(f"æ£€æŸ¥å¢å¼ºçŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def _get_character_consistency(self, character_name: str) -> str:
        """è·å–è§’è‰²ä¸€è‡´æ€§æè¿°"""
        try:
            if not self.character_scene_manager:
                logger.warning("è§’è‰²åœºæ™¯ç®¡ç†å™¨æœªåˆå§‹åŒ–")
                return ""

            characters_data = self.character_scene_manager._load_json(
                self.character_scene_manager.characters_file
            )

            # æŸ¥æ‰¾è§’è‰²æ•°æ®
            for _char_id, char_data in characters_data.get('characters', {}).items():
                if char_data.get('name') == character_name or char_data.get('id') == character_name:
                    return char_data.get('consistency_prompt', '')

        except Exception as e:
            logger.error(f"è·å–è§’è‰²ä¸€è‡´æ€§æè¿°å¤±è´¥ {character_name}: {e}")

        return ""
    
    def _embed_character_descriptions(self, original_desc: str, detected_characters: List[str]) -> str:
        """å°†è§’è‰²ä¸€è‡´æ€§æè¿°ç›´æ¥åµŒå…¥åˆ°åŸå§‹æè¿°ä¸­"""
        if not detected_characters:
            return original_desc
        
        enhanced_desc = original_desc
        
        # è·å–è§’è‰²ä¸€è‡´æ€§ä¿¡æ¯
        character_descriptions = {}
        for character_name in detected_characters:
            # ç›´æ¥ä½¿ç”¨_get_character_consistencyæ–¹æ³•è·å–è§’è‰²ä¸€è‡´æ€§æè¿°
            character_consistency = self._get_character_consistency(character_name)
            if character_consistency:
                character_descriptions[character_name] = character_consistency
        
        # æŒ‰è§’è‰²åé•¿åº¦é™åºæ’åºï¼Œä¼˜å…ˆæ›¿æ¢æ›´é•¿çš„è§’è‰²åï¼Œé¿å…"æé™å¦ˆå¦ˆ"è¢«"æé™"è¯¯åŒ¹é…
        sorted_characters = sorted(character_descriptions.items(), key=lambda x: len(x[0]), reverse=True)
        
        # åœ¨åŸå§‹æè¿°ä¸­æ›¿æ¢è§’è‰²åç§°ä¸ºè¯¦ç»†æè¿°
        for character_name, detailed_desc in sorted_characters:
            # ä½¿ç”¨ç²¾ç¡®åŒ¹é…è¿›è¡Œè§’è‰²æ›¿æ¢ï¼Œæ”¯æŒä¸­æ–‡å­—ç¬¦
            replacement = f"{character_name}ï¼ˆ{detailed_desc}ï¼‰"
            # åªæœ‰å½“è§’è‰²åè¿˜æ²¡æœ‰è¢«æ›¿æ¢è¿‡æ—¶æ‰è¿›è¡Œæ›¿æ¢ï¼ˆé¿å…é‡å¤æ›¿æ¢ï¼‰
            if character_name in enhanced_desc and f"{character_name}ï¼ˆ" not in enhanced_desc:
                # æ£€æŸ¥å½“å‰è§’è‰²åæ˜¯å¦æ˜¯å…¶ä»–æ›´é•¿è§’è‰²åçš„ä¸€éƒ¨åˆ†
                is_part_of_longer_name = False
                for other_char_name in character_descriptions.keys():
                    if other_char_name != character_name and len(other_char_name) > len(character_name):
                        if character_name in other_char_name and other_char_name in enhanced_desc:
                            is_part_of_longer_name = True
                            break
                
                # åªæœ‰å½“ä¸æ˜¯å…¶ä»–è§’è‰²åçš„ä¸€éƒ¨åˆ†æ—¶æ‰è¿›è¡Œæ›¿æ¢
                if not is_part_of_longer_name:
                    # å¯¹äºå•å­—ç¬¦è§’è‰²åï¼ˆå¦‚"æˆ‘"ï¼‰ï¼Œä½¿ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…
                     if len(character_name) == 1:
                         # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…ä½ç½®ï¼Œæ‰‹åŠ¨æ£€æŸ¥è¾¹ç•Œ
                         matches = []
                         start = 0
                         while True:
                             pos = enhanced_desc.find(character_name, start)
                             if pos == -1:
                                 break
                             # æ£€æŸ¥å‰åå­—ç¬¦ï¼Œç¡®ä¿è¿™æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„å­—ç¬¦
                             before_char = enhanced_desc[pos-1] if pos > 0 else ''
                             after_char = enhanced_desc[pos+len(character_name)] if pos+len(character_name) < len(enhanced_desc) else ''
                             
                             # å¯¹äº"æˆ‘"ï¼Œå¦‚æœåé¢æ˜¯"ä»¬"ï¼Œåˆ™è·³è¿‡
                             if character_name == 'æˆ‘' and after_char == 'ä»¬':
                                 start = pos + 1
                                 continue
                             
                             # å¦‚æœå‰åéƒ½ä¸æ˜¯å­—æ¯æ•°å­—æˆ–ä¸­æ–‡å­—ç¬¦ï¼Œåˆ™è®¤ä¸ºæ˜¯ç‹¬ç«‹çš„å­—ç¬¦
                             if (not before_char or not (before_char.isalnum() or '\u4e00' <= before_char <= '\u9fff')) and \
                                (not after_char or not (after_char.isalnum() or '\u4e00' <= after_char <= '\u9fff')):
                                 matches.append(pos)
                             start = pos + 1
                         
                         # ä»åå¾€å‰æ›¿æ¢ï¼Œé¿å…ä½ç½®åç§»
                         for pos in reversed(matches):
                             enhanced_desc = enhanced_desc[:pos] + replacement + enhanced_desc[pos+len(character_name):]
                     else:
                         enhanced_desc = enhanced_desc.replace(character_name, replacement)
                     logger.info(f"è§’è‰²æè¿°åµŒå…¥: {character_name} -> {replacement[:50]}...")
        
        return enhanced_desc
    
    def fuse_content(self, original: str, technical: Optional[TechnicalDetails],
                    consistency: Optional[ConsistencyInfo], strategy: str = 'intelligent', style: Optional[str] = None) -> FusionResult:
        """æ™ºèƒ½èåˆå†…å®¹
        
        Args:
            original: åŸå§‹æè¿°
            technical: æŠ€æœ¯ç»†èŠ‚
            consistency: ä¸€è‡´æ€§ä¿¡æ¯
            strategy: èåˆç­–ç•¥
            
        Returns:
            FusionResult: èåˆç»“æœ
        """
        try:
            logger.info(f"å¼€å§‹å†…å®¹èåˆï¼Œç­–ç•¥: {strategy}")
            
            # é¢„å¤„ç†å†…å®¹
            processed_content = self._preprocess_content(original, technical, consistency, style)
            
            # æ‰§è¡Œèåˆç­–ç•¥
            fusion_func = self.fusion_strategies.get(strategy, self._natural_fusion)
            result = fusion_func(processed_content)
            
            # åå¤„ç†å’Œè´¨é‡è¯„ä¼°
            result = self._postprocess_result(result)
            
            logger.info(f"å†…å®¹èåˆå®Œæˆï¼Œè´¨é‡è¯„åˆ†: {result.fusion_quality_score:.2f}")
            return result
            
        except Exception as e:
            logger.error(f"å†…å®¹èåˆå¤±è´¥: {e}")
            return FusionResult(enhanced_description=original)
    
    def _preprocess_content(self, original: str, technical: Optional[TechnicalDetails],
                          consistency: Optional[ConsistencyInfo], style: Optional[str] = None) -> Dict[str, Any]:
        """é¢„å¤„ç†å†…å®¹"""
        return {
            'original': original.strip(),
            'technical_parts': self._extract_technical_parts(technical),
            'consistency_parts': self._extract_consistency_parts(consistency),
            'detected_characters': getattr(consistency, 'detected_characters', []) if consistency else [],
            'detected_scenes': getattr(consistency, 'detected_scenes', []) if consistency else [],
            'original_length': len(original),
            'has_punctuation': original.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')),
            'style': style  # ğŸ”§ æ–°å¢ï¼šä¼ é€’é£æ ¼å‚æ•°
        }
    
    def _extract_technical_parts(self, technical: Optional[TechnicalDetails]) -> List[str]:
        """æå–æŠ€æœ¯ç»†èŠ‚éƒ¨åˆ†"""
        parts = []
        if technical:
            if technical.shot_type:
                parts.append(f"{technical.shot_type}é•œå¤´")
            if technical.camera_angle:
                parts.append(technical.camera_angle)
            if technical.lighting:
                parts.append(technical.lighting)
            if technical.camera_movement:
                parts.append(technical.camera_movement)
            if technical.composition:
                parts.append(technical.composition)
        return parts

    def _extract_consistency_parts(self, consistency: Optional[ConsistencyInfo]) -> List[str]:
        """æå–ä¸€è‡´æ€§ä¿¡æ¯éƒ¨åˆ†"""
        parts = []
        if consistency:
            # å¤„ç†è§’è‰²ä¸€è‡´æ€§
            for char_desc in consistency.characters:
                if char_desc and len(char_desc.strip()) > 0:
                    # æå–å…³é”®ç‰¹å¾æè¿°
                    key_features = self._extract_key_features(char_desc)
                    parts.extend(key_features)

            # å¤„ç†åœºæ™¯ä¸€è‡´æ€§
            for scene_desc in consistency.scenes:
                if scene_desc and len(scene_desc.strip()) > 0:
                    # æå–å…³é”®ç¯å¢ƒæè¿°
                    key_env = self._extract_key_environment(scene_desc)
                    parts.extend(key_env)
        return parts
    
    def _extract_key_features(self, description: str) -> List[str]:
        """ä»è§’è‰²æè¿°ä¸­æå–å…³é”®ç‰¹å¾"""
        # ç®€å•çš„å…³é”®ç‰¹å¾æå–é€»è¾‘
        features = []
        
        # å¤–è²Œç‰¹å¾å…³é”®è¯
        appearance_keywords = ['å¤´å‘', 'çœ¼ç›', 'èº«é«˜', 'ä½“å‹', 'æœè£…', 'ç©¿ç€', 'æˆ´ç€']
        for keyword in appearance_keywords:
            if keyword in description:
                # æå–åŒ…å«å…³é”®è¯çš„çŸ­è¯­
                sentences = description.split('ï¼Œ')
                for sentence in sentences:
                    if keyword in sentence and len(sentence.strip()) < 20:
                        features.append(sentence.strip())
                        break
        
        return features[:2]  # æœ€å¤šè¿”å›2ä¸ªå…³é”®ç‰¹å¾
    
    def _extract_key_environment(self, description: str) -> List[str]:
        """ä»åœºæ™¯æè¿°ä¸­æå–å…³é”®ç¯å¢ƒä¿¡æ¯"""
        env_info = []
        
        # ç¯å¢ƒç‰¹å¾å…³é”®è¯
        env_keywords = ['å…‰çº¿', 'æ°›å›´', 'èƒŒæ™¯', 'ç¯å¢ƒ', 'è®¾å¤‡', 'è£…é¥°']
        for keyword in env_keywords:
            if keyword in description:
                sentences = description.split('ï¼Œ')
                for sentence in sentences:
                    if keyword in sentence and len(sentence.strip()) < 25:
                        env_info.append(sentence.strip())
                        break
        
        return env_info[:1]  # æœ€å¤šè¿”å›1ä¸ªç¯å¢ƒä¿¡æ¯
    
    def _natural_fusion_impl(self, content: Dict[str, Any]) -> FusionResult:
        """è‡ªç„¶èåˆç­–ç•¥"""
        result = FusionResult()
        parts = [content['original']]
        
        # è‡ªç„¶åœ°æ·»åŠ æŠ€æœ¯ç»†èŠ‚
        if content['technical_parts']:
            tech_text = "ï¼Œ".join(content['technical_parts'][:2])  # é™åˆ¶æŠ€æœ¯ç»†èŠ‚æ•°é‡
            if content['has_punctuation']:
                parts[0] = parts[0].rstrip('ã€‚ï¼ï¼Ÿ.!?') + f"ï¼Œ{tech_text}ã€‚"
            else:
                parts[0] += f"ï¼Œ{tech_text}"
            result.technical_additions = content['technical_parts'][:2]
        
        # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥åŸå§‹æè¿°ä¸­æ˜¯å¦å·²ç»åŒ…å«è§’è‰²ä¸€è‡´æ€§æè¿°ï¼Œé¿å…é‡å¤æ·»åŠ 
        if content['consistency_parts']:
            # æ£€æŸ¥åŸå§‹æè¿°ä¸­æ˜¯å¦å·²ç»åŒ…å«è§’è‰²æè¿°ï¼ˆé€šè¿‡æ£€æŸ¥æ˜¯å¦æœ‰"ï¼ˆ"å’Œ"ï¼‰"åŒ…å›´çš„æè¿°ï¼‰
            has_embedded_character_desc = "ï¼ˆ" in content['original'] and "ï¼‰" in content['original']

            if not has_embedded_character_desc:
                # åªæœ‰åœ¨æ²¡æœ‰åµŒå…¥è§’è‰²æè¿°æ—¶æ‰æ·»åŠ ä¸€è‡´æ€§ä¿¡æ¯
                consistency_text = content['consistency_parts'][0] if content['consistency_parts'] else ""
                if consistency_text:
                    parts.append(f"ï¼ˆ{consistency_text}ï¼‰")
                    result.consistency_additions = content['consistency_parts'][:1]
            else:
                logger.debug("åŸå§‹æè¿°ä¸­å·²åŒ…å«è§’è‰²ä¸€è‡´æ€§æè¿°ï¼Œè·³è¿‡é‡å¤æ·»åŠ ")
        
        result.enhanced_description = "".join(parts)
        return result

    # _embed_character_descriptionsæ–¹æ³•å·²ç§»åŠ¨åˆ°SceneDescriptionEnhancerç±»ä¸­

    def _structured_fusion(self, content: Dict[str, Any]) -> FusionResult:
        """ç»“æ„åŒ–èåˆç­–ç•¥"""
        result = FusionResult()
        parts = [content['original']]
        
        # ç»“æ„åŒ–æ·»åŠ æŠ€æœ¯è§„æ ¼
        if content['technical_parts']:
            tech_section = "\næŠ€æœ¯è§„æ ¼ï¼š" + "ï¼Œ".join(content['technical_parts'])
            parts.append(tech_section)
            result.technical_additions = content['technical_parts']
        
        # ğŸ”§ ä¿®å¤ï¼šç»“æ„åŒ–æ·»åŠ ä¸€è‡´æ€§è¦æ±‚ï¼Œé¿å…é‡å¤
        if content['consistency_parts']:
            has_embedded_character_desc = "ï¼ˆ" in content['original'] and "ï¼‰" in content['original']
            if not has_embedded_character_desc:
                consistency_section = "\nä¸€è‡´æ€§è¦æ±‚ï¼š" + "ï¼Œ".join(content['consistency_parts'])
                parts.append(consistency_section)
                result.consistency_additions = content['consistency_parts']
            else:
                logger.debug("åŸå§‹æè¿°ä¸­å·²åŒ…å«è§’è‰²ä¸€è‡´æ€§æè¿°ï¼Œè·³è¿‡ç»“æ„åŒ–æ·»åŠ ")
        
        result.enhanced_description = "".join(parts)
        return result
    
    def _minimal_fusion(self, content: Dict[str, Any]) -> FusionResult:
        """æœ€å°åŒ–èåˆç­–ç•¥"""
        result = FusionResult()
        parts = [content['original']]
        
        # æœ€å°åŒ–æ·»åŠ å…³é”®ä¿¡æ¯
        additions = []
        if content['technical_parts']:
            additions.extend(content['technical_parts'][:1])  # åªå–æœ€é‡è¦çš„æŠ€æœ¯ç»†èŠ‚
            result.technical_additions = content['technical_parts'][:1]
        
        # ğŸ”§ ä¿®å¤ï¼šæœ€å°åŒ–æ·»åŠ ä¸€è‡´æ€§ä¿¡æ¯ï¼Œé¿å…é‡å¤
        if content['consistency_parts']:
            has_embedded_character_desc = "ï¼ˆ" in content['original'] and "ï¼‰" in content['original']
            if not has_embedded_character_desc:
                additions.extend(content['consistency_parts'][:1])  # åªå–æœ€é‡è¦çš„ä¸€è‡´æ€§ä¿¡æ¯
                result.consistency_additions = content['consistency_parts'][:1]
            else:
                logger.debug("åŸå§‹æè¿°ä¸­å·²åŒ…å«è§’è‰²ä¸€è‡´æ€§æè¿°ï¼Œè·³è¿‡æœ€å°åŒ–æ·»åŠ ")
        
        if additions:
            parts.append(f" [{','.join(additions)}]")
        
        result.enhanced_description = "".join(parts)
        return result
    
    def _natural_fusion(self, content: Dict[str, Any]) -> FusionResult:
        """æ™ºèƒ½èåˆç­–ç•¥ - æ ¹æ®å†…å®¹ç‰¹ç‚¹è‡ªé€‚åº”é€‰æ‹©æœ€ä½³èåˆæ–¹å¼"""
        result = FusionResult()
        
        # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦å·²ç»å¢å¼ºè¿‡ï¼Œé¿å…é‡å¤LLMè°ƒç”¨
        original_desc = content.get('original_description', '')
        if self._is_already_enhanced(original_desc):
            logger.info("å†…å®¹å·²ç»å¢å¼ºè¿‡ï¼Œè·³è¿‡LLMå¤„ç†")
            # ç›´æ¥è¿”å›åŸå§‹æè¿°
            result.enhanced_description = original_desc
            result.fusion_quality_score = 0.8  # ç»™å·²å¢å¼ºå†…å®¹ä¸€ä¸ªè¾ƒé«˜åˆ†æ•°
            return result

        # å¦‚æœæœ‰LLM APIå¯ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½èåˆ
        if self.llm_api and self.llm_api.is_configured():
            try:
                return self._llm_enhanced_fusion(content)
            except Exception as e:
                logger.warning(f"LLMå¢å¼ºèåˆå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•: {e}")
        
        # åˆ†æåŸå§‹æè¿°ç‰¹ç‚¹
        original_length = content['original_length']
        tech_count = len(content['technical_parts'])
        consistency_count = len(content['consistency_parts'])
        
        # æ ¹æ®å†…å®¹é•¿åº¦å’Œä¿¡æ¯é‡é€‰æ‹©ç­–ç•¥
        if original_length < 20 and (tech_count + consistency_count) > 3:
            # çŸ­æè¿° + å¤§é‡è¡¥å……ä¿¡æ¯ -> ä½¿ç”¨ç»“æ„åŒ–
            return self._structured_fusion(content)
        elif original_length > 100:
            # é•¿æè¿° -> ä½¿ç”¨æœ€å°åŒ–
            return self._minimal_fusion(content)
        else:
            # ä¸­ç­‰é•¿åº¦ -> ä½¿ç”¨è‡ªç„¶èåˆ
            return self._natural_fusion_impl(content)
    
    def _llm_enhanced_fusion(self, content: Dict[str, Any]) -> FusionResult:
        """ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å†…å®¹èåˆ"""
        result = FusionResult()
        
        # æ„å»ºLLMæç¤ºè¯
        original_desc = content['original']
        technical_parts = content['technical_parts']
        consistency_parts = content['consistency_parts']
        detected_characters = content.get('detected_characters', [])
        detected_scenes = content.get('detected_scenes', [])
        
        logger.info("=== åœºæ™¯å¢å¼ºå™¨LLMè¾…åŠ©ç”Ÿæˆå¼€å§‹ ===")
        logger.info(f"åŸå§‹åœºæ™¯æè¿°: {original_desc[:100]}..." if len(original_desc) > 100 else f"åŸå§‹åœºæ™¯æè¿°: {original_desc}")
        logger.info(f"æ£€æµ‹åˆ°çš„è§’è‰²: {detected_characters if detected_characters else 'æ— '}")
        logger.info(f"æ£€æµ‹åˆ°çš„åœºæ™¯: {detected_scenes if detected_scenes else 'æ— '}")
        
        # ğŸ”§ ä¿®å¤ï¼šé¢„å¤„ç†åŸå§‹æè¿°ï¼Œå°†è§’è‰²ä¸€è‡´æ€§æè¿°ç›´æ¥åµŒå…¥
        enhanced_original_desc = original_desc
        if self.character_scene_manager and detected_characters:
            # ç®€åŒ–çš„è§’è‰²æè¿°åµŒå…¥é€»è¾‘
            for character in detected_characters:
                character_desc = self._get_character_consistency_description(character)
                if character_desc and character in enhanced_original_desc:
                    # åœ¨è§’è‰²åç§°åæ·»åŠ ä¸€è‡´æ€§æè¿°
                    enhanced_original_desc = enhanced_original_desc.replace(
                        character, f"{character}ï¼ˆ{character_desc}ï¼‰", 1
                    )
        logger.info(f"è§’è‰²æè¿°åµŒå…¥å: {enhanced_original_desc[:150]}..." if len(enhanced_original_desc) > 150 else f"è§’è‰²æè¿°åµŒå…¥å: {enhanced_original_desc}")
        
        # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„é£æ ¼å‚æ•°ï¼Œè€Œä¸æ˜¯ä»æè¿°ä¸­æ£€æµ‹
        detected_style = None
        original_style_prompt = ""

        # 1. é¦–å…ˆå°è¯•ä»contentä¸­è·å–é£æ ¼å‚æ•°
        style = content.get('style', None)
        if style and self.style_manager:
            original_style_prompt = self.style_manager.style_prompts.get(style, "")
            if original_style_prompt:
                detected_style = style
                logger.info(f"ä½¿ç”¨ä¼ å…¥çš„é£æ ¼: {style}, æç¤ºè¯: {original_style_prompt}")
            else:
                logger.warning(f"ä¼ å…¥çš„é£æ ¼ {style} æ²¡æœ‰å¯¹åº”çš„æç¤ºè¯")

        # 2. å¦‚æœæ²¡æœ‰ä¼ å…¥é£æ ¼æˆ–é£æ ¼æ— æ•ˆï¼Œå°è¯•ä»é¡¹ç›®é…ç½®è·å–
        if not detected_style and self.style_manager:
            current_style = self._get_current_project_style()
            if current_style:
                original_style_prompt = self.style_manager.style_prompts.get(current_style, "")
                if original_style_prompt:
                    detected_style = current_style
                    logger.info(f"ä»é¡¹ç›®é…ç½®è·å–é£æ ¼: {current_style}, æç¤ºè¯: {original_style_prompt}")

        # 3. æœ€åå°è¯•ä»æè¿°ä¸­æ£€æµ‹é£æ ¼
        if not detected_style and self.style_manager:
            detected_style, detected_prompt = self.style_manager.detect_style_from_description(enhanced_original_desc)
            if detected_style and detected_prompt:
                original_style_prompt = detected_prompt
                logger.info(f"ä»æè¿°ä¸­æ£€æµ‹åˆ°é£æ ¼: {detected_style}, æç¤ºè¯: {original_style_prompt}")

        # 4. å¦‚æœä»ç„¶æ²¡æœ‰é£æ ¼ï¼Œä½¿ç”¨é»˜è®¤é£æ ¼
        if not detected_style:
            logger.warning("æœªèƒ½è·å–æœ‰æ•ˆé£æ ¼ï¼Œä½¿ç”¨é»˜è®¤ç”µå½±é£æ ¼")
            detected_style = "ç”µå½±é£æ ¼"
            if self.style_manager:
                original_style_prompt = self.style_manager.style_prompts.get("ç”µå½±é£æ ¼", "")

        logger.info(f"æœ€ç»ˆä½¿ç”¨é£æ ¼: {detected_style}, æç¤ºè¯: {original_style_prompt}")

        # æ„å»ºå¢å¼ºæç¤º
        enhancement_prompt = f"""è¯·å¯¹ä»¥ä¸‹ç”»é¢æè¿°è¿›è¡Œæ™ºèƒ½å¢å¼ºï¼Œè¦æ±‚ï¼š
1. ä¿æŒåŸå§‹æè¿°çš„æ ¸å¿ƒå†…å®¹å’Œé£æ ¼
2. è‡ªç„¶èå…¥æä¾›çš„æŠ€æœ¯ç»†èŠ‚
3. ç¡®ä¿æè¿°æµç•…è‡ªç„¶ï¼Œé¿å…ç”Ÿç¡¬æ‹¼æ¥
4. æ§åˆ¶æ€»é•¿åº¦åœ¨150-200å­—ä¹‹é—´ï¼ˆå‡å°‘å†—é•¿æè¿°ï¼‰
5. ã€é‡è¦ã€‘å¿…é¡»åœ¨æ¶‰åŠè§’è‰²çš„æè¿°ä¸­åŒ…å«ä¸€è‡´çš„æœè£…æè¿°ï¼Œç¡®ä¿åŒä¸€è§’è‰²åœ¨ä¸åŒåœºæ™¯ä¸­çš„æœè£…ä¿æŒä¸€è‡´æ€§ã€‚
6. ã€å…³é”®ã€‘å¦‚æœåŸå§‹æè¿°ä¸­åŒ…å«ç‰¹å®šé£æ ¼æç¤ºè¯ï¼ˆå¦‚"{original_style_prompt}"ï¼‰ï¼Œå¿…é¡»åœ¨å¢å¼ºæè¿°çš„ç»“å°¾ä¿æŒå®Œå…¨ç›¸åŒçš„é£æ ¼æç¤ºè¯ï¼Œä¸å¾—ä¿®æ”¹ã€æ›¿æ¢æˆ–çœç•¥ã€‚

åŸå§‹æè¿°ï¼š{enhanced_original_desc}

æŠ€æœ¯ç»†èŠ‚è¡¥å……ï¼š{'; '.join(technical_parts) if technical_parts else 'æ— '}

è¯·è¾“å‡ºå¢å¼ºåçš„ç”»é¢æè¿°ï¼ˆå¿…é¡»ä¿æŒåŸå§‹é£æ ¼æç¤ºè¯ä¸å˜ï¼‰ï¼š"""
        
        logger.info("æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œåœºæ™¯æè¿°å¢å¼º...")
        # è®°å½•å®Œæ•´çš„æç¤ºè¯å†…å®¹ï¼Œä¸æˆªæ–­
        logger.debug(f"LLMå¢å¼ºæç¤ºè¯å®Œæ•´å†…å®¹:\n{enhancement_prompt}")
        
        try:
            # è°ƒç”¨LLMè¿›è¡Œå¢å¼º
            if not self.llm_api:
                raise Exception("LLM API æœªåˆå§‹åŒ–")
            enhanced_text = self.llm_api.rewrite_text(enhancement_prompt)
            
            if enhanced_text and len(enhanced_text.strip()) > 0:
                enhanced_content = enhanced_text.strip()

                # ã€å…³é”®ã€‘å¼ºåˆ¶ä¿æŒé£æ ¼ä¸€è‡´æ€§ - æ£€æŸ¥å¹¶ä¿®å¤é£æ ¼æç¤ºè¯
                if original_style_prompt and self.style_manager:
                    enhanced_content = self.style_manager.ensure_style_consistency(enhanced_content, original_style_prompt)
                    logger.info(f"å·²å¼ºåˆ¶ä¿æŒé£æ ¼ä¸€è‡´æ€§: {original_style_prompt}")

                logger.info(f"âœ“ LLMå¢å¼ºæˆåŠŸå®Œæˆ")
                logger.info(f"  - åŸå§‹æè¿°é•¿åº¦: {len(original_desc)} å­—ç¬¦")
                logger.info(f"  - å¢å¼ºåé•¿åº¦: {len(enhanced_content)} å­—ç¬¦")
                logger.info(f"  - å¢å¼ºæ¯”ä¾‹: {len(enhanced_content)/len(original_desc):.2f}x")
                logger.info(f"æŠ€æœ¯ç»†èŠ‚è¡¥å……ï¼š{'; '.join(technical_parts) if technical_parts else 'æ— '}")
                # è§’è‰²ä¸€è‡´æ€§ä¿¡æ¯å·²é›†æˆåˆ°å¢å¼ºæè¿°ä¸­ï¼Œæ— éœ€å•ç‹¬æ˜¾ç¤º
                logger.info(f"å¢å¼ºååœºæ™¯æè¿°: {enhanced_content[:200]}..." if len(enhanced_content) > 200 else f"å¢å¼ºååœºæ™¯æè¿°: {enhanced_content}")

                # æ³¨æ„ï¼šæ–‡ä»¶ä¿å­˜å·²ç§»è‡³enhance_storyboardæ–¹æ³•ä¸­ç»Ÿä¸€å¤„ç†

                result.enhanced_description = enhanced_content
                result.technical_additions = technical_parts
                result.consistency_additions = consistency_parts
                result.fusion_quality_score = 0.85  # LLMå¢å¼ºçš„è´¨é‡è¯„åˆ†è¾ƒé«˜
                
                logger.info("=== åœºæ™¯å¢å¼ºå™¨LLMè¾…åŠ©ç”Ÿæˆå®Œæˆ ===")
                return result
            else:
                logger.warning("âœ— LLMå¢å¼ºç»“æœè´¨é‡ä¸ä½³ï¼Œå›é€€åˆ°è‡ªç„¶èåˆ")
                logger.info("=== åœºæ™¯å¢å¼ºå™¨LLMè¾…åŠ©ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ ===")
                raise Exception("LLMè¿”å›ç©ºç»“æœ")
                
        except Exception as e:
            logger.error(f"âœ— LLMå¢å¼ºèåˆå¤±è´¥: {e}")
            logger.info("=== åœºæ™¯å¢å¼ºå™¨LLMè¾…åŠ©ç”Ÿæˆå¼‚å¸¸ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ ===")
            # å›é€€åˆ°è‡ªç„¶èåˆ
            return self._natural_fusion(content)
    
    def _postprocess_result(self, result: FusionResult) -> FusionResult:
        """åå¤„ç†èåˆç»“æœ"""
        # æ¸…ç†å¤šä½™çš„æ ‡ç‚¹ç¬¦å·
        result.enhanced_description = re.sub(r'[ï¼Œã€‚]{2,}', 'ï¼Œ', result.enhanced_description)
        result.enhanced_description = re.sub(r'ï¼Œ+$', 'ã€‚', result.enhanced_description)
        
        # è®¡ç®—èåˆè´¨é‡è¯„åˆ†
        result.fusion_quality_score = self._calculate_quality_score(result)
        
        return result
    
    def _calculate_quality_score(self, result: FusionResult) -> float:
        """è®¡ç®—èåˆè´¨é‡è¯„åˆ†"""
        score = 0.0
        
        # é•¿åº¦å¹³è¡¡è¯„åˆ†
        length = len(result.enhanced_description)
        if 100 <= length <= 350:  # ç†æƒ³é•¿åº¦èŒƒå›´
            length_score = 1.0
        elif length < 100:
            length_score = length / 100.0
        else:
            length_score = max(0.5, 400 / length)
        
        score += length_score * self.quality_rules['length_balance']
        
        # ä¿¡æ¯å¯†åº¦è¯„åˆ†
        info_count = len(result.technical_additions) + len(result.consistency_additions)
        density_score = min(1.0, info_count / 4.0)  # æœ€å¤š4ä¸ªè¡¥å……ä¿¡æ¯ä¸ºæ»¡åˆ†
        score += density_score * self.quality_rules['information_density']
        
        # å†…å®¹è¿è´¯æ€§è¯„åˆ†ï¼ˆç®€åŒ–ç‰ˆï¼‰
        coherence_score = 0.8  # åŸºç¡€è¿è´¯æ€§è¯„åˆ†
        if 'ï¼Œï¼Œ' in result.enhanced_description or 'ã€‚ã€‚' in result.enhanced_description:
            coherence_score -= 0.2
        
        score += coherence_score * self.quality_rules['content_coherence']
        
        return min(1.0, score)

    def _get_character_consistency_description(self, character_name: str) -> str:
        """ğŸ”§ æ–°å¢ï¼šè·å–è§’è‰²ä¸€è‡´æ€§æè¿°"""
        try:
            if not self.character_scene_manager:
                return ""

            # ä»è§’è‰²åœºæ™¯ç®¡ç†å™¨è·å–è§’è‰²æè¿°
            characters_data = self.character_scene_manager.get_all_characters()
            for char_id, char_data in characters_data.items():
                if char_data.get('name') == character_name:
                    return char_data.get('consistency_prompt', '') or char_data.get('description', '')

            return ""
        except Exception as e:
            logger.error(f"è·å–è§’è‰²ä¸€è‡´æ€§æè¿°å¤±è´¥ {character_name}: {e}")
            return ""

    def _get_current_project_style(self) -> str:
        """ä»é¡¹ç›®é…ç½®ä¸­è·å–å½“å‰é£æ ¼

        Returns:
            str: å½“å‰é¡¹ç›®çš„é£æ ¼è®¾ç½®
        """
        try:
            if not self.project_root:
                logger.warning("é¡¹ç›®æ ¹ç›®å½•æœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤é£æ ¼")
                return "ç”µå½±é£æ ¼"

            import json
            import os
            project_json_path = os.path.join(self.project_root, "project.json")

            if not os.path.exists(project_json_path):
                logger.warning(f"é¡¹ç›®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {project_json_path}")
                return "ç”µå½±é£æ ¼"

            with open(project_json_path, 'r', encoding='utf-8') as f:
                project_data = json.load(f)

            # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆä»äº”é˜¶æ®µåˆ†é•œç³»ç»Ÿä¸­è·å–é£æ ¼
            current_style = None

            # 1. é¦–å…ˆå°è¯•ä»äº”é˜¶æ®µåˆ†é•œæ•°æ®ä¸­è·å–
            if 'five_stage_storyboard' in project_data:
                five_stage_data = project_data['five_stage_storyboard']
                current_style = five_stage_data.get('selected_style')
                if current_style:
                    logger.info(f"ä»äº”é˜¶æ®µåˆ†é•œç³»ç»Ÿè·å–å½“å‰é£æ ¼: {current_style}")
                    return current_style

            # 2. å…¶æ¬¡å°è¯•ä»é¡¹ç›®æ ¹çº§åˆ«è·å–
            current_style = project_data.get('selected_style') or project_data.get('style')
            if current_style:
                logger.info(f"ä»é¡¹ç›®æ ¹çº§åˆ«è·å–å½“å‰é£æ ¼: {current_style}")
                return current_style

            # 3. æœ€åä½¿ç”¨é»˜è®¤é£æ ¼
            logger.warning("æœªæ‰¾åˆ°é¡¹ç›®é£æ ¼è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤é£æ ¼")
            return "ç”µå½±é£æ ¼"

        except Exception as e:
            logger.error(f"è·å–é¡¹ç›®é£æ ¼å¤±è´¥: {e}")
            return "ç”µå½±é£æ ¼"


class SceneDescriptionEnhancer:
    """åœºæ™¯æè¿°æ™ºèƒ½å¢å¼ºå™¨ - ä¸»ç±»ï¼ˆç¬¬äºŒé˜¶æ®µå¢å¼ºç‰ˆï¼‰"""
    
    def __init__(self, project_root: str, character_scene_manager: Optional[CharacterSceneManager] = None, llm_api=None):
        self.project_root = project_root
        self.output_dir = project_root  # æ·»åŠ  output_dir å±æ€§

        # åˆå§‹åŒ–è§’è‰²åœºæ™¯ç®¡ç†å™¨
        if character_scene_manager:
            self.character_scene_manager = character_scene_manager
        else:
            self.character_scene_manager = CharacterSceneManager(project_root)

        # åˆå§‹åŒ–LLM API
        self.llm_api = llm_api

        # ğŸ”§ ä¿®å¤ï¼šåˆå§‹åŒ–é£æ ¼ä¸€è‡´æ€§ç®¡ç†å™¨
        from src.utils.style_consistency_manager import StyleConsistencyManager
        self.style_manager = StyleConsistencyManager(project_root) if project_root else None

        # åˆå§‹åŒ–ç»„ä»¶
        self.technical_analyzer = TechnicalDetailsAnalyzer()
        self.consistency_injector = ConsistencyInjector(self.character_scene_manager, service_manager=None)
        self.content_fuser = ContentFuser(project_root=self.project_root, llm_api=llm_api, character_scene_manager=self.character_scene_manager)  # ä¼ é€’LLM APIå’Œè§’è‰²ç®¡ç†å™¨ç»™å†…å®¹èåˆå™¨
        self.color_optimizer = ColorOptimizer()  # åˆå§‹åŒ–é¢œè‰²ä¼˜åŒ–å™¨
        
        # é…ç½®é€‰é¡¹
        self.config = {
            'enable_technical_details': True,
            'enable_consistency_injection': True,
            'enhancement_level': 'medium',  # low, medium, high
            'fusion_strategy': 'intelligent',  # natural, structured, minimal, intelligent
            'quality_threshold': 0.4,  # ğŸ”§ ä¿®æ”¹ï¼šé™ä½è´¨é‡é˜ˆå€¼ï¼Œå‡å°‘å¤‡ç”¨ç­–ç•¥è§¦å‘
            'enable_llm_enhancement': True  # å¯ç”¨LLMå¢å¼º
        }

        # ğŸ”§ æ–°å¢ï¼šå¢å¼ºç¼“å­˜ï¼Œé¿å…é‡å¤å¤„ç†
        self._enhancement_cache = {}

    def _is_already_enhanced(self, description: str) -> bool:
        """æ£€æŸ¥æè¿°æ˜¯å¦å·²ç»å¢å¼ºè¿‡"""
        try:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«è§’è‰²ä¸€è‡´æ€§æè¿°çš„ç‰¹å¾
            if "ï¼ˆä¸­å›½äººï¼Œ" in description and "å²" in description and ("æˆ˜è¢" in description or "å†›è£…" in description):
                return True

            # æ£€æŸ¥æ˜¯å¦åŒ…å«é£æ ¼æç¤ºè¯
            if "æ°´å½©ç”»é£ï¼ŒæŸ”å’Œç¬”è§¦ï¼Œç²‰å½©è‰²ï¼Œæ’ç”»ï¼Œæ¸©æŸ”" in description:
                return True

            # æ£€æŸ¥ç¼“å­˜
            desc_hash = hash(description)
            return desc_hash in self._enhancement_cache

        except Exception as e:
            logger.debug(f"æ£€æŸ¥å¢å¼ºçŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def enhance_description(self, original_description: str, characters: Optional[List[str]] = None, style: Optional[str] = None) -> str:
        """å¢å¼ºç”»é¢æè¿°ï¼ˆç¬¬äºŒé˜¶æ®µå¢å¼ºç‰ˆï¼‰

        Args:
            original_description: åŸå§‹ç”»é¢æè¿°
            characters: ç›¸å…³è§’è‰²åˆ—è¡¨
            style: ç”¨æˆ·é€‰æ‹©çš„é£æ ¼ï¼ˆå¦‚ç”µå½±é£æ ¼ã€åŠ¨æ¼«é£æ ¼ç­‰ï¼‰

        Returns:
            str: å¢å¼ºåçš„ç”»é¢æè¿°
        """
        try:
            # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦å·²ç»å¢å¼ºè¿‡ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
            if self._is_already_enhanced(original_description):
                logger.info("æè¿°å·²ç»å¢å¼ºè¿‡ï¼Œè·³è¿‡é‡å¤å¤„ç†")
                return original_description

            logger.info(f"å¼€å§‹å¢å¼ºç”»é¢æè¿°: {original_description[:50]}...")

            # ğŸ”§ ä¿®å¤ï¼šé¦–å…ˆåµŒå…¥è§’è‰²ä¸€è‡´æ€§æè¿°
            enhanced_description_with_characters = original_description
            if characters:
                enhanced_description_with_characters = self._embed_character_descriptions(original_description, characters)
                logger.debug(f"è§’è‰²ä¸€è‡´æ€§æè¿°åµŒå…¥å®Œæˆ")

            # 1. æŠ€æœ¯ç»†èŠ‚åˆ†æ
            technical_details = None
            if self.config['enable_technical_details']:
                technical_details = self.technical_analyzer.analyze_description(enhanced_description_with_characters)
                logger.debug(f"æŠ€æœ¯ç»†èŠ‚åˆ†æå®Œæˆ: {technical_details.to_description()}")

            # 2. ä¸€è‡´æ€§ä¿¡æ¯æå–ï¼ˆä½¿ç”¨åµŒå…¥è§’è‰²æè¿°åçš„æ–‡æœ¬ï¼‰
            consistency_info = None
            if self.config['enable_consistency_injection']:
                try:
                    consistency_info = self.consistency_injector.extract_consistency_info(
                        enhanced_description_with_characters, characters
                    )
                    logger.debug(f"ä¸€è‡´æ€§ä¿¡æ¯æå–å®Œæˆ: {consistency_info.to_description()}")
                except Exception as e:
                    logger.debug(f"ä¸€è‡´æ€§ä¿¡æ¯æå–å¤±è´¥ï¼Œè·³è¿‡: {e}")
                    consistency_info = None

            # 2.5. é¢œè‰²ä¸€è‡´æ€§å¤„ç†
            enhanced_description_with_colors = enhanced_description_with_characters
            if characters:
                enhanced_description_with_colors = self.color_optimizer.apply_color_consistency(
                    enhanced_description_with_characters, characters, self.character_scene_manager
                )
                logger.debug(f"é¢œè‰²ä¸€è‡´æ€§å¤„ç†å®Œæˆ")

            # 3. æ™ºèƒ½å†…å®¹èåˆï¼ˆç¬¬äºŒé˜¶æ®µæ ¸å¿ƒåŠŸèƒ½ï¼‰
            fusion_result = self.content_fuser.fuse_content(
                enhanced_description_with_colors,
                technical_details,
                consistency_info,
                self.config['fusion_strategy'],
                style  # ğŸ”§ ä¿®å¤ï¼šä¼ é€’é£æ ¼å‚æ•°
            )

            # 4. è´¨é‡æ§åˆ¶
            if fusion_result.fusion_quality_score >= self.config['quality_threshold']:
                enhanced_description = fusion_result.enhanced_description
                logger.info(f"ç”»é¢æè¿°å¢å¼ºå®Œæˆï¼Œè´¨é‡è¯„åˆ†: {fusion_result.fusion_quality_score:.2f}")
            else:
                # è´¨é‡ä¸è¾¾æ ‡ï¼Œä½¿ç”¨å¤‡ç”¨ç­–ç•¥
                logger.warning(f"èåˆè´¨é‡ä¸è¾¾æ ‡({fusion_result.fusion_quality_score:.2f})ï¼Œä½¿ç”¨å¤‡ç”¨ç­–ç•¥")
                backup_result = self.content_fuser.fuse_content(
                    enhanced_description_with_colors, technical_details, consistency_info, 'natural'
                )
                enhanced_description = backup_result.enhanced_description

            return enhanced_description

        except Exception as e:
            logger.error(f"ç”»é¢æè¿°å¢å¼ºå¤±è´¥: {e}")
            return original_description

    def enhance_description_with_llm(self, original_description: str, characters: Optional[List[str]] = None) -> str:
        """ğŸ”§ æ–°å¢ï¼šä½¿ç”¨LLMè¿›è¡ŒçœŸæ­£çš„æ™ºèƒ½å¢å¼º

        Args:
            original_description: åŸå§‹ç”»é¢æè¿°
            characters: ç›¸å…³è§’è‰²åˆ—è¡¨

        Returns:
            str: LLMå¢å¼ºåçš„ç”»é¢æè¿°
        """
        try:
            # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦å·²ç»å¢å¼ºè¿‡ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
            if self._is_already_enhanced(original_description):
                logger.info("æè¿°å·²ç»å¢å¼ºè¿‡ï¼Œè·³è¿‡LLMé‡å¤å¤„ç†")
                return original_description

            logger.info(f"å¼€å§‹LLMæ™ºèƒ½å¢å¼ºç”»é¢æè¿°: {original_description[:50]}...")

            # æ£€æŸ¥LLM APIæ˜¯å¦å¯ç”¨
            if not self.llm_api or not self.llm_api.is_configured():
                logger.warning("LLM APIæœªé…ç½®ï¼Œå›é€€åˆ°æ™®é€šå¢å¼º")
                return self.enhance_description(original_description, characters)

            # 1. æŠ€æœ¯ç»†èŠ‚åˆ†æ
            technical_details = None
            if self.config['enable_technical_details']:
                technical_details = self.technical_analyzer.analyze_description(original_description)
                logger.debug(f"æŠ€æœ¯ç»†èŠ‚åˆ†æå®Œæˆ: {technical_details.to_description()}")

            # 2. ä¸€è‡´æ€§ä¿¡æ¯æå–
            consistency_info = None
            if self.config['enable_consistency_injection']:
                consistency_info = self.consistency_injector.extract_consistency_info(
                    original_description, characters
                )
                logger.debug(f"ä¸€è‡´æ€§ä¿¡æ¯æå–å®Œæˆ: {consistency_info.to_description()}")

            # 3. å¼ºåˆ¶ä½¿ç”¨LLMå¢å¼ºèåˆ
            fusion_result = self.content_fuser.fuse_content(
                original_description,
                technical_details,
                consistency_info,
                'intelligent'  # å¼ºåˆ¶ä½¿ç”¨intelligentç­–ç•¥è§¦å‘LLMå¢å¼º
            )

            logger.info(f"LLMæ™ºèƒ½å¢å¼ºå®Œæˆï¼Œè´¨é‡è¯„åˆ†: {fusion_result.fusion_quality_score:.2f}")
            return fusion_result.enhanced_description

        except Exception as e:
            logger.error(f"LLMæ™ºèƒ½å¢å¼ºå¤±è´¥: {e}")
            # å›é€€åˆ°æ™®é€šå¢å¼º
            return self.enhance_description(original_description, characters)
    
    def enhance_description_with_details(self, original_description: str, characters: Optional[List[str]] = None) -> Dict[str, Any]:
        """å¢å¼ºç”»é¢æè¿°å¹¶è¿”å›è¯¦ç»†ä¿¡æ¯
        
        Args:
            original_description: åŸå§‹ç”»é¢æè¿°
            characters: ç›¸å…³è§’è‰²åˆ—è¡¨
            
        Returns:
            Dict: åŒ…å«å¢å¼ºç»“æœå’Œè¯¦ç»†ä¿¡æ¯çš„å­—å…¸
        """
        try:
            logger.info(f"å¼€å§‹è¯¦ç»†å¢å¼ºç”»é¢æè¿°: {original_description[:50]}...")
            
            # 1. æŠ€æœ¯ç»†èŠ‚åˆ†æ
            technical_details = None
            if self.config['enable_technical_details']:
                technical_details = self.technical_analyzer.analyze_description(original_description)
            
            # 2. ä¸€è‡´æ€§ä¿¡æ¯æå–
            consistency_info = None
            if self.config['enable_consistency_injection']:
                consistency_info = self.consistency_injector.extract_consistency_info(
                    original_description, characters
                )
            
            # 3. æ™ºèƒ½å†…å®¹èåˆ
            fusion_result = self.content_fuser.fuse_content(
                original_description, 
                technical_details, 
                consistency_info, 
                self.config['fusion_strategy']
            )
            
            # 4. ç»„è£…è¯¦ç»†ç»“æœ
            result = {
                'original_description': original_description,
                'enhanced_description': fusion_result.enhanced_description,
                'technical_details': technical_details.to_description() if technical_details else "",
                'consistency_info': consistency_info.to_description() if consistency_info else "",
                'technical_additions': fusion_result.technical_additions,
                'consistency_additions': fusion_result.consistency_additions,
                'fusion_quality_score': fusion_result.fusion_quality_score,
                'fusion_strategy': self.config['fusion_strategy'],
                'enhancement_config': self.config.copy()
            }
            
            logger.info(f"è¯¦ç»†å¢å¼ºå®Œæˆï¼Œè´¨é‡è¯„åˆ†: {fusion_result.fusion_quality_score:.2f}")
            return result
            
        except Exception as e:
            logger.error(f"è¯¦ç»†å¢å¼ºå¤±è´¥: {e}")
            return {
                'original_description': original_description,
                'enhanced_description': original_description,
                'error': str(e)
            }
    
    def _fuse_content(self, original: str, technical: TechnicalDetails, consistency: ConsistencyInfo) -> str:
        """èåˆåŸå§‹æè¿°ã€æŠ€æœ¯ç»†èŠ‚å’Œä¸€è‡´æ€§ä¿¡æ¯"""
        parts = [original]
        
        # æ·»åŠ æŠ€æœ¯ç»†èŠ‚
        if technical and self.config['enable_technical_details']:
            tech_desc = technical.to_description()
            if tech_desc:
                if self.config['fusion_strategy'] == 'natural':
                    parts.append(f"ï¼ˆ{tech_desc}ï¼‰")
                elif self.config['fusion_strategy'] == 'structured':
                    parts.append(f"\næŠ€æœ¯è§„æ ¼ï¼š{tech_desc}")
                else:  # minimal
                    parts.append(f" [{tech_desc}]")
        
        # æ·»åŠ ä¸€è‡´æ€§ä¿¡æ¯
        if consistency and self.config['enable_consistency_injection']:
            consistency_desc = consistency.to_description()
            if consistency_desc:
                if self.config['fusion_strategy'] == 'natural':
                    parts.append(f"ï¼ˆ{consistency_desc}ï¼‰")
                elif self.config['fusion_strategy'] == 'structured':
                    parts.append(f"\nä¸€è‡´æ€§è¦æ±‚ï¼š{consistency_desc}")
                else:  # minimal
                    parts.append(f" [{consistency_desc}]")
        
        return "".join(parts)
    
    def update_config(self, **kwargs):
        """æ›´æ–°é…ç½®"""
        for key, value in kwargs.items():
            if key in self.config:
                self.config[key] = value
                logger.info(f"é…ç½®å·²æ›´æ–°: {key} = {value}")
    
    def reload_config(self):
        """é‡æ–°åŠ è½½é…ç½®"""
        try:
            # é‡æ–°åˆå§‹åŒ–é…ç½®
            from src.utils.config_manager import ConfigManager
            config_manager = ConfigManager()
            
            # è·å–å¢å¼ºå™¨é…ç½®
            enhancer_config = config_manager.get_setting("scene_enhancer", {})

            # æ›´æ–°é…ç½®å¯¹è±¡
            if enhancer_config:
                for key, value in enhancer_config.items():
                    if key in self.config:
                        self.config[key] = value
            
            # é‡æ–°åˆå§‹åŒ–å†…å®¹èåˆå™¨
            if hasattr(self, 'content_fuser'):
                self.content_fuser = ContentFuser(project_root=self.project_root, character_scene_manager=self.character_scene_manager)
            
            logger.info("åœºæ™¯æè¿°å¢å¼ºå™¨é…ç½®å·²é‡æ–°åŠ è½½")
            
        except Exception as e:
            logger.error(f"é‡æ–°åŠ è½½é…ç½®å¤±è´¥: {e}")
            raise
    
    def get_config(self) -> Dict[str, Any]:
        """è·å–å½“å‰é…ç½®"""
        return self.config.copy()
    
    def _load_scene_mapping_from_project(self) -> Optional[List[Dict[str, Any]]]:
        """ä»project.jsonä¸­åŠ è½½åœºæ™¯æ˜ å°„ä¿¡æ¯
        
        Returns:
            List[Dict]: åŒ…å«åœºæ™¯æ˜ å°„ä¿¡æ¯çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«scene_nameå’Œscene_index
        """
        try:
            # è·å–å½“å‰é¡¹ç›®çš„è¾“å‡ºç›®å½•
            if hasattr(self, 'output_dir') and self.output_dir:
                project_file = os.path.join(self.output_dir, 'project.json')
            else:
                # å°è¯•ä»å½“å‰å·¥ä½œç›®å½•æŸ¥æ‰¾
                project_file = None
                current_dir = os.getcwd()
                for root, _, files in os.walk(current_dir):
                    if 'project.json' in files:
                        project_file = os.path.join(root, 'project.json')
                        break
            
            if not project_file or not os.path.exists(project_file):
                logger.warning("æœªæ‰¾åˆ°project.jsonæ–‡ä»¶ï¼Œå°†ä½¿ç”¨é»˜è®¤åœºæ™¯åˆ†ç»„")
                return None
            
            with open(project_file, 'r', encoding='utf-8') as f:
                project_data = json.load(f)
            
            # ä»five_stage_storyboard.stage_data.4.storyboard_resultsä¸­æå–åœºæ™¯æ˜ å°„
            scene_mapping = []
            if ('five_stage_storyboard' in project_data and 
                'stage_data' in project_data['five_stage_storyboard'] and
                '4' in project_data['five_stage_storyboard']['stage_data'] and
                'storyboard_results' in project_data['five_stage_storyboard']['stage_data']['4']):
                storyboard_results = project_data['five_stage_storyboard']['stage_data']['4']['storyboard_results']
                for scene_data in storyboard_results:
                    scene_index = scene_data.get('scene_index', 0)
                    scene_info = scene_data.get('scene_info', '')
                    scene_name = scene_info if isinstance(scene_info, str) else f'## åœºæ™¯{scene_index + 1}'
                    
                    # ä»storyboard_scriptä¸­è®¡ç®—é•œå¤´æ•°é‡
                    storyboard_script = scene_data.get('storyboard_script', '')
                    shot_count = storyboard_script.count('### é•œå¤´') if storyboard_script else 1
                    
                    # ä¸ºè¯¥åœºæ™¯çš„æ¯ä¸ªé•œå¤´åˆ›å»ºæ˜ å°„
                    for shot_idx in range(shot_count):
                        scene_mapping.append({
                            'scene_name': scene_name,
                            'scene_index': scene_index,
                            'scene_description': scene_info
                        })
            
            logger.info(f"ä»project.jsonåŠ è½½äº†{len(scene_mapping)}ä¸ªé•œå¤´çš„åœºæ™¯æ˜ å°„ä¿¡æ¯")
            return scene_mapping
            
        except Exception as e:
            logger.error(f"åŠ è½½project.jsonåœºæ™¯æ˜ å°„å¤±è´¥: {e}")
            return None
    
    def enhance_storyboard(self, storyboard_script: str, style: Optional[str] = None) -> Dict[str, Any]:
        """å¢å¼ºæ•´ä¸ªåˆ†é•œè„šæœ¬ä¸­çš„ç”»é¢æè¿°

        Args:
            storyboard_script: å®Œæ•´çš„åˆ†é•œè„šæœ¬å†…å®¹
            style: ç”¨æˆ·é€‰æ‹©çš„é£æ ¼ï¼ˆå¦‚ç”µå½±é£æ ¼ã€åŠ¨æ¼«é£æ ¼ç­‰ï¼‰

        Returns:
            Dict: åŒ…å«å¢å¼ºç»“æœå’Œè¯¦ç»†ä¿¡æ¯çš„å­—å…¸
        """
        try:
            # å®‰å…¨å¤„ç†storyboard_scriptï¼Œç¡®ä¿å®ƒæ˜¯å­—ç¬¦ä¸²
            if not isinstance(storyboard_script, str):
                logger.error(f"storyboard_scriptåº”è¯¥æ˜¯å­—ç¬¦ä¸²ï¼Œä½†å¾—åˆ°: {type(storyboard_script)}")
                if isinstance(storyboard_script, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•è·å–è„šæœ¬å†…å®¹
                    storyboard_script = storyboard_script.get('storyboard_script', '') or storyboard_script.get('content', '') or str(storyboard_script)
                else:
                    storyboard_script = str(storyboard_script) if storyboard_script else ""

            logger.info(f"å¼€å§‹å¢å¼ºåˆ†é•œè„šæœ¬ï¼ŒåŸå§‹é•¿åº¦: {len(storyboard_script)}")

            # å°è¯•ä»project.jsonä¸­è¯»å–åœºæ™¯ä¿¡æ¯
            scene_mapping = self._load_scene_mapping_from_project()

            # è§£æåˆ†é•œè„šæœ¬ï¼Œæå–ç”»é¢æè¿°å’ŒæŠ€æœ¯ç»†èŠ‚
            enhanced_descriptions = []
            current_shot_info = {}

            lines = storyboard_script.split('\n')
            current_scene = None
            shot_counter = 0  # ç”¨äºæ˜ å°„åˆ°project.jsonä¸­çš„åœºæ™¯
            global_shot_counter = 1  # ğŸ”§ ä¿®å¤ï¼šå…¨å±€é•œå¤´è®¡æ•°å™¨ï¼Œç¡®ä¿é•œå¤´ç¼–å·å”¯ä¸€

            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # æ£€æµ‹åœºæ™¯æ ‡é¢˜ - ä¿ç•™åœºæ™¯æ ‡é¢˜åˆ°è¾“å‡ºç»“æœä¸­
                # ä½†ä¸åŒ…æ‹¬'## åœºæ™¯åˆ†é•œè„šæœ¬'ï¼Œè¿™åªæ˜¯æ ¼å¼æ ‡è®°
                if ((line.startswith('# åœºæ™¯') or 
                    (line.startswith('## åœºæ™¯') and 'åˆ†é•œè„šæœ¬' not in line) or 
                    line.startswith('### åœºæ™¯') or 
                    (line.startswith('åœºæ™¯') and not line.startswith('åœºæ™¯åˆ†é•œè„šæœ¬')))):
                    current_scene = line
                    logger.info(f"[enhance_storyboard] æ£€æµ‹åˆ°åœºæ™¯æ ‡é¢˜: '{current_scene}'")
                    # å°†åœºæ™¯æ ‡é¢˜æ·»åŠ åˆ°è¾“å‡ºç»“æœä¸­
                    enhanced_descriptions.append({
                        'type': 'scene_title',
                        'content': line,
                        'scene': current_scene,
                        'enhanced': line,  # åœºæ™¯æ ‡é¢˜ä¸éœ€è¦å¢å¼ºï¼Œç›´æ¥ä½¿ç”¨åŸå†…å®¹
                        'original': line
                    })
                    continue  # ç»§ç»­å¤„ç†ä¸‹ä¸€è¡Œ
                
                # æ£€æµ‹é•œå¤´å¼€å§‹
                if line.startswith('### é•œå¤´') or line.startswith('## é•œå¤´'):
                    # å¦‚æœæœ‰ä¹‹å‰çš„é•œå¤´ä¿¡æ¯ï¼Œå¤„ç†å®ƒ
                    if current_shot_info.get('ç”»é¢æè¿°'):
                        # ä»project.jsonæ˜ å°„ä¸­è·å–åœºæ™¯ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ£€æµ‹åˆ°çš„åœºæ™¯
                        if scene_mapping and shot_counter < len(scene_mapping):
                            current_shot_info['scene'] = scene_mapping[shot_counter]['scene_name']
                            current_shot_info['scene_index'] = scene_mapping[shot_counter]['scene_index']
                            logger.info(f"[enhance_storyboard] ä»project.jsonä¸ºé•œå¤´ {current_shot_info.get('é•œå¤´ç¼–å·', 'Unknown')} åˆ†é…åœºæ™¯: '{scene_mapping[shot_counter]['scene_name']}'")
                        else:
                            current_shot_info['scene'] = current_scene or "æœªçŸ¥åœºæ™¯"
                            logger.info(f"[enhance_storyboard] ä¸ºé•œå¤´ {current_shot_info.get('é•œå¤´ç¼–å·', 'Unknown')} æ·»åŠ åœºæ™¯ä¿¡æ¯: '{current_scene or 'æœªçŸ¥åœºæ™¯'}'")

                        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å…¨å±€é•œå¤´ç¼–å·ï¼Œç¡®ä¿å”¯ä¸€æ€§
                        original_shot_number = current_shot_info.get('é•œå¤´ç¼–å·', '')
                        global_shot_number = f"### é•œå¤´{global_shot_counter}"
                        current_shot_info['é•œå¤´ç¼–å·'] = global_shot_number
                        logger.info(f"[enhance_storyboard] å°†é•œå¤´ç¼–å·ä» '{original_shot_number}' æ›´æ–°ä¸º '{global_shot_number}'")

                        enhanced_desc = self._enhance_shot_description(current_shot_info, style)
                        enhanced_descriptions.append(enhanced_desc)
                        shot_counter += 1
                        global_shot_counter += 1

                    # é‡ç½®å½“å‰é•œå¤´ä¿¡æ¯
                    current_shot_info = {'é•œå¤´ç¼–å·': line}
                    continue
                
                # æå–æŠ€æœ¯ç»†èŠ‚å’Œç”»é¢æè¿°
                if '**' in line and ('ï¼š' in line or ':' in line):
                    # æå–å­—æ®µåå’Œå€¼
                    if 'ï¼š' in line:
                        field_part, value_part = line.split('ï¼š', 1)
                    else:
                        field_part, value_part = line.split(':', 1)
                    
                    # æ¸…ç†å­—æ®µå
                    field_name = field_part.replace('**', '').replace('-', '').strip()
                    value = value_part.strip()
                    
                    # å­˜å‚¨ä¿¡æ¯
                    current_shot_info[field_name] = value
            
            # å¤„ç†æœ€åä¸€ä¸ªé•œå¤´
            if current_shot_info.get('ç”»é¢æè¿°'):
                # ä»project.jsonæ˜ å°„ä¸­è·å–åœºæ™¯ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ£€æµ‹åˆ°çš„åœºæ™¯
                if scene_mapping and shot_counter < len(scene_mapping):
                    current_shot_info['scene'] = scene_mapping[shot_counter]['scene_name']
                    current_shot_info['scene_index'] = scene_mapping[shot_counter]['scene_index']
                    logger.info(f"[enhance_storyboard] ä»project.jsonä¸ºæœ€åä¸€ä¸ªé•œå¤´ {current_shot_info.get('é•œå¤´ç¼–å·', 'Unknown')} åˆ†é…åœºæ™¯: '{scene_mapping[shot_counter]['scene_name']}'")
                else:
                    current_shot_info['scene'] = current_scene or "æœªçŸ¥åœºæ™¯"
                    logger.info(f"[enhance_storyboard] ä¸ºæœ€åä¸€ä¸ªé•œå¤´ {current_shot_info.get('é•œå¤´ç¼–å·', 'Unknown')} æ·»åŠ åœºæ™¯ä¿¡æ¯: '{current_scene or 'æœªçŸ¥åœºæ™¯'}'")

                # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å…¨å±€é•œå¤´ç¼–å·ï¼Œç¡®ä¿å”¯ä¸€æ€§
                original_shot_number = current_shot_info.get('é•œå¤´ç¼–å·', '')
                global_shot_number = f"### é•œå¤´{global_shot_counter}"
                current_shot_info['é•œå¤´ç¼–å·'] = global_shot_number
                logger.info(f"[enhance_storyboard] å°†æœ€åä¸€ä¸ªé•œå¤´ç¼–å·ä» '{original_shot_number}' æ›´æ–°ä¸º '{global_shot_number}'")

                enhanced_desc = self._enhance_shot_description(current_shot_info, style)
                enhanced_descriptions.append(enhanced_desc)
            
            # ç»„åˆæ‰€æœ‰å¢å¼ºåçš„ç”»é¢æè¿°
            enhanced_content = '\n\n'.join([desc['enhanced'] for desc in enhanced_descriptions])
            
            # è®¡ç®—è´¨é‡è¯„åˆ†
            quality_score = min(1.0, len(enhanced_descriptions) * 0.2) if enhanced_descriptions else 0.5
            
            result = {
                'enhanced_description': enhanced_content,
                'original_description': storyboard_script,
                'enhanced_count': len(enhanced_descriptions),
                'enhanced_details': enhanced_descriptions,
                'fusion_quality_score': quality_score,
                'config': self.config.copy(),
                'technical_details': {},
                'consistency_details': {}
            }
            
            # ä¿å­˜å¢å¼ºç»“æœåˆ°project.jsonæ–‡ä»¶
            self._save_enhanced_descriptions_to_project(enhanced_descriptions)
            logger.info("âœ“ å¢å¼ºç»“æœå·²ä¿å­˜åˆ°project.jsonæ–‡ä»¶")

            # ğŸ”§ ä¿®æ”¹ï¼šç§»é™¤å•æ¬¡åœºæ™¯å¢å¼ºæ—¶çš„ä¸€è‡´æ€§æè¿°ä¿å­˜ï¼Œæ”¹ä¸ºåœ¨æ‰€æœ‰åœºæ™¯å®Œæˆåç»Ÿä¸€å¤„ç†
            
            logger.info(f"åˆ†é•œè„šæœ¬å¢å¼ºå®Œæˆï¼Œå¢å¼ºäº†{len(enhanced_descriptions)}ä¸ªç”»é¢æè¿°")
            return result
            
        except Exception as e:
            logger.error(f"åˆ†é•œè„šæœ¬å¢å¼ºå¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return {
                'enhanced_description': storyboard_script,
                'original_description': storyboard_script,
                'error': str(e),
                'fusion_quality_score': 0.0
            }
    
    def _enhance_shot_description(self, shot_info: Dict[str, str], style: Optional[str] = None) -> Dict[str, Any]:
        """å¢å¼ºå•ä¸ªé•œå¤´çš„ç”»é¢æè¿°

        Args:
            shot_info: åŒ…å«é•œå¤´ä¿¡æ¯çš„å­—å…¸
            style: ç”¨æˆ·é€‰æ‹©çš„é£æ ¼ï¼ˆå¦‚ç”µå½±é£æ ¼ã€åŠ¨æ¼«é£æ ¼ç­‰ï¼‰

        Returns:
            Dict: åŒ…å«åŸå§‹å’Œå¢å¼ºæè¿°çš„å­—å…¸
        """
        try:
            original_desc = shot_info.get('ç”»é¢æè¿°', '')
            if not original_desc:
                return {'original': '', 'enhanced': ''}

            # ğŸ”§ ä¿®å¤ï¼šä»é¡¹ç›®é…ç½®ä¸­è·å–å½“å‰é£æ ¼ï¼Œè€Œä¸æ˜¯ä½¿ç”¨ç¡¬ç¼–ç 
            current_style = self._get_current_project_style()
            if style:
                # å¦‚æœä¼ å…¥äº†é£æ ¼å‚æ•°ï¼Œä½¿ç”¨ä¼ å…¥çš„é£æ ¼
                current_style = style
                logger.info(f"ä½¿ç”¨ä¼ å…¥çš„é£æ ¼å‚æ•°: {style}")
            else:
                logger.info(f"ä»é¡¹ç›®é…ç½®è·å–é£æ ¼: {current_style}")

            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨é£æ ¼ä¸€è‡´æ€§ç®¡ç†å™¨è·å–é£æ ¼æç¤ºè¯ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç 
            style_prompt = ""
            if current_style and self.style_manager:
                style_prompt = self.style_manager.style_prompts.get(current_style, "")
                if style_prompt:
                    logger.info(f"ä¸ºé•œå¤´æè¿°æ·»åŠ {current_style}é£æ ¼æç¤ºè¯: {style_prompt}")

            # ğŸ”§ ä¿®å¤ï¼šä¸åœ¨è¿™é‡Œæ·»åŠ é£æ ¼æç¤ºè¯ï¼Œä¿æŒåŸå§‹æè¿°çš„çº¯å‡€æ€§
            # é£æ ¼æç¤ºè¯åº”è¯¥åœ¨å›¾åƒç”Ÿæˆæ—¶æ·»åŠ ï¼Œè€Œä¸æ˜¯åœ¨æè¿°å­˜å‚¨æ—¶æ·»åŠ 
            enhanced_desc = original_desc
            
            # æå–æŠ€æœ¯ç»†èŠ‚
            technical_details = TechnicalDetails(
                shot_type=shot_info.get('é•œå¤´ç±»å‹', ''),
                camera_angle=shot_info.get('æœºä½è§’åº¦', ''),
                camera_movement=shot_info.get('é•œå¤´è¿åŠ¨', ''),
                depth_of_field=shot_info.get('æ™¯æ·±æ•ˆæœ', ''),
                lighting=shot_info.get('å…‰å½±è®¾è®¡', ''),
                composition=shot_info.get('æ„å›¾è¦ç‚¹', ''),
                color_tone=shot_info.get('è‰²å½©åŸºè°ƒ', '')
            )
            
            # æå–è§’è‰²ä¿¡æ¯ï¼ˆä»ç”»é¢æè¿°ä¸­è¯†åˆ«ï¼‰
            characters = self._extract_characters_from_description(original_desc)
            
            # åµŒå…¥è§’è‰²ä¸€è‡´æ€§æè¿°
            enhanced_original_desc = self._embed_character_descriptions(original_desc, characters)
            
            # è·å–ä¸€è‡´æ€§ä¿¡æ¯
            consistency_info = None
            if self.config['enable_consistency_injection']:
                consistency_info = self.consistency_injector.extract_consistency_info(
                    enhanced_original_desc, characters
                )
            
            # æ™ºèƒ½èåˆå†…å®¹
            fusion_result = self.content_fuser.fuse_content(
                enhanced_desc,  # ä½¿ç”¨å¸¦æœ‰é£æ ¼æç¤ºè¯çš„æè¿°
                technical_details,
                consistency_info,
                self.config['fusion_strategy'],
                style  # ğŸ”§ æ–°å¢ï¼šä¼ é€’é£æ ¼å‚æ•°
            )
            
            return {
                'original': original_desc,  # ğŸ”§ ä¿®å¤ï¼šè¿”å›çº¯å‡€çš„åŸå§‹æè¿°ï¼Œä¸åŒ…å«é£æ ¼æç¤ºè¯
                'enhanced': fusion_result.enhanced_description,
                'technical_details': technical_details.to_description(),
                'consistency_info': consistency_info.to_description() if consistency_info else '',
                'characters': characters,
                'fusion_quality_score': fusion_result.fusion_quality_score,
                'shot_info': shot_info,  # ä¿å­˜åŸå§‹çš„shot_infoç”¨äºé‡å»ºoriginal_description
                'é•œå¤´ç¼–å·': shot_info.get('é•œå¤´ç¼–å·', '### é•œå¤´1'),  # ç¡®ä¿é•œå¤´ç¼–å·è¢«ä¼ é€’
                'current_style': current_style,  # ğŸ”§ æ–°å¢ï¼šä¿å­˜å½“å‰é£æ ¼ä¿¡æ¯
                'style_prompt': style_prompt  # ğŸ”§ æ–°å¢ï¼šä¿å­˜é£æ ¼æç¤ºè¯ï¼ˆä½†ä¸åµŒå…¥åˆ°æè¿°ä¸­ï¼‰
            }
            
        except Exception as e:
            logger.error(f"å¢å¼ºé•œå¤´æè¿°å¤±è´¥: {e}")
            # ğŸ”§ ä¿®å¤ï¼šå³ä½¿å‡ºé”™ä¹Ÿè¿”å›çº¯å‡€çš„åŸå§‹æè¿°
            original_desc = shot_info.get('ç”»é¢æè¿°', '')
            current_style = self._get_current_project_style()
            if style:
                current_style = style

            return {
                'original': original_desc,  # ğŸ”§ ä¿®å¤ï¼šè¿”å›çº¯å‡€çš„åŸå§‹æè¿°
                'enhanced': original_desc,  # å‡ºé”™æ—¶ä½¿ç”¨åŸå§‹æè¿°ä½œä¸ºå¢å¼ºç»“æœ
                'error': str(e),
                'shot_info': shot_info,  # å³ä½¿å‡ºé”™ä¹Ÿä¿å­˜åŸå§‹ä¿¡æ¯
                'é•œå¤´ç¼–å·': shot_info.get('é•œå¤´ç¼–å·', '### é•œå¤´1'),  # ç¡®ä¿é•œå¤´ç¼–å·è¢«ä¼ é€’
                'current_style': current_style,  # ä¿å­˜å½“å‰é£æ ¼ä¿¡æ¯
                'style_prompt': ""  # å‡ºé”™æ—¶é£æ ¼æç¤ºè¯ä¸ºç©º
            }
    
    def _extract_characters_from_description(self, description: str) -> List[str]:
        """æ™ºèƒ½è§’è‰²æå–æ–¹æ³•

        Args:
            description: ç”»é¢æè¿°æ–‡æœ¬

        Returns:
            List[str]: è¯†åˆ«å‡ºçš„è§’è‰²åˆ—è¡¨
        """
        characters = []

        # é¦–å…ˆå°è¯•ç®€å•çš„å…³é”®è¯åŒ¹é…
        characters.extend(self._extract_simple_characters(description))

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå†ä½¿ç”¨å¤æ‚çš„æ™ºèƒ½è¯†åˆ«
        if not characters:
            # ç¬¬ä¸€å±‚ï¼šæ™ºèƒ½å¤åˆè§’è‰²åç§°è¯†åˆ«
            characters.extend(self._extract_compound_characters(description))

            # ç¬¬äºŒå±‚ï¼šè¯­ä¹‰è§’è‰²å…³ç³»è¯†åˆ«
            characters.extend(self._extract_semantic_characters(description))

            # ç¬¬ä¸‰å±‚ï¼šä¼ ç»Ÿå…³é”®è¯åŒ¹é…
            characters.extend(self._extract_keyword_characters(description))

        # å»é‡å¹¶ä¿æŒé¡ºåº
        unique_characters = []
        seen = set()
        for char in characters:
            if char and char not in seen:
                unique_characters.append(char)
                seen.add(char)

        logger.debug(f"æ™ºèƒ½è§’è‰²æå–ç»“æœ: {unique_characters}")
        return unique_characters

    def _extract_simple_characters(self, description: str) -> List[str]:
        """ç®€å•çš„è§’è‰²å…³é”®è¯åŒ¹é…

        Args:
            description: ç”»é¢æè¿°æ–‡æœ¬

        Returns:
            List[str]: è¯†åˆ«å‡ºçš„è§’è‰²åˆ—è¡¨
        """
        characters = []

        # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ç²¾ç¡®çš„é¡¹ç›®è§’è‰²æ•°æ®åŒ¹é…
        try:
            if hasattr(self, 'character_scene_manager') and self.character_scene_manager:
                project_characters = self.character_scene_manager.get_all_characters()

                # æŒ‰è§’è‰²åç§°é•¿åº¦æ’åºï¼Œä¼˜å…ˆåŒ¹é…é•¿åç§°ï¼ˆé¿å…"èµµ"åŒ¹é…åˆ°"èµµæ‹¬"çš„é—®é¢˜ï¼‰
                sorted_characters = sorted(project_characters.items(),
                                         key=lambda x: len(x[1].get('name', '')), reverse=True)

                for char_id, char_data in sorted_characters:
                    char_name = char_data.get('name', '')
                    if char_name and char_name in description and char_name not in characters:
                        characters.append(char_name)
                        logger.info(f"ä»é¡¹ç›®æ•°æ®ä¸­è¯†åˆ«åˆ°è§’è‰²: {char_name}")

                    # æ£€æŸ¥è§’è‰²åˆ«å
                    aliases = char_data.get('aliases', [])
                    if aliases:
                        for alias in aliases:
                            if alias and alias in description and char_name not in characters:
                                characters.append(char_name)  # ä½¿ç”¨ä¸»åç§°è€Œä¸æ˜¯åˆ«å
                                logger.info(f"é€šè¿‡åˆ«å'{alias}'è¯†åˆ«åˆ°è§’è‰²: {char_name}")
                                break

        except Exception as e:
            logger.warning(f"ä»é¡¹ç›®æ•°æ®åŒ¹é…è§’è‰²å¤±è´¥: {e}")

        # ğŸ”§ ä¿®å¤ï¼šå¦‚æœå·²ç»ä»é¡¹ç›®æ•°æ®ä¸­æ‰¾åˆ°è§’è‰²ï¼Œç›´æ¥è¿”å›ï¼Œä¸å†è¿›è¡Œå…¶ä»–åŒ¹é…
        if characters:
            return characters

        # é€šç”¨è§’è‰²å…³é”®è¯åˆ—è¡¨ï¼ˆé€‚ç”¨äºå„ç§æ–‡å­¦ä½œå“ï¼‰
        simple_character_keywords = [
            # æ ¸å¿ƒè§’è‰²ç±»å‹
            'ä¸»è¦è§’è‰²', 'ä¸»è§’', 'ä¸»äººå…¬', 'ç”·ä¸»', 'å¥³ä¸»', 'åæ´¾', 'é…è§’', 'é¾™å¥—',

            # ç°ä»£èŒä¸šï¼ˆç°ä»£é¢˜æï¼‰
            'ç§‘å­¦å®¶', 'åŒ»ç”Ÿ', 'æŠ¤å£«', 'è€å¸ˆ', 'å­¦ç”Ÿ', 'è­¦å¯Ÿ', 'å¾‹å¸ˆ', 'è®°è€…', 'ä½œå®¶',
            'ç”»å®¶', 'æ­Œæ‰‹', 'æ¼”å‘˜', 'å¯¼æ¼”', 'å¨å¸ˆ', 'å¸æœº', 'å·¥äºº', 'å†œæ°‘', 'å•†äºº',
            'è€æ¿', 'ç»ç†', 'ç§˜ä¹¦', 'ç¨‹åºå‘˜', 'è®¾è®¡å¸ˆ', 'å·¥ç¨‹å¸ˆ', 'å»ºç­‘å¸ˆ',

            # å†å²å¤ä»£èŒä¸šï¼ˆå†å²é¢˜æï¼‰
            'çš‡å¸', 'çš‡å', 'å¤ªå­', 'å…¬ä¸»', 'å¤§è‡£', 'å°†å†›', 'ä¸ç›¸', 'å¤ªå°‰', 'å…ƒå¸…',
            'æ¨èè€…', 'ä½¿è€…', 'è°‹å£«', 'æ­¦å°†', 'æ–‡å®˜', 'ä¾å«', 'å®«å¥³', 'å¤ªç›‘',
            'ä¹¦ç”Ÿ', 'å•†è´¾', 'å†œå¤«', 'å·¥åŒ ', 'çŒæˆ·', 'æ¸”å¤«', 'æ¨µå¤«',

            # ç§‘å¹»å¥‡å¹»è§’è‰²ï¼ˆç§‘å¹»å¥‡å¹»é¢˜æï¼‰
            'æœºå™¨äºº', 'AI', 'äººå·¥æ™ºèƒ½', 'å¤–æ˜Ÿäºº', 'å¼‚æ—', 'ç²¾çµ', 'çŸ®äºº', 'å…½äºº',
            'é¾™æ—', 'å¤©ä½¿', 'æ¶é­”', 'æ³•å¸ˆ', 'æˆ˜å£«', 'ç›—è´¼', 'ç‰§å¸ˆ', 'éª‘å£«',
            'å·«å¸ˆ', 'æœ¯å£«', 'å¾·é²ä¼Š', 'æ¸¸ä¾ ', 'åˆºå®¢', 'åœ£éª‘å£«', 'æ­»çµæ³•å¸ˆ',

            # å†›äº‹ç§‘å¹»ï¼ˆå†›äº‹ç§‘å¹»é¢˜æï¼‰
            'èˆ°é•¿', 'æŒ‡æŒ¥å®˜', 'é£è¡Œå‘˜', 'ç‰¹å·¥', 'é—´è°', 'æ¢å‘˜', 'å£«å®˜', 'åˆ—å…µ',
            'ä¸­å°‰', 'ä¸Šå°‰', 'å°‘æ ¡', 'ä¸­æ ¡', 'ä¸Šæ ¡', 'å°†å†›', 'å…ƒå¸…',

            # å®¶åº­å…³ç³»ï¼ˆé€šç”¨ï¼‰
            'çˆ¶äº²', 'æ¯äº²', 'çˆ¸çˆ¸', 'å¦ˆå¦ˆ', 'å„¿å­', 'å¥³å„¿', 'å“¥å“¥', 'å§å§', 'å¼Ÿå¼Ÿ', 'å¦¹å¦¹',
            'çˆ·çˆ·', 'å¥¶å¥¶', 'å¤–å…¬', 'å¤–å©†', 'å”å”', 'é˜¿å§¨', 'èˆ…èˆ…', 'å§‘å§‘',
            'ä¸ˆå¤«', 'å¦»å­', 'ç”·å‹', 'å¥³å‹', 'æ‹äºº', 'ä¼´ä¾£',

            # ç¤¾ä¼šå…³ç³»ï¼ˆé€šç”¨ï¼‰
            'æœ‹å‹', 'åŒäº‹', 'åŒå­¦', 'é‚»å±…', 'é™Œç”Ÿäºº', 'è·¯äºº', 'å®¢äºº', 'è®¿å®¢',
            'æ•Œäºº', 'å¯¹æ‰‹', 'ç«äº‰è€…', 'ç›Ÿå‹', 'ä¼™ä¼´', 'é˜Ÿå‹',

            # å¹´é¾„æ€§åˆ«æè¿°ï¼ˆé€šç”¨ï¼‰
            'ç”·å­', 'å¥³å­', 'ç”·äºº', 'å¥³äºº', 'ç”·å­©', 'å¥³å­©', 'å­©å­', 'å°å­©',
            'è€äºº', 'å¹´è½»äºº', 'ä¸­å¹´äºº', 'é’å¹´', 'å°‘å¹´', 'å°‘å¥³', 'é’å°‘å¹´',
            'å©´å„¿', 'å¹¼å„¿', 'å„¿ç«¥', 'æˆå¹´äºº', 'è€å¹´äºº'
        ]

        # æŒ‰é•¿åº¦é™åºæ’åºï¼Œä¼˜å…ˆåŒ¹é…æ›´é•¿çš„è¯æ±‡
        simple_character_keywords.sort(key=len, reverse=True)

        for keyword in simple_character_keywords:
            if keyword in description:
                characters.append(keyword)

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¯èƒ½çš„äººåå’Œè§’è‰²
        import re
        # é€šç”¨çš„è§’è‰²è¯†åˆ«æ¨¡å¼ï¼ˆé€‚ç”¨äºå„ç§æ–‡å­¦ä½œå“ï¼‰
        name_patterns = [
            # ä¸­æ–‡äººåæ¨¡å¼ï¼ˆ2-4ä¸ªæ±‰å­—ï¼‰
            r'([\u4e00-\u9fa5]{2,4}(?=[çš„|ï¼Œ|ã€‚|ï¼|ï¼Ÿ|ï¼š|ï¼›|ã€|è¯´|é“|æƒ³|çœ‹|å¬|èµ°|è·‘|ç«™|å|ç¬‘|å“­|å«|å–Š]))',

            # å†å²äººç‰©å’Œå¤ä»£ç§°è°“ï¼ˆå†å²é¢˜æï¼‰
            r'([å»‰é¢‡|èµµç‹|èµµæ‹¬|æ¨èè€…|ç§¦ç‹|ç™½èµ·|ç‹ç¿¦|æç‰§|è’™æ¬])',
            r'([èµµ|ç§¦|æ¥š|é½|ç‡•|éŸ©|é­|å´|èœ€|é­][ç‹|ä¾¯|å…¬|å›|å¸])',
            r'([\u4e00-\u9fa5]{2,3}[å°†å†›|å¤§å¤«|ä¸ç›¸|å¤ªå°‰|å¸é©¬|éƒ½å°‰|å…ƒå¸…|ç»Ÿé¢†])',

            # ç°ä»£äººåå’Œç§°è°“ï¼ˆç°ä»£é¢˜æï¼‰
            r'([å¼ |æ|ç‹|åˆ˜|é™ˆ|æ¨|é»„|èµµ|å‘¨|å´|å¾|å­™|èƒ¡|æœ±|é«˜|æ—|ä½•|éƒ­|é©¬|ç½—|æ¢|å®‹|éƒ‘|è°¢|éŸ©|å”|å†¯|äº|è‘£|è§|ç¨‹|æ›¹|è¢|é‚“|è®¸|å‚…|æ²ˆ|æ›¾|å½­|å•|è‹|å¢|è’‹|è”¡|è´¾|ä¸|é­|è–›|å¶|é˜|ä½™|æ½˜|æœ|æˆ´|å¤|é’Ÿ|æ±ª|ç”°|ä»»|å§œ|èŒƒ|æ–¹|çŸ³|å§š|è°­|å»–|é‚¹|ç†Š|é‡‘|é™†|éƒ|å­”|ç™½|å´”|åº·|æ¯›|é‚±|ç§¦|æ±Ÿ|å²|é¡¾|ä¾¯|é‚µ|å­Ÿ|é¾™|ä¸‡|æ®µ|æ¼•|é’±|æ±¤|å°¹|é»|æ˜“|å¸¸|æ­¦|ä¹”|è´º|èµ–|é¾š|æ–‡][\u4e00-\u9fa5]{1,2})',

            # ç§‘å¹»/å¥‡å¹»è§’è‰²ï¼ˆç§‘å¹»å¥‡å¹»é¢˜æï¼‰
            r'([æœºå™¨äºº|AI|äººå·¥æ™ºèƒ½|å¤–æ˜Ÿäºº|å¼‚æ—|ç²¾çµ|çŸ®äºº|å…½äºº|é¾™æ—|å¤©ä½¿|æ¶é­”|æ³•å¸ˆ|æˆ˜å£«|ç›—è´¼|ç‰§å¸ˆ|éª‘å£«][\u4e00-\u9fa5]*)',
            r'([\u4e00-\u9fa5]*[åšå£«|æ•™æˆ|é˜Ÿé•¿|æŒ‡æŒ¥å®˜|èˆ°é•¿|é£è¡Œå‘˜|ç‰¹å·¥|é—´è°|æ¢å‘˜])',

            # èŒä¸šå’Œèº«ä»½ï¼ˆé€šç”¨ï¼‰
            r'([åŒ»ç”Ÿ|æŠ¤å£«|è€å¸ˆ|å­¦ç”Ÿ|è­¦å¯Ÿ|å¾‹å¸ˆ|è®°è€…|ä½œå®¶|ç”»å®¶|æ­Œæ‰‹|æ¼”å‘˜|å¯¼æ¼”|å¨å¸ˆ|å¸æœº|å·¥äºº|å†œæ°‘|å•†äºº|è€æ¿|ç»ç†|ç§˜ä¹¦][\u4e00-\u9fa5]*)',

            # å®¶åº­å…³ç³»ï¼ˆé€šç”¨ï¼‰
            r'([çˆ¶äº²|æ¯äº²|çˆ¸çˆ¸|å¦ˆå¦ˆ|å„¿å­|å¥³å„¿|å“¥å“¥|å§å§|å¼Ÿå¼Ÿ|å¦¹å¦¹|çˆ·çˆ·|å¥¶å¥¶|å¤–å…¬|å¤–å©†|å”å”|é˜¿å§¨|èˆ…èˆ…|å§‘å§‘|ä¸ˆå¤«|å¦»å­|ç”·å‹|å¥³å‹])',
        ]

        for pattern in name_patterns:
            matches = re.findall(pattern, description)
            for match in matches:
                if match and match not in characters:
                    characters.append(match)
                    logger.debug(f"é€šè¿‡æ­£åˆ™åŒ¹é…è¯†åˆ«åˆ°è§’è‰²: {match}")

        return characters

    def _extract_compound_characters(self, description: str) -> list:
        """
        æå–å¤åˆè§’è‰²åç§°ï¼ˆå¦‚ï¼šæé™å¦ˆå¦ˆã€å¼ ä¸‰å¸ˆå‚…ã€å°æ˜çš„çŒ«ç­‰ï¼‰
        æ”¯æŒè¢«æ‹¬å·æˆ–å…¶ä»–å†…å®¹åˆ†éš”çš„æƒ…å†µ
        
        Args:
            description: ç”»é¢æè¿°æ–‡æœ¬
            
        Returns:
            list: æå–åˆ°çš„å¤åˆè§’è‰²åç§°åˆ—è¡¨
        """
        import re
        characters = []
        
        # æ‰©å±•çš„è§’è‰²åç¼€è¯åº“
        role_suffixes = [
            # å®¶åº­å…³ç³»
            'å¦ˆå¦ˆ', 'çˆ¸çˆ¸', 'æ¯äº²', 'çˆ¶äº²', 'çˆ·çˆ·', 'å¥¶å¥¶', 'å¤–å…¬', 'å¤–å©†',
            'å„¿å­', 'å¥³å„¿', 'å“¥å“¥', 'å§å§', 'å¼Ÿå¼Ÿ', 'å¦¹å¦¹', 'ä¸ˆå¤«', 'å¦»å­',
            # èŒä¸šèº«ä»½
            'è€å¸ˆ', 'åŒ»ç”Ÿ', 'æŠ¤å£«', 'è­¦å¯Ÿ', 'å¸æœº', 'è€æ¿', 'ç»ç†', 'ç§˜ä¹¦',
            'æœåŠ¡å‘˜', 'åº—ä¸»', 'å¨å¸ˆ', 'å¾‹å¸ˆ', 'æ³•å®˜', 'è®°è€…', 'æ¼”å‘˜', 'æ­Œæ‰‹',
            'æ•™æˆ', 'å­¦ç”Ÿ', 'å†›äºº', 'å£«å…µ', 'å·¥äºº', 'å†œæ°‘', 'å•†äºº', 'åŠ©ç†',
            # å¸ˆå¾’å…³ç³»
            'å¸ˆå‚…', 'å¸ˆçˆ¶', 'å¸ˆå…„', 'å¸ˆå§', 'å¸ˆå¼Ÿ', 'å¸ˆå¦¹', 'å¾’å¼Ÿ', 'å­¦å¾’',
            # ç¤¾ä¼šå…³ç³»
            'æœ‹å‹', 'åŒäº‹', 'åŒå­¦', 'é‚»å±…', 'å®¤å‹', 'ä¼™ä¼´', 'æ­æ¡£', 'åŠ©æ‰‹',
            # ç‰¹æ®Šå…³ç³»
            'ä¿é•–', 'å¸æœº', 'ç§˜ä¹¦', 'ç®¡å®¶', 'ä¿å§†', 'æŠ¤å·¥', 'å‘å¯¼', 'ç¿»è¯‘',
            # åŠ¨ç‰©/å® ç‰©
            'çš„çŒ«', 'çš„ç‹—', 'çš„é¸Ÿ', 'çš„é©¬', 'çš„é±¼', 'çš„å…”å­', 'çš„ä»“é¼ ',
            # ç§°è°“
            'å¤§å”', 'å¤§çˆ·', 'å¤§å¦ˆ', 'é˜¿å§¨', 'å”å”', 'å©¶å©¶', 'èˆ…èˆ…', 'å§‘å§‘'
        ]
        
        # æ„å»ºåŠ¨æ€æ­£åˆ™è¡¨è¾¾å¼
        suffix_pattern = '|'.join(re.escape(suffix) for suffix in role_suffixes)
        
        # åŒ¹é…æ¨¡å¼ï¼šäººå+è§’è‰²åç¼€ï¼ˆæ”¯æŒè¢«åˆ†éš”çš„æƒ…å†µï¼‰
        patterns = [
            # ç›´æ¥è¿æ¥ï¼šæé™å¦ˆå¦ˆ
            rf'([\u4e00-\u9fa5]{{2,4}})({suffix_pattern})',
            # å¸¦"çš„"ï¼šæé™çš„çŒ«
            rf'([\u4e00-\u9fa5]{{2,4}})çš„({suffix_pattern.replace("çš„", "")})',
            # ç©ºæ ¼åˆ†éš”ï¼šæé™ å¦ˆå¦ˆ
            rf'([\u4e00-\u9fa5]{{2,4}})\s+({suffix_pattern})',
            # è¢«æ‹¬å·å†…å®¹åˆ†éš”ï¼šæé™ï¼ˆ...ï¼‰å¦ˆå¦ˆ
            rf'([\u4e00-\u9fa5]{{2,4}})ï¼ˆ[^ï¼‰]*ï¼‰({suffix_pattern})',
            # è¢«å…¶ä»–æ ‡ç‚¹åˆ†éš”ï¼šæé™ï¼Œå¦ˆå¦ˆ / æé™ã€‚å¦ˆå¦ˆ
            rf'([\u4e00-\u9fa5]{{2,4}})[ï¼Œã€‚ã€ï¼›ï¼šï¼ï¼Ÿ]\s*({suffix_pattern})',
            # è¢«æè¿°æ€§å†…å®¹åˆ†éš”ï¼ˆæ›´å®½æ³›çš„åŒ¹é…ï¼‰ï¼šæé™...å¦ˆå¦ˆ
            rf'([\u4e00-\u9fa5]{{2,4}})[^\u4e00-\u9fa5]*?({suffix_pattern})(?=[ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€\s]|$)',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, description)
            for match in matches:
                if len(match) == 2:  # ç¡®ä¿åŒ¹é…åˆ°ä¸¤ä¸ªéƒ¨åˆ†
                    name_part, role_part = match
                    
                    # éªŒè¯æ˜¯å¦æ˜¯æœ‰æ•ˆçš„è§’è‰²ç»„åˆ
                    if self._is_valid_character_combination(name_part, role_part, description):
                        # é‡æ„å®Œæ•´è§’è‰²åç§°
                        if 'çš„' in pattern and not role_part.startswith('çš„'):
                            full_name = f"{name_part}çš„{role_part}"
                        else:
                            full_name = f"{name_part}{role_part}"
                        
                        if len(full_name) >= 3:  # è‡³å°‘3ä¸ªå­—ç¬¦çš„å¤åˆåç§°
                            characters.append(full_name)
                            logger.debug(f"è¯†åˆ«åˆ°å¤åˆè§’è‰²: {full_name} (æ¥æº: {name_part} + {role_part})")
        
        return characters
    
    def _is_valid_character_combination(self, name_part: str, role_part: str, description: str) -> bool:
        """
        éªŒè¯äººåå’Œè§’è‰²éƒ¨åˆ†çš„ç»„åˆæ˜¯å¦æœ‰æ•ˆ
        
        Args:
            name_part: äººåéƒ¨åˆ†
            role_part: è§’è‰²éƒ¨åˆ†
            description: åŸå§‹æè¿°
            
        Returns:
            bool: æ˜¯å¦æ˜¯æœ‰æ•ˆçš„è§’è‰²ç»„åˆ
        """
        # æ’é™¤æ˜æ˜¾ä¸æ˜¯äººåçš„è¯æ±‡
        invalid_names = [
            'ä¸€ä¸ª', 'è¿™ä¸ª', 'é‚£ä¸ª', 'æŸä¸ª', 'æ¯ä¸ª', 'æ‰€æœ‰', 'å…¨éƒ¨',
            'å¹´è½»', 'ä¸­å¹´', 'è€å¹´', 'å°å°', 'å¤§å¤§', 'é«˜é«˜', 'çŸ®çŸ®',
            'ç¾ä¸½', 'æ¼‚äº®', 'è‹±ä¿Š', 'å¸…æ°”', 'å¯çˆ±', 'æ¸©æŸ”', 'å–„è‰¯'
        ]
        
        if name_part in invalid_names:
            return False
        
        # æ£€æŸ¥ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿è¿™ç¡®å®æ˜¯ä¸€ä¸ªè§’è‰²å…³ç³»
        # ä¾‹å¦‚ï¼š"æé™ï¼ˆæè¿°ï¼‰å¦ˆå¦ˆ" ä¸­ï¼Œå¦ˆå¦ˆåº”è¯¥æ˜¯åœ¨æè¿°æé™çš„å¦ˆå¦ˆ
        context_indicators = [
            f"{name_part}.*{role_part}",  # åŸºæœ¬åŒ¹é…
            f"{role_part}.*{name_part}",  # åå‘åŒ¹é…
        ]
        
        import re
        for indicator in context_indicators:
            if re.search(indicator, description):
                return True
        
        return True  # é»˜è®¤è®¤ä¸ºæœ‰æ•ˆ
    
    def _extract_semantic_characters(self, description: str) -> list:
        """
        åŸºäºè¯­ä¹‰çš„è§’è‰²è¯†åˆ«ï¼ˆè¯†åˆ«ä¸Šä¸‹æ–‡ä¸­çš„è§’è‰²å…³ç³»ï¼‰
        
        Args:
            description: ç”»é¢æè¿°æ–‡æœ¬
            
        Returns:
            list: æå–åˆ°çš„è¯­ä¹‰è§’è‰²åˆ—è¡¨
        """
        import re
        characters = []
        
        # è¯­ä¹‰æ¨¡å¼ï¼šåŠ¨ä½œ+è§’è‰²å…³ç³»
        semantic_patterns = [
            # æ‰€æœ‰æ ¼æ¨¡å¼ï¼šXXçš„YY
            r'([\u4e00-\u9fa5]{2,4})çš„([\u4e00-\u9fa5]{2,4})',
            # ç§°å‘¼æ¨¡å¼ï¼šå«XXã€åå«XX
            r'(?:å«|åå«|ç§°ä¸º)([\u4e00-\u9fa5]{2,4})',
            # ä»‹ç»æ¨¡å¼ï¼šè¿™æ˜¯XXã€é‚£æ˜¯XX
            r'(?:è¿™æ˜¯|é‚£æ˜¯|å°±æ˜¯)([\u4e00-\u9fa5]{2,4})',
            # åŠ¨ä½œä¸»è¯­æ¨¡å¼ï¼šXXåšäº†ä»€ä¹ˆ
            r'([\u4e00-\u9fa5]{2,4})(?:æ­£åœ¨|åœ¨|å¼€å§‹|ç»§ç»­|åœæ­¢)([\u4e00-\u9fa5]+)',
        ]
        
        # è§’è‰²æŒ‡ç¤ºè¯
        role_indicators = [
            'äºº', 'è€…', 'å‘˜', 'å¸ˆ', 'ç”Ÿ', 'æ‰‹', 'å·¥', 'å®¶', 'é•¿', 'ä¸»', 'å®¢', 'å‹'
        ]
        
        for pattern in semantic_patterns:
            matches = re.findall(pattern, description)
            for match in matches:
                if isinstance(match, tuple):
                    # å¤„ç†å…ƒç»„åŒ¹é…
                    for part in match:
                        if self._is_likely_character_name(part, role_indicators):
                            characters.append(part)
                else:
                    # å¤„ç†å•ä¸ªåŒ¹é…
                    if self._is_likely_character_name(match, role_indicators):
                        characters.append(match)
        
        return characters
    
    def _is_likely_character_name(self, text: str, role_indicators: list) -> bool:
        """
        åˆ¤æ–­æ–‡æœ¬æ˜¯å¦å¯èƒ½æ˜¯è§’è‰²åç§°
        
        Args:
            text: å¾…åˆ¤æ–­çš„æ–‡æœ¬
            role_indicators: è§’è‰²æŒ‡ç¤ºè¯åˆ—è¡¨
            
        Returns:
            bool: æ˜¯å¦å¯èƒ½æ˜¯è§’è‰²åç§°
        """
        if not text or len(text) < 2:
            return False
        
        # æ’é™¤æ˜æ˜¾ä¸æ˜¯è§’è‰²çš„è¯æ±‡
        non_character_words = [
            'æ—¶å€™', 'åœ°æ–¹', 'ä¸œè¥¿', 'äº‹æƒ…', 'é—®é¢˜', 'æ–¹æ³•', 'åŠæ³•', 'æ ·å­',
            'é¢œè‰²', 'å£°éŸ³', 'å‘³é“', 'æ„Ÿè§‰', 'å¿ƒæƒ…', 'æƒ³æ³•', 'æ„æ€', 'å†…å®¹'
        ]
        
        if text in non_character_words:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è§’è‰²æŒ‡ç¤ºè¯
        for indicator in role_indicators:
            if text.endswith(indicator):
                return True
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§äººåæ¨¡å¼
        import re
        if re.match(r'^[\u4e00-\u9fa5]{2,4}$', text):
            return True
        
        return False
    
    def _extract_keyword_characters(self, description: str) -> list:
        """
        ä¼ ç»Ÿå…³é”®è¯åŒ¹é…è§’è‰²æå–
        
        Args:
            description: ç”»é¢æè¿°æ–‡æœ¬
            
        Returns:
            list: æå–åˆ°çš„è§’è‰²åˆ—è¡¨
        """
        characters = []
        
        # æ‰©å±•çš„è§’è‰²å…³é”®è¯åº“
        character_keywords = [
            # ä¸»è¦è§’è‰²
            'ä¸»äººå…¬', 'ä¸»è§’', 'ç”·ä¸»', 'å¥³ä¸»', 'ä¸»äººç¿',
            # åŸºæœ¬äººç‰©ç±»å‹
            'ç”·å­', 'å¥³å­', 'ç”·äºº', 'å¥³äºº', 'ç”·å­©', 'å¥³å­©', 'å­©å­', 'å°å­©',
            'è€äºº', 'è€è€…', 'é•¿è€…', 'å¹´è½»äºº', 'é’å¹´', 'ä¸­å¹´äºº',
            # å®¶åº­å…³ç³»
            'çˆ¶äº²', 'æ¯äº²', 'çˆ¸çˆ¸', 'å¦ˆå¦ˆ', 'çˆ·çˆ·', 'å¥¶å¥¶', 'å¤–å…¬', 'å¤–å©†',
            'å„¿å­', 'å¥³å„¿', 'å“¥å“¥', 'å§å§', 'å¼Ÿå¼Ÿ', 'å¦¹å¦¹', 'ä¸ˆå¤«', 'å¦»å­',
            # èŒä¸šèº«ä»½
            'åŒ»ç”Ÿ', 'æŠ¤å£«', 'è€å¸ˆ', 'æ•™æˆ', 'å­¦ç”Ÿ', 'è­¦å¯Ÿ', 'å†›äºº', 'å£«å…µ',
            'å¸æœº', 'å·¥äºº', 'å†œæ°‘', 'å•†äºº', 'è€æ¿', 'ç»ç†', 'ç§˜ä¹¦', 'åŠ©ç†',
            'æœåŠ¡å‘˜', 'åº—ä¸»', 'åº—å‘˜', 'æ”¶é“¶å‘˜', 'ä¿å®‰', 'é—¨å«', 'æ¸…æ´å·¥',
            'å¨å¸ˆ', 'å¾‹å¸ˆ', 'æ³•å®˜', 'è®°è€…', 'æ¼”å‘˜', 'æ­Œæ‰‹', 'ç”»å®¶', 'ä½œå®¶',
            # ç‰¹å¾æè¿°
            'å…‰å¤´å¤§å”', 'å¤§å”', 'å¤§çˆ·', 'å¤§å¦ˆ', 'é˜¿å§¨', 'å”å”', 'å©¶å©¶',
            'å¸…å“¥', 'ç¾å¥³', 'èƒ–å­', 'ç˜¦å­', 'é«˜ä¸ªå­', 'çŸ®ä¸ªå­',
            # ç¾¤ä½“è§’è‰²
            'è·¯äºº', 'è¡Œäºº', 'ä¹˜å®¢', 'é¡¾å®¢', 'å®¢äºº', 'è§‚ä¼—', 'ç¾¤ä¼—', 'æ°‘ä¼—',
            'åŒäº‹', 'æœ‹å‹', 'åŒå­¦', 'é‚»å±…', 'é™Œç”Ÿäºº'
        ]
        
        for keyword in character_keywords:
            if keyword in description:
                # ä½¿ç”¨è§’è‰²åç§°æ ‡å‡†åŒ–
                normalized_name = CharacterDetectionConfig.normalize_character_name(keyword)
                characters.append(normalized_name)
        
        return characters

    def _get_current_project_style(self) -> str:
        """ä»é¡¹ç›®é…ç½®ä¸­è·å–å½“å‰é£æ ¼

        Returns:
            str: å½“å‰é¡¹ç›®çš„é£æ ¼è®¾ç½®
        """
        try:
            if not self.project_root:
                logger.warning("é¡¹ç›®æ ¹ç›®å½•æœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤é£æ ¼")
                return "ç”µå½±é£æ ¼"

            import json
            import os
            project_json_path = os.path.join(self.project_root, "project.json")

            if not os.path.exists(project_json_path):
                logger.warning(f"é¡¹ç›®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {project_json_path}")
                return "ç”µå½±é£æ ¼"

            with open(project_json_path, 'r', encoding='utf-8') as f:
                project_data = json.load(f)

            # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆä»äº”é˜¶æ®µåˆ†é•œç³»ç»Ÿä¸­è·å–é£æ ¼
            current_style = None

            # 1. é¦–å…ˆå°è¯•ä»äº”é˜¶æ®µåˆ†é•œæ•°æ®ä¸­è·å–
            if 'five_stage_storyboard' in project_data:
                five_stage_data = project_data['five_stage_storyboard']
                current_style = five_stage_data.get('selected_style')
                if current_style:
                    logger.info(f"ä»äº”é˜¶æ®µåˆ†é•œç³»ç»Ÿè·å–å½“å‰é£æ ¼: {current_style}")
                    return current_style

            # 2. å…¶æ¬¡å°è¯•ä»é¡¹ç›®æ ¹çº§åˆ«è·å–
            current_style = project_data.get('selected_style') or project_data.get('style')
            if current_style:
                logger.info(f"ä»é¡¹ç›®æ ¹çº§åˆ«è·å–å½“å‰é£æ ¼: {current_style}")
                return current_style

            # 3. æœ€åä½¿ç”¨é»˜è®¤é£æ ¼
            logger.warning("æœªæ‰¾åˆ°é¡¹ç›®é£æ ¼è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤é£æ ¼")
            return "ç”µå½±é£æ ¼"

        except Exception as e:
            logger.error(f"è·å–é¡¹ç›®é£æ ¼å¤±è´¥: {e}")
            return "ç”µå½±é£æ ¼"

    def _remove_existing_style_prompts(self, description: str, style_prompts: dict) -> str:
        """ç§»é™¤æè¿°ä¸­å·²å­˜åœ¨çš„é£æ ¼æç¤ºè¯

        Args:
            description: åŸå§‹æè¿°
            style_prompts: é£æ ¼æç¤ºè¯å­—å…¸

        Returns:
            str: æ¸…ç†åçš„æè¿°
        """
        import re

        cleaned_desc = description.strip()

        # æ”¶é›†æ‰€æœ‰é£æ ¼æç¤ºè¯
        all_style_keywords = []
        for style_prompt in style_prompts.values():
            # åˆ†å‰²é£æ ¼æç¤ºè¯
            keywords = [kw.strip() for kw in style_prompt.split('ï¼Œ') if kw.strip()]
            all_style_keywords.extend(keywords)

        # æ·»åŠ å¸¸è§çš„é£æ ¼å…³é”®è¯
        additional_keywords = [
            'ç”µå½±æ„Ÿ', 'è¶…å†™å®', '4K', 'èƒ¶ç‰‡é¢—ç²’', 'æ™¯æ·±',
            'åŠ¨æ¼«é£', 'é²œè‰³è‰²å½©', 'å¹²å‡€çº¿æ¡', 'èµ›ç’ç’æ¸²æŸ“', 'æ—¥æœ¬åŠ¨ç”»',
            'å‰åœåŠ›é£', 'æŸ”å’Œè‰²å½©', 'å¥‡å¹»', 'æ¢¦å¹»', 'ä¸°å¯ŒèƒŒæ™¯',
            'èµ›åšæœ‹å…‹', 'éœ“è™¹ç¯', 'æœªæ¥éƒ½å¸‚', 'é›¨å¤œ', 'æš—è‰²æ°›å›´',
            'æ°´å½©ç”»é£', 'æŸ”å’Œç¬”è§¦', 'ç²‰å½©è‰²', 'æ’ç”»', 'æ¸©æŸ”',
            'åƒç´ é£', '8ä½', 'å¤å¤', 'ä½åˆ†è¾¨ç‡', 'æ¸¸æˆé£',
            'çœŸå®å…‰çº¿', 'é«˜ç»†èŠ‚', 'å†™å®æ‘„å½±'
        ]
        all_style_keywords.extend(additional_keywords)

        # ç§»é™¤é‡å¤çš„å…³é”®è¯
        all_style_keywords = list(set(all_style_keywords))

        # æ„å»ºæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼ŒåŒ¹é…é£æ ¼æç¤ºè¯
        # åŒ¹é…æ¨¡å¼ï¼šï¼Œé£æ ¼è¯1ï¼Œé£æ ¼è¯2ï¼Œé£æ ¼è¯3 æˆ–è€… é£æ ¼è¯1ï¼Œé£æ ¼è¯2ï¼Œé£æ ¼è¯3
        for keyword in all_style_keywords:
            # è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
            escaped_keyword = re.escape(keyword)

            # åŒ¹é…æ¨¡å¼ï¼š
            # 1. ï¼Œå…³é”®è¯ï¼ˆåœ¨å¥å­ä¸­é—´ï¼‰
            # 2. å…³é”®è¯ï¼Œï¼ˆåœ¨å¥å­å¼€å¤´ï¼‰
            # 3. ï¼Œå…³é”®è¯ï¼ˆåœ¨å¥å­ç»“å°¾ï¼‰
            patterns = [
                rf'ï¼Œ\s*{escaped_keyword}\s*(?=ï¼Œ|$)',  # ï¼Œå…³é”®è¯ï¼Œæˆ–ï¼Œå…³é”®è¯ï¼ˆç»“å°¾ï¼‰
                rf'^{escaped_keyword}\s*ï¼Œ\s*',        # å…³é”®è¯ï¼Œï¼ˆå¼€å¤´ï¼‰
                rf'ï¼Œ\s*{escaped_keyword}$',           # ï¼Œå…³é”®è¯ï¼ˆç»“å°¾ï¼‰
                rf'^{escaped_keyword}$'                # å•ç‹¬çš„å…³é”®è¯
            ]

            for pattern in patterns:
                cleaned_desc = re.sub(pattern, '', cleaned_desc)

        # æ¸…ç†å¤šä½™çš„é€—å·å’Œç©ºæ ¼
        cleaned_desc = re.sub(r'ï¼Œ+', 'ï¼Œ', cleaned_desc)  # å¤šä¸ªé€—å·åˆå¹¶ä¸ºä¸€ä¸ª
        cleaned_desc = re.sub(r'^ï¼Œ+|ï¼Œ+$', '', cleaned_desc)  # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„é€—å·
        cleaned_desc = re.sub(r'\s+', ' ', cleaned_desc)  # å¤šä¸ªç©ºæ ¼åˆå¹¶ä¸ºä¸€ä¸ª
        cleaned_desc = cleaned_desc.strip()

        if cleaned_desc != description:
            logger.info(f"æ¸…ç†é£æ ¼æç¤ºè¯: '{description}' -> '{cleaned_desc}'")

        return cleaned_desc

    def _save_generated_text_to_file(self, enhanced_descriptions):
        """ä¿å­˜ç”Ÿæˆçš„æ–‡æœ¬åˆ°é¡¹ç›®textsæ–‡ä»¶å¤¹çš„promptæ–‡ä»¶"""
        try:
            import os
            import json
            from datetime import datetime
            
            # è·å–é¡¹ç›®æ ¹ç›®å½•
            if hasattr(self, 'project_root') and self.project_root:
                project_root = self.project_root
            else:
                logger.error("æœªè®¾ç½®é¡¹ç›®æ ¹ç›®å½•ï¼Œæ— æ³•ä¿å­˜å¢å¼ºæè¿°æ–‡ä»¶")
                return
                
            # æ„å»ºé¡¹ç›®è¾“å‡ºç›®å½•ä¸‹çš„textsæ–‡ä»¶å¤¹è·¯å¾„
            # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„é¡¹ç›®ç›®å½•ç»“æ„ï¼šproject_root/texts
            texts_dir = os.path.join(project_root, "texts")
            
            # æ£€æŸ¥textsç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
            # æ³¨æ„ï¼šè¿™é‡Œåº”è¯¥ä½¿ç”¨é¡¹ç›®ç›®å½•ä¸‹çš„textsï¼Œè€Œä¸æ˜¯ç¨‹åºæ ¹ç›®å½•ä¸‹çš„texts
            if not os.path.exists(texts_dir):
                os.makedirs(texts_dir)
            
            # æŒ‰åœºæ™¯ç»„ç»‡æ•°æ®
            scenes_data = {}
            
            # åˆ†ç¦»åœºæ™¯æ ‡é¢˜å’Œé•œå¤´æ•°æ®
            scene_titles = []
            shot_descriptions = []
            
            for desc in enhanced_descriptions:
                if desc.get('type') == 'scene_title':
                    scene_titles.append(desc)
                else:
                    shot_descriptions.append(desc)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„åœºæ™¯ä¿¡æ¯
            has_valid_scenes = len(scene_titles) > 0
            logger.info(f"[_save_generated_text_to_file] å‘ç° {len(scene_titles)} ä¸ªåœºæ™¯æ ‡é¢˜ï¼Œ{len(shot_descriptions)} ä¸ªé•œå¤´")
            
            if scene_titles:
                for scene_title_data in scene_titles:
                    scene_name = scene_title_data.get('content', '## åœºæ™¯åˆ†é•œè„šæœ¬')
                    logger.info(f"[_save_generated_text_to_file] å¤„ç†åœºæ™¯: '{scene_name}'")
            
            # å¦‚æœæ²¡æœ‰åœºæ™¯æ ‡é¢˜ï¼Œæ£€æŸ¥é•œå¤´ä¸­çš„åœºæ™¯ä¿¡æ¯
            if not has_valid_scenes:
                for i, desc in enumerate(shot_descriptions):
                    scene_info = desc.get('shot_info', {}).get('scene', '')
                    logger.info(f"[_save_generated_text_to_file] é•œå¤´ {i+1} çš„åœºæ™¯ä¿¡æ¯: '{scene_info}'")
                    if scene_info and scene_info.strip() and scene_info != 'None' and not scene_info.startswith('## åœºæ™¯åˆ†é•œè„šæœ¬'):
                        has_valid_scenes = True
                        logger.info(f"[_save_generated_text_to_file] å‘ç°æœ‰æ•ˆåœºæ™¯ä¿¡æ¯: '{scene_info}'")
                        break
            logger.info(f"[_save_generated_text_to_file] æ˜¯å¦æœ‰æœ‰æ•ˆåœºæ™¯ä¿¡æ¯: {has_valid_scenes}")
            
            if not has_valid_scenes:
                # æ‰€æœ‰é•œå¤´éƒ½æ”¾åœ¨ç»Ÿä¸€çš„åœºæ™¯åˆ†é•œè„šæœ¬ä¸‹
                scene_name = "## åœºæ™¯åˆ†é•œè„šæœ¬"
                scenes_data[scene_name] = []
                
                for i, desc in enumerate(shot_descriptions):
                    # é‡æ–°æ„å»ºoriginal_descriptionï¼ŒåŒ…å«å®Œæ•´çš„åˆ†é•œè„šæœ¬æ ¼å¼
                    # åœ¨ç»Ÿä¸€åœºæ™¯ä¸‹ï¼Œé•œå¤´ç¼–å·ä»1å¼€å§‹è¿ç»­ç¼–å·
                    shot_number = f"### é•œå¤´{i+1}"
                    shot_info = desc.get('shot_info', {})
                    
                    # æ„å»ºå®Œæ•´çš„original_descriptionï¼ŒåŒ…å«æ‰€æœ‰æŠ€æœ¯ç»†èŠ‚
                    original_parts = [shot_number]
                    
                    # æŒ‰ç…§æ ‡å‡†åˆ†é•œè„šæœ¬æ ¼å¼æ·»åŠ æŠ€æœ¯ç»†èŠ‚
                    technical_fields = [
                        'é•œå¤´ç±»å‹', 'æœºä½è§’åº¦', 'é•œå¤´è¿åŠ¨', 'æ™¯æ·±æ•ˆæœ', 'æ„å›¾è¦ç‚¹', 
                        'å…‰å½±è®¾è®¡', 'è‰²å½©åŸºè°ƒ', 'æ—¶é•¿', 'é•œå¤´è§’è‰²', 'ç”»é¢æè¿°', 
                        'å°è¯/æ—ç™½', 'éŸ³æ•ˆæç¤º', 'è½¬åœºæ–¹å¼'
                    ]
                    
                    # å­—æ®µæ ‡å‡†åŒ–ï¼šç¡®ä¿æ‰€æœ‰é•œå¤´éƒ½åŒ…å«å®Œæ•´çš„æŠ€æœ¯å­—æ®µ
                    default_values = {
                        'é•œå¤´ç±»å‹': 'ä¸­æ™¯',
                        'æœºä½è§’åº¦': 'å¹³è§†',
                        'é•œå¤´è¿åŠ¨': 'é™æ­¢',
                        'æ™¯æ·±æ•ˆæœ': 'æ­£å¸¸æ™¯æ·±',
                        'æ„å›¾è¦ç‚¹': 'å±…ä¸­æ„å›¾',
                        'å…‰å½±è®¾è®¡': 'è‡ªç„¶å…‰',
                        'è‰²å½©åŸºè°ƒ': 'è‡ªç„¶è‰²è°ƒ',
                        # 'æ—¶é•¿': '3ç§’',  # ç§»é™¤ç¡¬ç¼–ç æ—¶é•¿ï¼Œåº”æ ¹æ®é…éŸ³ç¡®å®š
                        'éŸ³æ•ˆæç¤º': 'ç¯å¢ƒéŸ³',
                        'è½¬åœºæ–¹å¼': 'åˆ‡æ¢'
                    }
                    
                    for field in technical_fields:
                        if field in shot_info and shot_info[field]:
                            original_parts.append(f"- **{field}**ï¼š{shot_info[field]}")
                        elif field in default_values:
                            # å¦‚æœå­—æ®µç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼
                            original_parts.append(f"- **{field}**ï¼š{default_values[field]}")
                            logger.debug(f"ä¸ºé•œå¤´ {shot_number} æ·»åŠ ç¼ºå¤±å­—æ®µ {field}: {default_values[field]}")
                    
                    original_description = '\n'.join(original_parts)
                    
                    # ä»enhanced_descriptionsä¸­æå–æ­£ç¡®çš„å­—æ®µ
                    shot_data = {
                        "shot_number": shot_number,
                        "original_description": original_description,
                        "enhanced_prompt": desc.get('enhanced', '')
                    }
                    scenes_data[scene_name].append(shot_data)
            else:
                # æŒ‰å®é™…åœºæ™¯åˆ†ç»„ï¼Œå¹¶åœ¨æ¯ä¸ªåœºæ™¯å†…é‡æ–°ç¼–å·
                # å¦‚æœæœ‰åœºæ™¯æ ‡é¢˜ï¼Œæ ¹æ®é•œå¤´ä¸­çš„åœºæ™¯ä¿¡æ¯æ­£ç¡®åˆ†ç»„
                if scene_titles:
                    # é¦–å…ˆæŒ‰é•œå¤´ä¸­çš„åœºæ™¯ä¿¡æ¯åˆ†ç»„
                    scene_groups = {}
                    for desc in shot_descriptions:
                        # ä»é•œå¤´çš„shot_infoä¸­è·å–åœºæ™¯ä¿¡æ¯
                        scene_info = desc.get('shot_info', {}).get('scene', '')
                        if not scene_info or scene_info.strip() == '' or scene_info == 'None':
                            scene_info = 'æœªçŸ¥åœºæ™¯'

                        if scene_info not in scene_groups:
                            scene_groups[scene_info] = []
                        scene_groups[scene_info].append(desc)

                    logger.info(f"æŒ‰é•œå¤´åœºæ™¯ä¿¡æ¯åˆ†ç»„ç»“æœ: {list(scene_groups.keys())}")

                    # å¦‚æœåœºæ™¯åˆ†ç»„å¤±è´¥ï¼ˆæ‰€æœ‰é•œå¤´éƒ½åœ¨åŒä¸€ä¸ªåœºæ™¯ï¼‰ï¼Œåˆ™ä½¿ç”¨åœºæ™¯æ ‡é¢˜æ•°é‡å¹³å‡åˆ†é…
                    if len(scene_groups) == 1 and 'æœªçŸ¥åœºæ™¯' in scene_groups:
                        logger.info("é•œå¤´åœºæ™¯ä¿¡æ¯ä¸å®Œæ•´ï¼Œä½¿ç”¨åœºæ™¯æ ‡é¢˜æ•°é‡å¹³å‡åˆ†é…")
                        # é‡æ–°æŒ‰åœºæ™¯æ ‡é¢˜æ•°é‡åˆ†é…
                        scene_groups = {}
                        shots_per_scene = len(shot_descriptions) // len(scene_titles)
                        remaining_shots = len(shot_descriptions) % len(scene_titles)

                        shot_index = 0
                        for i, scene_title_data in enumerate(scene_titles):
                            scene_name = scene_title_data.get('content', f'## åœºæ™¯{i + 1}')
                            scene_groups[scene_name] = []

                            # è®¡ç®—å½“å‰åœºæ™¯çš„é•œå¤´æ•°é‡
                            current_shots_count = shots_per_scene
                            if i == len(scene_titles) - 1:  # æœ€åä¸€ä¸ªåœºæ™¯åŒ…å«å‰©ä½™é•œå¤´
                                current_shots_count += remaining_shots

                            # åˆ†é…é•œå¤´åˆ°å½“å‰åœºæ™¯
                            for j in range(current_shots_count):
                                if shot_index < len(shot_descriptions):
                                    scene_groups[scene_name].append(shot_descriptions[shot_index])
                                    shot_index += 1

                    # ä¸ºæ¯ä¸ªåœºæ™¯å†…çš„é•œå¤´é‡æ–°ç¼–å·å¹¶ä¿å­˜
                    for scene_name, scene_shots in scene_groups.items():
                        # æ¸…ç†åœºæ™¯åç§°ï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
                        if not scene_name.startswith('##'):
                            if scene_name.startswith('åœºæ™¯'):
                                scene_name = f"## {scene_name}"
                            else:
                                scene_name = f"## åœºæ™¯ï¼š{scene_name}"

                        scenes_data[scene_name] = []

                        for i, desc in enumerate(scene_shots):
                            # åœ¨æ¯ä¸ªåœºæ™¯å†…ï¼Œé•œå¤´ç¼–å·ä»1å¼€å§‹
                            shot_number = f"### é•œå¤´{i+1}"
                            shot_info = desc.get('shot_info', {})

                            # æ„å»ºå®Œæ•´çš„original_descriptionï¼ŒåŒ…å«æ‰€æœ‰æŠ€æœ¯ç»†èŠ‚
                            original_parts = [shot_number]

                            # æŒ‰ç…§æ ‡å‡†åˆ†é•œè„šæœ¬æ ¼å¼æ·»åŠ æŠ€æœ¯ç»†èŠ‚
                            technical_fields = [
                                'é•œå¤´ç±»å‹', 'æœºä½è§’åº¦', 'é•œå¤´è¿åŠ¨', 'æ™¯æ·±æ•ˆæœ', 'æ„å›¾è¦ç‚¹',
                                'å…‰å½±è®¾è®¡', 'è‰²å½©åŸºè°ƒ', 'æ—¶é•¿', 'é•œå¤´è§’è‰²', 'ç”»é¢æè¿°',
                                'å°è¯/æ—ç™½', 'éŸ³æ•ˆæç¤º', 'è½¬åœºæ–¹å¼'
                            ]

                            # å­—æ®µæ ‡å‡†åŒ–ï¼šç¡®ä¿æ‰€æœ‰é•œå¤´éƒ½åŒ…å«å®Œæ•´çš„æŠ€æœ¯å­—æ®µ
                            default_values = {
                                'é•œå¤´ç±»å‹': 'ä¸­æ™¯',
                                'æœºä½è§’åº¦': 'å¹³è§†',
                                'é•œå¤´è¿åŠ¨': 'é™æ­¢',
                                'æ™¯æ·±æ•ˆæœ': 'æ­£å¸¸æ™¯æ·±',
                                'æ„å›¾è¦ç‚¹': 'å±…ä¸­æ„å›¾',
                                'å…‰å½±è®¾è®¡': 'è‡ªç„¶å…‰',
                                'è‰²å½©åŸºè°ƒ': 'è‡ªç„¶è‰²è°ƒ',
                                # 'æ—¶é•¿': '3ç§’',  # ç§»é™¤ç¡¬ç¼–ç æ—¶é•¿ï¼Œåº”æ ¹æ®é…éŸ³ç¡®å®š
                                'éŸ³æ•ˆæç¤º': 'ç¯å¢ƒéŸ³',
                                'è½¬åœºæ–¹å¼': 'åˆ‡æ¢'
                            }

                            for field in technical_fields:
                                if field in shot_info and shot_info[field]:
                                    original_parts.append(f"- **{field}**ï¼š{shot_info[field]}")
                                elif field in default_values:
                                    # å¦‚æœå­—æ®µç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼
                                    original_parts.append(f"- **{field}**ï¼š{default_values[field]}")
                                    logger.debug(f"ä¸ºé•œå¤´ {shot_number} æ·»åŠ ç¼ºå¤±å­—æ®µ {field}: {default_values[field]}")

                            original_description = '\n'.join(original_parts)

                            shot_data = {
                                "shot_number": shot_number,
                                "original_description": original_description,
                                "enhanced_prompt": desc.get('enhanced', '')
                            }
                            scenes_data[scene_name].append(shot_data)

                        logger.info(f"åœºæ™¯ '{scene_name}' åŒ…å« {len(scene_shots)} ä¸ªé•œå¤´")
                else:
                    # ä½¿ç”¨é•œå¤´ä¸­çš„åœºæ™¯ä¿¡æ¯åˆ†ç»„
                    scene_groups = {}
                    for desc in shot_descriptions:
                        scene_name = desc.get('shot_info', {}).get('scene', '## åœºæ™¯ä¸€')
                        if not scene_name or scene_name.strip() == '' or scene_name == 'None':
                            scene_name = '## åœºæ™¯ä¸€'
                        
                        if scene_name not in scene_groups:
                            scene_groups[scene_name] = []
                        scene_groups[scene_name].append(desc)
                    
                    # ä¸ºæ¯ä¸ªåœºæ™¯å†…çš„é•œå¤´é‡æ–°ç¼–å·
                    for scene_name, scene_shots in scene_groups.items():
                        scenes_data[scene_name] = []
                        
                        for i, desc in enumerate(scene_shots):
                            # åœ¨æ¯ä¸ªåœºæ™¯å†…ï¼Œé•œå¤´ç¼–å·ä»1å¼€å§‹
                            shot_number = f"### é•œå¤´{i+1}"
                            shot_info = desc.get('shot_info', {})
                            
                            # æ„å»ºå®Œæ•´çš„original_descriptionï¼ŒåŒ…å«æ‰€æœ‰æŠ€æœ¯ç»†èŠ‚
                            original_parts = [shot_number]
                            
                            # æŒ‰ç…§æ ‡å‡†åˆ†é•œè„šæœ¬æ ¼å¼æ·»åŠ æŠ€æœ¯ç»†èŠ‚
                            technical_fields = [
                                'é•œå¤´ç±»å‹', 'æœºä½è§’åº¦', 'é•œå¤´è¿åŠ¨', 'æ™¯æ·±æ•ˆæœ', 'æ„å›¾è¦ç‚¹', 
                                'å…‰å½±è®¾è®¡', 'è‰²å½©åŸºè°ƒ', 'æ—¶é•¿', 'é•œå¤´è§’è‰²', 'ç”»é¢æè¿°', 
                                'å°è¯/æ—ç™½', 'éŸ³æ•ˆæç¤º', 'è½¬åœºæ–¹å¼'
                            ]
                            
                            # å­—æ®µæ ‡å‡†åŒ–ï¼šç¡®ä¿æ‰€æœ‰é•œå¤´éƒ½åŒ…å«å®Œæ•´çš„æŠ€æœ¯å­—æ®µ
                            default_values = {
                                'é•œå¤´ç±»å‹': 'ä¸­æ™¯',
                                'æœºä½è§’åº¦': 'å¹³è§†',
                                'é•œå¤´è¿åŠ¨': 'é™æ­¢',
                                'æ™¯æ·±æ•ˆæœ': 'æ­£å¸¸æ™¯æ·±',
                                'æ„å›¾è¦ç‚¹': 'å±…ä¸­æ„å›¾',
                                'å…‰å½±è®¾è®¡': 'è‡ªç„¶å…‰',
                                'è‰²å½©åŸºè°ƒ': 'è‡ªç„¶è‰²è°ƒ',
                                # 'æ—¶é•¿': '3ç§’',  # ç§»é™¤ç¡¬ç¼–ç æ—¶é•¿ï¼Œåº”æ ¹æ®é…éŸ³ç¡®å®š
                                'éŸ³æ•ˆæç¤º': 'ç¯å¢ƒéŸ³',
                                'è½¬åœºæ–¹å¼': 'åˆ‡æ¢'
                            }
                            
                            for field in technical_fields:
                                if field in shot_info and shot_info[field]:
                                    original_parts.append(f"- **{field}**ï¼š{shot_info[field]}")
                                elif field in default_values:
                                    # å¦‚æœå­—æ®µç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼
                                    original_parts.append(f"- **{field}**ï¼š{default_values[field]}")
                                    logger.debug(f"ä¸ºé•œå¤´ {shot_number} æ·»åŠ ç¼ºå¤±å­—æ®µ {field}: {default_values[field]}")
                            
                            original_description = '\n'.join(original_parts)
                            
                            shot_data = {
                                "shot_number": shot_number,
                                "original_description": original_description,
                                "enhanced_prompt": desc.get('enhanced', '')
                            }
                            scenes_data[scene_name].append(shot_data)
            
            # å‡†å¤‡ä¿å­˜çš„æ•°æ®
            prompt_data = {
                "scenes": scenes_data,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "source": "scene_description_enhancer",
                "version": "2.0"
            }
            
            # ä¿å­˜åˆ°promptæ–‡ä»¶
            prompt_file = os.path.join(texts_dir, "prompt.json")
            with open(prompt_file, 'w', encoding='utf-8') as f:
                json.dump(prompt_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"åœºæ™¯å¢å¼ºå™¨ç”Ÿæˆçš„ä¼˜åŒ–æç¤ºè¯å·²ä¿å­˜åˆ°: {prompt_file}")
                
        except Exception as e:
            logger.error(f"ä¿å­˜ç”Ÿæˆæ–‡æœ¬åˆ°æ–‡ä»¶å¤±è´¥: {e}")

    def _save_enhanced_descriptions_to_project(self, enhanced_descriptions: List[Dict[str, Any]]):
        """å°†å¢å¼ºæè¿°ä¿å­˜åˆ°project.jsonæ–‡ä»¶ä¸­ï¼ˆå®Œå…¨é‡å†™ï¼Œç¡®ä¿å…¨å±€é•œå¤´ç¼–å·ï¼‰"""
        try:
            # æŸ¥æ‰¾project.jsonæ–‡ä»¶
            project_file = None
            if self.project_root:
                project_file = os.path.join(self.project_root, "project.json")

            if not project_file or not os.path.exists(project_file):
                logger.warning("æœªæ‰¾åˆ°project.jsonæ–‡ä»¶ï¼Œæ— æ³•ä¿å­˜å¢å¼ºæè¿°")
                return

            # è¯»å–ç°æœ‰çš„project.jsonæ•°æ®
            with open(project_file, 'r', encoding='utf-8') as f:
                project_data = json.load(f)

            # ğŸ”§ ä¿®å¤ï¼šå®Œå…¨é‡å†™enhanced_descriptionså­—æ®µï¼Œç¡®ä¿å…¨å±€é•œå¤´ç¼–å·
            # ä¸å†ç´¯ç§¯ä¿å­˜ï¼Œè€Œæ˜¯å®Œå…¨æ›¿æ¢ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»åœ¨enhance_storyboardä¸­å¤„ç†äº†å…¨å±€ç¼–å·
            enhanced_data = {}

            logger.info(f"ğŸ”§ å¼€å§‹ä¿å­˜{len(enhanced_descriptions)}ä¸ªå¢å¼ºæè¿°åˆ°project.json")

            for i, desc in enumerate(enhanced_descriptions):
                if desc.get('type') == 'scene_title':
                    continue  # è·³è¿‡åœºæ™¯æ ‡é¢˜

                shot_number = desc.get('é•œå¤´ç¼–å·', '')
                scene = desc.get('scene', '')
                enhanced_prompt = desc.get('enhanced', '')
                original_prompt = desc.get('original', '')

                if shot_number and enhanced_prompt:
                    # ğŸ”§ ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨å·²ç»å¤„ç†è¿‡çš„å…¨å±€é•œå¤´ç¼–å·
                    # ä¸å†é‡æ–°å¤„ç†ï¼Œå› ä¸ºenhance_storyboardæ–¹æ³•å·²ç»ç¡®ä¿äº†å…¨å±€å”¯ä¸€æ€§
                    shot_key = shot_number  # ç›´æ¥ä½¿ç”¨ï¼Œåº”è¯¥å·²ç»æ˜¯"### é•œå¤´X"æ ¼å¼

                    enhanced_data[shot_key] = {
                        'shot_number': shot_key,
                        'scene': scene,
                        'original_prompt': original_prompt,
                        'enhanced_prompt': enhanced_prompt,
                        'technical_details': desc.get('technical_details', ''),
                        'consistency_info': desc.get('consistency_info', ''),
                        'characters': desc.get('characters', []),
                        'fusion_quality_score': desc.get('fusion_quality_score', 0.0)
                    }

                    logger.debug(f"ä¿å­˜é•œå¤´ {i+1}/{len(enhanced_descriptions)}: {shot_key}")

            # ğŸ”§ ä¿®å¤ï¼šå®Œå…¨æ›¿æ¢enhanced_descriptionså­—æ®µ
            project_data['enhanced_descriptions'] = enhanced_data

            # ä¿å­˜æ›´æ–°åçš„project.json
            with open(project_file, 'w', encoding='utf-8') as f:
                json.dump(project_data, f, ensure_ascii=False, indent=2)

            total_shots = len(enhanced_data)
            logger.info(f"âœ… å·²å°†{total_shots}ä¸ªå¢å¼ºæè¿°å®Œå…¨ä¿å­˜åˆ°project.json")

            # ğŸ”§ æ–°å¢ï¼šéªŒè¯ä¿å­˜ç»“æœ
            if total_shots > 0:
                shot_numbers = list(enhanced_data.keys())
                logger.info(f"ä¿å­˜çš„é•œå¤´ç¼–å·: {shot_numbers[:5]}{'...' if len(shot_numbers) > 5 else ''}")

                # æ£€æŸ¥é•œå¤´ç¼–å·æ˜¯å¦è¿ç»­
                import re
                numbers = []
                for shot_key in shot_numbers:
                    match = re.search(r'é•œå¤´(\d+)', shot_key)
                    if match:
                        numbers.append(int(match.group(1)))

                if numbers:
                    numbers.sort()
                    logger.info(f"é•œå¤´ç¼–å·èŒƒå›´: {min(numbers)} - {max(numbers)}")
                    if numbers == list(range(min(numbers), max(numbers) + 1)):
                        logger.info("âœ… é•œå¤´ç¼–å·è¿ç»­ï¼Œä¿å­˜æˆåŠŸ")
                    else:
                        logger.warning("âš ï¸ é•œå¤´ç¼–å·ä¸è¿ç»­ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜")

        except Exception as e:
            logger.error(f"ä¿å­˜å¢å¼ºæè¿°åˆ°project.jsonå¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

    # ğŸ”§ ä¿®æ”¹ï¼šç§»é™¤save_original_descriptions_by_sceneæ–¹æ³•ï¼Œæ”¹ä¸ºåœ¨æ‰€æœ‰åœºæ™¯å®Œæˆåç»Ÿä¸€å¤„ç†ä¸€è‡´æ€§æè¿°

    def _intelligent_character_embedding_filter(self, description: str, detected_characters: List[str]) -> List[str]:
        """æ™ºèƒ½è¿‡æ»¤éœ€è¦åµŒå…¥ä¸€è‡´æ€§æè¿°çš„è§’è‰²

        Args:
            description: ç”»é¢æè¿°
            detected_characters: æ£€æµ‹åˆ°çš„è§’è‰²åˆ—è¡¨

        Returns:
            List[str]: éœ€è¦åµŒå…¥ä¸€è‡´æ€§æè¿°çš„è§’è‰²åˆ—è¡¨
        """
        if not detected_characters:
            return []

        try:
            # ä½¿ç”¨LLMæ™ºèƒ½åˆ¤æ–­
            if hasattr(self, 'llm_api') and self.llm_api and self.llm_api.is_configured():
                return self._llm_character_embedding_filter(description, detected_characters)
            else:
                # å¦‚æœLLMä¸å¯ç”¨ï¼Œä½¿ç”¨è§„åˆ™è¿‡æ»¤
                return self._rule_based_character_embedding_filter(description, detected_characters)
        except Exception as e:
            logger.error(f"æ™ºèƒ½è§’è‰²è¿‡æ»¤å¤±è´¥: {e}")
            # å‡ºé”™æ—¶è¿”å›æ‰€æœ‰è§’è‰²
            return detected_characters

    def _llm_character_embedding_filter(self, description: str, detected_characters: List[str]) -> List[str]:
        """ä½¿ç”¨LLMæ™ºèƒ½åˆ¤æ–­å“ªäº›è§’è‰²éœ€è¦åµŒå…¥ä¸€è‡´æ€§æè¿°"""
        try:
            characters_str = 'ã€'.join(detected_characters)
            prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”»é¢æè¿°ï¼Œåˆ¤æ–­å“ªäº›è§’è‰²éœ€è¦åµŒå…¥å¤–è²Œä¸€è‡´æ€§æè¿°ã€‚

é€šç”¨è§„åˆ™ï¼ˆé€‚ç”¨äºå„ç§æ–‡å­¦ä½œå“ï¼‰ï¼š
1. å¦‚æœè§’è‰²æœ¬äººç›´æ¥å‡ºç°åœ¨ç”»é¢ä¸­ï¼Œéœ€è¦åµŒå…¥ä¸€è‡´æ€§æè¿°
   - å†å²é¢˜æï¼šå¦‚"èµµæ‹¬ä¸¥è‚ƒçš„é¢å­”"ã€"å»‰é¢‡çš„è¡¨æƒ…"
   - ç°ä»£é¢˜æï¼šå¦‚"å¼ åŒ»ç”Ÿç–²æƒ«çš„ç¥æƒ…"ã€"æè€å¸ˆæ¸©å’Œçš„ç¬‘å®¹"
   - ç§‘å¹»é¢˜æï¼šå¦‚"æœºå™¨äººX-01çš„é‡‘å±å¤–å£³"ã€"å¤–æ˜Ÿäººé¦–é¢†çš„è§¦æ‰‹"
   - å¥‡å¹»é¢˜æï¼šå¦‚"ç²¾çµç‹å­çš„å°–è€³æœµ"ã€"çŸ®äººæˆ˜å£«çš„èƒ¡é¡»"

2. å¦‚æœåªæ˜¯æåˆ°è§’è‰²çš„ç‰©å“ã€åŠ¿åŠ›ã€å½±å“ç­‰ï¼Œä¸éœ€è¦åµŒå…¥
   - å†å²é¢˜æï¼šå¦‚"èµµæ‹¬çš„å†›é˜Ÿ"ã€"å»‰é¢‡çš„æˆ˜ç•¥"
   - ç°ä»£é¢˜æï¼šå¦‚"å¼ åŒ»ç”Ÿçš„è¯Šæ‰€"ã€"æè€å¸ˆçš„è¯¾å ‚"
   - ç§‘å¹»é¢˜æï¼šå¦‚"æœºå™¨äººçš„å·¥å‚"ã€"å¤–æ˜Ÿäººçš„é£èˆ¹"
   - å¥‡å¹»é¢˜æï¼šå¦‚"ç²¾çµçš„æ£®æ—"ã€"çŸ®äººçš„çŸ¿å±±"

3. ç¾¤ä½“åœºæ™¯ä¸­çš„ä¸ªä½“è§’è‰²ï¼Œéœ€è¦åµŒå…¥
4. è¿œæ™¯æˆ–å…¨æ™¯ä¸­çš„å°äººç‰©ï¼Œå¯ä»¥ä¸åµŒå…¥

ç”»é¢æè¿°ï¼š{description}

æ£€æµ‹åˆ°çš„è§’è‰²ï¼š{characters_str}

è¯·åªè¿”å›éœ€è¦åµŒå…¥ä¸€è‡´æ€§æè¿°çš„è§’è‰²åç§°ï¼Œç”¨ä¸­æ–‡é¡¿å·ï¼ˆã€ï¼‰åˆ†éš”ã€‚å¦‚æœéƒ½ä¸éœ€è¦ï¼Œè¿”å›"æ— "ã€‚

ç¤ºä¾‹ï¼š
- "èµµæ‹¬ä¸¥è‚ƒçš„é¢å­”" â†’ èµµæ‹¬
- "èµµæ‹¬çš„å†›é˜Ÿæºƒæ•£" â†’ æ— 
- "å¼ åŒ»ç”Ÿå’ŒææŠ¤å£«äº¤è°ˆ" â†’ å¼ åŒ»ç”Ÿã€ææŠ¤å£«
- "æœºå™¨äººX-01çš„çº¢è‰²çœ¼ç›é—ªçƒ" â†’ æœºå™¨äººX-01
- "ç²¾çµçš„é­”æ³•æ£®æ—" â†’ æ— """

            # å°è¯•è°ƒç”¨LLM API
            try:
                if hasattr(self.llm_api, '_make_api_call'):
                    messages = [
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§’è‰²åˆ†æå¸ˆï¼Œæ“…é•¿åˆ¤æ–­ç”»é¢æè¿°ä¸­å“ªäº›è§’è‰²éœ€è¦è¯¦ç»†çš„å¤–è²Œæè¿°ã€‚"},
                        {"role": "user", "content": prompt}
                    ]
                    response = self.llm_api._make_api_call(
                        model_name=getattr(self.llm_api, 'rewrite_model_name', 'gpt-3.5-turbo'),
                        messages=messages,
                        task_name="character_embedding_filter"
                    )
                else:
                    # å¦‚æœæ²¡æœ‰_make_api_callæ–¹æ³•ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
                    response = None
            except Exception as api_error:
                logger.error(f"LLM APIè°ƒç”¨å¤±è´¥: {api_error}")
                response = None

            if response and response.strip() and response.strip() != "æ— ":
                # è§£æLLMè¿”å›çš„è§’è‰²åˆ—è¡¨
                filtered_characters = []
                for char in response.strip().split('ã€'):
                    char = char.strip()
                    if char and char in detected_characters:
                        filtered_characters.append(char)

                logger.info(f"LLMæ™ºèƒ½è¿‡æ»¤ç»“æœ: {detected_characters} â†’ {filtered_characters}")
                return filtered_characters
            else:
                logger.info("LLMåˆ¤æ–­æ— éœ€åµŒå…¥ä»»ä½•è§’è‰²ä¸€è‡´æ€§æè¿°")
                return []

        except Exception as e:
            logger.error(f"LLMè§’è‰²è¿‡æ»¤å¤±è´¥: {e}")
            return self._rule_based_character_embedding_filter(description, detected_characters)

    def _rule_based_character_embedding_filter(self, description: str, detected_characters: List[str]) -> List[str]:
        """åŸºäºè§„åˆ™çš„è§’è‰²è¿‡æ»¤ï¼ˆé€šç”¨ç‰ˆæœ¬ï¼Œé€‚ç”¨äºå„ç§æ–‡å­¦ä½œå“ï¼‰"""
        filtered_characters = []

        for character in detected_characters:
            # æ£€æŸ¥æ˜¯å¦æ˜¯"XXçš„XX"æ ¼å¼ï¼ˆé€šå¸¸ä¸éœ€è¦åµŒå…¥ï¼‰
            possession_patterns = [
                # å†å²é¢˜æ
                f"{character}çš„å†›é˜Ÿ", f"{character}çš„éƒ¨é˜Ÿ", f"{character}çš„å£«å…µ",
                f"{character}çš„å‰‘", f"{character}çš„æ­¦å™¨", f"{character}çš„è£…å¤‡",
                f"{character}çš„ç‹å›½", f"{character}çš„é¢†åœŸ", f"{character}çš„å®«æ®¿",

                # ç°ä»£é¢˜æ
                f"{character}çš„å…¬å¸", f"{character}çš„åŠå…¬å®¤", f"{character}çš„è½¦",
                f"{character}çš„æˆ¿å­", f"{character}çš„å®¶", f"{character}çš„å·¥ä½œ",
                f"{character}çš„ç”µè¯", f"{character}çš„ç”µè„‘", f"{character}çš„æ‰‹æœº",

                # ç§‘å¹»é¢˜æ
                f"{character}çš„é£èˆ¹", f"{character}çš„åŸºåœ°", f"{character}çš„å®éªŒå®¤",
                f"{character}çš„æœºå™¨äºº", f"{character}çš„AI", f"{character}çš„ç³»ç»Ÿ",

                # å¥‡å¹»é¢˜æ
                f"{character}çš„é­”æ³•", f"{character}çš„æ³•æœ¯", f"{character}çš„å’’è¯­",
                f"{character}çš„åŸå ¡", f"{character}çš„æ£®æ—", f"{character}çš„é¾™",

                # é€šç”¨
                f"{character}çš„å½±å“", f"{character}çš„å£°éŸ³", f"{character}çš„å‘½ä»¤",
                f"{character}çš„æƒ³æ³•", f"{character}çš„è®¡åˆ’", f"{character}çš„ç­–ç•¥"
            ]

            is_possession = any(pattern in description for pattern in possession_patterns)

            if not is_possession:
                # æ£€æŸ¥æ˜¯å¦ç›´æ¥æè¿°è§’è‰²æœ¬äºº
                direct_patterns = [
                    # å¤–è²Œæè¿°
                    f"{character}çš„é¢å­”", f"{character}çš„è¡¨æƒ…", f"{character}çš„çœ¼ç¥",
                    f"{character}çš„å¤´å‘", f"{character}çš„çš®è‚¤", f"{character}çš„èº«æ",

                    # æƒ…ç»ªçŠ¶æ€
                    f"{character}ä¸¥è‚ƒ", f"{character}ç„¦è™‘", f"{character}æ¿€åŠ¨",
                    f"{character}æ„¤æ€’", f"{character}é«˜å…´", f"{character}æ‚²ä¼¤",
                    f"{character}å¾®ç¬‘", f"{character}çš±çœ‰", f"{character}å“­æ³£",

                    # åŠ¨ä½œè¡Œä¸º
                    f"{character}ç«™", f"{character}å", f"{character}èµ°",
                    f"{character}è·‘", f"{character}è·³", f"{character}é£",
                    f"{character}è¯´", f"{character}å–Š", f"{character}å«",
                    f"{character}çœ‹", f"{character}å¬", f"{character}æƒ³",

                    # ç©¿ç€æ‰“æ‰®
                    f"{character}ç©¿ç€", f"{character}æˆ´ç€", f"{character}æ‹¿ç€",
                    f"{character}èº«ç€", f"{character}æ‰‹æŒ", f"{character}ä½©æˆ´"
                ]

                is_direct = any(pattern in description for pattern in direct_patterns)

                # å¦‚æœæ˜¯ç›´æ¥æè¿°æˆ–è€…è§’è‰²åç§°ç›´æ¥å‡ºç°åœ¨æè¿°ä¸­ï¼ˆä½†ä¸æ˜¯æ‰€æœ‰æ ¼å½¢å¼ï¼‰
                if is_direct or (character in description and f"{character}çš„" not in description):
                    filtered_characters.append(character)

        logger.info(f"è§„åˆ™è¿‡æ»¤ç»“æœ: {detected_characters} â†’ {filtered_characters}")
        return filtered_characters

    def _embed_character_descriptions(self, original_desc: str, detected_characters: List[str]) -> str:
        """å°†è§’è‰²ä¸€è‡´æ€§æè¿°æ™ºèƒ½åµŒå…¥åˆ°åŸå§‹æè¿°ä¸­"""
        if not detected_characters:
            return original_desc

        enhanced_desc = original_desc

        # ä½¿ç”¨LLMæ™ºèƒ½åˆ¤æ–­å“ªäº›è§’è‰²éœ€è¦åµŒå…¥ä¸€è‡´æ€§æè¿°
        characters_to_embed = self._intelligent_character_embedding_filter(original_desc, detected_characters)

        if not characters_to_embed:
            logger.info("ç»è¿‡æ™ºèƒ½åˆ†æï¼Œæ— éœ€åµŒå…¥è§’è‰²ä¸€è‡´æ€§æè¿°")
            return original_desc

        # è·å–è§’è‰²ä¸€è‡´æ€§ä¿¡æ¯
        character_descriptions = {}
        for character_name in characters_to_embed:
            # ç›´æ¥ä½¿ç”¨_get_character_consistencyæ–¹æ³•è·å–è§’è‰²ä¸€è‡´æ€§æè¿°
            character_consistency = self._get_character_consistency(character_name)
            if character_consistency:
                character_descriptions[character_name] = character_consistency
                logger.info(f"å‡†å¤‡åµŒå…¥è§’è‰²'{character_name}'çš„ä¸€è‡´æ€§æè¿°: {character_consistency}")
            else:
                logger.warning(f"è§’è‰²'{character_name}'æ²¡æœ‰å¯ç”¨çš„ä¸€è‡´æ€§æè¿°")

        # æŒ‰è§’è‰²åé•¿åº¦é™åºæ’åºï¼Œä¼˜å…ˆæ›¿æ¢æ›´é•¿çš„è§’è‰²åï¼Œé¿å…"æé™å¦ˆå¦ˆ"è¢«"æé™"è¯¯åŒ¹é…
        sorted_characters = sorted(character_descriptions.items(), key=lambda x: len(x[0]), reverse=True)
        
        # åœ¨åŸå§‹æè¿°ä¸­æ›¿æ¢è§’è‰²åç§°ä¸ºè¯¦ç»†æè¿°
        for character_name, detailed_desc in sorted_characters:
            # ä½¿ç”¨ç²¾ç¡®åŒ¹é…è¿›è¡Œè§’è‰²æ›¿æ¢ï¼Œæ”¯æŒä¸­æ–‡å­—ç¬¦
            replacement = f"{character_name}ï¼ˆ{detailed_desc}ï¼‰"
            # åªæœ‰å½“è§’è‰²åè¿˜æ²¡æœ‰è¢«æ›¿æ¢è¿‡æ—¶æ‰è¿›è¡Œæ›¿æ¢ï¼ˆé¿å…é‡å¤æ›¿æ¢ï¼‰
            if character_name in enhanced_desc and f"{character_name}ï¼ˆ" not in enhanced_desc:
                # æ£€æŸ¥å½“å‰è§’è‰²åæ˜¯å¦æ˜¯å…¶ä»–æ›´é•¿è§’è‰²åçš„ä¸€éƒ¨åˆ†
                is_part_of_longer_name = False
                for other_char_name in character_descriptions.keys():
                    if other_char_name != character_name and len(other_char_name) > len(character_name):
                        if character_name in other_char_name and other_char_name in enhanced_desc:
                            is_part_of_longer_name = True
                            break

                if not is_part_of_longer_name:
                    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ›´ç²¾ç¡®çš„æ›¿æ¢ï¼Œé¿å…é‡å¤åµŒå…¥
                    # æ£€æŸ¥æ˜¯å¦å·²ç»åµŒå…¥è¿‡è¯¥è§’è‰²çš„æè¿°
                    if f"{character_name}ï¼ˆ" not in enhanced_desc:
                        # åªæ›¿æ¢ç¬¬ä¸€æ¬¡å‡ºç°çš„å®Œæ•´è§’è‰²åç§°
                        import re
                        pattern = rf'\b{re.escape(character_name)}\b'
                        if re.search(pattern, enhanced_desc):
                            enhanced_desc = re.sub(pattern, replacement, enhanced_desc, count=1)
                            logger.info(f"æˆåŠŸåµŒå…¥è§’è‰²ä¸€è‡´æ€§æè¿°: {character_name} -> {replacement}")
                        else:
                            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´åŒ¹é…ï¼Œä½¿ç”¨ç®€å•æ›¿æ¢
                            enhanced_desc = enhanced_desc.replace(character_name, replacement, 1)
                            logger.info(f"æˆåŠŸåµŒå…¥è§’è‰²ä¸€è‡´æ€§æè¿°(ç®€å•æ›¿æ¢): {character_name} -> {replacement}")
                        logger.info(f"è§’è‰²æè¿°åµŒå…¥: {character_name} -> {replacement[:50]}...")
                    else:
                        logger.debug(f"è§’è‰²'{character_name}'å·²ç»åµŒå…¥è¿‡æè¿°ï¼Œè·³è¿‡")
                else:
                    logger.debug(f"è·³è¿‡è§’è‰²'{character_name}'ï¼Œå› ä¸ºå®ƒæ˜¯æ›´é•¿è§’è‰²åçš„ä¸€éƒ¨åˆ†")
        
        return enhanced_desc
    
    def _get_character_consistency(self, character_name: str) -> str:
        """è·å–è§’è‰²ä¸€è‡´æ€§æè¿°"""
        try:
            if self.character_scene_manager:
                # è§’è‰²åç§°æ˜ å°„ï¼Œå°†æ£€æµ‹åˆ°çš„è§’è‰²åç§°æ˜ å°„åˆ°æ•°æ®åº“ä¸­çš„è§’è‰²åç§°
                character_name_mapping = {
                    'ä¸»è¦è§’è‰²': 'ä¸»è§’',
                    'ä¸»äººå…¬': 'ä¸»è§’',
                    'ç”·ä¸»': 'ä¸»è§’',
                    'å¥³ä¸»': 'ä¸»è§’',
                    'ç§‘å­¦å®¶': 'ç§‘å­¦å®¶',
                    'å†›äºº': 'å†›äºº',
                    'å£«å…µ': 'å†›äºº',
                    'æ”¿æ²»å®¶': 'æ”¿æ²»å®¶'
                }

                # å°è¯•æ˜ å°„è§’è‰²åç§°
                mapped_name = character_name_mapping.get(character_name, character_name)

                # é€šè¿‡è§’è‰²åç§°æŸ¥æ‰¾è§’è‰²ï¼ˆè€Œä¸æ˜¯é€šè¿‡IDï¼‰
                all_characters = self.character_scene_manager.get_all_characters()
                character_info = None

                for char_id, char_data in all_characters.items():
                    if char_data.get('name') == mapped_name:
                        character_info = char_data
                        break

                if character_info:
                    # ç›´æ¥ä½¿ç”¨consistency_promptå­—æ®µ
                    consistency_prompt = character_info.get('consistency_prompt', '')
                    if consistency_prompt:
                        return consistency_prompt

                    # å¦‚æœæ²¡æœ‰consistency_promptï¼Œåˆ™æ„å»ºè§’è‰²ä¸€è‡´æ€§æè¿°
                    consistency_parts = []

                    # æ·»åŠ å¤–è²Œæè¿°
                    if character_info.get('appearance'):
                        consistency_parts.append(character_info['appearance'])

                    # æ·»åŠ æœè£…æè¿°
                    if character_info.get('clothing'):
                        consistency_parts.append(character_info['clothing'])

                    # æ·»åŠ ç‰¹å¾æè¿°
                    if character_info.get('features'):
                        consistency_parts.append(character_info['features'])

                    return 'ï¼Œ'.join(consistency_parts) if consistency_parts else ''
            return ''
        except Exception as e:
            logger.error(f"è·å–è§’è‰²ä¸€è‡´æ€§æè¿°å¤±è´¥ {character_name}: {e}")
            return ''