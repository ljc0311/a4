#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLMÊúçÂä°
Áªü‰∏ÄÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊúçÂä°ÔºåÊîØÊåÅÂ§öÁßçÊèê‰æõÂïÜÂíåÊ®°Âûã
"""

import asyncio
import aiohttp
from typing import Dict, Optional

from src.utils.logger import logger
from src.core.service_base import ServiceBase, ServiceResult
from src.core.api_manager import APIManager, APIConfig, APIType

class LLMService(ServiceBase):
    """LLMÊúçÂä°Á±ª"""
    
    def __init__(self, api_manager: APIManager):
        super().__init__(api_manager, "LLMÊúçÂä°")
        
        # È¢ÑËÆæÁöÑÊèêÁ§∫ËØçÊ®°Êùø
        self.prompt_templates = {
            'storyboard_generation': """
‰Ω†ÊòØ‰∏Ä‰∏™‰∏ì‰∏öÁöÑÂΩ±ËßÜÂàÜÈïúÂ∏à„ÄÇËØ∑Ê†πÊçÆ‰ª•‰∏ãÊñáÊú¨ÂÜÖÂÆπÔºåÁîüÊàêËØ¶ÁªÜÁöÑÂàÜÈïúË°®Ê†º„ÄÇ

Ë¶ÅÊ±ÇÔºö
1. ÊØè‰∏™ÈïúÂ§¥ÂåÖÂê´ÔºöÈïúÂ§¥ÁºñÂè∑„ÄÅÂú∫ÊôØÊèèËø∞„ÄÅËßíËâ≤„ÄÅÂä®‰Ωú„ÄÅÂØπËØù„ÄÅÁîªÈù¢ÊèèËø∞
2. Âú∫ÊôØÊèèËø∞Ë¶ÅÂÖ∑‰ΩìÔºåÂåÖÂê´ÁéØÂ¢É„ÄÅÊó∂Èó¥„ÄÅÊ∞õÂõ¥
3. ËßíËâ≤ÊèèËø∞Ë¶ÅËØ¶ÁªÜÔºåÂåÖÂê´Â§ñËßÇ„ÄÅË°®ÊÉÖ„ÄÅÂä®‰Ωú
4. ÁîªÈù¢ÊèèËø∞Ë¶ÅÈÄÇÂêàAIÁªòÁîªÔºåÂåÖÂê´ÊûÑÂõæ„ÄÅÂÖâÁ∫ø„ÄÅÈ£éÊ†º
5. ËæìÂá∫Ê†ºÂºè‰∏∫JSONÔºåÂåÖÂê´shotsÊï∞ÁªÑ

ÊñáÊú¨ÂÜÖÂÆπÔºö
{text}

È£éÊ†ºË¶ÅÊ±ÇÔºö{style}

ËØ∑ÁîüÊàêÂàÜÈïúË°®Ê†ºÔºö
""",
            
            'text_rewrite': """
ËØ∑ÂØπ‰ª•‰∏ãÊñáÊú¨ËøõË°åÊîπÂÜôÔºåË¶ÅÊ±ÇÔºö
1. ‰øùÊåÅÂéüÊÑè‰∏çÂèò
2. ËØ≠Ë®ÄÊõ¥Âä†ÁîüÂä®ÊúâË∂£
3. ÈÄÇÂêàËßÜÈ¢ëËÑöÊú¨
4. ÈïøÂ∫¶ÈÄÇ‰∏≠

ÂéüÊñáÔºö
{text}

ÊîπÂÜôÂêéÁöÑÊñáÊú¨Ôºö
""",

            'story_creation': """
‰Ω†ÊòØ‰∏Ä‰ΩçÊâçÂçéÊ®™Ê∫¢ÁöÑÂ∞èËØ¥ÂÆ∂ÂíåÊïÖ‰∫ãÂàõ‰Ωú‰∏ìÂÆ∂„ÄÇËØ∑Ê†πÊçÆÁî®Êà∑Êèê‰æõÁöÑ‰∏ªÈ¢òÂàõ‰Ωú‰∏Ä‰∏™Âºï‰∫∫ÂÖ•ËÉú„ÄÅÂÜÖÂÆπ‰∏∞ÂØåÁöÑÂÆåÊï¥ÊïÖ‰∫ã„ÄÇ

Âàõ‰ΩúË¶ÅÊ±ÇÔºö
1. ÊïÖ‰∫ãÈïøÂ∫¶Ôºö1500-2000Â≠óÂ∑¶Âè≥ÔºåÂÜÖÂÆπÂÖÖÂÆûÔºåÊÉÖËäÇÂÆåÊï¥
2. ÁªìÊûÑÂÆåÊï¥ÔºöÂåÖÂê´ÂºÄÂ§¥„ÄÅÂèëÂ±ï„ÄÅÈ´òÊΩÆ„ÄÅÁªìÂ±ÄÁöÑÂÆåÊï¥ÊïÖ‰∫ãÁªìÊûÑ
3. ‰∫∫Áâ©È≤úÊòéÔºöÂ°ëÈÄ†ÊúâË°ÄÊúâËÇâÁöÑËßíËâ≤ÔºåÂåÖÂê´‰∏ªË¶ÅËßíËâ≤ÁöÑÊÄßÊ†ºÁâπÁÇπÂíåËÉåÊôØ
4. ÊÉÖËäÇÁîüÂä®ÔºöÂåÖÂê´ÂÜ≤Á™Å„ÄÅËΩ¨Êäò„ÄÅÊÇ¨ÂøµÁ≠âÊïÖ‰∫ãÂÖÉÁ¥†ÔºåËÆ©ËØªËÄÖ‰∫ßÁîü‰ª£ÂÖ•ÊÑü
5. ÊèèÂÜôÁªÜËÖªÔºöÈÄÇÂΩìÁöÑÁéØÂ¢ÉÊèèÂÜô„ÄÅÂøÉÁêÜÊèèÂÜôÂíåÂä®‰ΩúÊèèÂÜôÔºåÂ¢ûÂº∫ÊïÖ‰∫ãÁöÑÁîªÈù¢ÊÑü
6. ‰∏ªÈ¢òÊ∑±ÂàªÔºöÂú®Â®±‰πêÊÄßÁöÑÂü∫Á°Ä‰∏äÔºå‰ΩìÁé∞‰∏ÄÂÆöÁöÑÊÄùÊÉ≥ÂÜÖÊ∂µÊàñ‰∫∫ÁîüÊÑüÊÇü
7. ËØ≠Ë®Ä‰ºòÁæéÔºö‰ΩøÁî®ÁîüÂä®„ÄÅÂØåÊúâÊÑüÊüìÂäõÁöÑËØ≠Ë®ÄÔºåÈÅøÂÖçÂπ≥Èì∫Áõ¥Âèô
8. ÈÄÇÂêàÊîπÁºñÔºöÊïÖ‰∫ãÂ∫îËØ•ÂÖ∑ÊúâËâØÂ•ΩÁöÑËßÜËßâÂåñÊΩúÂäõÔºå‰æø‰∫éÂêéÁª≠Âà∂‰ΩúÊàêËßÜÈ¢ë

ÈáçË¶ÅÊ†ºÂºèË¶ÅÊ±ÇÔºö
- Áõ¥Êé•ËæìÂá∫Á∫ØÊñáÊú¨ÊïÖ‰∫ãÂÜÖÂÆπÔºå‰∏çË¶ÅÂåÖÂê´‰ªª‰ΩïÊ†áÈ¢ò„ÄÅÁ´†ËäÇÊ†áËÆ∞„ÄÅÂ∫èÂè∑
- ‰∏çË¶Å‰ΩøÁî® ### „ÄÅ#### „ÄÅÁ¨¨‰∏ÄÁ´†„ÄÅÂºÄÂ§¥„ÄÅÂèëÂ±ï„ÄÅÈ´òÊΩÆ„ÄÅÁªìÂ±ÄÁ≠âÊ†áÈ¢òÊ†ºÂºè
- ‰∏çË¶ÅÊ∑ªÂä†‰ªª‰ΩïMarkdownÊ†ºÂºèÊ†áËÆ∞
- ‰∏çË¶ÅÂåÖÂê´Âàõ‰ΩúËØ¥Êòé„ÄÅÊÄªÁªìÊàñÂÖ∂‰ªñÈùûÊïÖ‰∫ãÂÜÖÂÆπ
- ÊïÖ‰∫ãÂ∫îËØ•ÊòØËøûË¥ØÁöÑÁ∫ØÊñáÊú¨ÂèôËø∞

Âàõ‰Ωú‰∏ªÈ¢òÔºö{theme}

ËØ∑ÂºÄÂßã‰Ω†ÁöÑÂàõ‰ΩúÔºö
""",

            'prompt_optimization': """
ËØ∑‰ºòÂåñ‰ª•‰∏ãAIÁªòÁîªÊèêÁ§∫ËØçÔºåË¶ÅÊ±ÇÔºö
1. Êõ¥Âä†ËØ¶ÁªÜÂíåÂÖ∑‰Ωì
2. ÂåÖÂê´Ëâ∫ÊúØÈ£éÊ†ºÊèèËø∞
3. ÂåÖÂê´ÊäÄÊúØÂèÇÊï∞Âª∫ËÆÆ
4. ÈÄÇÂêàStable DiffusionÁ≠âÊ®°Âûã

ÂéüÊèêÁ§∫ËØçÔºö
{prompt}

È£éÊ†ºÔºö{style}

‰ºòÂåñÂêéÁöÑÊèêÁ§∫ËØçÔºö
"""
        }
    
    def get_api_type(self) -> APIType:
        return APIType.LLM
    
    async def _execute_request(self, api_config: APIConfig, **kwargs) -> ServiceResult:
        """ÊâßË°åLLM APIËØ∑Ê±Ç"""
        try:
            prompt = kwargs.get('prompt', '')
            max_tokens = kwargs.get('max_tokens', 2000)
            temperature = kwargs.get('temperature', 0.7)

            logger.info(f"üîß LLM APIÊâßË°åËØ∑Ê±Ç")
            logger.info(f"  üåê Êèê‰æõÂïÜ: {api_config.provider}")
            logger.info(f"  ü§ñ Ê®°Âûã: {api_config.model_name}")
            logger.info(f"  üìù ÊèêÁ§∫ËØçÈïøÂ∫¶: {len(prompt)} Â≠óÁ¨¶")
            logger.info(f"  ‚öôÔ∏è max_tokens: {max_tokens}, temperature: {temperature}")

            if not prompt:
                logger.error("  ‚ùå ÊèêÁ§∫ËØç‰∏∫Á©∫")
                return ServiceResult(success=False, error="ÊèêÁ§∫ËØç‰∏çËÉΩ‰∏∫Á©∫")

            # Ê†πÊçÆ‰∏çÂêåÊèê‰æõÂïÜÊûÑÂª∫ËØ∑Ê±Ç
            logger.info(f"  üöÄ ÂºÄÂßãË∞ÉÁî® {api_config.provider} API...")

            if api_config.provider.lower() == 'deepseek':
                response = await self._call_deepseek_api(api_config, prompt, max_tokens, temperature)
            elif api_config.provider.lower() == 'tongyi':
                response = await self._call_tongyi_api(api_config, prompt, max_tokens, temperature)
            elif api_config.provider.lower() == 'zhipu':
                response = await self._call_zhipu_api(api_config, prompt, max_tokens, temperature)
            elif api_config.provider.lower() == 'google':
                response = await self._call_google_api(api_config, prompt, max_tokens, temperature)
            elif api_config.provider.lower() == 'openai':
                response = await self._call_openai_api(api_config, prompt, max_tokens, temperature)
            elif api_config.provider.lower() == 'siliconflow':
                response = await self._call_siliconflow_api(api_config, prompt, max_tokens, temperature)
            else:
                error_msg = f"‰∏çÊîØÊåÅÁöÑÊèê‰æõÂïÜ: {api_config.provider}"
                logger.error(f"  ‚ùå {error_msg}")
                return ServiceResult(success=False, error=error_msg)

            # ËÆ∞ÂΩïÊàêÂäü‰ø°ÊÅØ
            content_length = len(response.get('content', ''))
            tokens_used = response.get('usage', {}).get('total_tokens', 0)
            logger.info(f"  ‚úÖ APIË∞ÉÁî®ÊàêÂäü")
            logger.info(f"  üìä ËøîÂõûÂÜÖÂÆπÈïøÂ∫¶: {content_length} Â≠óÁ¨¶")
            logger.info(f"  üî¢ ‰ΩøÁî®TokenÊï∞: {tokens_used}")

            return ServiceResult(
                success=True,
                data=response,
                metadata={
                    'provider': api_config.provider,
                    'model': api_config.model_name,
                    'tokens_used': tokens_used
                }
            )
            
        except Exception as e:
            logger.error(f"LLM APIËØ∑Ê±ÇÂ§±Ë¥•: {e}")
            return ServiceResult(success=False, error=str(e))
    
    async def _call_deepseek_api(self, api_config: APIConfig, prompt: str, max_tokens: int, temperature: float) -> Dict:
        """Ë∞ÉÁî®DeepSeek API"""
        headers = {
            'Authorization': f'Bearer {api_config.api_key}',
            'Content-Type': 'application/json'
        }

        data = {
            'model': api_config.model_name or 'deepseek-chat',
            'messages': [
                {'role': 'user', 'content': prompt}
            ],
            'max_tokens': max_tokens,
            'temperature': temperature
        }

        # üîß ‰øÆÂ§çÔºöÊ£ÄÊü•URLÊòØÂê¶Â∑≤ÁªèÂåÖÂê´endpointÔºåÈÅøÂÖçÈáçÂ§çÊ∑ªÂä†
        api_url = api_config.api_url
        if not api_url.endswith('/chat/completions'):
            api_url = f"{api_url.rstrip('/')}/chat/completions"

        try:
            # üîß Â¢ûÂä†Ë∂ÖÊó∂Êó∂Èó¥ÔºåDeepSeekÊúâÊó∂ÂìçÂ∫îËæÉÊÖ¢
            timeout = max(api_config.timeout, 60)  # Ëá≥Â∞ë60Áßí
            connector = aiohttp.TCPConnector(use_dns_cache=False)

            # üîß Ê∑ªÂä†ÔºöÊ£ÄÊµãÊòØÂê¶ÈúÄË¶Å‰ª£ÁêÜÔºàÊüê‰∫õÁΩëÁªúÁéØÂ¢É‰∏ãDeepSeek‰πüÂèØËÉΩÈúÄË¶Å‰ª£ÁêÜÔºâ
            proxy_url = None
            try:
                # Âø´ÈÄüÊµãËØïÁõ¥ËøûÊòØÂê¶ÂèØÁî®
                test_connector = aiohttp.TCPConnector(use_dns_cache=False)
                async with aiohttp.ClientSession(connector=test_connector) as test_session:
                    async with test_session.get(
                        "https://api.deepseek.com",
                        timeout=aiohttp.ClientTimeout(total=5)
                    ) as test_response:
                        if test_response.status not in [200, 404]:  # 404‰πüË°®Á§∫ËÉΩËøûÈÄö
                            # Áõ¥ËøûÊúâÈóÆÈ¢òÔºåÂ∞ùËØï‰ª£ÁêÜ
                            proxy_url = "http://127.0.0.1:12334"
            except:
                # Áõ¥ËøûÂ§±Ë¥•ÔºåÂ∞ùËØï‰ª£ÁêÜ
                proxy_url = "http://127.0.0.1:12334"

            async with aiohttp.ClientSession(connector=connector) as session:
                async with session.post(
                    api_url,
                    headers=headers,
                    json=data,
                    timeout=aiohttp.ClientTimeout(total=timeout),
                    proxy=proxy_url  # üîß Ê∑ªÂä†Ôºö‰ΩøÁî®‰ª£ÁêÜÔºàÂ¶ÇÊûúÈúÄË¶ÅÔºâ
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        return {
                            'content': result['choices'][0]['message']['content'],
                            'usage': result.get('usage', {})
                        }
                    else:
                        error_text = await response.text()
                        raise Exception(f"APIËØ∑Ê±ÇÂ§±Ë¥• (Áä∂ÊÄÅÁ†Å: {response.status}): {error_text}")

        except asyncio.TimeoutError:
            raise Exception(f"DeepSeek APIËØ∑Ê±ÇË∂ÖÊó∂ (>{timeout}Áßí)")
        except aiohttp.ClientError as e:
            raise Exception(f"DeepSeek APIÁΩëÁªúÈîôËØØ: {e}")
        except Exception as e:
            if "APIËØ∑Ê±ÇÂ§±Ë¥•" in str(e):
                raise  # ÈáçÊñ∞ÊäõÂá∫APIÈîôËØØ
            else:
                raise Exception(f"DeepSeek APIË∞ÉÁî®ÂºÇÂ∏∏: {e}")
    
    async def _call_tongyi_api(self, api_config: APIConfig, prompt: str, max_tokens: int, temperature: float) -> Dict:
        """Ë∞ÉÁî®ÈÄö‰πâÂçÉÈóÆAPI"""
        headers = {
            'Authorization': f'Bearer {api_config.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': api_config.model_name or 'qwen-turbo',
            'messages': [
                {'role': 'user', 'content': prompt}
            ],
            'max_tokens': max_tokens,
            'temperature': temperature
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                api_config.api_url,
                headers=headers,
                json=data,
                timeout=aiohttp.ClientTimeout(total=api_config.timeout)
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    return {
                        'content': result['choices'][0]['message']['content'],
                        'usage': result.get('usage', {})
                    }
                else:
                    error_text = await response.text()
                    raise Exception(f"APIËØ∑Ê±ÇÂ§±Ë¥• (Áä∂ÊÄÅÁ†Å: {response.status}): {error_text}")
    
    async def _call_zhipu_api(self, api_config: APIConfig, prompt: str, max_tokens: int, temperature: float) -> Dict:
        """Ë∞ÉÁî®Êô∫Ë∞±AI API"""
        headers = {
            'Authorization': f'Bearer {api_config.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': api_config.model_name or 'glm-4-flash',
            'messages': [
                {'role': 'user', 'content': prompt}
            ],
            'max_tokens': max_tokens,
            'temperature': temperature
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                api_config.api_url,
                headers=headers,
                json=data,
                timeout=aiohttp.ClientTimeout(total=api_config.timeout)
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    return {
                        'content': result['choices'][0]['message']['content'],
                        'usage': result.get('usage', {})
                    }
                else:
                    error_text = await response.text()
                    raise Exception(f"APIËØ∑Ê±ÇÂ§±Ë¥• (Áä∂ÊÄÅÁ†Å: {response.status}): {error_text}")
    
    async def _call_google_api(self, api_config: APIConfig, prompt: str, max_tokens: int, temperature: float) -> Dict:
        """Ë∞ÉÁî®Google Gemini API"""
        headers = {
            'Content-Type': 'application/json'
        }

        data = {
            'contents': [{
                'parts': [{'text': prompt}]
            }],
            'generationConfig': {
                'maxOutputTokens': max_tokens,
                'temperature': temperature
            }
        }

        # üîß ‰øÆÂ§çÔºöÊ£ÄÊü•URLÊòØÂê¶Â∑≤ÁªèÂåÖÂê´ÂÆåÊï¥Ë∑ØÂæÑ
        if 'generateContent' in api_config.api_url:
            # URLÂ∑≤ÁªèÂåÖÂê´ÂÆåÊï¥Ë∑ØÂæÑÔºåÁõ¥Êé•Ê∑ªÂä†APIÂØÜÈí•
            url = f"{api_config.api_url}?key={api_config.api_key}"
        else:
            # URLÂè™ÂåÖÂê´Âü∫Á°ÄË∑ØÂæÑÔºåÈúÄË¶ÅÊ∑ªÂä†Ê®°ÂûãË∑ØÂæÑ
            url = f"{api_config.api_url}/v1beta/models/{api_config.model_name or 'gemini-1.5-flash'}:generateContent?key={api_config.api_key}"

        # üîß Ê∑ªÂä†ÔºöÊ£ÄÊµãHiddify‰ª£ÁêÜÊîØÊåÅ
        proxy_url = None
        try:
            # Ê£ÄÊü•Hiddify‰ª£ÁêÜÊòØÂê¶ÂèØÁî®ÔºàÁ´ØÂè£12334Ôºâ
            connector = aiohttp.TCPConnector(use_dns_cache=False)
            async with aiohttp.ClientSession(connector=connector) as test_session:
                async with test_session.get(
                    "https://www.google.com",
                    timeout=aiohttp.ClientTimeout(total=3),
                    proxy="http://127.0.0.1:12334"
                ) as test_response:
                    if test_response.status == 200:
                        proxy_url = "http://127.0.0.1:12334"
                        self.logger.info("üåê Ê£ÄÊµãÂà∞Hiddify‰ª£ÁêÜÔºåÂ∞Ü‰ΩøÁî®‰ª£ÁêÜËÆøÈóÆGoogle API")
        except:
            # ‰ª£ÁêÜ‰∏çÂèØÁî®Ôºå‰ΩøÁî®Áõ¥Ëøû
            pass

        connector = aiohttp.TCPConnector(use_dns_cache=False)
        async with aiohttp.ClientSession(connector=connector) as session:
            async with session.post(
                url,
                headers=headers,
                json=data,
                timeout=aiohttp.ClientTimeout(total=api_config.timeout),
                proxy=proxy_url  # üîß Ê∑ªÂä†Ôºö‰ΩøÁî®‰ª£ÁêÜÔºàÂ¶ÇÊûúÂèØÁî®Ôºâ
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    content = result['candidates'][0]['content']['parts'][0]['text']
                    return {
                        'content': content,
                        'usage': result.get('usageMetadata', {})
                    }
                else:
                    error_text = await response.text()
                    raise Exception(f"APIËØ∑Ê±ÇÂ§±Ë¥• (Áä∂ÊÄÅÁ†Å: {response.status}): {error_text}")
    
    async def generate_storyboard(self, text: str, style: Optional[str] = None, provider: Optional[str] = None) -> ServiceResult:
        """ÁîüÊàêÂàÜÈïúËÑöÊú¨"""
        try:
            # Â¶ÇÊûúÊ≤°ÊúâÊåáÂÆöÈ£éÊ†ºÔºå‰ªéÈÖçÁΩÆ‰∏≠Ëé∑ÂèñÈªòËÆ§È£éÊ†º
            if style is None:
                from src.utils.config_manager import ConfigManager
                config_manager = ConfigManager()
                style_setting = config_manager.get_setting("default_style", "ÁîµÂΩ±È£éÊ†º")
                style = str(style_setting) if style_setting else "ÁîµÂΩ±È£éÊ†º"
            
            # ÈÄâÊã©Êèê‰æõÂïÜ
            if not provider:
                providers = self.get_available_providers()
                provider = providers[0] if providers else None
            
            # ÊûÑÂª∫ÊèêÁ§∫ËØç
            prompt = f"""ËØ∑Ê†πÊçÆ‰ª•‰∏ãÊñáÊú¨ÁîüÊàê{style}ÁöÑÂàÜÈïúËÑöÊú¨Ôºö

{text}

ËØ∑ÊåâÁÖß‰ª•‰∏ãÊ†ºÂºèËæìÂá∫ÂàÜÈïú‰ø°ÊÅØÔºö
ÈïúÂ§¥1Ôºö[Âú∫ÊôØÊèèËø∞]
ÈïúÂ§¥2Ôºö[Âú∫ÊôØÊèèËø∞]
...

ÊØè‰∏™ÈïúÂ§¥Â∫îËØ•ÂåÖÂê´Ôºö
- Âú∫ÊôØËÆæÁΩÆ
- ËßíËâ≤Âä®‰Ωú
- ÈïúÂ§¥ËßíÂ∫¶
- ÊÉÖÊÑüÊ∞õÂõ¥"""
            
            # Ë∞ÉÁî®LLM API
            result = await self.execute(provider=provider, prompt=prompt)

            if result.success:
                return ServiceResult(
                    success=True,
                    data={
                        "storyboard": result.data,
                        "style": style,
                        "provider": provider
                    }
                )
            else:
                return result

        except Exception as e:
            logger.error(f"ÁîüÊàêÂàÜÈïúËÑöÊú¨Â§±Ë¥•: {e}")
            return ServiceResult(
                success=False,
                error=str(e)
            )
    


    async def rewrite_text(self, text: str, provider: Optional[str] = None) -> ServiceResult:
        """ÊîπÂÜôÊñáÊú¨"""
        logger.info(f"‚úèÔ∏è LLMÊúçÂä°ÔºöÂºÄÂßãÊñáÊú¨ÊîπÂÜô")
        logger.info(f"  üìù ÂéüÊñáÈïøÂ∫¶: {len(text)} Â≠óÁ¨¶")
        logger.info(f"  üìÑ ÂéüÊñáÈ¢ÑËßà: {text[:50]}...")
        logger.info(f"  ü§ñ Êèê‰æõÂïÜ: {provider or 'ÈªòËÆ§'}")

        prompt = self.prompt_templates['text_rewrite'].format(text=text)

        logger.info(f"  üìù ÊèêÁ§∫ËØçÈïøÂ∫¶: {len(prompt)} Â≠óÁ¨¶")
        logger.info(f"  ‚öôÔ∏è ÂèÇÊï∞ËÆæÁΩÆ: max_tokens=1500, temperature=0.8")

        result = await self.execute(
            provider=provider,
            prompt=prompt,
            max_tokens=1500,
            temperature=0.8
        )

        if result.success:
            content_length = len(result.data.get('content', ''))
            logger.info(f"  ‚úÖ ÊñáÊú¨ÊîπÂÜôÂÆåÊàêÔºåÂÜÖÂÆπÈïøÂ∫¶: {content_length} Â≠óÁ¨¶")
        else:
            logger.error(f"  ‚ùå ÊñáÊú¨ÊîπÂÜôÂ§±Ë¥•: {result.error}")

        return result

    async def create_story_from_theme(self, theme: str, provider: Optional[str] = None) -> ServiceResult:
        """Ê†πÊçÆ‰∏ªÈ¢òÂàõ‰ΩúÊïÖ‰∫ã"""
        logger.info(f"üìö LLMÊúçÂä°ÔºöÂºÄÂßãÊïÖ‰∫ãÂàõ‰Ωú")
        logger.info(f"  üé≠ ‰∏ªÈ¢ò: {theme}")
        logger.info(f"  ü§ñ Êèê‰æõÂïÜ: {provider or 'ÈªòËÆ§'}")

        prompt = self.prompt_templates['story_creation'].format(theme=theme)

        logger.info(f"  üìù ÊèêÁ§∫ËØçÈïøÂ∫¶: {len(prompt)} Â≠óÁ¨¶")
        logger.info(f"  ‚öôÔ∏è ÂèÇÊï∞ËÆæÁΩÆ: max_tokens=2500, temperature=0.9")

        result = await self.execute(
            provider=provider,
            prompt=prompt,
            max_tokens=2500,
            temperature=0.9
        )

        if result.success:
            content_length = len(result.data.get('content', ''))
            logger.info(f"  ‚úÖ ÊïÖ‰∫ãÂàõ‰ΩúÂÆåÊàêÔºåÂÜÖÂÆπÈïøÂ∫¶: {content_length} Â≠óÁ¨¶")
        else:
            logger.error(f"  ‚ùå ÊïÖ‰∫ãÂàõ‰ΩúÂ§±Ë¥•: {result.error}")

        return result

    async def optimize_prompt(self, prompt: str, style: str = "ÂÜôÂÆûÈ£éÊ†º", provider: Optional[str] = None) -> ServiceResult:
        """‰ºòÂåñÁªòÁîªÊèêÁ§∫ËØç"""
        optimization_prompt = self.prompt_templates['prompt_optimization'].format(
            prompt=prompt,
            style=style
        )
        
        return await self.execute(
            provider=provider,
            prompt=optimization_prompt,
            max_tokens=1000,
            temperature=0.6
        )
    
    async def generate_text(self, prompt: str, max_tokens: int = 2000, temperature: float = 0.7, provider: Optional[str] = None) -> ServiceResult:
        """ÁîüÊàêÊñáÊú¨ÔºàÈÄöÁî®ÊñπÊ≥ïÔºâ"""
        return await self.execute(
            provider=provider,
            prompt=prompt,
            max_tokens=max_tokens,
            temperature=temperature
        )

    async def custom_request(self, prompt: str, max_tokens: int = 2000, temperature: float = 0.7, provider: Optional[str] = None) -> ServiceResult:
        """Ëá™ÂÆö‰πâËØ∑Ê±Ç"""
        return await self.execute(
            provider=provider,
            prompt=prompt,
            max_tokens=max_tokens,
            temperature=temperature
        )
    
    async def _call_openai_api(self, api_config: APIConfig, prompt: str, max_tokens: int, temperature: float) -> Dict:
        """Ë∞ÉÁî®OpenAI API"""
        headers = {
            'Authorization': f'Bearer {api_config.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': api_config.model_name or 'gpt-3.5-turbo',
            'messages': [
                {'role': 'user', 'content': prompt}
            ],
            'max_tokens': max_tokens,
            'temperature': temperature
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(api_config.api_url, headers=headers, json=data) as response:
                if response.status == 200:
                    result = await response.json()
                    return {
                        'content': result['choices'][0]['message']['content'],
                        'usage': result.get('usage', {})
                    }
                else:
                    error_text = await response.text()
                    raise Exception(f"OpenAI APIËØ∑Ê±ÇÂ§±Ë¥• (Áä∂ÊÄÅÁ†Å: {response.status}): {error_text}")
    
    async def _call_siliconflow_api(self, api_config: APIConfig, prompt: str, max_tokens: int, temperature: float) -> Dict:
        """Ë∞ÉÁî®SiliconFlow API"""
        headers = {
            'Authorization': f'Bearer {api_config.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': api_config.model_name or 'Qwen/Qwen2.5-7B-Instruct',
            'messages': [
                {'role': 'user', 'content': prompt}
            ],
            'max_tokens': max_tokens,
            'temperature': temperature
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(api_config.api_url, headers=headers, json=data) as response:
                if response.status == 200:
                    result = await response.json()
                    return {
                        'content': result['choices'][0]['message']['content'],
                        'usage': result.get('usage', {})
                    }
                else:
                    error_text = await response.text()
                    raise Exception(f"SiliconFlow APIËØ∑Ê±ÇÂ§±Ë¥• (Áä∂ÊÄÅÁ†Å: {response.status}): {error_text}")