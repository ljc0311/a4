# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆä¸€é”®å‘å¸ƒæœåŠ¡
ä¸ä¾èµ–SQLAlchemyï¼Œä½¿ç”¨JSONæ–‡ä»¶å­˜å‚¨æ•°æ®
"""

import os
import json
import uuid
import asyncio
from typing import Dict, List, Any, Optional, Callable
from datetime import datetime
from pathlib import Path

from .platform_publisher.publisher_factory import PublisherFactory
from .platform_publisher.base_publisher import VideoMetadata, PublishResult
from src.utils.logger import logger
from src.services.publisher_database_service import PublisherDatabaseService

class SimplePublisherService:
    """ç®€åŒ–ç‰ˆå‘å¸ƒæœåŠ¡"""
    
    def __init__(self):
        self.publisher_factory = PublisherFactory()

        # ğŸ”§ ä¼˜åŒ–ï¼šä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®åº“æœåŠ¡
        self.db_service = PublisherDatabaseService()

        # ä¿ç•™æ•°æ®å­˜å‚¨ç›®å½•ç”¨äºå…¼å®¹æ€§ï¼ˆå¦‚æœéœ€è¦è¿ç§»æ—§æ•°æ®ï¼‰
        self.data_dir = Path("data/publisher")
        self.data_dir.mkdir(parents=True, exist_ok=True)

        # æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºæ•°æ®è¿ç§»ï¼‰
        self.accounts_file = self.data_dir / "accounts.json"
        self.tasks_file = self.data_dir / "tasks.json"
        self.records_file = self.data_dir / "records.json"

        # ğŸ”§ æ–°å¢ï¼šè‡ªåŠ¨è¿ç§»æ—§æ•°æ®åˆ°æ•°æ®åº“
        self._migrate_old_data_if_needed()

        logger.info("ç®€åŒ–ç‰ˆå‘å¸ƒæœåŠ¡åˆå§‹åŒ–å®Œæˆï¼ˆä½¿ç”¨ç»Ÿä¸€æ•°æ®åº“ï¼‰")

    def _migrate_old_data_if_needed(self):
        """ğŸ”§ æ–°å¢ï¼šè¿ç§»æ—§æ•°æ®åˆ°ç»Ÿä¸€æ•°æ®åº“"""
        try:
            migrated_count = 0

            # è¿ç§»è´¦å·æ•°æ®
            if self.accounts_file.exists():
                accounts = self._load_json(self.accounts_file)
                for account in accounts:
                    # è½¬æ¢ä¸ºæ•°æ®åº“æ ¼å¼å¹¶ä¿å­˜
                    account_data = {
                        'platform_name': account.get('platform_name', ''),
                        'account_name': account.get('account_name', ''),
                        'credentials': account.get('credentials', {}),
                        'is_active': account.get('is_active', True),
                        'last_login': account.get('last_login'),
                        'created_at': account.get('created_at', datetime.now().isoformat()),
                        'updated_at': account.get('updated_at', datetime.now().isoformat())
                    }

                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing_accounts = self.db_service.data.get('platform_accounts', [])
                    account_exists = any(
                        acc.get('platform_name') == account_data['platform_name'] and
                        acc.get('account_name') == account_data['account_name']
                        for acc in existing_accounts
                    )

                    if not account_exists:
                        account_data['id'] = f"account_{len(existing_accounts) + 1}_{int(datetime.now().timestamp())}"
                        self.db_service.data['platform_accounts'].append(account_data)
                        migrated_count += 1

                logger.info(f"è¿ç§»äº† {migrated_count} ä¸ªè´¦å·åˆ°æ•°æ®åº“")

            # è¿ç§»ä»»åŠ¡æ•°æ®
            if self.tasks_file.exists():
                tasks = self._load_json(self.tasks_file)
                for task in tasks:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing_tasks = self.db_service.data.get('video_tasks', [])
                    task_exists = any(
                        t.get('id') == task.get('id') for t in existing_tasks
                    )

                    if not task_exists:
                        self.db_service.data['video_tasks'].append(task)
                        migrated_count += 1

                logger.info(f"è¿ç§»äº† {len(tasks)} ä¸ªä»»åŠ¡åˆ°æ•°æ®åº“")

            # è¿ç§»å‘å¸ƒè®°å½•
            if self.records_file.exists():
                records = self._load_json(self.records_file)
                for record in records:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing_records = self.db_service.data.get('publish_records', [])
                    record_exists = any(
                        r.get('id') == record.get('id') for r in existing_records
                    )

                    if not record_exists:
                        self.db_service.data['publish_records'].append(record)
                        migrated_count += 1

                logger.info(f"è¿ç§»äº† {len(records)} ä¸ªå‘å¸ƒè®°å½•åˆ°æ•°æ®åº“")

            # ä¿å­˜è¿ç§»åçš„æ•°æ®
            if migrated_count > 0:
                self.db_service._save_data()
                logger.info(f"âœ… æ•°æ®è¿ç§»å®Œæˆï¼Œå…±è¿ç§» {migrated_count} æ¡è®°å½•")

        except Exception as e:
            logger.error(f"æ•°æ®è¿ç§»å¤±è´¥: {e}")

    def _init_data_files(self):
        """åˆå§‹åŒ–æ•°æ®æ–‡ä»¶"""
        for file_path in [self.accounts_file, self.tasks_file, self.records_file]:
            if not file_path.exists():
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump([], f, ensure_ascii=False, indent=2)
                    
    def _load_json(self, file_path: Path) -> List[Dict]:
        """åŠ è½½JSONæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"åŠ è½½JSONæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return []
            
    def _save_json(self, file_path: Path, data: List[Dict]) -> bool:
        """ä¿å­˜JSONæ–‡ä»¶"""
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
            return True
        except Exception as e:
            logger.error(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return False
            
    # ==================== è´¦å·ç®¡ç† ====================
    
    def create_platform_account(self, platform: str, account_name: str,
                              credentials: Dict[str, Any]) -> str:
        """ğŸ”§ ä¼˜åŒ–ï¼šåˆ›å»ºå¹³å°è´¦å·ï¼ˆä½¿ç”¨æ•°æ®åº“ï¼‰"""
        try:
            account_data = {
                'platform_name': platform,
                'account_name': account_name,
                'credentials': credentials,
                'is_active': True,
                'last_login': None,
                'created_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat()
            }

            # ç”Ÿæˆè´¦å·ID
            account_id = f"account_{len(self.db_service.data.get('platform_accounts', [])) + 1}_{int(datetime.now().timestamp())}"
            account_data['id'] = account_id

            # ä¿å­˜åˆ°æ•°æ®åº“
            if 'platform_accounts' not in self.db_service.data:
                self.db_service.data['platform_accounts'] = []

            self.db_service.data['platform_accounts'].append(account_data)
            self.db_service._save_data()

            logger.info(f"åˆ›å»ºå¹³å°è´¦å·æˆåŠŸ: {platform} - {account_name}")
            return account_id
                
        except Exception as e:
            logger.error(f"åˆ›å»ºå¹³å°è´¦å·å¤±è´¥: {e}")
            raise
            
    def get_platform_accounts(self, platform: str = None, active_only: bool = True) -> List[Dict[str, Any]]:
        """ğŸ”§ ä¼˜åŒ–ï¼šè·å–å¹³å°è´¦å·åˆ—è¡¨ï¼ˆä½¿ç”¨æ•°æ®åº“ï¼‰"""
        try:
            accounts = self.db_service.data.get('platform_accounts', [])

            result = []
            for account in accounts:
                if platform and account.get('platform_name') != platform:
                    continue
                if active_only and not account.get('is_active', True):
                    continue

                result.append(account)

            return result

        except Exception as e:
            logger.error(f"è·å–å¹³å°è´¦å·å¤±è´¥: {e}")
            return []
            
    def delete_platform_account(self, account_id: str) -> bool:
        """åˆ é™¤å¹³å°è´¦å·"""
        try:
            accounts = self._load_json(self.accounts_file)
            
            # æ‰¾åˆ°å¹¶åˆ é™¤è´¦å·
            accounts = [acc for acc in accounts if acc.get('id') != account_id]
            
            if self._save_json(self.accounts_file, accounts):
                logger.info(f"åˆ é™¤å¹³å°è´¦å·æˆåŠŸ: {account_id}")
                return True
            return False
            
        except Exception as e:
            logger.error(f"åˆ é™¤å¹³å°è´¦å·å¤±è´¥: {e}")
            return False
            
    # ==================== å‘å¸ƒåŠŸèƒ½ ====================
    
    async def publish_video(self, 
                           video_path: str,
                           metadata: VideoMetadata,
                           target_platforms: List[str],
                           project_name: str = None,
                           progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """å‘å¸ƒè§†é¢‘åˆ°å¤šä¸ªå¹³å°"""
        try:
            if not os.path.exists(video_path):
                raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                
            if progress_callback:
                progress_callback(0.1, "å¼€å§‹å‘å¸ƒä»»åŠ¡...")
                
            # åˆ›å»ºä»»åŠ¡è®°å½•
            task_id = str(uuid.uuid4())
            task_data = {
                'task_id': task_id,
                'project_name': project_name,
                'video_path': video_path,
                'title': metadata.title,
                'description': metadata.description,
                'tags': metadata.tags,
                'target_platforms': target_platforms,
                'status': 'processing',
                'created_at': datetime.now().isoformat()
            }
            
            # ä¿å­˜ä»»åŠ¡
            tasks = self._load_json(self.tasks_file)
            tasks.append(task_data)
            self._save_json(self.tasks_file, tasks)
            
            if progress_callback:
                progress_callback(0.2, "å¼€å§‹å‘å¸ƒåˆ°å„å¹³å°...")
                
            # å‘å¸ƒåˆ°å„å¹³å°
            publish_results = {}
            success_count = 0
            
            for i, platform in enumerate(target_platforms):
                try:
                    if progress_callback:
                        progress = 0.2 + (i / len(target_platforms)) * 0.7
                        progress_callback(progress, f"å‘å¸ƒåˆ° {platform}...")
                        
                    result = await self._publish_to_single_platform(
                        task_id, platform, metadata, video_path
                    )
                    
                    publish_results[platform] = result
                    if result.get('success', False):
                        success_count += 1
                        
                except Exception as e:
                    logger.error(f"å‘å¸ƒåˆ° {platform} å¤±è´¥: {e}")
                    publish_results[platform] = {
                        'success': False,
                        'error': str(e),
                        'platform': platform
                    }
                    
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            if success_count == len(target_platforms):
                status = 'completed'
            elif success_count > 0:
                status = 'partially_completed'
            else:
                status = 'failed'
                
            # æ›´æ–°ä»»åŠ¡è®°å½•
            tasks = self._load_json(self.tasks_file)
            for task in tasks:
                if task['task_id'] == task_id:
                    task['status'] = status
                    task['completed_at'] = datetime.now().isoformat()
                    break
            self._save_json(self.tasks_file, tasks)
            
            if progress_callback:
                progress_callback(1.0, f"å‘å¸ƒå®Œæˆï¼ŒæˆåŠŸ {success_count}/{len(target_platforms)} ä¸ªå¹³å°")
                
            return {
                'task_id': task_id,
                'status': status,
                'success_count': success_count,
                'total_platforms': len(target_platforms),
                'publish_results': publish_results
            }
            
        except Exception as e:
            logger.error(f"å‘å¸ƒè§†é¢‘å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
            
    async def _publish_to_single_platform(self, task_id: str, platform: str, 
                                         metadata: VideoMetadata, video_path: str) -> Dict[str, Any]:
        """å‘å¸ƒåˆ°å•ä¸ªå¹³å°"""
        try:
            # è·å–å¹³å°è´¦å·
            accounts = self.get_platform_accounts(platform)
            if not accounts:
                raise Exception(f"æœªæ‰¾åˆ° {platform} å¹³å°çš„å¯ç”¨è´¦å·")
                
            account = accounts[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨è´¦å·
            
            # åˆ›å»ºå‘å¸ƒå™¨
            publisher = self.publisher_factory.create_publisher(platform)
            if not publisher:
                raise Exception(f"ä¸æ”¯æŒçš„å¹³å°: {platform}")
                
            # è®¤è¯ï¼ˆç›®å‰ä½¿ç”¨æ¨¡æ‹Ÿè®¤è¯ï¼‰
            auth_success = await publisher.authenticate(account['credentials'])
            if not auth_success:
                raise Exception(f"å¹³å° {platform} è®¤è¯å¤±è´¥")
                
            # æ‰§è¡Œå‘å¸ƒï¼ˆç›®å‰ä½¿ç”¨æ¨¡æ‹Ÿå‘å¸ƒï¼‰
            result = await publisher.full_publish_workflow(video_path, metadata)
            
            # è®°å½•å‘å¸ƒç»“æœ
            record = {
                'id': str(uuid.uuid4()),
                'task_id': task_id,
                'account_id': account['id'],
                'platform_name': platform,
                'platform_video_id': result.video_id,
                'platform_video_url': result.video_url,
                'published_title': metadata.title,
                'published_description': metadata.description,
                'published_tags': metadata.tags,
                'status': 'published' if result.success else 'failed',
                'error_message': result.error_message,
                'publish_time': datetime.now().isoformat() if result.success else None,
                'created_at': datetime.now().isoformat()
            }
            
            records = self._load_json(self.records_file)
            records.append(record)
            self._save_json(self.records_file, records)
            
            return {
                'success': result.success,
                'platform': platform,
                'video_id': result.video_id,
                'video_url': result.video_url,
                'error_message': result.error_message
            }
            
        except Exception as e:
            logger.error(f"å‘å¸ƒåˆ° {platform} å¤±è´¥: {e}")
            return {
                'success': False,
                'platform': platform,
                'error': str(e)
            }
            
    # ==================== æŸ¥è¯¢åŠŸèƒ½ ====================
    
    def get_supported_platforms(self) -> List[str]:
        """è·å–æ”¯æŒçš„å¹³å°åˆ—è¡¨"""
        return self.publisher_factory.get_supported_platforms()
        
    def get_publish_history(self, limit: int = 50) -> List[Dict[str, Any]]:
        """ğŸ”§ ä¼˜åŒ–ï¼šè·å–å‘å¸ƒå†å²ï¼ˆä½¿ç”¨æ•°æ®åº“ï¼‰"""
        try:
            records = self.db_service.data.get('publish_records', [])
            # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—
            records.sort(key=lambda x: x.get('created_at', ''), reverse=True)
            return records[:limit]
        except Exception as e:
            logger.error(f"è·å–å‘å¸ƒå†å²å¤±è´¥: {e}")
            return []
            
    def get_statistics(self, days: int = 30) -> Dict[str, Any]:
        """ğŸ”§ ä¼˜åŒ–ï¼šè·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆä½¿ç”¨æ•°æ®åº“ï¼‰"""
        try:
            records = self.db_service.data.get('publish_records', [])
            tasks = self.db_service.data.get('video_tasks', [])

            # ç®€å•ç»Ÿè®¡
            total_tasks = len(tasks)
            total_records = len(records)

            # æŒ‰çŠ¶æ€ç»Ÿè®¡
            status_counts = {}
            for task in tasks:
                status = task.get('status', 'unknown')
                status_counts[status] = status_counts.get(status, 0) + 1

            # æŒ‰å¹³å°ç»Ÿè®¡
            platform_stats = {}
            for record in records:
                platform = record.get('platform_name', 'unknown')
                if platform not in platform_stats:
                    platform_stats[platform] = {'total': 0, 'success': 0, 'failed': 0}

                platform_stats[platform]['total'] += 1
                if record.get('status') == 'published':
                    platform_stats[platform]['success'] += 1
                else:
                    platform_stats[platform]['failed'] += 1

            return {
                'total_tasks': total_tasks,
                'total_records': total_records,
                'status_counts': status_counts,
                'platform_stats': platform_stats,
                'period_days': days
            }
            
        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
