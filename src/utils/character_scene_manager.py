import os
import json
import uuid
import asyncio
from datetime import datetime
from typing import Dict, List, Any, Optional
from .logger import logger
from .character_detection_config import CharacterDetectionConfig

class CharacterSceneManager:
    """è§’è‰²åœºæ™¯æ•°æ®åº“ç®¡ç†å™¨ - è´Ÿè´£ç®¡ç†é¡¹ç›®ä¸­çš„è§’è‰²å’Œåœºæ™¯ä¸€è‡´æ€§æ•°æ®"""
    
    def __init__(self, project_root: str, service_manager=None):
        self.project_root = project_root
        
        # ç»Ÿä¸€ä½¿ç”¨src/character_scene_dbç›®å½•ç»“æ„
        # æ£€æµ‹ç°æœ‰çš„è§’è‰²æ•°æ®åº“è·¯å¾„ï¼Œä¼˜å…ˆä½¿ç”¨æœ‰æ•°æ®çš„ç›®å½•
        possible_db_paths = [
            os.path.join(project_root, 'src', 'character_scene_db'),
            os.path.join(project_root, 'character_scene_db')  # å…¼å®¹æ—§é¡¹ç›®
        ]
        
        self.database_dir = None
        for db_path in possible_db_paths:
            characters_file = os.path.join(db_path, 'characters.json')
            if os.path.exists(characters_file):
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è¯»ï¼ˆä¸ç®¡æ˜¯å¦æœ‰æ•°æ®ï¼‰
                try:
                    with open(characters_file, 'r', encoding='utf-8') as f:
                        json.load(f)  # åªè¦èƒ½æ­£å¸¸è§£æJSONå°±ä½¿ç”¨è¿™ä¸ªè·¯å¾„
                        self.database_dir = db_path
                        break
                except:
                    continue
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ•°æ®åº“ï¼Œä½¿ç”¨ç»Ÿä¸€çš„é»˜è®¤è·¯å¾„
        if not self.database_dir:
            self.database_dir = os.path.join(project_root, 'src', 'character_scene_db')
        
        os.makedirs(self.database_dir, exist_ok=True)
        
        # æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        self.characters_file = os.path.join(self.database_dir, 'characters.json')
        self.scenes_file = os.path.join(self.database_dir, 'scenes.json')
        self.consistency_rules_file = os.path.join(self.database_dir, 'consistency_rules.json')
        
        # æœåŠ¡ç®¡ç†å™¨ï¼ˆç”¨äºè°ƒç”¨LLMæœåŠ¡ï¼‰
        self.service_manager = service_manager
        
        # åˆå§‹åŒ–æ•°æ®ç»“æ„
        self._init_database_files()
    
    def _init_database_files(self):
        """åˆå§‹åŒ–æ•°æ®åº“æ–‡ä»¶"""
        # åˆå§‹åŒ–è§’è‰²æ•°æ®åº“
        if not os.path.exists(self.characters_file):
            default_characters = {
                "characters": {},
                "last_updated": "",
                "version": "1.0"
            }
            self._save_json(self.characters_file, default_characters)
        
        # åˆå§‹åŒ–åœºæ™¯æ•°æ®åº“
        if not os.path.exists(self.scenes_file):
            default_scenes = {
                "scenes": {},
                "scene_categories": {
                    "indoor": ["å®¶åº­", "åŠå…¬å®¤", "æ•™å®¤", "é¤å…", "å§å®¤", "å®¢å…", "å¨æˆ¿", "æµ´å®¤"],
                    "outdoor": ["è¡—é“", "å…¬å›­", "å¹¿åœº", "å±±æ—", "æµ·è¾¹", "ç”°é‡", "åŸå¸‚", "ä¹¡æ‘"],
                    "special": ["æ¢¦å¢ƒ", "å›å¿†", "å¹»æƒ³", "è™šæ‹Ÿç©ºé—´"]
                },
                "last_updated": "",
                "version": "1.0"
            }
            self._save_json(self.scenes_file, default_scenes)
        
        # åˆå§‹åŒ–ä¸€è‡´æ€§è§„åˆ™
        if not os.path.exists(self.consistency_rules_file):
            default_rules = {
                "character_consistency": {
                    "appearance_keywords": ["å¤–è²Œ", "é•¿ç›¸", "èº«æ", "å‘å‹", "çœ¼ç›", "è‚¤è‰²"],
                    "clothing_keywords": ["æœè£…", "è¡£æœ", "ç©¿ç€", "æ‰“æ‰®", "è£…æ‰®"],
                    "personality_keywords": ["æ€§æ ¼", "æ°”è´¨", "è¡¨æƒ…", "ç¥æ€", "æƒ…ç»ª"]
                },
                "scene_consistency": {
                    "environment_keywords": ["ç¯å¢ƒ", "èƒŒæ™¯", "åœºæ‰€", "åœ°ç‚¹", "ä½ç½®"],
                    "lighting_keywords": ["å…‰çº¿", "ç…§æ˜", "æ˜æš—", "é˜´å½±", "å…‰å½±"],
                    "atmosphere_keywords": ["æ°›å›´", "æ°”æ°›", "æƒ…è°ƒ", "æ„Ÿè§‰", "é£æ ¼"]
                },
                "last_updated": "",
                "version": "1.0"
            }
            self._save_json(self.consistency_rules_file, default_rules)
    
    def _save_json(self, file_path: str, data: Dict):
        """ä¿å­˜JSONæ•°æ®åˆ°æ–‡ä»¶"""
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    def _load_json(self, file_path: str) -> Dict:
        """ä»æ–‡ä»¶åŠ è½½JSONæ•°æ®"""
        try:
            if os.path.exists(file_path):
                with open(file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logger.error(f"åŠ è½½JSONæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return {}
    
    def extract_characters_from_text(self, text: str, world_bible: str = "") -> List[Dict[str, Any]]:
        """ä»æ–‡æœ¬ä¸­æå–è§’è‰²ä¿¡æ¯

        Args:
            text: è¾“å…¥æ–‡æœ¬
            world_bible: ä¸–ç•Œè§‚åœ£ç»å†…å®¹ï¼Œç”¨äºæä¾›æ—¶ä»£èƒŒæ™¯ä¿¡æ¯

        Returns:
            List[Dict]: æå–çš„è§’è‰²ä¿¡æ¯åˆ—è¡¨
        """
        try:
            # ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ™ºèƒ½è§’è‰²æå–ï¼Œç»“åˆä¸–ç•Œè§‚åœ£ç»
            return self._extract_characters_with_llm(text, world_bible)
        except Exception as e:
            logger.error(f"å¤§æ¨¡å‹è§’è‰²æå–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•: {e}")
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨åŸºäºLLMçš„ç®€åŒ–ç‰ˆæœ¬
            return self._extract_characters_fallback(text)
    
    def _extract_characters_with_llm(self, text: str, world_bible: str = "") -> List[Dict[str, Any]]:
        """ä½¿ç”¨å¤§æ¨¡å‹æå–è§’è‰²ä¿¡æ¯ï¼Œç»“åˆä¸–ç•Œè§‚åœ£ç»çš„æ—¶ä»£èƒŒæ™¯"""

        # æ™ºèƒ½æ£€æµ‹æ–‡åŒ–èƒŒæ™¯
        cultural_info = self._detect_cultural_background(text, world_bible)

        # æ„å»ºåŒ…å«ä¸–ç•Œè§‚ä¿¡æ¯çš„æç¤ºè¯
        world_bible_context = ""
        if world_bible:
            world_bible_context = f"""
ğŸ“– **ä¸–ç•Œè§‚åœ£ç»å‚è€ƒ**ï¼š
{world_bible[:500]}...

è¯·æ ¹æ®ä¸–ç•Œè§‚åœ£ç»ä¸­çš„æ—¶ä»£èƒŒæ™¯ã€æ–‡åŒ–è®¾å®šæ¥åˆ†æè§’è‰²ç‰¹å¾ã€‚
"""

        # æ·»åŠ æ–‡åŒ–èƒŒæ™¯æŒ‡å¯¼
        cultural_context = f"""
ğŸŒ **æ–‡åŒ–èƒŒæ™¯æŒ‡å¯¼**ï¼š
æ ¹æ®æ–‡æœ¬åˆ†æï¼Œè§’è‰²å¯èƒ½å±äº{cultural_info['culture']}æ–‡åŒ–èƒŒæ™¯ã€‚
è¯·åœ¨æè¿°è§’è‰²æ—¶è€ƒè™‘ç›¸åº”çš„æ–‡åŒ–ç‰¹å¾ï¼Œä½†ä¸è¦ç¡¬ç¼–ç ç‰¹å®šå›½å®¶ã€‚
å¦‚æœæ–‡æœ¬ä¸­æ²¡æœ‰æ˜ç¡®çš„æ–‡åŒ–æŒ‡ç¤ºï¼Œè¯·ä½¿ç”¨é€šç”¨çš„äººç±»ç‰¹å¾æè¿°ã€‚
"""

        prompt = f"""
è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œæå–å…¶ä¸­çš„æ‰€æœ‰è§’è‰²ä¿¡æ¯ã€‚é‡ç‚¹å…³æ³¨è§’è‰²çš„å¤–è²Œç‰¹å¾å’Œæœè£…ï¼Œç”Ÿæˆä¸“é—¨ç”¨äºAIæ–‡ç”Ÿå›¾çš„ä¸€è‡´æ€§æè¿°ã€‚

{world_bible_context}

{cultural_context}

ğŸ¯ **é‡è¦è¦æ±‚**ï¼š
1. **æ—¶ä»£èƒŒæ™¯**ï¼šæ ¹æ®ä¸–ç•Œè§‚åœ£ç»ç¡®å®šè§’è‰²æ‰€å¤„çš„å†å²æ—¶æœŸï¼Œé¿å…æ—¶ä»£é”™è¯¯ï¼ˆå¦‚å¤ä»£äººç©¿ç°ä»£æœè£…ï¼‰
2. **å›½å®¶äººç§**ï¼šæ ¹æ®æ–‡æœ¬å†…å®¹å’Œä¸–ç•Œè§‚åœ£ç»æ™ºèƒ½åˆ¤æ–­è§’è‰²çš„å›½å®¶å’Œäººç§ç‰¹å¾ï¼Œä¸è¦ç¡¬ç¼–ç ç‰¹å®šå›½å®¶ï¼Œå¦‚æœæ— æ³•ç¡®å®šåˆ™ä½¿ç”¨"äººç±»"
3. **å¤–è²Œç‰¹å¾**ï¼šè¯¦ç»†æè¿°ç¬¦åˆæ—¶ä»£èƒŒæ™¯å’Œåœ°åŸŸç‰¹è‰²çš„é¢éƒ¨ç‰¹å¾ã€ä½“å‹ã€å‘å‹ç­‰
4. **æœè£…é¢œè‰²**ï¼šæ¯ä»¶æœè£…åªä½¿ç”¨ä¸€ç§å…·ä½“é¢œè‰²ï¼Œå¦‚"æ·±è“è‰²æˆ˜è¢"ã€"é»‘è‰²é•¿è£¤"ã€"çº¢è‰²è¿è¡£è£™"ï¼Œé¿å…"çº¢è‰²æˆ–è“è‰²"ç­‰æ¨¡ç³Šæè¿°
5. **ä¸€è‡´æ€§æç¤ºè¯**ï¼šç”ŸæˆåŒ…å«æ—¶ä»£èƒŒæ™¯å’Œåœ°åŸŸç‰¹è‰²çš„AIç»˜ç”»æç¤ºè¯

âš ï¸ **é¿å…å†…å®¹**ï¼š
- é¿å…æ—¶ä»£é”™è¯¯ï¼ˆå¤ä»£äººä¸èƒ½æœ‰ç°ä»£ç‰¹å¾ï¼‰
- é¿å…ç¡¬ç¼–ç ç‰¹å®šå›½å®¶ï¼ˆé™¤éæ–‡æœ¬æ˜ç¡®æŒ‡å‡ºï¼‰
- é¿å…æ¨¡ç³Šçš„æœè£…é¢œè‰²æè¿°ï¼ˆå¦‚"çº¢è‰²æˆ–è“è‰²"ã€"å¤šç§é¢œè‰²"ï¼‰
- å‡å°‘æˆ–ä¸è¦çœ¼ç¥è¡¨æƒ…æè¿°
- é¿å…æŠ½è±¡çš„æ€§æ ¼æè¿°
- ä¸è¦è¿‡å¤šçš„è¡Œä¸ºä¹ æƒ¯æè¿°

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "characters": [
    {{
      "name": "è§’è‰²åç§°",
      "description": "è§’è‰²çš„åŸºæœ¬æè¿°",
      "historical_period": "å†å²æ—¶æœŸï¼ˆå¦‚ï¼šæˆ˜å›½æ—¶æœŸã€å”æœã€ç°ä»£ç­‰ï¼‰",
      "appearance": {{
        "nationality": "å›½å®¶äººç§ï¼ˆæ ¹æ®æ–‡æœ¬å†…å®¹æ™ºèƒ½åˆ¤æ–­ï¼Œå¦‚ï¼šä¸­å›½äººã€è‹±å›½äººã€æ—¥æœ¬äººç­‰ï¼Œæ— æ³•ç¡®å®šæ—¶ä½¿ç”¨'äººç±»'ï¼‰",
        "gender": "æ€§åˆ«",
        "age_range": "å¹´é¾„èŒƒå›´",
        "height": "èº«é«˜æè¿°",
        "hair": "ç¬¦åˆæ—¶ä»£çš„å‘å‹å’Œå‘è‰²",
        "eyes": "çœ¼ç›ç‰¹å¾ï¼ˆé¢œè‰²ã€å½¢çŠ¶ï¼‰",
        "skin": "è‚¤è‰²ï¼ˆå…·ä½“æè¿°ï¼‰",
        "build": "ä½“å‹ï¼ˆå…·ä½“æè¿°ï¼‰",
        "facial_features": "é¢éƒ¨ç‰¹å¾ï¼ˆé¼»å­ã€å˜´å”‡ã€è„¸å‹ç­‰ï¼‰"
      }},
      "clothing": {{
        "period_style": "æ—¶ä»£æœè£…é£æ ¼ï¼ˆå¦‚ï¼šæˆ˜å›½å†›è£…ã€å”æœå®˜æœç­‰ï¼‰",
        "style": "å…·ä½“æœè£…æ¬¾å¼",
        "primary_color": "ä¸»è¦é¢œè‰²ï¼ˆåªé€‰æ‹©ä¸€ç§å…·ä½“é¢œè‰²ï¼Œå¦‚ï¼šæ·±è“è‰²ã€æš—çº¢è‰²ã€å¢¨ç»¿è‰²ç­‰ï¼‰",
        "material": "ç¬¦åˆæ—¶ä»£çš„æœè£…æè´¨",
        "accessories": ["æ—¶ä»£é…é¥°1", "æ—¶ä»£é…é¥°2"],
        "details": "æœè£…ç»†èŠ‚æè¿°"
      }},
      "consistency_prompt": "ä¸“é—¨ç”¨äºAIæ–‡ç”Ÿå›¾çš„è§’è‰²ä¸€è‡´æ€§æç¤ºè¯ï¼ŒåŒ…å«ï¼šå†å²æ—¶æœŸ+å›½å®¶äººç§+å¤–è²Œç‰¹å¾+å…·ä½“é¢œè‰²çš„æœè£…ï¼ˆå¦‚æ·±è“è‰²æˆ˜è¢ï¼‰ï¼Œæ§åˆ¶åœ¨60å­—ä»¥å†…"
    }}
  ]
}}

æ–‡æœ¬å†…å®¹ï¼š
{text}

è¯·è¿”å›JSONæ ¼å¼çš„è§’è‰²ä¿¡æ¯ï¼š
"""
        
        # è¿™é‡Œéœ€è¦è°ƒç”¨LLMæœåŠ¡
        # ç”±äºå½“å‰ä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›´æ¥çš„LLMæœåŠ¡å®ä¾‹ï¼Œæˆ‘ä»¬å…ˆè¿”å›ä¸€ä¸ªå ä½ç¬¦
        # å®é™…å®ç°æ—¶éœ€è¦æ³¨å…¥LLMæœåŠ¡ä¾èµ–
        logger.info("æ­£åœ¨ä½¿ç”¨å¤§æ¨¡å‹æå–è§’è‰²ä¿¡æ¯...")
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå¼‚æ­¥è°ƒç”¨ï¼Œé¿å…é˜»å¡GUIä¸»çº¿ç¨‹
        if self.service_manager:
            try:
                from src.core.service_manager import ServiceType
                llm_service = self.service_manager.get_service(ServiceType.LLM)
                if llm_service:
                    try:
                        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå¼‚æ­¥æ“ä½œï¼Œé¿å…åœ¨ä¸»çº¿ç¨‹ä¸­ä½¿ç”¨asyncio.run()
                        result = self._execute_llm_with_timeout(
                            llm_service, prompt, max_tokens=3000, temperature=0.3, timeout=60
                        )

                        if result and result.success:
                            return self._parse_llm_character_response(result.data['content'])
                        else:
                            logger.warning("LLMè°ƒç”¨æœªè¿”å›æˆåŠŸç»“æœ")
                            return []
                    except Exception as e:
                        logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
                        raise
            except Exception as e:
                logger.error(f"è°ƒç”¨LLMæœåŠ¡å¤±è´¥: {e}")

        # å¦‚æœLLMæœåŠ¡ä¸å¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
        logger.warning("LLMæœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡æ™ºèƒ½è§’è‰²æå–")
        return []

    def _execute_llm_with_timeout(self, llm_service, prompt: str, max_tokens: int = 3000,
                                 temperature: float = 0.3, timeout: int = 60):
        """åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒLLMè°ƒç”¨ï¼Œé¿å…é˜»å¡GUIä¸»çº¿ç¨‹"""
        import concurrent.futures
        import threading

        def run_async_in_thread():
            """åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥æ“ä½œ"""
            try:
                # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    # æ‰§è¡Œå¼‚æ­¥æ“ä½œ
                    result = loop.run_until_complete(
                        llm_service.execute(prompt=prompt, max_tokens=max_tokens, temperature=temperature)
                    )
                    return result
                finally:
                    # æ¸…ç†äº‹ä»¶å¾ªç¯
                    try:
                        pending = asyncio.all_tasks(loop)
                        for task in pending:
                            task.cancel()
                        if pending:
                            loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))
                    except Exception as cleanup_error:
                        logger.warning(f"æ¸…ç†äº‹ä»¶å¾ªç¯æ—¶å‡ºé”™: {cleanup_error}")
                    finally:
                        loop.close()
            except Exception as e:
                logger.error(f"çº¿ç¨‹ä¸­æ‰§è¡ŒLLMè°ƒç”¨å¤±è´¥: {e}")
                return None

        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œï¼Œè®¾ç½®è¶…æ—¶
        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(run_async_in_thread)
            try:
                result = future.result(timeout=timeout)
                return result
            except concurrent.futures.TimeoutError:
                logger.error(f"LLMè°ƒç”¨è¶…æ—¶ ({timeout}ç§’)")
                return None
            except Exception as e:
                logger.error(f"LLMè°ƒç”¨æ‰§è¡Œå¤±è´¥: {e}")
                return None

    def _extract_characters_fallback(self, text: str) -> List[Dict[str, Any]]:
        """å¤‡ç”¨è§’è‰²æå–æ–¹æ³•ï¼ˆåŸºäºLLMçš„ç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            # æ™ºèƒ½æ£€æµ‹æ–‡åŒ–èƒŒæ™¯
            cultural_info = self._detect_cultural_background(text)
            default_nationality = cultural_info.get('nationality', 'äººç±»')

            # ä½¿ç”¨ç®€åŒ–çš„LLMæç¤ºè¯è¿›è¡Œè§’è‰²æå–
            simple_prompt = f"""
è¯·ç®€å•åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œæå–ä¸»è¦è§’è‰²åç§°ã€‚åªéœ€è¦è¿”å›è§’è‰²åç§°åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªè§’è‰²åã€‚

æ–‡æœ¬å†…å®¹ï¼š
{text[:1000]}

è§’è‰²åç§°ï¼š
"""

            # å¦‚æœæœ‰LLMæœåŠ¡ï¼Œä½¿ç”¨ç®€åŒ–æç¤ºè¯
            if self.service_manager:
                try:
                    from src.core.service_manager import ServiceType
                    llm_service = self.service_manager.get_service(ServiceType.LLM)
                    if llm_service:
                        result = self._execute_llm_with_timeout(
                            llm_service, simple_prompt, max_tokens=500, temperature=0.1, timeout=30
                        )

                        if result and result.success:
                            # è§£æç®€å•çš„è§’è‰²åç§°åˆ—è¡¨
                            character_names = []
                            lines = result.data['content'].strip().split('\n')
                            for line in lines:
                                line = line.strip()
                                if line and not line.startswith('è§’è‰²') and len(line) < 20:
                                    character_names.append(line)

                            # ä¸ºæ¯ä¸ªè§’è‰²åˆ›å»ºåŸºç¡€ä¿¡æ¯
                            characters = []
                            for char_name in character_names[:5]:  # é™åˆ¶æœ€å¤š5ä¸ªè§’è‰²
                                # ğŸ”§ ä¿®å¤ï¼šç”Ÿæˆæ›´è¯¦ç»†çš„è§’è‰²ä¸€è‡´æ€§æè¿°
                                # æ ¹æ®è§’è‰²åç§°æ¨æµ‹å¹´é¾„å’Œæ€§åˆ«
                                age_gender_info = self._infer_age_gender_from_name(char_name)

                                character_info = {
                                    "name": char_name,
                                    "description": f"ä»æ–‡æœ¬ä¸­è¯†åˆ«çš„{char_name}è§’è‰²",
                                    "appearance": f"å›½å®¶äººç§ï¼š{default_nationality}ï¼Œæ€§åˆ«ï¼š{age_gender_info['gender']}ï¼Œå¹´é¾„ï¼š{age_gender_info['age']}å²ï¼Œå‘å‹ï¼š{age_gender_info['hair']}ï¼Œè‚¤è‰²ï¼šç™½çš™ï¼Œä½“å‹ï¼š{age_gender_info['build']}ï¼Œé¢éƒ¨ç‰¹å¾ï¼š{age_gender_info['face']}",
                                    "clothing": f"é£æ ¼ï¼š{age_gender_info['clothing_style']}ï¼Œé¢œè‰²ï¼š{age_gender_info['clothing_color']}ï¼Œæè´¨ï¼š{age_gender_info['material']}ï¼Œé…é¥°ï¼š{age_gender_info['accessories']}",
                                    "personality": "",
                                    "consistency_prompt": f"{default_nationality}ï¼Œ{age_gender_info['age']}å²{age_gender_info['gender_desc']}ï¼Œ{age_gender_info['build']}ï¼Œ{age_gender_info['face']}ï¼Œ{age_gender_info['hair']}ï¼Œ{age_gender_info['clothing_color']}{age_gender_info['clothing_style']}ï¼Œ{age_gender_info['accessories']}",
                                    "extracted_from_text": True,
                                    "manual_edited": False
                                }
                                characters.append(character_info)

                            return characters
                except Exception as e:
                    logger.warning(f"ç®€åŒ–LLMè§’è‰²æå–å¤±è´¥: {e}")

            # ğŸ”§ ä¿®å¤ï¼šæœ€ç»ˆå¤‡ç”¨æ–¹æ¡ˆä¹Ÿä½¿ç”¨è¯¦ç»†çš„è§’è‰²æè¿°
            age_gender_info = self._infer_age_gender_from_name("ä¸»è¦è§’è‰²")
            return [{
                "name": "ä¸»è¦è§’è‰²",
                "description": "ä»æ–‡æœ¬ä¸­è¯†åˆ«çš„ä¸»è¦è§’è‰²",
                "appearance": f"å›½å®¶äººç§ï¼š{default_nationality}ï¼Œæ€§åˆ«ï¼š{age_gender_info['gender']}ï¼Œå¹´é¾„ï¼š{age_gender_info['age']}å²ï¼Œå‘å‹ï¼š{age_gender_info['hair']}ï¼Œè‚¤è‰²ï¼šç™½çš™ï¼Œä½“å‹ï¼š{age_gender_info['build']}ï¼Œé¢éƒ¨ç‰¹å¾ï¼š{age_gender_info['face']}",
                "clothing": f"é£æ ¼ï¼š{age_gender_info['clothing_style']}ï¼Œé¢œè‰²ï¼š{age_gender_info['clothing_color']}ï¼Œæè´¨ï¼š{age_gender_info['material']}ï¼Œé…é¥°ï¼š{age_gender_info['accessories']}",
                "personality": "",
                "consistency_prompt": f"{default_nationality}ï¼Œ{age_gender_info['age']}å²{age_gender_info['gender_desc']}ï¼Œ{age_gender_info['build']}ï¼Œ{age_gender_info['face']}ï¼Œ{age_gender_info['hair']}ï¼Œ{age_gender_info['clothing_color']}{age_gender_info['clothing_style']}ï¼Œ{age_gender_info['accessories']}",
                "extracted_from_text": True,
                "manual_edited": False
            }]

        except Exception as e:
            logger.error(f"å¤‡ç”¨è§’è‰²æå–å¤±è´¥: {e}")
            return []
    
    def extract_scenes_from_text(self, text: str, world_bible: str = "") -> List[Dict[str, Any]]:
        """ä»æ–‡æœ¬ä¸­æå–åœºæ™¯ä¿¡æ¯ï¼ˆå·²ç¦ç”¨ï¼‰

        Args:
            text: è¾“å…¥æ–‡æœ¬
            world_bible: ä¸–ç•Œè§‚åœ£ç»å†…å®¹ï¼Œç”¨äºæä¾›æ—¶ä»£èƒŒæ™¯ä¿¡æ¯

        Returns:
            List[Dict]: æå–çš„åœºæ™¯ä¿¡æ¯åˆ—è¡¨
        """
        try:
            # ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ™ºèƒ½åœºæ™¯æå–ï¼Œç»“åˆä¸–ç•Œè§‚åœ£ç»
            return self._extract_scenes_with_llm(text, world_bible)
        except Exception as e:
            logger.error(f"å¤§æ¨¡å‹åœºæ™¯æå–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•: {e}")
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨åŸºäºLLMçš„ç®€åŒ–ç‰ˆæœ¬
            return self._extract_scenes_fallback(text)
    
    def _extract_scenes_with_llm(self, text: str, world_bible: str = "") -> List[Dict[str, Any]]:
        """ä½¿ç”¨å¤§æ¨¡å‹æå–åœºæ™¯ä¿¡æ¯ï¼Œç»“åˆä¸–ç•Œè§‚åœ£ç»çš„æ—¶ä»£èƒŒæ™¯"""

        # æ„å»ºåŒ…å«ä¸–ç•Œè§‚ä¿¡æ¯çš„æç¤ºè¯
        world_bible_context = ""
        if world_bible:
            world_bible_context = f"""
ğŸ“– **ä¸–ç•Œè§‚åœ£ç»å‚è€ƒ**ï¼š
{world_bible[:500]}...

è¯·æ ¹æ®ä¸–ç•Œè§‚åœ£ç»ä¸­çš„æ—¶ä»£èƒŒæ™¯ã€åœ°ç†ç¯å¢ƒã€æ–‡åŒ–è®¾å®šæ¥åˆ†æåœºæ™¯ç‰¹å¾ã€‚
"""

        prompt = f"""
è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œæå–å…¶ä¸­çš„æ‰€æœ‰åœºæ™¯ä¿¡æ¯ã€‚é‡ç‚¹å…³æ³¨åœºæ™¯çš„åŸºæœ¬ä¿¡æ¯ï¼Œä¸éœ€è¦è¯¦ç»†çš„å¢å¼ºæè¿°ã€‚

{world_bible_context}

ğŸ¯ **æå–è¦æ±‚**ï¼š
1. **åŸºæœ¬ä¿¡æ¯**ï¼šåœºæ™¯åç§°ã€ç±»å‹ã€ç®€å•æè¿°
2. **æ—¶ä»£èƒŒæ™¯**ï¼šæ ¹æ®ä¸–ç•Œè§‚åœ£ç»ç¡®å®šåœºæ™¯æ‰€å¤„çš„å†å²æ—¶æœŸ
3. **ç®€å•ç‰¹å¾**ï¼šåŸºæœ¬çš„ç¯å¢ƒã€å…‰çº¿ã€æ°›å›´ä¿¡æ¯
4. **ä¸€è‡´æ€§æç¤ºè¯**ï¼šç”Ÿæˆç®€å•çš„AIç»˜ç”»æç¤ºè¯

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "scenes": [
    {{
      "name": "åœºæ™¯åç§°",
      "category": "åœºæ™¯ç±»å‹ï¼ˆindoor/outdoor/specialï¼‰",
      "description": "åœºæ™¯çš„åŸºæœ¬æè¿°",
      "environment": "åŸºæœ¬ç¯å¢ƒæè¿°",
      "lighting": "åŸºæœ¬å…‰çº¿æè¿°",
      "atmosphere": "åŸºæœ¬æ°›å›´æè¿°",
      "consistency_prompt": "ç®€å•çš„AIç»˜ç”»ä¸€è‡´æ€§æç¤ºè¯ï¼Œæ§åˆ¶åœ¨50å­—ä»¥å†…"
    }}
  ]
}}

æ–‡æœ¬å†…å®¹ï¼š
{text}

è¯·è¿”å›JSONæ ¼å¼çš„åœºæ™¯ä¿¡æ¯ï¼š
"""

        # è°ƒç”¨LLMæœåŠ¡
        logger.info("æ­£åœ¨ä½¿ç”¨å¤§æ¨¡å‹æå–åœºæ™¯ä¿¡æ¯...")

        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå¼‚æ­¥è°ƒç”¨ï¼Œé¿å…é˜»å¡GUIä¸»çº¿ç¨‹
        if self.service_manager:
            try:
                from src.core.service_manager import ServiceType
                llm_service = self.service_manager.get_service(ServiceType.LLM)
                if llm_service:
                    try:
                        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå¼‚æ­¥æ“ä½œï¼Œé¿å…åœ¨ä¸»çº¿ç¨‹ä¸­ä½¿ç”¨asyncio.run()
                        result = self._execute_llm_with_timeout(
                            llm_service, prompt, max_tokens=2000, temperature=0.3, timeout=60
                        )

                        if result and result.success:
                            return self._parse_llm_scene_response(result.data['content'])
                        else:
                            logger.warning("LLMè°ƒç”¨æœªè¿”å›æˆåŠŸç»“æœ")
                            return []
                    except Exception as e:
                        logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
                        raise
            except Exception as e:
                logger.error(f"è°ƒç”¨LLMæœåŠ¡å¤±è´¥: {e}")

        # å¦‚æœLLMæœåŠ¡ä¸å¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
        logger.warning("LLMæœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡æ™ºèƒ½åœºæ™¯æå–")
        return []


    
    def _extract_scenes_fallback(self, text: str) -> List[Dict[str, Any]]:
        """å¤‡ç”¨åœºæ™¯æå–æ–¹æ³•ï¼ˆåŸºäºLLMçš„ç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            # ä½¿ç”¨ç®€åŒ–çš„LLMæç¤ºè¯è¿›è¡Œåœºæ™¯æå–
            simple_prompt = f"""
è¯·ç®€å•åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œæå–ä¸»è¦åœºæ™¯åœ°ç‚¹ã€‚åªéœ€è¦è¿”å›åœºæ™¯åç§°åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªåœºæ™¯ã€‚

æ–‡æœ¬å†…å®¹ï¼š
{text[:1000]}

åœºæ™¯åœ°ç‚¹ï¼š
"""

            # å¦‚æœæœ‰LLMæœåŠ¡ï¼Œä½¿ç”¨ç®€åŒ–æç¤ºè¯
            if self.service_manager:
                try:
                    from src.core.service_manager import ServiceType
                    llm_service = self.service_manager.get_service(ServiceType.LLM)
                    if llm_service:
                        result = self._execute_llm_with_timeout(
                            llm_service, simple_prompt, max_tokens=500, temperature=0.1, timeout=30
                        )

                        if result and result.success:
                            # è§£æç®€å•çš„åœºæ™¯åç§°åˆ—è¡¨
                            scene_names = []
                            lines = result.data['content'].strip().split('\n')
                            for line in lines:
                                line = line.strip()
                                if line and not line.startswith('åœºæ™¯') and len(line) < 30:
                                    scene_names.append(line)

                            # ä¸ºæ¯ä¸ªåœºæ™¯åˆ›å»ºåŸºç¡€ä¿¡æ¯
                            scenes = []
                            for scene_name in scene_names[:5]:  # é™åˆ¶æœ€å¤š5ä¸ªåœºæ™¯
                                scene_info = {
                                    "name": scene_name,
                                    "category": "indoor" if any(word in scene_name for word in ['å®¤å†…', 'æˆ¿é—´', 'å±‹', 'å…', 'é™¢']) else "outdoor",
                                    "description": f"ä»æ–‡æœ¬ä¸­è¯†åˆ«çš„{scene_name}åœºæ™¯",
                                    "environment": f"åœ°ç‚¹ï¼š{scene_name}",
                                    "lighting": "è‡ªç„¶å…‰ç…§",
                                    "atmosphere": "åŸºæœ¬æ°›å›´",
                                    "consistency_prompt": f"{scene_name}åœºæ™¯",
                                    "extracted_from_text": True,
                                    "manual_edited": False
                                }
                                scenes.append(scene_info)

                            return scenes
                except Exception as e:
                    logger.warning(f"ç®€åŒ–LLMåœºæ™¯æå–å¤±è´¥: {e}")

            # æœ€ç»ˆå¤‡ç”¨æ–¹æ¡ˆï¼šè¿”å›é€šç”¨åœºæ™¯
            return [{
                "name": "ä¸»è¦åœºæ™¯",
                "category": "indoor",
                "description": "ä»æ–‡æœ¬ä¸­è¯†åˆ«çš„ä¸»è¦åœºæ™¯",
                "environment": "å®¤å†…åœºæ™¯",
                "lighting": "è‡ªç„¶å…‰ç…§",
                "atmosphere": "åŸºæœ¬æ°›å›´",
                "consistency_prompt": "å®¤å†…åœºæ™¯",
                "extracted_from_text": True,
                "manual_edited": False
            }]

        except Exception as e:
            logger.error(f"å¤‡ç”¨åœºæ™¯æå–å¤±è´¥: {e}")
            return []
    
    def _parse_llm_character_response(self, llm_response: str) -> List[Dict[str, Any]]:
        """è§£æLLMè¿”å›çš„è§’è‰²ä¿¡æ¯"""
        try:
            # å°è¯•ä»å“åº”ä¸­æå–JSON
            import re
            json_match = re.search(r'\[.*\]', llm_response, re.DOTALL)
            if json_match:
                characters_data = json.loads(json_match.group())
                
                # éªŒè¯å’Œæ ‡å‡†åŒ–æ•°æ®æ ¼å¼
                validated_characters = []
                for char in characters_data:
                    if isinstance(char, dict) and 'name' in char:
                        # ğŸ”§ ä¿®å¤ï¼šå¤„ç†å¤–è²Œä¿¡æ¯ï¼Œç¡®ä¿å›½å®¶äººç§ä¸º"ä¸­å›½äºº"
                        appearance = char.get('appearance', {})
                        if isinstance(appearance, dict):
                            # è·å–å›½å®¶äººç§ï¼Œå¦‚æœæ˜¯"äººç±»"æˆ–"æœªçŸ¥"ï¼Œåˆ™æ”¹ä¸º"ä¸­å›½äºº"
                            nationality = appearance.get('nationality', 'ä¸­å›½äºº')
                            if nationality in ['äººç±»', 'æœªçŸ¥', 'human', '']:
                                nationality = 'ä¸­å›½äºº'

                            appearance_str = f"å›½å®¶äººç§ï¼š{nationality}ï¼Œæ€§åˆ«ï¼š{appearance.get('gender', 'æœªçŸ¥')}ï¼Œå¹´é¾„ï¼š{appearance.get('age_range', 'æœªçŸ¥')}ï¼Œå‘å‹ï¼š{appearance.get('hair', 'æœªçŸ¥')}ï¼Œè‚¤è‰²ï¼š{appearance.get('skin', 'æœªçŸ¥')}ï¼Œä½“å‹ï¼š{appearance.get('build', 'æœªçŸ¥')}"
                            if appearance.get('facial_features'):
                                appearance_str += f"ï¼Œé¢éƒ¨ç‰¹å¾ï¼š{appearance.get('facial_features')}"
                        else:
                            # å¦‚æœappearanceä¸æ˜¯å­—å…¸ï¼Œç›´æ¥å¤„ç†å­—ç¬¦ä¸²
                            appearance_str = str(appearance)
                            # æ›¿æ¢"äººç±»"ä¸º"ä¸­å›½äºº"
                            appearance_str = appearance_str.replace('å›½å®¶äººç§ï¼šäººç±»', 'å›½å®¶äººç§ï¼šä¸­å›½äºº')

                        # å¤„ç†æœè£…ä¿¡æ¯
                        clothing = char.get('clothing', {})
                        if isinstance(clothing, dict):
                            # ä¼˜å…ˆä½¿ç”¨primary_colorï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨colorsæ•°ç»„çš„ç¬¬ä¸€ä¸ª
                            primary_color = clothing.get('primary_color', '')
                            if not primary_color:
                                colors = clothing.get('colors', [])
                                if colors and isinstance(colors, list) and len(colors) > 0:
                                    primary_color = colors[0]
                                else:
                                    primary_color = 'æœªçŸ¥'

                            clothing_str = f"é£æ ¼ï¼š{clothing.get('style', 'æœªçŸ¥')}ï¼Œé¢œè‰²ï¼š{primary_color}ï¼Œæè´¨ï¼š{clothing.get('material', 'æœªçŸ¥')}ï¼Œé…é¥°ï¼š{', '.join(clothing.get('accessories', []))}"
                            if clothing.get('details'):
                                clothing_str += f"ï¼Œç»†èŠ‚ï¼š{clothing.get('details')}"
                        else:
                            clothing_str = str(clothing)

                        # ğŸ”§ ä¿®å¤ï¼šå¤„ç†ä¸€è‡´æ€§æè¿°ï¼Œç¡®ä¿åŒ…å«"ä¸­å›½äºº"å’Œè¯¦ç»†ä¿¡æ¯
                        consistency_prompt = char.get('consistency_prompt', '')
                        if consistency_prompt:
                            # æ›¿æ¢"äººç±»"ä¸º"ä¸­å›½äºº"
                            consistency_prompt = consistency_prompt.replace('äººç±»', 'ä¸­å›½äºº')
                            # å¦‚æœä¸€è‡´æ€§æè¿°è¿‡äºç®€å•ï¼Œå°è¯•å¢å¼º
                            if len(consistency_prompt) < 20:
                                # ä»å¤–è²Œå’Œæœè£…ä¿¡æ¯ä¸­æå–å…³é”®ä¿¡æ¯æ¥å¢å¼º
                                age_info = appearance.get('age_range', 'æˆå¹´') if isinstance(appearance, dict) else 'æˆå¹´'
                                gender_info = appearance.get('gender', 'ç”·æ€§') if isinstance(appearance, dict) else 'ç”·æ€§'
                                build_info = appearance.get('build', 'åŒ€ç§°') if isinstance(appearance, dict) else 'åŒ€ç§°'
                                clothing_style = clothing.get('style', 'ä¼ ç»Ÿæœè£…') if isinstance(clothing, dict) else 'ä¼ ç»Ÿæœè£…'
                                clothing_color = clothing.get('primary_color', 'æ·±è‰²') if isinstance(clothing, dict) else 'æ·±è‰²'

                                consistency_prompt = f"ä¸­å›½äººï¼Œ{age_info}{gender_info}ï¼Œ{build_info}ï¼Œ{clothing_color}{clothing_style}"
                        else:
                            # å¦‚æœæ²¡æœ‰ä¸€è‡´æ€§æè¿°ï¼Œç”Ÿæˆä¸€ä¸ªåŸºç¡€çš„
                            consistency_prompt = "ä¸­å›½äººï¼Œæˆå¹´ç”·æ€§ï¼ŒåŒ€ç§°ä½“å‹ï¼Œä¼ ç»Ÿæœè£…"

                        validated_char = {
                            'id': char.get('name', '').replace(' ', '_').lower(),
                            'name': char.get('name', ''),
                            'description': char.get('description', ''),
                            'appearance': appearance_str,
                            'clothing': clothing_str,
                            'personality': char.get('personality', ''),  # ä¿ç•™ä½†ä¸å¼ºè°ƒ
                            'consistency_prompt': consistency_prompt,
                            'created_at': self._get_current_time(),
                            'updated_at': self._get_current_time()
                        }
                        validated_characters.append(validated_char)
                
                logger.info(f"æˆåŠŸè§£æ{len(validated_characters)}ä¸ªè§’è‰²")
                return validated_characters
            else:
                logger.warning("LLMå“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ ¼å¼")
                return []
        except Exception as e:
            logger.error(f"è§£æLLMè§’è‰²å“åº”å¤±è´¥: {e}")
            return []
    
    def _parse_llm_scene_response(self, llm_response: str) -> List[Dict[str, Any]]:
        """è§£æLLMè¿”å›çš„åœºæ™¯ä¿¡æ¯"""
        try:
            # å°è¯•ä»å“åº”ä¸­æå–JSON
            import re
            json_match = re.search(r'\{.*\}', llm_response, re.DOTALL)
            if json_match:
                response_data = json.loads(json_match.group())
                scenes_data = response_data.get('scenes', [])

                # éªŒè¯å’Œæ ‡å‡†åŒ–æ•°æ®æ ¼å¼
                validated_scenes = []
                for scene in scenes_data:
                    if isinstance(scene, dict) and 'name' in scene:
                        validated_scene = {
                            'id': scene.get('name', '').replace(' ', '_').lower(),
                            'name': scene.get('name', ''),
                            'description': scene.get('description', ''),
                            'environment': scene.get('environment', ''),
                            'lighting': scene.get('lighting', ''),
                            'atmosphere': scene.get('atmosphere', ''),
                            'consistency_prompt': scene.get('consistency_prompt', ''),
                            'created_at': self._get_current_time(),
                            'updated_at': self._get_current_time()
                        }
                        validated_scenes.append(validated_scene)

                logger.info(f"æˆåŠŸè§£æ{len(validated_scenes)}ä¸ªåœºæ™¯")
                return validated_scenes
            else:
                logger.warning("LLMå“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ ¼å¼")
                return []
        except Exception as e:
            logger.error(f"è§£æLLMåœºæ™¯å“åº”å¤±è´¥: {e}")
            return []
    
    def save_character(self, character_id: str, character_data: Dict[str, Any]):
        """ä¿å­˜è§’è‰²ä¿¡æ¯
        
        Args:
            character_id: è§’è‰²ID
            character_data: è§’è‰²æ•°æ®
        """
        try:
            characters_db = self._load_json(self.characters_file)
            characters_db["characters"][character_id] = character_data
            characters_db["last_updated"] = self._get_current_time()
            self._save_json(self.characters_file, characters_db)
            logger.info(f"è§’è‰²ä¿¡æ¯å·²ä¿å­˜: {character_id}")
        except Exception as e:
            logger.error(f"ä¿å­˜è§’è‰²ä¿¡æ¯å¤±è´¥: {e}")
    
    def save_scene(self, scene_id: str, scene_data: Dict[str, Any]):
        """ä¿å­˜åœºæ™¯ä¿¡æ¯

        Args:
            scene_id: åœºæ™¯ID
            scene_data: åœºæ™¯æ•°æ®
        """
        try:
            # ğŸ”§ ä¿®å¤ï¼šåªè¿‡æ»¤æ‰çœŸæ­£æ— ç”¨çš„åœºæ™¯æ•°æ®ï¼ˆåŒ…å«å­—å…¸å­—ç¬¦ä¸²çš„IDï¼‰
            scene_name = scene_data.get('name', '')

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ— ç”¨çš„è‡ªåŠ¨ç”Ÿæˆåœºæ™¯ï¼ˆåªè¿‡æ»¤åŒ…å«å­—å…¸å­—ç¬¦ä¸²çš„IDï¼‰
            if (scene_id.startswith('é•œå¤´åœºæ™¯_') and '{' in scene_id):
                logger.warning(f"è·³è¿‡ä¿å­˜æ— ç”¨çš„è‡ªåŠ¨ç”Ÿæˆåœºæ™¯: {scene_id}")
                return

            scenes_db = self._load_json(self.scenes_file)
            scenes_db["scenes"][scene_id] = scene_data
            scenes_db["last_updated"] = self._get_current_time()
            self._save_json(self.scenes_file, scenes_db)
            logger.info(f"åœºæ™¯ä¿¡æ¯å·²ä¿å­˜: {scene_id}")
        except Exception as e:
            logger.error(f"ä¿å­˜åœºæ™¯ä¿¡æ¯å¤±è´¥: {e}")
    
    def get_character(self, character_id: str) -> Optional[Dict[str, Any]]:
        """è·å–è§’è‰²ä¿¡æ¯
        
        Args:
            character_id: è§’è‰²ID
            
        Returns:
            Optional[Dict]: è§’è‰²æ•°æ®
        """
        characters_db = self._load_json(self.characters_file)
        return characters_db.get("characters", {}).get(character_id)
    
    def get_scene(self, scene_id: str) -> Optional[Dict[str, Any]]:
        """è·å–åœºæ™¯ä¿¡æ¯
        
        Args:
            scene_id: åœºæ™¯ID
            
        Returns:
            Optional[Dict]: åœºæ™¯æ•°æ®
        """
        scenes_db = self._load_json(self.scenes_file)
        return scenes_db.get("scenes", {}).get(scene_id)
    
    def get_all_characters(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰è§’è‰²ä¿¡æ¯"""
        characters_db = self._load_json(self.characters_file)
        return characters_db.get("characters", {})
    
    def get_all_scenes(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰åœºæ™¯ä¿¡æ¯ï¼Œè¿‡æ»¤æ‰åˆ†é•œç”Ÿæˆçš„ä¸´æ—¶åœºæ™¯"""
        scenes_db = self._load_json(self.scenes_file)
        all_scenes = scenes_db.get("scenes", {})

        # è¿‡æ»¤æ‰åˆ†é•œç”Ÿæˆçš„ä¸´æ—¶åœºæ™¯
        filtered_scenes = {}
        for scene_id, scene_data in all_scenes.items():
            # æ’é™¤åŒ…å«å­—å…¸å­—ç¬¦ä¸²çš„æ— ç”¨åœºæ™¯
            if (scene_id.startswith('é•œå¤´åœºæ™¯_') and '{' in scene_id):
                continue

            filtered_scenes[scene_id] = scene_data

        return filtered_scenes

    def clean_auto_generated_scenes(self) -> int:
        """æ¸…ç†è‡ªåŠ¨ç”Ÿæˆçš„ä¸´æ—¶åœºæ™¯æ•°æ®

        Returns:
            int: æ¸…ç†çš„åœºæ™¯æ•°é‡
        """
        scenes_db = self._load_json(self.scenes_file)
        all_scenes = scenes_db.get("scenes", {})

        # æ‰¾å‡ºéœ€è¦æ¸…ç†çš„åœºæ™¯
        scenes_to_remove = []
        for scene_id, scene_data in all_scenes.items():
            scene_name = scene_data.get('name', '')

            # æ ‡è®°éœ€è¦åˆ é™¤çš„åœºæ™¯ï¼ˆåªåˆ é™¤åŒ…å«å­—å…¸å­—ç¬¦ä¸²çš„æ— ç”¨åœºæ™¯ï¼‰
            if (scene_id.startswith('é•œå¤´åœºæ™¯_') and '{' in scene_id):
                scenes_to_remove.append(scene_id)

        # åˆ é™¤æ ‡è®°çš„åœºæ™¯
        for scene_id in scenes_to_remove:
            del all_scenes[scene_id]

        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        scenes_db["scenes"] = all_scenes
        scenes_db["last_updated"] = self._get_current_time()
        self._save_json(self.scenes_file, scenes_db)

        logger.info(f"æ¸…ç†äº† {len(scenes_to_remove)} ä¸ªè‡ªåŠ¨ç”Ÿæˆçš„ä¸´æ—¶åœºæ™¯")
        return len(scenes_to_remove)
    
    def delete_character(self, character_id: str):
        """åˆ é™¤è§’è‰²ä¿¡æ¯"""
        try:
            characters_db = self._load_json(self.characters_file)
            if character_id in characters_db.get("characters", {}):
                del characters_db["characters"][character_id]
                characters_db["last_updated"] = self._get_current_time()
                self._save_json(self.characters_file, characters_db)
                logger.info(f"è§’è‰²ä¿¡æ¯å·²åˆ é™¤: {character_id}")
        except Exception as e:
            logger.error(f"åˆ é™¤è§’è‰²ä¿¡æ¯å¤±è´¥: {e}")
    
    def delete_scene(self, scene_id: str):
        """åˆ é™¤åœºæ™¯ä¿¡æ¯"""
        try:
            scenes_db = self._load_json(self.scenes_file)
            if scene_id in scenes_db.get("scenes", {}):
                del scenes_db["scenes"][scene_id]
                scenes_db["last_updated"] = self._get_current_time()
                self._save_json(self.scenes_file, scenes_db)
                logger.info(f"åœºæ™¯ä¿¡æ¯å·²åˆ é™¤: {scene_id}")
        except Exception as e:
            logger.error(f"åˆ é™¤åœºæ™¯ä¿¡æ¯å¤±è´¥: {e}")
    
    def generate_consistency_prompt(self, character_ids: Optional[List[str]] = None, scene_ids: Optional[List[str]] = None) -> str:
        """ç”Ÿæˆä¸€è‡´æ€§æç¤ºè¯
        
        Args:
            character_ids: è¦åŒ…å«çš„è§’è‰²IDåˆ—è¡¨
            scene_ids: è¦åŒ…å«çš„åœºæ™¯IDåˆ—è¡¨
            
        Returns:
            str: ç”Ÿæˆçš„ä¸€è‡´æ€§æç¤ºè¯
        """
        prompt_parts = []
        
        # æ·»åŠ è§’è‰²ä¸€è‡´æ€§æç¤º
        if character_ids:
            characters = self.get_all_characters()
            for char_id in character_ids:
                if char_id in characters:
                    char_data = characters[char_id]
                    if char_data.get("consistency_prompt"):
                        prompt_parts.append(f"è§’è‰²{char_data['name']}: {char_data['consistency_prompt']}")
        
        # æ·»åŠ åœºæ™¯ä¸€è‡´æ€§æç¤º
        if scene_ids:
            scenes = self.get_all_scenes()
            for scene_id in scene_ids:
                if scene_id in scenes:
                    scene_data = scenes[scene_id]
                    if scene_data.get("consistency_prompt"):
                        prompt_parts.append(f"åœºæ™¯{scene_data['name']}: {scene_data['consistency_prompt']}")
        
        return "; ".join(prompt_parts)

    def _detect_cultural_background(self, text: str, world_bible: str = "") -> Dict[str, Any]:
        """æ™ºèƒ½æ£€æµ‹æ–‡æœ¬çš„æ–‡åŒ–èƒŒæ™¯ä¿¡æ¯

        Args:
            text: è¾“å…¥æ–‡æœ¬
            world_bible: ä¸–ç•Œè§‚åœ£ç»å†…å®¹

        Returns:
            Dict: åŒ…å«å›½å®¶ã€åœ°åŒºã€æ—¶ä»£ç­‰ä¿¡æ¯
        """
        try:
            # æ–‡åŒ–èƒŒæ™¯å…³é”®è¯æ˜ å°„
            cultural_indicators = {
                "ä¸­å›½": {
                    "keywords": ["ä¸­å›½", "åå¤", "æ±‰æ—", "å”æœ", "å®‹æœ", "æ˜æœ", "æ¸…æœ", "æˆ˜å›½", "æ˜¥ç§‹", "ç§¦æœ", "æ±‰æœ", "å…ƒæœ", "æ°‘å›½", "é•¿å®‰", "åŒ—äº¬", "å—äº¬", "æ´›é˜³", "å¼€å°", "æ­å·", "æˆéƒ½", "è¥¿å®‰", "é‚¯éƒ¸"],
                    "names": ["æ", "ç‹", "å¼ ", "åˆ˜", "é™ˆ", "æ¨", "èµµ", "é»„", "å‘¨", "å´", "å¾", "å­™", "èƒ¡", "æœ±", "é«˜", "æ—", "ä½•", "éƒ­", "é©¬", "ç½—"],
                    "nationality": "ä¸­å›½äºº",
                    "ethnicity": "ä¸œäºšäºº"
                },
                "æ—¥æœ¬": {
                    "keywords": ["æ—¥æœ¬", "ä¸œäº¬", "äº¬éƒ½", "å¤§é˜ª", "æ±Ÿæˆ·", "å¹³å®‰", "é•°ä»“", "å®¤ç”º", "æˆ˜å›½", "æ˜æ²»", "å¤§æ­£", "æ˜­å’Œ", "å’Œæœ", "æ­¦å£«", "å¿è€…", "å¤©çš‡", "å¹•åºœ"],
                    "names": ["ç”°ä¸­", "ä½è—¤", "é“ƒæœ¨", "é«˜æ¡¥", "æ¸¡è¾¹", "ä¼Šè—¤", "å±±æœ¬", "ä¸­æ‘", "å°æ—", "åŠ è—¤", "å‰ç”°", "å±±ç”°", "ä½ä½æœ¨", "å±±å£", "æ¾æœ¬"],
                    "nationality": "æ—¥æœ¬äºº",
                    "ethnicity": "ä¸œäºšäºº"
                },
                "è‹±å›½": {
                    "keywords": ["è‹±å›½", "è‹±æ ¼å…°", "è‹æ ¼å…°", "å¨å°”å£«", "ä¼¦æ•¦", "æ›¼å½»æ–¯ç‰¹", "åˆ©ç‰©æµ¦", "çˆ±ä¸å ¡", "ç»´å¤šåˆ©äºš", "éƒ½é“", "æ–¯å›¾äºšç‰¹", "æ±‰è¯ºå¨", "æ¸©è"],
                    "names": ["Smith", "Johnson", "Williams", "Brown", "Jones", "Miller", "Davis", "Garcia", "Rodriguez", "Wilson", "Martinez", "Anderson", "Taylor", "Thomas", "Hernandez"],
                    "nationality": "è‹±å›½äºº",
                    "ethnicity": "æ¬§æ´²äºº"
                },
                "ç¾å›½": {
                    "keywords": ["ç¾å›½", "çº½çº¦", "æ´›æ‰çŸ¶", "èŠåŠ å“¥", "ä¼‘æ–¯é¡¿", "è´¹åŸ", "å‡¤å‡°åŸ", "åœ£å®‰ä¸œå°¼å¥¥", "åœ£åœ°äºšå“¥", "è¾¾æ‹‰æ–¯", "åœ£ä½•å¡", "åç››é¡¿"],
                    "names": ["Smith", "Johnson", "Williams", "Brown", "Jones", "Miller", "Davis", "Garcia", "Rodriguez", "Wilson", "Martinez", "Anderson", "Taylor", "Thomas", "Hernandez"],
                    "nationality": "ç¾å›½äºº",
                    "ethnicity": "å¤šå…ƒåŒ–"
                },
                "æ³•å›½": {
                    "keywords": ["æ³•å›½", "å·´é»", "é©¬èµ›", "é‡Œæ˜‚", "å›¾å¢å…¹", "å°¼æ–¯", "å—ç‰¹", "æ–¯ç‰¹æ‹‰æ–¯å ¡", "è’™å½¼åˆ©åŸƒ", "æ³¢å°”å¤š", "é‡Œå°”"],
                    "names": ["Martin", "Bernard", "Thomas", "Petit", "Robert", "Richard", "Durand", "Dubois", "Moreau", "Laurent", "Simon", "Michel", "Lefebvre", "Leroy", "Roux"],
                    "nationality": "æ³•å›½äºº",
                    "ethnicity": "æ¬§æ´²äºº"
                }
            }

            # åˆ†æä¸–ç•Œè§‚åœ£ç»
            combined_text = f"{world_bible} {text}"

            # è®¡ç®—æ¯ç§æ–‡åŒ–çš„åŒ¹é…åˆ†æ•°
            culture_scores = {}
            for culture, indicators in cultural_indicators.items():
                score = 0

                # å…³é”®è¯åŒ¹é…
                for keyword in indicators["keywords"]:
                    if keyword in combined_text:
                        score += 2

                # äººååŒ¹é…
                for name in indicators["names"]:
                    if name in combined_text:
                        score += 3

                culture_scores[culture] = score

            # æ‰¾åˆ°æœ€é«˜åˆ†çš„æ–‡åŒ–èƒŒæ™¯
            if culture_scores:
                best_culture = max(culture_scores.keys(), key=lambda x: culture_scores[x])
                if culture_scores[best_culture] > 0:
                    return {
                        "nationality": cultural_indicators[best_culture]["nationality"],
                        "ethnicity": cultural_indicators[best_culture]["ethnicity"],
                        "culture": best_culture,
                        "confidence": min(culture_scores[best_culture] / 10, 1.0)
                    }

            # ğŸ”§ ä¿®å¤ï¼šé»˜è®¤è¿”å›ä¸­å›½äººè€Œä¸æ˜¯"äººç±»"
            return {
                "nationality": "ä¸­å›½äºº",
                "ethnicity": "ä¸œäºšäºº",
                "culture": "ä¸­å›½",
                "confidence": 0.0
            }

        except Exception as e:
            logger.error(f"æ–‡åŒ–èƒŒæ™¯æ£€æµ‹å¤±è´¥: {e}")
            return {
                "nationality": "ä¸­å›½äºº",
                "ethnicity": "ä¸œäºšäºº",
                "culture": "ä¸­å›½",
                "confidence": 0.0
            }

    def get_world_bible_content(self) -> str:
        """è·å–ä¸–ç•Œè§‚åœ£ç»å†…å®¹

        Returns:
            str: ä¸–ç•Œè§‚åœ£ç»å†…å®¹
        """
        try:
            # æ–¹æ³•1ï¼šä»é¡¹ç›®æ–‡ä»¶ä¸­è¯»å–
            if hasattr(self, 'project_root') and self.project_root:
                import os
                import json

                # å°è¯•ä»project.jsonä¸­è¯»å–
                project_file = os.path.join(self.project_root, 'project.json')
                if os.path.exists(project_file):
                    try:
                        with open(project_file, 'r', encoding='utf-8') as f:
                            project_data = json.load(f)

                        # å°è¯•ä»äº”é˜¶æ®µåˆ†é•œæ•°æ®ä¸­è·å–
                        if 'five_stage_storyboard' in project_data:
                            world_bible = project_data['five_stage_storyboard'].get('world_bible', '')
                            if world_bible:
                                logger.debug("ä»äº”é˜¶æ®µåˆ†é•œæ•°æ®è·å–ä¸–ç•Œè§‚åœ£ç»å†…å®¹")
                                return world_bible

                        # å°è¯•ä»æ ¹çº§åˆ«è·å–
                        world_bible = project_data.get('world_bible', '')
                        if world_bible:
                            logger.debug("ä»é¡¹ç›®æ ¹çº§åˆ«è·å–ä¸–ç•Œè§‚åœ£ç»å†…å®¹")
                            return world_bible

                    except Exception as e:
                        logger.warning(f"è¯»å–é¡¹ç›®æ–‡ä»¶å¤±è´¥: {e}")

                # æ–¹æ³•2ï¼šä»ä¸“é—¨çš„ä¸–ç•Œè§‚åœ£ç»æ–‡ä»¶ä¸­è¯»å–
                world_bible_file = os.path.join(self.project_root, 'texts', 'world_bible.json')
                if os.path.exists(world_bible_file):
                    try:
                        with open(world_bible_file, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                            world_bible = data.get('content', '')
                            if world_bible:
                                logger.debug("ä»ä¸–ç•Œè§‚åœ£ç»æ–‡ä»¶è·å–å†…å®¹")
                                return world_bible
                    except Exception as e:
                        logger.warning(f"è¯»å–ä¸–ç•Œè§‚åœ£ç»æ–‡ä»¶å¤±è´¥: {e}")

            logger.debug("æœªæ‰¾åˆ°ä¸–ç•Œè§‚åœ£ç»å†…å®¹")
            return ""

        except Exception as e:
            logger.error(f"è·å–ä¸–ç•Œè§‚åœ£ç»å†…å®¹å¤±è´¥: {e}")
            return ""

    def auto_extract_and_save(self, text: str) -> Dict[str, Any]:
        """è‡ªåŠ¨æå–å¹¶ä¿å­˜è§’è‰²å’Œåœºæ™¯ä¿¡æ¯

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            Dict: æå–ç»“æœç»Ÿè®¡
        """
        try:
            # æ¸…é™¤ä¹‹å‰è‡ªåŠ¨æå–çš„è§’è‰²å’Œåœºæ™¯ï¼ˆæ›¿æ¢è€Œä¸æ˜¯è¿½åŠ ï¼‰
            self._clear_auto_extracted_data()

            # è·å–ä¸–ç•Œè§‚åœ£ç»å†…å®¹
            world_bible = self.get_world_bible_content()
            if world_bible:
                logger.info("è·å–åˆ°ä¸–ç•Œè§‚åœ£ç»å†…å®¹ï¼Œå°†ç”¨äºæŒ‡å¯¼æå–")
            else:
                logger.info("æœªæ‰¾åˆ°ä¸–ç•Œè§‚åœ£ç»å†…å®¹ï¼Œä½¿ç”¨é»˜è®¤æå–æ–¹å¼")

            # æå–è§’è‰²ï¼ˆç»“åˆä¸–ç•Œè§‚åœ£ç»ï¼‰
            extracted_characters = self.extract_characters_from_text(text, world_bible)
            character_count = 0
            for char in extracted_characters:
                char_id = f"auto_{char['name']}_{self._get_current_time().replace(':', '_')}"
                self.save_character(char_id, char)
                character_count += 1

            # æå–åœºæ™¯ï¼ˆç»“åˆä¸–ç•Œè§‚åœ£ç»ï¼‰- ä½†ä¸è¿›è¡Œå¢å¼ºæè¿°
            extracted_scenes = self.extract_scenes_from_text(text, world_bible)
            scene_count = 0
            for scene in extracted_scenes:
                # ä½¿ç”¨ç®€å•çš„åœºæ™¯åç§°
                scene_name = scene.get('name', f'åœºæ™¯{scene_count + 1}')
                # æ¸…ç†åœºæ™¯åç§°ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦
                clean_scene_name = scene_name.replace(':', '_').replace('/', '_').replace('\\', '_')
                scene_id = f"auto_{clean_scene_name}_{self._get_current_time().replace(':', '_')}"
                self.save_scene(scene_id, scene)
                scene_count += 1

            result = {
                "success": True,
                "characters_extracted": character_count,
                "scenes_extracted": scene_count,
                "message": f"æˆåŠŸæå– {character_count} ä¸ªè§’è‰²å’Œ {scene_count} ä¸ªåœºæ™¯"
            }

            logger.info(f"è‡ªåŠ¨æå–å®Œæˆ: {result['message']}")
            return result

        except Exception as e:
            logger.error(f"è‡ªåŠ¨æå–å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "è‡ªåŠ¨æå–å¤±è´¥"
            }
    
    def _clear_auto_extracted_data(self):
        """æ¸…é™¤ä¹‹å‰è‡ªåŠ¨æå–çš„è§’è‰²å’Œåœºæ™¯æ•°æ®"""
        try:
            # æ¸…é™¤è‡ªåŠ¨æå–çš„è§’è‰²ï¼ˆIDä»¥"auto_"å¼€å¤´çš„ï¼‰
            characters_db = self._load_json(self.characters_file)
            characters = characters_db.get("characters", {})
            auto_character_ids = [char_id for char_id in characters.keys() if char_id.startswith("auto_")]
            
            for char_id in auto_character_ids:
                del characters[char_id]
                logger.info(f"å·²æ¸…é™¤è‡ªåŠ¨æå–çš„è§’è‰²: {char_id}")
            
            if auto_character_ids:
                characters_db["last_updated"] = self._get_current_time()
                self._save_json(self.characters_file, characters_db)
            
            # æ¸…é™¤è‡ªåŠ¨æå–çš„åœºæ™¯ï¼ˆIDä»¥"auto_"å¼€å¤´çš„ï¼‰
            scenes_db = self._load_json(self.scenes_file)
            scenes = scenes_db.get("scenes", {})
            auto_scene_ids = [scene_id for scene_id in scenes.keys() if scene_id.startswith("auto_")]
            
            for scene_id in auto_scene_ids:
                del scenes[scene_id]
                logger.info(f"å·²æ¸…é™¤è‡ªåŠ¨æå–çš„åœºæ™¯: {scene_id}")
            
            if auto_scene_ids:
                scenes_db["last_updated"] = self._get_current_time()
                self._save_json(self.scenes_file, scenes_db)
            
            # ğŸ”§ ä¿®å¤ï¼šåŒæ—¶æ¸…é™¤é¡¹ç›®æ•°æ®ä¸­çš„selected_characterså’Œselected_scenesåˆ—è¡¨ä¸­çš„ç›¸å…³ID
            self._clear_project_selections(auto_character_ids, auto_scene_ids)

            if auto_character_ids or auto_scene_ids:
                logger.info(f"å·²æ¸…é™¤ {len(auto_character_ids)} ä¸ªè‡ªåŠ¨æå–çš„è§’è‰²å’Œ {len(auto_scene_ids)} ä¸ªè‡ªåŠ¨æå–çš„åœºæ™¯")

        except Exception as e:
            logger.error(f"æ¸…é™¤è‡ªåŠ¨æå–æ•°æ®å¤±è´¥: {e}")

    def _clear_project_selections(self, auto_character_ids: List[str], auto_scene_ids: List[str]):
        """æ¸…é™¤é¡¹ç›®æ•°æ®ä¸­çš„selected_characterså’Œselected_scenesåˆ—è¡¨ä¸­çš„è‡ªåŠ¨æå–ID"""
        try:
            if not auto_character_ids and not auto_scene_ids:
                return

            # è¯»å–é¡¹ç›®æ–‡ä»¶
            project_file = os.path.join(self.project_root, 'project.json')
            if not os.path.exists(project_file):
                logger.warning("é¡¹ç›®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¸…é™¤é¡¹ç›®é€‰æ‹©")
                return

            with open(project_file, 'r', encoding='utf-8') as f:
                project_data = json.load(f)

            # æ£€æŸ¥æ˜¯å¦æœ‰äº”é˜¶æ®µåˆ†é•œæ•°æ®
            if 'five_stage_storyboard' not in project_data:
                logger.debug("é¡¹ç›®ä¸­æ²¡æœ‰äº”é˜¶æ®µåˆ†é•œæ•°æ®ï¼Œè·³è¿‡æ¸…é™¤é¡¹ç›®é€‰æ‹©")
                return

            five_stage_data = project_data['five_stage_storyboard']
            updated = False

            # ğŸ”§ ä¿®å¤ï¼šæ¸…é™¤selected_charactersä¸­çš„æ‰€æœ‰è‡ªåŠ¨æå–è§’è‰²IDï¼ˆä¸ä»…ä»…æ˜¯å½“å‰æ‰¹æ¬¡ï¼‰
            if 'selected_characters' in five_stage_data:
                original_count = len(five_stage_data['selected_characters'])
                five_stage_data['selected_characters'] = [
                    char_id for char_id in five_stage_data['selected_characters']
                    if not char_id.startswith('auto_')
                ]
                removed_chars = original_count - len(five_stage_data['selected_characters'])
                if removed_chars > 0:
                    logger.info(f"å·²ä»é¡¹ç›®é€‰æ‹©ä¸­æ¸…é™¤ {removed_chars} ä¸ªè‡ªåŠ¨æå–çš„è§’è‰²ID")
                    updated = True

            # ğŸ”§ ä¿®å¤ï¼šæ¸…é™¤selected_scenesä¸­çš„æ‰€æœ‰è‡ªåŠ¨æå–åœºæ™¯IDï¼ˆä¸ä»…ä»…æ˜¯å½“å‰æ‰¹æ¬¡ï¼‰
            if 'selected_scenes' in five_stage_data:
                original_count = len(five_stage_data['selected_scenes'])
                five_stage_data['selected_scenes'] = [
                    scene_id for scene_id in five_stage_data['selected_scenes']
                    if not scene_id.startswith('auto_')
                ]
                removed_scenes = original_count - len(five_stage_data['selected_scenes'])
                if removed_scenes > 0:
                    logger.info(f"å·²ä»é¡¹ç›®é€‰æ‹©ä¸­æ¸…é™¤ {removed_scenes} ä¸ªè‡ªåŠ¨æå–çš„åœºæ™¯ID")
                    updated = True

            # å¦‚æœæœ‰æ›´æ–°ï¼Œä¿å­˜é¡¹ç›®æ–‡ä»¶
            if updated:
                with open(project_file, 'w', encoding='utf-8') as f:
                    json.dump(project_data, f, ensure_ascii=False, indent=2)
                logger.info("é¡¹ç›®é€‰æ‹©æ•°æ®å·²æ›´æ–°")

        except Exception as e:
            logger.error(f"æ¸…é™¤é¡¹ç›®é€‰æ‹©æ•°æ®å¤±è´¥: {e}")

    def _infer_age_gender_from_name(self, char_name: str) -> Dict[str, str]:
        """ğŸ”§ æ–°å¢ï¼šæ ¹æ®è§’è‰²åç§°æ¨æµ‹å¹´é¾„ã€æ€§åˆ«ç­‰ä¿¡æ¯"""
        try:
            # æ€§åˆ«æ¨æµ‹å…³é”®è¯
            male_keywords = ['å…¬å­', 'å°‘çˆ·', 'å…ˆç”Ÿ', 'å›', 'ç‹', 'å°†å†›', 'å¤§äºº', 'å…„', 'çˆ¶', 'çˆ·', 'å”', 'ä¼¯']
            female_keywords = ['å°å§', 'å¤«äºº', 'å¨˜', 'æ¯', 'å§', 'å¦¹', 'å¥³']

            # å¹´é¾„æ¨æµ‹å…³é”®è¯
            young_keywords = ['å°‘', 'å°', 'ç«¥', 'å„¿', 'å­']
            middle_keywords = ['ä¸­', 'æˆ', 'æ¯', 'çˆ¶']  # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ "æ¯"å’Œ"çˆ¶"åˆ°ä¸­å¹´å…³é”®è¯
            old_keywords = ['è€', 'é•¿', 'ç¿', 'å©†', 'çˆ·', 'å¥¶']

            # é»˜è®¤å€¼
            gender = "ç”·"
            gender_desc = "ç”·æ€§"
            age = 25

            # æ€§åˆ«æ¨æµ‹
            for keyword in female_keywords:
                if keyword in char_name:
                    gender = "å¥³"
                    gender_desc = "å¥³æ€§"
                    break

            # å¹´é¾„æ¨æµ‹
            for keyword in young_keywords:
                if keyword in char_name:
                    age = 18
                    break
            for keyword in old_keywords:
                if keyword in char_name:
                    age = 55
                    break
            for keyword in middle_keywords:
                if keyword in char_name:
                    age = 35
                    break

            # æ ¹æ®æ€§åˆ«å’Œå¹´é¾„ç”Ÿæˆè¯¦ç»†ä¿¡æ¯
            if gender == "å¥³":
                if age <= 20:
                    build = "å¨‡å°ç²ç‘"
                    face = "åœ†è„¸æ¸…ç§€"
                    hair = "é»‘è‰²é•¿å‘æŸæˆé©¬å°¾"
                    clothing_style = "é•¿è£™"
                    clothing_color = "ç²‰è‰²"
                    material = "ä¸ç»¸"
                    accessories = "å‘ç°ªè£…é¥°"
                elif age <= 40:
                    build = "åŒ€ç§°ä¼˜é›…"
                    face = "ç“œå­è„¸ç«¯åº„"
                    hair = "é»‘è‰²é•¿å‘ç›˜æˆå‘é«»"
                    clothing_style = "é•¿è¢"
                    clothing_color = "æµ…è“è‰²"
                    material = "é”¦ç¼"
                    accessories = "ç‰é•¯è£…é¥°"
                else:
                    build = "ä¸°æ»¡æ…ˆç¥¥"
                    face = "åœ†è„¸æ…ˆçœ‰å–„ç›®"
                    hair = "èŠ±ç™½å¤´å‘ç›˜æˆå‘é«»"
                    clothing_style = "å®½è¢–è¢"
                    clothing_color = "æ·±ç´«è‰²"
                    material = "æ£‰éº»"
                    accessories = "é“¶ç°ªè£…é¥°"
            else:
                if age <= 20:
                    build = "ç˜¦å‰ŠæŒºæ‹”"
                    face = "æ¸…ç§€ä¿Šæœ—"
                    hair = "é»‘è‰²çŸ­å‘æ•´é½"
                    clothing_style = "é•¿è¢"
                    clothing_color = "é’è‰²"
                    material = "éº»å¸ƒ"
                    accessories = "è…°å¸¦è£…é¥°"
                elif age <= 40:
                    build = "å¥å£®æœ‰åŠ›"
                    face = "æ–¹è„¸è‹±æ­¦"
                    hair = "é»‘è‰²çŸ­å‘åˆ©è½"
                    clothing_style = "æˆ˜è¢"
                    clothing_color = "æ·±è“è‰²"
                    material = "çš®é©"
                    accessories = "ä½©å‰‘è£…é¥°"
                else:
                    build = "é­æ¢§å¨ä¸¥"
                    face = "å›½å­—è„¸å¨ä¸¥"
                    hair = "èŠ±ç™½çŸ­å‘æ•´é½"
                    clothing_style = "å®½è¢–è¢"
                    clothing_color = "æ·±ç°è‰²"
                    material = "ä¸ç»¸"
                    accessories = "ç‰ä½©è£…é¥°"

            return {
                'gender': gender,
                'gender_desc': gender_desc,
                'age': str(age),
                'build': build,
                'face': face,
                'hair': hair,
                'clothing_style': clothing_style,
                'clothing_color': clothing_color,
                'material': material,
                'accessories': accessories
            }

        except Exception as e:
            logger.error(f"æ¨æµ‹è§’è‰²ä¿¡æ¯å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤å€¼
            return {
                'gender': "ç”·",
                'gender_desc': "ç”·æ€§",
                'age': "25",
                'build': "åŒ€ç§°",
                'face': "æ™®é€šé¢å®¹",
                'hair': "é»‘è‰²çŸ­å‘",
                'clothing_style': "é•¿è¢",
                'clothing_color': "æ·±è“è‰²",
                'material': "æ£‰å¸ƒ",
                'accessories': "è…°å¸¦è£…é¥°"
            }

    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    def export_database(self, export_path: str) -> bool:
        """å¯¼å‡ºæ•°æ®åº“åˆ°æŒ‡å®šè·¯å¾„

        Args:
            export_path: å¯¼å‡ºè·¯å¾„

        Returns:
            bool: å¯¼å‡ºæ˜¯å¦æˆåŠŸ
        """
        try:
            import shutil
            if self.database_dir and os.path.exists(self.database_dir):
                shutil.copytree(self.database_dir, export_path, dirs_exist_ok=True)
                logger.info(f"æ•°æ®åº“å·²å¯¼å‡ºåˆ°: {export_path}")
                return True
            else:
                logger.error("æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨")
                return False
        except Exception as e:
            logger.error(f"å¯¼å‡ºæ•°æ®åº“å¤±è´¥: {e}")
            return False
    
    def auto_match_characters_to_shots(self, storyboard_data: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """è‡ªåŠ¨å°†è§’è‰²åŒ¹é…åˆ°ç›¸å…³çš„åˆ†é•œä¸­"""
        logger.info("å¼€å§‹è‡ªåŠ¨åŒ¹é…è§’è‰²åˆ°åˆ†é•œ...")
        
        characters = self.get_all_characters()
        character_shot_mapping = {}
        
        for character_id, character in characters.items():
            character_name = character.get('name', '')
            character_shot_mapping[character_id] = []
            
            # éå†æ‰€æœ‰åˆ†é•œï¼ŒæŸ¥æ‰¾åŒ…å«è¯¥è§’è‰²çš„åˆ†é•œ
            for i, shot in enumerate(storyboard_data):
                shot_text = ''
                
                # æ”¶é›†åˆ†é•œä¸­çš„æ‰€æœ‰æ–‡æœ¬ä¿¡æ¯
                if 'description' in shot:
                    shot_text += shot['description'] + ' '
                if 'dialogue' in shot:
                    shot_text += shot['dialogue'] + ' '
                if 'action' in shot:
                    shot_text += shot['action'] + ' '
                if 'scene_description' in shot:
                    shot_text += shot['scene_description'] + ' '
                
                shot_text = shot_text.lower()
                
                # æ£€æŸ¥è§’è‰²åç§°æ˜¯å¦å‡ºç°åœ¨åˆ†é•œæ–‡æœ¬ä¸­
                if character_name.lower() in shot_text:
                    character_shot_mapping[character_id].append(f"shot_{i+1}")
                    logger.debug(f"è§’è‰² {character_name} åŒ¹é…åˆ°åˆ†é•œ {i+1}")
        
        logger.info(f"å®Œæˆè§’è‰²åˆ°åˆ†é•œçš„è‡ªåŠ¨åŒ¹é…ï¼Œå…±åŒ¹é…{len([shots for shots in character_shot_mapping.values() if shots])}ä¸ªè§’è‰²")
        return character_shot_mapping
    
    def get_consistency_rules(self) -> Dict[str, Any]:
        """è·å–ä¸€è‡´æ€§è§„åˆ™"""
        return self._load_json(self.consistency_rules_file)
    
    def save_consistency_rules(self, rules: Dict[str, Any]):
        """ä¿å­˜ä¸€è‡´æ€§è§„åˆ™"""
        self._save_json(self.consistency_rules_file, rules)
    
    def update_character_shot_mapping(self, character_id: str, shot_ids: List[str]):
        """æ›´æ–°æŒ‡å®šè§’è‰²çš„åˆ†é•œæ˜ å°„"""
        consistency_rules = self.get_consistency_rules()
        if 'character_shot_mapping' not in consistency_rules:
            consistency_rules['character_shot_mapping'] = {}
        
        consistency_rules['character_shot_mapping'][character_id] = shot_ids
        consistency_rules['updated_at'] = self._get_current_time()
        self.save_consistency_rules(consistency_rules)
        
        logger.info(f"å·²æ›´æ–°è§’è‰² {character_id} çš„åˆ†é•œæ˜ å°„: {shot_ids}")
    
    def get_character_shot_mapping(self, character_id: Optional[str] = None) -> Dict[str, List[str]]:
        """è·å–è§’è‰²åˆ†é•œæ˜ å°„"""
        consistency_rules = self.get_consistency_rules()
        character_shot_mapping = consistency_rules.get('character_shot_mapping', {})
        
        if character_id:
            return {character_id: character_shot_mapping.get(character_id, [])}
        return character_shot_mapping
    
    def import_database(self, import_path: str) -> bool:
        """ä»æŒ‡å®šè·¯å¾„å¯¼å…¥æ•°æ®åº“

        Args:
            import_path: å¯¼å…¥è·¯å¾„

        Returns:
            bool: å¯¼å…¥æ˜¯å¦æˆåŠŸ
        """
        try:
            import shutil
            if os.path.exists(import_path) and self.database_dir:
                shutil.copytree(import_path, self.database_dir, dirs_exist_ok=True)
                logger.info(f"æ•°æ®åº“å·²ä» {import_path} å¯¼å…¥")
                return True
            else:
                if not os.path.exists(import_path):
                    logger.error(f"å¯¼å…¥è·¯å¾„ä¸å­˜åœ¨: {import_path}")
                else:
                    logger.error("æ•°æ®åº“ç›®å½•æœªåˆå§‹åŒ–")
                return False
        except Exception as e:
            logger.error(f"å¯¼å…¥æ•°æ®åº“å¤±è´¥: {e}")
            return False