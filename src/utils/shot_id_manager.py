"""
ç»Ÿä¸€é•œå¤´IDç®¡ç†å™¨
è§£å†³é…éŸ³æ®µè½IDå’Œå›¾åƒé•œå¤´IDä¸åŒ¹é…çš„é—®é¢˜
"""

import re
import logging
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class ShotMapping:
    """é•œå¤´æ˜ å°„æ•°æ®ç»“æ„"""
    global_index: int  # å…¨å±€é•œå¤´ç´¢å¼• (1, 2, 3, ...)
    scene_id: str      # åœºæ™¯ID (scene_1, scene_2, ...)
    shot_id: str       # é•œå¤´ID (shot_1, shot_2, ...)
    text_segment_id: str  # æ–‡æœ¬æ®µè½ID (text_segment_001, text_segment_002, ...)
    unified_key: str   # ç»Ÿä¸€é”® (scene_1_shot_1)
    original_text: str # å¯¹åº”çš„åŸæ–‡å†…å®¹
    scene_index: int   # åœºæ™¯å†…é•œå¤´ç´¢å¼• (1, 2, 3, ...)


class ShotIDManager:
    """ç»Ÿä¸€é•œå¤´IDç®¡ç†å™¨"""
    
    def __init__(self):
        self.shot_mappings: List[ShotMapping] = []
        self.id_conversion_cache: Dict[str, str] = {}
        self.reverse_conversion_cache: Dict[str, str] = {}
    
    def initialize_from_project_data(self, project_data: Dict[str, Any]) -> bool:
        """ä»é¡¹ç›®æ•°æ®åˆå§‹åŒ–é•œå¤´æ˜ å°„"""
        try:
            self.shot_mappings.clear()
            self.id_conversion_cache.clear()
            self.reverse_conversion_cache.clear()
            
            # è·å–é…éŸ³æ®µè½æ•°æ®
            voice_segments = project_data.get('voice_generation', {}).get('voice_segments', [])
            
            # è·å–å›¾åƒæ˜ å°„æ•°æ®
            shot_image_mappings = project_data.get('shot_image_mappings', {})
            
            # è·å–åˆ†é•œæ•°æ®
            storyboard_data = project_data.get('five_stage_storyboard', {})
            
            logger.info(f"åˆå§‹åŒ–é•œå¤´æ˜ å°„: {len(voice_segments)}ä¸ªé…éŸ³æ®µè½, {len(shot_image_mappings)}ä¸ªå›¾åƒæ˜ å°„")
            
            # åˆ›å»ºç»Ÿä¸€çš„é•œå¤´æ˜ å°„
            self._create_unified_mappings(voice_segments, shot_image_mappings, storyboard_data)
            
            logger.info(f"é•œå¤´æ˜ å°„åˆå§‹åŒ–å®Œæˆï¼Œå…± {len(self.shot_mappings)} ä¸ªæ˜ å°„")
            return True
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–é•œå¤´æ˜ å°„å¤±è´¥: {e}")
            return False
    
    def _create_unified_mappings(self, voice_segments: List[Dict],
                               shot_image_mappings: Dict[str, Any],
                               storyboard_data: Dict[str, Any]) -> None:
        """åˆ›å»ºç»Ÿä¸€çš„é•œå¤´æ˜ å°„"""

        # ğŸ”§ ä¿®å¤ï¼šåªåŸºäºé…éŸ³æ®µè½åˆ›å»ºæ˜ å°„ï¼Œä¸è¡¥å……é¢å¤–çš„æ˜ å°„
        # ç»Ÿè®¡æ¯ä¸ªåœºæ™¯çš„é•œå¤´æ•°é‡
        scene_shot_counts = {}
        for segment in voice_segments:
            scene_id = segment.get('scene_id', 'scene_1')
            scene_id = self._normalize_scene_id(scene_id)
            if scene_id not in scene_shot_counts:
                scene_shot_counts[scene_id] = 0
            scene_shot_counts[scene_id] += 1

        # ä¸ºæ¯ä¸ªé…éŸ³æ®µè½åˆ›å»ºæ˜ å°„
        scene_shot_indices = {}  # è®°å½•æ¯ä¸ªåœºæ™¯å½“å‰çš„é•œå¤´ç´¢å¼•

        for i, segment in enumerate(voice_segments):
            global_index = i + 1
            scene_id = segment.get('scene_id', f'scene_{(i // 3) + 1}')
            scene_id = self._normalize_scene_id(scene_id)

            # è®¡ç®—åœºæ™¯å†…çš„é•œå¤´ç¼–å·
            if scene_id not in scene_shot_indices:
                scene_shot_indices[scene_id] = 0
            scene_shot_indices[scene_id] += 1
            shot_index_in_scene = scene_shot_indices[scene_id]

            shot_mapping = ShotMapping(
                global_index=global_index,
                scene_id=scene_id,
                shot_id=f"shot_{shot_index_in_scene}",
                text_segment_id=f"text_segment_{global_index:03d}",
                unified_key=f"{scene_id}_shot_{shot_index_in_scene}",
                original_text=segment.get('original_text', ''),
                scene_index=shot_index_in_scene
            )

            self.shot_mappings.append(shot_mapping)

            # å»ºç«‹è½¬æ¢ç¼“å­˜
            self._update_conversion_cache(shot_mapping)

        # æ’åºç¡®ä¿ä¸€è‡´æ€§
        self.shot_mappings.sort(key=lambda x: x.global_index)
    
    def _normalize_scene_id(self, scene_id: str) -> str:
        """æ ‡å‡†åŒ–åœºæ™¯IDæ ¼å¼"""
        if not scene_id:
            return "scene_1"
        
        # å¦‚æœå·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if re.match(r'^scene_\d+$', scene_id):
            return scene_id
        
        # æå–æ•°å­—
        numbers = re.findall(r'\d+', scene_id)
        if numbers:
            return f"scene_{numbers[0]}"
        
        return "scene_1"
    
    def _extract_scene_number(self, scene_id: str) -> int:
        """ä»åœºæ™¯IDä¸­æå–æ•°å­—"""
        numbers = re.findall(r'\d+', scene_id)
        return int(numbers[0]) if numbers else 1
    

    
    def _update_conversion_cache(self, shot_mapping: ShotMapping) -> None:
        """æ›´æ–°IDè½¬æ¢ç¼“å­˜"""
        # text_segment_XXX -> scene_X_shot_Y
        self.id_conversion_cache[shot_mapping.text_segment_id] = shot_mapping.unified_key
        
        # scene_X_shot_Y -> text_segment_XXX
        self.reverse_conversion_cache[shot_mapping.unified_key] = shot_mapping.text_segment_id
        
        # å…¶ä»–å¯èƒ½çš„æ ¼å¼
        self.id_conversion_cache[f"é•œå¤´{shot_mapping.global_index}"] = shot_mapping.unified_key
        self.id_conversion_cache[str(shot_mapping.global_index)] = shot_mapping.unified_key
    
    def convert_id(self, source_id: str, target_format: str = "unified") -> Optional[str]:
        """
        è½¬æ¢IDæ ¼å¼
        
        Args:
            source_id: æºID
            target_format: ç›®æ ‡æ ¼å¼ ("unified", "text_segment", "shot_only")
        
        Returns:
            è½¬æ¢åçš„IDï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # ç›´æ¥æŸ¥æ‰¾ç¼“å­˜
            if target_format == "unified" and source_id in self.id_conversion_cache:
                return self.id_conversion_cache[source_id]
            
            if target_format == "text_segment" and source_id in self.reverse_conversion_cache:
                return self.reverse_conversion_cache[source_id]
            
            # æŸ¥æ‰¾æ˜ å°„
            for mapping in self.shot_mappings:
                if (source_id == mapping.text_segment_id or 
                    source_id == mapping.unified_key or
                    source_id == f"é•œå¤´{mapping.global_index}" or
                    source_id == str(mapping.global_index)):
                    
                    if target_format == "unified":
                        return mapping.unified_key
                    elif target_format == "text_segment":
                        return mapping.text_segment_id
                    elif target_format == "shot_only":
                        return mapping.shot_id
            
            logger.warning(f"æ— æ³•è½¬æ¢ID: {source_id} -> {target_format}")
            return None
            
        except Exception as e:
            logger.error(f"IDè½¬æ¢å¤±è´¥: {source_id} -> {target_format}, é”™è¯¯: {e}")
            return None
    
    def get_mapping_by_id(self, shot_id: str) -> Optional[ShotMapping]:
        """æ ¹æ®ä»»æ„æ ¼å¼çš„IDè·å–æ˜ å°„"""
        for mapping in self.shot_mappings:
            if (shot_id == mapping.text_segment_id or 
                shot_id == mapping.unified_key or
                shot_id == mapping.shot_id or
                shot_id == f"é•œå¤´{mapping.global_index}" or
                shot_id == str(mapping.global_index)):
                return mapping
        return None
    
    def get_all_mappings(self) -> List[ShotMapping]:
        """è·å–æ‰€æœ‰é•œå¤´æ˜ å°„"""
        return self.shot_mappings.copy()
    
    def get_mappings_by_scene(self, scene_id: str) -> List[ShotMapping]:
        """è·å–æŒ‡å®šåœºæ™¯çš„æ‰€æœ‰é•œå¤´æ˜ å°„"""
        normalized_scene_id = self._normalize_scene_id(scene_id)
        return [mapping for mapping in self.shot_mappings if mapping.scene_id == normalized_scene_id]
    
    def validate_consistency(self) -> Tuple[bool, List[str]]:
        """éªŒè¯æ˜ å°„ä¸€è‡´æ€§"""
        issues = []
        
        # æ£€æŸ¥å…¨å±€ç´¢å¼•è¿ç»­æ€§
        global_indices = [mapping.global_index for mapping in self.shot_mappings]
        global_indices.sort()
        
        for i, index in enumerate(global_indices):
            if i > 0 and index != global_indices[i-1] + 1:
                issues.append(f"å…¨å±€ç´¢å¼•ä¸è¿ç»­: {global_indices[i-1]} -> {index}")
        
        # æ£€æŸ¥é‡å¤çš„unified_key
        unified_keys = [mapping.unified_key for mapping in self.shot_mappings]
        if len(unified_keys) != len(set(unified_keys)):
            issues.append("å­˜åœ¨é‡å¤çš„unified_key")
        
        # æ£€æŸ¥é‡å¤çš„text_segment_id
        text_segment_ids = [mapping.text_segment_id for mapping in self.shot_mappings]
        if len(text_segment_ids) != len(set(text_segment_ids)):
            issues.append("å­˜åœ¨é‡å¤çš„text_segment_id")
        
        return len(issues) == 0, issues

    def sync_with_project_data(self, project_data: Dict[str, Any]) -> bool:
        """å°†æ˜ å°„åŒæ­¥åˆ°é¡¹ç›®æ•°æ®"""
        try:
            # ç¡®ä¿voice_generationç»“æ„å­˜åœ¨
            if 'voice_generation' not in project_data:
                project_data['voice_generation'] = {'voice_segments': []}

            # ç¡®ä¿shot_image_mappingsç»“æ„å­˜åœ¨
            if 'shot_image_mappings' not in project_data:
                project_data['shot_image_mappings'] = {}

            # åŒæ­¥é…éŸ³æ®µè½çš„IDæ ¼å¼
            voice_segments = project_data['voice_generation']['voice_segments']
            for i, segment in enumerate(voice_segments):
                if i < len(self.shot_mappings):
                    mapping = self.shot_mappings[i]
                    # æ›´æ–°IDå­—æ®µä½†ä¿ç•™å…¶ä»–æ•°æ®
                    segment['shot_id'] = mapping.text_segment_id
                    segment['scene_id'] = mapping.scene_id

            # åŒæ­¥å›¾åƒæ˜ å°„çš„é”®æ ¼å¼
            shot_image_mappings = project_data['shot_image_mappings']
            updated_mappings = {}

            for mapping in self.shot_mappings:
                # æŸ¥æ‰¾å¯¹åº”çš„å›¾åƒæ˜ å°„æ•°æ®
                old_data = None
                for key, data in shot_image_mappings.items():
                    if (key == mapping.unified_key or
                        key == mapping.text_segment_id or
                        self._keys_match(key, mapping)):
                        old_data = data
                        break

                if old_data:
                    # ä½¿ç”¨ç»Ÿä¸€é”®æ ¼å¼ä¿å­˜
                    updated_mappings[mapping.unified_key] = old_data
                    # ç¡®ä¿æ•°æ®ä¸­çš„IDå­—æ®µæ­£ç¡®
                    updated_mappings[mapping.unified_key]['scene_id'] = mapping.scene_id
                    updated_mappings[mapping.unified_key]['shot_id'] = mapping.shot_id

            project_data['shot_image_mappings'] = updated_mappings

            logger.info(f"é¡¹ç›®æ•°æ®åŒæ­¥å®Œæˆï¼Œ{len(voice_segments)}ä¸ªé…éŸ³æ®µè½ï¼Œ{len(updated_mappings)}ä¸ªå›¾åƒæ˜ å°„")
            return True

        except Exception as e:
            logger.error(f"é¡¹ç›®æ•°æ®åŒæ­¥å¤±è´¥: {e}")
            return False

    def _keys_match(self, key: str, mapping: ShotMapping) -> bool:
        """æ£€æŸ¥é”®æ˜¯å¦åŒ¹é…æ˜ å°„"""
        # å°è¯•å„ç§å¯èƒ½çš„åŒ¹é…æ–¹å¼
        possible_matches = [
            mapping.unified_key,
            mapping.text_segment_id,
            f"scene_1_{mapping.shot_id}",
            f"scene_1_shot_{mapping.global_index}",
            str(mapping.global_index)
        ]

        return key in possible_matches

    def create_missing_mappings(self, target_count: int) -> List[ShotMapping]:
        """åˆ›å»ºç¼ºå¤±çš„é•œå¤´æ˜ å°„"""
        current_count = len(self.shot_mappings)
        new_mappings = []

        for i in range(current_count, target_count):
            global_index = i + 1
            scene_number = (i // 5) + 1  # æ¯5ä¸ªé•œå¤´ä¸€ä¸ªåœºæ™¯
            shot_index_in_scene = (i % 5) + 1

            shot_mapping = ShotMapping(
                global_index=global_index,
                scene_id=f"scene_{scene_number}",
                shot_id=f"shot_{shot_index_in_scene}",
                text_segment_id=f"text_segment_{global_index:03d}",
                unified_key=f"scene_{scene_number}_shot_{shot_index_in_scene}",
                original_text="",
                scene_index=shot_index_in_scene
            )

            new_mappings.append(shot_mapping)
            self.shot_mappings.append(shot_mapping)
            self._update_conversion_cache(shot_mapping)

        return new_mappings

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æ˜ å°„ç»Ÿè®¡ä¿¡æ¯"""
        scene_counts = {}
        for mapping in self.shot_mappings:
            scene_counts[mapping.scene_id] = scene_counts.get(mapping.scene_id, 0) + 1

        return {
            'total_shots': len(self.shot_mappings),
            'total_scenes': len(scene_counts),
            'shots_per_scene': scene_counts,
            'max_global_index': max([m.global_index for m in self.shot_mappings]) if self.shot_mappings else 0
        }
